{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ebc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pathlib, random, time\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "\n",
    "from environment import Env, validate_against_hint, load_word_lists, construct_word_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae1b8e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = construct_word_df(*load_word_lists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895b599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def construct_state_tensor(guesses, history):\n",
    "        #print(history)\n",
    "        #so the state is going to be:\n",
    "            #  The number of green locations we know\n",
    "            #  The number of other letters we know to be in the word\n",
    "            #  The sequence number of the guess (1st guess, 2nd guess etc.)\n",
    "\n",
    "        #the number of locations which were green at some point in the history\n",
    "        num_green_locs = np.count_nonzero(history.max(axis=0) == 2)\n",
    "\n",
    "        green_chars = [guesses[x][y] for x,y in np.argwhere(history == 2) ]\n",
    "        orange_chars = [guesses[x][y] for x,y in np.argwhere(history == 1) ]\n",
    "        black_chars = [guesses[x][y] for x,y in np.argwhere(history == 0) ]\n",
    "        num_other_letters = len(set(orange_chars) - set(green_chars))\n",
    "        num_black_letters = len(set(black_chars))\n",
    "\n",
    "        sequence_number = int(history.size / 5)\n",
    "        #print(f'construct_state() with seqno {sequence_number}')\n",
    "\n",
    "        sequence_number_onehot = np.zeros(Env.num_guesses)\n",
    "        sequence_number_onehot[sequence_number] = 1.0\n",
    "        arr = np.concatenate((np.array([num_green_locs, num_other_letters, num_black_letters])/5, sequence_number_onehot))\n",
    "        return torch.tensor(arr, device=device, dtype=torch.float)\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0339f14",
   "metadata": {},
   "source": [
    "The aim here is to use a NN to represent the policy, rather than the value function.  We will shrink the action space (ie, so that we have a few actions, rather than 12000).  This will remove the model's ability to learn novel strategies, rather it will just be learning when to employ the different strategies (actions) that I give it.  Start w\n",
    "ith these 3 word selection tactics:\n",
    "\n",
    "1. choose words which match the current history\n",
    "1. choose words which contain the greatest number of new letters\n",
    "1. choose words which have the highest frequency score\n",
    "\n",
    "then we will construct 6 actions by choosing every possible order of these strategies\n",
    "1. 1,2,3\n",
    "1. 1,3,2\n",
    "1. 2,1,3\n",
    "1. 2,3,1\n",
    "1. 3,1,2\n",
    "1. 3,2,1\n",
    "\n",
    "for all these actions there may be multiple words, so sample a random one.  The policy then becomes a logistic regressor which selects one of these actions to execute.  The loss to train the regressor will be derived using the policy gradiet theorem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9dd99de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count, permutations\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "#plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "832e7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def clear(self):\n",
    "        self.memory.clear()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae28e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_actions):\n",
    "        super(PolicyNetNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, 20)\n",
    "        self.head = nn.Linear(20, num_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.softmax(self.head(x), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8c642286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_actions):\n",
    "        super(PolicyNetLinear, self).__init__()\n",
    "        self.head = nn.Linear(num_inputs, num_actions)\n",
    "        #print(f'PolicyNetLinear {num_inputs}, {num_actions}')\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        return F.softmax(self.head(x), dim=0)\n",
    "    \n",
    "class PolicyMonteCarlo(nn.Module):\n",
    "    def __init__(self, num_guesses, num_actions):\n",
    "        super(PolicyMonteCarlo, self).__init__()\n",
    "        self.weights = torch.nn.Parameter(torch.rand((num_guesses, num_actions), dtype=float), requires_grad=True)\n",
    "        #self.weights.require_grad = True\n",
    "        self.x = torch.Tensor([1.0,1.0])\n",
    "        \n",
    "    def forward(self, state):\n",
    "        onehot = state[3:]\n",
    "        step_idx = torch.argmax(onehot, dim=0)\n",
    "        \n",
    "        y = F.softmax(self.x.mul(self.weights[step_idx]), dim=0)\n",
    "        #print(f'onehot {onehot}, step_idx {step_idx}')\n",
    "        #print(self.weights)\n",
    "        #print(self.weights[step_idx])\n",
    "        #print(y)\n",
    "        return y\n",
    "    \n",
    "class PolicyAvgReward():\n",
    "    def __init__(self, num_guesses, num_actions):\n",
    "        #self.weights = torch.Tensor([[.5,.5],[1,0],[1,0],[1,0],[1,0],[1,0]])\n",
    "        self.weights = torch.rand((num_guesses, num_actions), dtype=float)\n",
    "        \n",
    "        self.reward_stats = [(defaultdict(int),defaultdict(int)) for _ in range(num_guesses)]\n",
    "        self.num_guesses = num_guesses\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "    def __call__(self, state):\n",
    "        onehot = state[3:]\n",
    "        step_idx = torch.argmax(onehot, dim=0)\n",
    "        #if step_idx == 0:\n",
    "        return F.softmax(self.weights[step_idx], dim=0)\n",
    "        #else:\n",
    "        #    return self.weights[step_idx]\n",
    "    \n",
    "    def calc_avgs(self):\n",
    "        for action in range(self.num_actions):\n",
    "            for step_idx in range(self.num_guesses):\n",
    "                if self.reward_stats[step_idx][action]['count'] > 0:\n",
    "                    self.weights[step_idx][action] = self.reward_stats[step_idx][action]['total'] / self.reward_stats[step_idx][action]['count']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5313599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the word-selection tactics\n",
    "n_state_features = 9\n",
    "\n",
    "class PolicyHelper:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.actions = [[env.find_target_words, env.find_words_matching_current_history]]\n",
    "        self.actions.append([env.find_words_with_highest_new_letter_freq_score])\n",
    "                \n",
    "        self.num_actions = len(self.actions)\n",
    "        #self.net = PolicyNetLinear(n_state_features, len(self.actions))\n",
    "        \n",
    "    def perform_action(self, action_idx):\n",
    "        tactic_tuple = self.actions[action_idx]\n",
    "        df = self.env.df\n",
    "        for tactic in tactic_tuple: # apply all the tactics in the given order\n",
    "            newdf = tactic(df)\n",
    "            if not newdf.empty: #if that tactic produced no results, then quit\n",
    "                df = newdf\n",
    "        return df.sample()['word'][0] # then pick a random word from what is left\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bb9ed4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_values(vals, axes=['duration', 'episode']):\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel(axes[1])\n",
    "    plt.ylabel(axes[0])\n",
    "    plt.plot(np.array(vals))\n",
    "    # Take 20 episode averages and plot them too\n",
    "    window_width = 20\n",
    "    if len(vals) >= window_width:\n",
    "        cumsum_vec = np.cumsum(np.insert(vals, 0, 0)) \n",
    "        ma_vec = (cumsum_vec[window_width:] - cumsum_vec[:-window_width]) / window_width\n",
    "        plt.plot(np.insert(ma_vec, 0, [None]*int(window_width/2)))\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    #if is_ipython:\n",
    "    #    display.clear_output(wait=True)\n",
    "    #    display.display(plt.gcf())\n",
    "    \n",
    "def plot_all(episode_durations, episode_rewards, losses, epsilons, gammas):\n",
    "    plot_values(episode_durations, axes=['duration', 'episode'])\n",
    "    plot_values(episode_rewards, axes=['reward', 'episode'])\n",
    "    if losses: plot_values(losses, axes=['loss', 'step'])\n",
    "    if epsilons: plot_values(epsilons, axes=['epsilon', 'step'])\n",
    "    if gammas: plot_values(gammas, axes=['gamma', 'step'])\n",
    "    #plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "14c1200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model_batch(model, optimizer, memory, batch_size=128):\n",
    "    if batch_size <= 0:\n",
    "        transitions = memory.memory\n",
    "    else:\n",
    "        transitions = memory.sample(batch_size)\n",
    "    print(f'optimize_model_batch {batch_size} {len(transitions)}')\n",
    "    losses = [optimize_model_single(model, optimizer, tr.state, tr.action, tr.reward) for tr in transitions]\n",
    "    \n",
    "    return losses\n",
    "\n",
    "optimizations_run = 0\n",
    "\n",
    "def optimize_model_single(model, optimizer, state, action, reward):\n",
    "    global optimizations_run\n",
    "    optimizations_run += 1\n",
    "    if isinstance(model, PolicyAvgReward):\n",
    "        onehot = state[3:]\n",
    "        step_idx = torch.argmax(onehot, dim=0)\n",
    "        model.reward_stats[step_idx][action]['count'] += 1\n",
    "        model.reward_stats[step_idx][action]['total'] += reward\n",
    "        model.calc_avgs()\n",
    "        return reward\n",
    "    # calculate gradient\n",
    "    probs = model(state)\n",
    "    sampler = Categorical(probs)\n",
    "    #print(f'sampler {sampler}')\n",
    "    log_probs = -sampler.log_prob(action)   # \"-\" because it was built to work with gradient descent, but we are using gradient ascent\n",
    "\n",
    "    pseudo_loss = log_probs * reward # loss that when differentiated with autograd gives the gradient of J(θ)\n",
    "    #print(f'log_prob {log_probs}, reward {reward}, loss {pseudo_loss} ')\n",
    "    # update policy weights\n",
    "    optimizer.zero_grad()\n",
    "    pseudo_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return pseudo_loss\n",
    "\n",
    "\n",
    "class TrainConfig():\n",
    "    def __init__(self, optimizer='adam', batch_size=64, train_interval=64, clear_memory=False, lr=0.01):\n",
    "        self.optimizer = optimizer\n",
    "        self.clear_memory = clear_memory\n",
    "        self.lr = lr\n",
    "        self.train_interval = train_interval\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "class ValueConfig():\n",
    "    def __init__(self, name='reward', gamma=[0.9, 0.05, 200]):\n",
    "        self.name = name\n",
    "        self.gamma = gamma\n",
    "        \n",
    "class ModelConfig():\n",
    "    def __init__(self, name='naive', startword=None, target_list_only=None):\n",
    "        self.name = name\n",
    "        self.startword = startword\n",
    "        self.target_list_only = target_list_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "71c62073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "def run_experiment(model=ModelConfig(name='naive', startword=None, target_list_only=False),\n",
    "                   num_episodes=128,\n",
    "                   eps=[0.9, 0.05, 200],\n",
    "                   value_function=ValueConfig(name='reward',gamma=[0.0, 1.0, 200]),\n",
    "                   training=TrainConfig(),\n",
    "                   seed=0):\n",
    "    global optimizations_run\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    GAMMA_START, GAMMA_END, GAMMA_DECAY = value_function.gamma\n",
    "    env = Env(df)\n",
    "    memory = ReplayMemory(10000)\n",
    "    starting_state = construct_state_tensor(env.guesses, env.history)\n",
    "\n",
    "    steps_done = 0\n",
    "    last_training = 0\n",
    "    losses = []\n",
    "    episode_rewards = []\n",
    "    episode_durations = []\n",
    "    epsilons = []\n",
    "    gammas = []\n",
    "    reward_stats = [(defaultdict(int),defaultdict(int)) for _ in range(env.num_guesses)]\n",
    "    transitions_added_to_memory = 0\n",
    "    optimizations_run = 0\n",
    "    \n",
    "    policy_helper = PolicyHelper(env)\n",
    "    \n",
    "    if model.name == 'linear':\n",
    "        policy_net = PolicyNetLinear(n_state_features, len(policy_helper.actions)).to(device)\n",
    "    elif model.name == 'monte':\n",
    "        policy_net = PolicyMonteCarlo(env.num_guesses, len(policy_helper.actions)).to(device)\n",
    "        print('monte weights')\n",
    "        print(policy_net.weights)\n",
    "        print(F.softmax(policy_net.weights, dim=1))\n",
    "    elif model.name == 'avg_reward':\n",
    "        policy_net = PolicyAvgReward(env.num_guesses, len(policy_helper.actions))\n",
    "    else:\n",
    "        policy_net = PolicyNetNN(n_state_features, len(policy_helper.actions)).to(device)\n",
    "    \n",
    "    if model.name == 'avg_reward':\n",
    "        optimizer = None\n",
    "    elif training.optimizer == 'rmsprop':\n",
    "            optimizer = optim.RMSprop(policy_net.parameters(), lr=training.lr)\n",
    "    elif training.optimizer == 'sgd':\n",
    "            optimizer = optim.SGD(policy_net.parameters(), lr=training.lr)\n",
    "    else:\n",
    "            optimizer = optim.Adam(policy_net.parameters(), lr=training.lr)\n",
    "\n",
    "        #print(f'pn params {list(policy_net.parameters())}')\n",
    "    for i_episode in range(num_episodes):\n",
    "        # Initialize the environment and state\n",
    "        env.reset()\n",
    "        print(f'=========================episode {i_episode} {env.target}======================')\n",
    "\n",
    "        episode_memory = []\n",
    "        state = starting_state\n",
    "        guesses = []\n",
    "        for t in count():\n",
    "            GAMMA = GAMMA_END + (GAMMA_START - GAMMA_END) * math.exp(-1. * steps_done / GAMMA_DECAY)\n",
    "            gammas.append(GAMMA)\n",
    "            steps_done += 1\n",
    "            # Select and perform an action\n",
    "            #print(state, actions)\n",
    "            probs = policy_net(state)\n",
    "            sampler = Categorical(probs)\n",
    "            action_idx = sampler.sample()\n",
    "            chosen_word = policy_helper.perform_action(action_idx)\n",
    "            guesses.append(chosen_word)\n",
    "            print(f'------guess {t} {action_idx} {guesses[-1]}-------')\n",
    "            history, reward, done = env.step(chosen_word)\n",
    "            #here next_state == env.history\n",
    "            if not done:\n",
    "                next_state = construct_state_tensor(guesses, history)\n",
    "            \n",
    "            #action_tensor = action_idx.clone().detach()\n",
    "            action = action_idx #F.one_hot(action_idx, num_classes=policy_helper.num_actions)\n",
    "                \n",
    "            print(f'reward {reward} done {done} action {action}')\n",
    "            #reward = np.array([reward])\n",
    "\n",
    "            # Store the transition in memory\n",
    "            #memory.push(state, action_idx, reward)\n",
    "            episode_memory.append([state, action, reward])\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                episode_durations.append(t + 1)\n",
    "                episode_reward = sum([tr[2] for tr in episode_memory])\n",
    "                print(f'episode {i_episode} finished.  reward {episode_reward}  eps {eps}  gamma {GAMMA}  steps {steps_done}  memory {len(memory)}')\n",
    "                episode_rewards.append(episode_reward)\n",
    "                \n",
    "                for idx,tr in enumerate(episode_memory):\n",
    "                    #print(f'pushing episode_reward {episode_reward} {episode_reward.__class__}')\n",
    "                    transitions_added_to_memory += 1\n",
    "                    memory.push(tr[0], tr[1], episode_reward)\n",
    "                    #loss = optimize_model_single(policy_net, optimizer, tr[0], tr[1], episode_reward)\n",
    "                    #losses.append(loss)\n",
    "                \n",
    "                    reward_stats[idx][tr[1]]['count'] += 1\n",
    "                    reward_stats[idx][tr[1]]['total'] += episode_reward\n",
    "                    episode_reward -= tr[2]\n",
    "                    \n",
    "                    \n",
    "                # If we have gathered enough data, Perform one step of the optimization (on the policy network)\n",
    "                if len(memory) >= max(1,training.batch_size) \\\n",
    "                    and i_episode % training.train_interval == 0:\n",
    "                    losses += optimize_model_batch(policy_net, optimizer, memory, batch_size=training.batch_size)\n",
    "                    if training.clear_memory: memory.clear()\n",
    "                        \n",
    "                    if model.name == 'monte':\n",
    "                        print('monte weights')\n",
    "                        print(policy_net.weights)\n",
    "                        print(F.softmax(policy_net.weights, dim=1))\n",
    "                        for rs in reward_stats:\n",
    "                            if rs[0]['count'] > 0:\n",
    "                                rs[0]['avg'] = rs[0]['total'] / rs[0]['count']\n",
    "                            if rs[1]['count'] > 0:\n",
    "                                rs[1]['avg'] = rs[1]['total'] / rs[1]['count']\n",
    "                            print(dict(rs[0]), dict(rs[1]))\n",
    "                    elif model.name == 'avg_reward':\n",
    "                        print('monte weights')\n",
    "                        print(policy_net.weights)\n",
    "                        print(F.softmax(policy_net.weights, dim=1))\n",
    "                        for rs in policy_net.reward_stats:\n",
    "                            if rs[0]['count'] > 0:\n",
    "                                rs[0]['avg'] = rs[0]['total'] / rs[0]['count']\n",
    "                            if rs[1]['count'] > 0:\n",
    "                                rs[1]['avg'] = rs[1]['total'] / rs[1]['count']\n",
    "                            print(dict(rs[0]), dict(rs[1]))\n",
    "                    print(f'done {optimizations_run} optimizations, {transitions_added_to_memory} transitions added to memory')\n",
    "                    \n",
    "                        \n",
    "                        \n",
    "                \n",
    "                #plot_durations()\n",
    "                break\n",
    "\n",
    "    print('Complete')\n",
    "    \n",
    "    \n",
    "    return episode_durations, episode_rewards, losses, epsilons, gammas\n",
    "\n",
    "#env.render()\n",
    "#env.close()\n",
    "#plt.ioff()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f94916dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================episode 0 nanny======================\n",
      "------guess 0 0 spied-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 manly-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 fanny-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 canny-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 nanny-------\n",
      "reward 0 done True action 0\n",
      "episode 0 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.019801326693244747  steps 5  memory 0\n",
      "optimize_model_batch -1 5\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 1, 'total': -4, 'avg': -4.0} {'count': 0}\n",
      "{'count': 1, 'total': -3, 'avg': -3.0} {'count': 0}\n",
      "{'count': 1, 'total': -2, 'avg': -2.0} {'count': 0}\n",
      "{'count': 1, 'total': -1, 'avg': -1.0} {'count': 0}\n",
      "{'count': 1, 'total': 0, 'avg': 0.0} {'count': 0}\n",
      "{'count': 0} {'count': 0}\n",
      "done 5 optimizations, 5 transitions added to memory\n",
      "=========================episode 1 essay======================\n",
      "------guess 0 0 again-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 broad-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sweat-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 essay-------\n",
      "reward 0 done True action 0\n",
      "episode 1 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.03921056084767682  steps 9  memory 0\n",
      "=========================episode 2 liken======================\n",
      "------guess 0 0 alibi-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 devil-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 liner-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 liken-------\n",
      "reward 0 done True action 0\n",
      "episode 2 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.05823546641575128  steps 13  memory 4\n",
      "=========================episode 3 clang======================\n",
      "------guess 0 0 loamy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 flare-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 gland-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 slang-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 clang-------\n",
      "reward 0 done True action 0\n",
      "episode 3 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.08148771559854262  steps 18  memory 8\n",
      "=========================episode 4 itchy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 timid-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 glint-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 itchy-------\n",
      "reward 0 done True action 0\n",
      "episode 4 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.09967547741373439  steps 22  memory 13\n",
      "=========================episode 5 mount======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 stout-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 count-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 mount-------\n",
      "reward 0 done True action 0\n",
      "episode 5 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.11750309741540454  steps 26  memory 17\n",
      "=========================episode 6 crime======================\n",
      "------guess 0 0 juror-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 rebel-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wider-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 inert-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 prime-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 crime-------\n",
      "reward 0 done True action 0\n",
      "episode 6 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.1435848225163865  steps 32  memory 21\n",
      "=========================episode 7 idyll======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 spiny-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 idyll-------\n",
      "reward 0 done True action 0\n",
      "episode 7 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.1563351834036163  steps 35  memory 27\n",
      "=========================episode 8 credo======================\n",
      "------guess 0 0 quite-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 haven-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wreck-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 credo-------\n",
      "reward 0 done True action 0\n",
      "episode 8 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.1730408660566377  steps 39  memory 30\n",
      "optimize_model_batch -1 34\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 6, 'total': -22, 'avg': -3.6666666666666665} {'count': 3, 'total': -8, 'avg': -2.6666666666666665}\n",
      "{'count': 9, 'total': -21, 'avg': -2.3333333333333335} {'count': 0}\n",
      "{'count': 9, 'total': -12, 'avg': -1.3333333333333333} {'count': 0}\n",
      "{'count': 8, 'total': -4, 'avg': -0.5} {'count': 0}\n",
      "{'count': 3, 'total': -1, 'avg': -0.3333333333333333} {'count': 0}\n",
      "{'count': 1, 'total': 0, 'avg': 0.0} {'count': 0}\n",
      "done 39 optimizations, 39 transitions added to memory\n",
      "=========================episode 9 quail======================\n",
      "------guess 0 0 known-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 humph-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 buyer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 quilt-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 quail-------\n",
      "reward 0 done True action 0\n",
      "episode 9 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.19345855982267313  steps 44  memory 0\n",
      "=========================episode 10 comma======================\n",
      "------guess 0 0 ardor-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 omega-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 comma-------\n",
      "reward 0 done True action 0\n",
      "episode 10 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.20546639749666595  steps 47  memory 5\n",
      "=========================episode 11 speck======================\n",
      "------guess 0 0 tough-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 weary-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 spiel-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 spend-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 speck-------\n",
      "reward 0 done True action 0\n",
      "episode 11 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.22508350203891903  steps 52  memory 8\n",
      "=========================episode 12 polka======================\n",
      "------guess 0 0 prick-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 pesky-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 polka-------\n",
      "reward 0 done True action 0\n",
      "episode 12 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.23662050566314685  steps 55  memory 13\n",
      "=========================episode 13 undue======================\n",
      "------guess 0 0 cairn-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 nobly-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 unset-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 undue-------\n",
      "reward 0 done True action 0\n",
      "episode 13 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.25173643242143473  steps 59  memory 16\n",
      "=========================episode 14 guilt======================\n",
      "------guess 0 0 alien-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 built-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 guilt-------\n",
      "reward 0 done True action 0\n",
      "episode 14 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.2628766256083722  steps 62  memory 20\n",
      "=========================episode 15 catty======================\n",
      "------guess 0 0 suing-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 cheer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 cabby-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 caddy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 catty-------\n",
      "reward 0 done True action 0\n",
      "episode 15 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.28107626656807383  steps 67  memory 23\n",
      "=========================episode 16 clerk======================\n",
      "------guess 0 0 weary-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 shire-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 overt-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 clerk-------\n",
      "reward 0 done True action 0\n",
      "episode 16 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.29531191028128656  steps 71  memory 28\n",
      "optimize_model_batch -1 32\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 14, 'total': -46, 'avg': -3.2857142857142856} {'count': 3, 'total': -8, 'avg': -2.6666666666666665}\n",
      "{'count': 17, 'total': -37, 'avg': -2.176470588235294} {'count': 0}\n",
      "{'count': 17, 'total': -20, 'avg': -1.1764705882352942} {'count': 0}\n",
      "{'count': 13, 'total': -7, 'avg': -0.5384615384615384} {'count': 0}\n",
      "{'count': 6, 'total': -1, 'avg': -0.16666666666666666} {'count': 0}\n",
      "{'count': 1, 'total': 0, 'avg': 0.0} {'count': 0}\n",
      "done 71 optimizations, 71 transitions added to memory\n",
      "=========================episode 17 whine======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 judge-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 mince-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 whine-------\n",
      "reward 0 done True action 0\n",
      "episode 17 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.3092656693626453  steps 75  memory 0\n",
      "=========================episode 18 steep======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 thief-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 unset-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 steel-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 steed-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 steep-------\n",
      "reward 0 done True action 0\n",
      "episode 18 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.3296799539643607  steps 81  memory 4\n",
      "=========================episode 19 zonal======================\n",
      "------guess 0 0 limbo-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 offal-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 total-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 vocal-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 zonal-------\n",
      "reward 0 done True action 0\n",
      "episode 19 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.3462302148701527  steps 86  memory 10\n",
      "=========================episode 20 bench======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 yield-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bench-------\n",
      "reward 0 done True action 0\n",
      "episode 20 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.3559635789168586  steps 89  memory 15\n",
      "=========================episode 21 alley======================\n",
      "------guess 0 0 worst-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 filly-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 alley-------\n",
      "reward 0 done True action 0\n",
      "episode 21 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.3655520320517718  steps 92  memory 18\n",
      "=========================episode 22 midge======================\n",
      "------guess 0 0 joist-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 lyric-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 ennui-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 midge-------\n",
      "reward 0 done True action 0\n",
      "episode 22 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.3781149435349799  steps 96  memory 21\n",
      "=========================episode 23 chord======================\n",
      "------guess 0 0 cried-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 chard-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 chord-------\n",
      "reward 0 done True action 0\n",
      "episode 23 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.3873736058155839  steps 99  memory 25\n",
      "=========================episode 24 aside======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 sedan-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 aside-------\n",
      "reward 0 done True action 0\n",
      "episode 24 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.39649442457295947  steps 102  memory 28\n",
      "optimize_model_batch -1 31\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 18, 'total': -57, 'avg': -3.1666666666666665} {'count': 7, 'total': -20, 'avg': -2.857142857142857}\n",
      "{'count': 25, 'total': -52, 'avg': -2.08} {'count': 0}\n",
      "{'count': 25, 'total': -27, 'avg': -1.08} {'count': 0}\n",
      "{'count': 17, 'total': -10, 'avg': -0.5882352941176471} {'count': 0}\n",
      "{'count': 8, 'total': -2, 'avg': -0.25} {'count': 0}\n",
      "{'count': 2, 'total': 0, 'avg': 0.0} {'count': 0}\n",
      "done 102 optimizations, 102 transitions added to memory\n",
      "=========================episode 25 vigor======================\n",
      "------guess 0 0 havoc-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 visor-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 vigor-------\n",
      "reward 0 done True action 0\n",
      "episode 25 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.4054794520298056  steps 105  memory 0\n",
      "=========================episode 26 awake======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 beady-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shave-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 plane-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 image-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 quake-------\n",
      "reward -1 done True action 0\n",
      "episode 26 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.42305018961951335  steps 111  memory 3\n",
      "=========================episode 27 elegy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 seedy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 enemy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 elegy-------\n",
      "reward 0 done True action 0\n",
      "episode 27 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.4344745613004629  steps 115  memory 9\n",
      "=========================episode 28 lunar======================\n",
      "------guess 0 0 siren-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 brand-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lunar-------\n",
      "reward 0 done True action 0\n",
      "episode 28 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.4428941381878261  steps 118  memory 13\n",
      "=========================episode 29 clung======================\n",
      "------guess 0 0 roast-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 quick-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 clung-------\n",
      "reward 0 done True action 0\n",
      "episode 29 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.4511883639059736  steps 121  memory 16\n",
      "=========================episode 30 gruel======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 dress-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 grief-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 gruel-------\n",
      "reward 0 done True action 0\n",
      "episode 30 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.4620555624053255  steps 125  memory 19\n",
      "=========================episode 31 jetty======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 testy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 jetty-------\n",
      "reward 0 done True action 0\n",
      "episode 31 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.47006451168243146  steps 128  memory 23\n",
      "=========================episode 32 askew======================\n",
      "------guess 0 0 laden-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 abbey-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 after-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 askew-------\n",
      "reward 0 done True action 0\n",
      "episode 32 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.48055793741295183  steps 132  memory 26\n",
      "optimize_model_batch -1 30\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 22, 'total': -66, 'avg': -3.0} {'count': 11, 'total': -34, 'avg': -3.090909090909091}\n",
      "{'count': 33, 'total': -67, 'avg': -2.0303030303030303} {'count': 0}\n",
      "{'count': 33, 'total': -34, 'avg': -1.0303030303030303} {'count': 0}\n",
      "{'count': 21, 'total': -13, 'avg': -0.6190476190476191} {'count': 0}\n",
      "{'count': 9, 'total': -4, 'avg': -0.4444444444444444} {'count': 0}\n",
      "{'count': 3, 'total': -1, 'avg': -0.3333333333333333} {'count': 0}\n",
      "done 132 optimizations, 132 transitions added to memory\n",
      "=========================episode 33 count======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 motif-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 doubt-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 count-------\n",
      "reward 0 done True action 0\n",
      "episode 33 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.4908435793924508  steps 136  memory 0\n",
      "=========================episode 34 saint======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 tawny-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 vaunt-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 3 0 saint-------\n",
      "reward 0 done True action 0\n",
      "episode 34 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.500925552014864  steps 140  memory 4\n",
      "=========================episode 35 deign======================\n",
      "------guess 0 0 baron-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 hymen-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 elfin-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 deign-------\n",
      "reward 0 done True action 0\n",
      "episode 35 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.5108078882036684  steps 144  memory 8\n",
      "=========================episode 36 elite======================\n",
      "------guess 0 0 glade-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 close-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 fluke-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 elite-------\n",
      "reward 0 done True action 0\n",
      "episode 36 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.5204945410251058  steps 148  memory 12\n",
      "=========================episode 37 rabbi======================\n",
      "------guess 0 0 sleek-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 group-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 tardy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 ranch-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 rabbi-------\n",
      "reward 0 done True action 0\n",
      "episode 37 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.5323335729900908  steps 153  memory 16\n",
      "=========================episode 38 drift======================\n",
      "------guess 0 0 salsa-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 fibre-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 drift-------\n",
      "reward 0 done True action 0\n",
      "episode 38 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.5392962190010342  steps 156  memory 21\n",
      "=========================episode 39 whiny======================\n",
      "------guess 0 0 winch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 whiny-------\n",
      "reward 0 done True action 0\n",
      "episode 39 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.5438802982143608  steps 158  memory 24\n",
      "=========================episode 40 beach======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 leafy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 peach-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 beach-------\n",
      "reward 0 done True action 0\n",
      "episode 40 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.5529120734406436  steps 162  memory 26\n",
      "optimize_model_batch -1 30\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 27, 'total': -79, 'avg': -2.925925925925926} {'count': 14, 'total': -43, 'avg': -3.0714285714285716}\n",
      "{'count': 41, 'total': -81, 'avg': -1.975609756097561} {'count': 0}\n",
      "{'count': 40, 'total': -41, 'avg': -1.025} {'count': 0}\n",
      "{'count': 27, 'total': -14, 'avg': -0.5185185185185185} {'count': 0}\n",
      "{'count': 10, 'total': -4, 'avg': -0.4} {'count': 0}\n",
      "{'count': 3, 'total': -1, 'avg': -0.3333333333333333} {'count': 0}\n",
      "done 162 optimizations, 162 transitions added to memory\n",
      "=========================episode 41 bawdy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 madly-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 daisy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 gaudy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 handy-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 bawdy-------\n",
      "reward 0 done True action 0\n",
      "episode 41 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.5661255185670091  steps 168  memory 0\n",
      "=========================episode 42 lying======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 vivid-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 pubic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 swing-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 fling-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 lying-------\n",
      "reward 0 done True action 0\n",
      "episode 42 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.5789484473726788  steps 174  memory 6\n",
      "=========================episode 43 fancy======================\n",
      "------guess 0 0 repel-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 sauna-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 cabin-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 fancy-------\n",
      "reward 0 done True action 0\n",
      "episode 43 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.5872858267209504  steps 178  memory 12\n",
      "=========================episode 44 uncle======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 wedge-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 spike-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 cycle-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 uncle-------\n",
      "reward 0 done True action 0\n",
      "episode 44 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.597475775966364  steps 183  memory 16\n",
      "=========================episode 45 unmet======================\n",
      "------guess 0 0 cable-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 power-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 duvet-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 unset-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 unmet-------\n",
      "reward 0 done True action 0\n",
      "episode 45 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.6074141344684816  steps 188  memory 21\n",
      "=========================episode 46 snuck======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 unzip-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 snuck-------\n",
      "reward 0 done True action 0\n",
      "episode 46 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.6132589765454988  steps 191  memory 26\n",
      "=========================episode 47 ascot======================\n",
      "------guess 0 0 dread-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 pansy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 swath-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 ascot-------\n",
      "reward 0 done True action 0\n",
      "episode 47 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.6209169618966012  steps 195  memory 29\n",
      "=========================episode 48 bossy======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 hippo-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bosom-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bossy-------\n",
      "reward 0 done True action 0\n",
      "episode 48 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.6284233089779543  steps 199  memory 33\n",
      "optimize_model_batch -1 37\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 30, 'total': -89, 'avg': -2.966666666666667} {'count': 19, 'total': -62, 'avg': -3.263157894736842}\n",
      "{'count': 49, 'total': -102, 'avg': -2.0816326530612246} {'count': 0}\n",
      "{'count': 48, 'total': -54, 'avg': -1.125} {'count': 0}\n",
      "{'count': 34, 'total': -20, 'avg': -0.5882352941176471} {'count': 0}\n",
      "{'count': 14, 'total': -6, 'avg': -0.42857142857142855} {'count': 0}\n",
      "{'count': 5, 'total': -1, 'avg': -0.2} {'count': 0}\n",
      "done 199 optimizations, 199 transitions added to memory\n",
      "=========================episode 49 grope======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 broke-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 drove-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 prone-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 grope-------\n",
      "reward 0 done True action 0\n",
      "episode 49 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.6375975701675096  steps 204  memory 0\n",
      "=========================episode 50 music======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 wimpy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 climb-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 music-------\n",
      "reward 0 done True action 0\n",
      "episode 50 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.6447736190750485  steps 208  memory 5\n",
      "=========================episode 51 north======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 worth-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 forth-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 north-------\n",
      "reward 0 done True action 0\n",
      "episode 51 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.6518075726938024  steps 212  memory 9\n",
      "=========================episode 52 villa======================\n",
      "------guess 0 0 theta-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 pizza-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 villa-------\n",
      "reward 0 done True action 0\n",
      "episode 52 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.6569914825812934  steps 215  memory 13\n",
      "=========================episode 53 metro======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 voter-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 retro-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 metro-------\n",
      "reward 0 done True action 0\n",
      "episode 53 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.6637835062932667  steps 219  memory 16\n",
      "=========================episode 54 craze======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 drape-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 graze-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 craze-------\n",
      "reward 0 done True action 0\n",
      "episode 54 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.670441038924811  steps 223  memory 20\n",
      "=========================episode 55 throb======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 worst-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 throb-------\n",
      "reward 0 done True action 0\n",
      "episode 55 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.6753475326416503  steps 226  memory 24\n",
      "=========================episode 56 trove======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 trove-------\n",
      "reward 0 done True action 0\n",
      "episode 56 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.6785778786656087  steps 228  memory 27\n",
      "optimize_model_batch -1 29\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 31, 'total': -91, 'avg': -2.935483870967742} {'count': 26, 'total': -81, 'avg': -3.1153846153846154}\n",
      "{'count': 57, 'total': -115, 'avg': -2.017543859649123} {'count': 0}\n",
      "{'count': 55, 'total': -60, 'avg': -1.0909090909090908} {'count': 0}\n",
      "{'count': 39, 'total': -21, 'avg': -0.5384615384615384} {'count': 0}\n",
      "{'count': 15, 'total': -6, 'avg': -0.4} {'count': 0}\n",
      "{'count': 5, 'total': -1, 'avg': -0.2} {'count': 0}\n",
      "done 228 optimizations, 228 transitions added to memory\n",
      "=========================episode 57 moron======================\n",
      "------guess 0 0 scare-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 rugby-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 morph-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 moron-------\n",
      "reward 0 done True action 0\n",
      "episode 57 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.6849424630965867  steps 232  memory 0\n",
      "=========================episode 58 grace======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 crave-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 grace-------\n",
      "reward 0 done True action 0\n",
      "episode 58 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.689633058734515  steps 235  memory 4\n",
      "=========================episode 59 month======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 joist-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 mouth-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 month-------\n",
      "reward 0 done True action 0\n",
      "episode 59 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.6957787359332959  steps 239  memory 7\n",
      "=========================episode 60 swami======================\n",
      "------guess 0 0 briar-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 viola-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 panic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 image-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 swami-------\n",
      "reward 0 done True action 0\n",
      "episode 60 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.7032899857059547  steps 244  memory 11\n",
      "=========================episode 61 chant======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 await-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 scant-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 chant-------\n",
      "reward 0 done True action 0\n",
      "episode 61 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7091652376321484  steps 248  memory 16\n",
      "=========================episode 62 brace======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 grace-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 brace-------\n",
      "reward 0 done True action 0\n",
      "episode 62 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7134952031398099  steps 251  memory 20\n",
      "=========================episode 63 thump======================\n",
      "------guess 0 0 spoof-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 recap-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 tulip-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 thump-------\n",
      "reward 0 done True action 0\n",
      "episode 63 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7191683782216203  steps 255  memory 23\n",
      "=========================episode 64 spoke======================\n",
      "------guess 0 0 morph-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 spook-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 spoke-------\n",
      "reward 0 done True action 0\n",
      "episode 64 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7233494163680265  steps 258  memory 27\n",
      "optimize_model_batch -1 30\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 35, 'total': -103, 'avg': -2.942857142857143} {'count': 30, 'total': -91, 'avg': -3.033333333333333}\n",
      "{'count': 65, 'total': -129, 'avg': -1.9846153846153847} {'count': 0}\n",
      "{'count': 63, 'total': -66, 'avg': -1.0476190476190477} {'count': 0}\n",
      "{'count': 44, 'total': -22, 'avg': -0.5} {'count': 0}\n",
      "{'count': 16, 'total': -6, 'avg': -0.375} {'count': 0}\n",
      "{'count': 5, 'total': -1, 'avg': -0.2} {'count': 0}\n",
      "done 258 optimizations, 258 transitions added to memory\n",
      "=========================episode 65 assay======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 fanny-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 apply-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 assay-------\n",
      "reward 0 done True action 0\n",
      "episode 65 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7288274649544001  steps 262  memory 0\n",
      "=========================episode 66 slain======================\n",
      "------guess 0 0 ralph-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 octal-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 llama-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 blaze-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 slang-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 slain-------\n",
      "reward 0 done True action 0\n",
      "episode 66 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.7368418245439713  steps 268  memory 4\n",
      "=========================episode 67 crone======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 drone-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 crone-------\n",
      "reward 0 done True action 0\n",
      "episode 67 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7407597393541085  steps 271  memory 10\n",
      "=========================episode 68 shoot======================\n",
      "------guess 0 0 twirl-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 0 scent-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 squat-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 shoot-------\n",
      "reward 0 done True action 0\n",
      "episode 68 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7458930404471997  steps 275  memory 13\n",
      "=========================episode 69 manly======================\n",
      "------guess 0 0 among-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 human-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 manly-------\n",
      "reward 0 done True action 0\n",
      "episode 69 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7496762002083039  steps 278  memory 17\n",
      "=========================episode 70 shall======================\n",
      "------guess 0 0 clear-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 afoul-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shall-------\n",
      "reward 0 done True action 0\n",
      "episode 70 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7534030360583935  steps 281  memory 20\n",
      "=========================episode 71 derby======================\n",
      "------guess 0 0 screw-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 borne-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 derby-------\n",
      "reward 0 done True action 0\n",
      "episode 71 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7570743865512576  steps 284  memory 23\n",
      "=========================episode 72 linen======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 dicey-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 pixel-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 linen-------\n",
      "reward 0 done True action 0\n",
      "episode 72 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.761884635985313  steps 288  memory 26\n",
      "optimize_model_batch -1 30\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 40, 'total': -117, 'avg': -2.925} {'count': 33, 'total': -99, 'avg': -3.0}\n",
      "{'count': 73, 'total': -143, 'avg': -1.9589041095890412} {'count': 0}\n",
      "{'count': 71, 'total': -72, 'avg': -1.0140845070422535} {'count': 0}\n",
      "{'count': 48, 'total': -24, 'avg': -0.5} {'count': 0}\n",
      "{'count': 17, 'total': -7, 'avg': -0.4117647058823529} {'count': 0}\n",
      "{'count': 6, 'total': -1, 'avg': -0.16666666666666666} {'count': 0}\n",
      "done 288 optimizations, 288 transitions added to memory\n",
      "=========================episode 73 ethic======================\n",
      "------guess 0 0 vigil-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 unzip-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 maxim-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 their-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 ethic-------\n",
      "reward 0 done True action 0\n",
      "episode 73 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.7677637252702412  steps 293  memory 0\n",
      "=========================episode 74 apple======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 valve-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 ample-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 apple-------\n",
      "reward 0 done True action 0\n",
      "episode 74 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7723623116161873  steps 297  memory 5\n",
      "=========================episode 75 lying======================\n",
      "------guess 0 0 larva-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 lemon-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lynch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 lying-------\n",
      "reward 0 done True action 0\n",
      "episode 75 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7768698398515702  steps 301  memory 9\n",
      "=========================episode 76 needy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 weedy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 needy-------\n",
      "reward 0 done True action 0\n",
      "episode 76 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7801918151522382  steps 304  memory 13\n",
      "=========================episode 77 float======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 ascot-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 float-------\n",
      "reward 0 done True action 0\n",
      "episode 77 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.783464332683993  steps 307  memory 16\n",
      "=========================episode 78 chief======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 lumen-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 speed-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 chief-------\n",
      "reward 0 done True action 0\n",
      "episode 78 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7877520261732569  steps 311  memory 19\n",
      "=========================episode 79 rouge======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 borne-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 rouse-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 rouge-------\n",
      "reward 0 done True action 0\n",
      "episode 79 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7919548176429796  steps 315  memory 23\n",
      "=========================episode 80 smear======================\n",
      "------guess 0 0 blink-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 tempo-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 masse-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 smear-------\n",
      "reward 0 done True action 0\n",
      "episode 80 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7960743882657866  steps 319  memory 27\n",
      "optimize_model_batch -1 31\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 43, 'total': -127, 'avg': -2.953488372093023} {'count': 38, 'total': -112, 'avg': -2.9473684210526314}\n",
      "{'count': 81, 'total': -158, 'avg': -1.9506172839506173} {'count': 0}\n",
      "{'count': 79, 'total': -79, 'avg': -1.0} {'count': 0}\n",
      "{'count': 54, 'total': -25, 'avg': -0.46296296296296297} {'count': 0}\n",
      "{'count': 18, 'total': -7, 'avg': -0.3888888888888889} {'count': 0}\n",
      "{'count': 6, 'total': -1, 'avg': -0.16666666666666666} {'count': 0}\n",
      "done 319 optimizations, 319 transitions added to memory\n",
      "=========================episode 81 await======================\n",
      "------guess 0 0 value-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 khaki-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 staid-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 train-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 await-------\n",
      "reward 0 done True action 0\n",
      "episode 81 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8011093295591803  steps 324  memory 0\n",
      "=========================episode 82 preen======================\n",
      "------guess 0 0 scrum-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 prong-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 prawn-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 preen-------\n",
      "reward 0 done True action 0\n",
      "episode 82 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8050476287008175  steps 328  memory 5\n",
      "=========================episode 83 mover======================\n",
      "------guess 0 0 gypsy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 brink-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 occur-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 rotor-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 mower-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 mover-------\n",
      "reward 0 done True action 0\n",
      "episode 83 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.810809342018018  steps 334  memory 9\n",
      "=========================episode 84 worst======================\n",
      "------guess 0 0 crypt-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 rebut-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 flirt-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 tarot-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 worst-------\n",
      "reward 0 done True action 0\n",
      "episode 84 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8154804760070107  steps 339  memory 15\n",
      "=========================episode 85 chair======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 briar-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 flair-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 chair-------\n",
      "reward 0 done True action 0\n",
      "episode 85 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8191342073828779  steps 343  memory 20\n",
      "=========================episode 86 repay======================\n",
      "------guess 0 0 alike-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 heath-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 vegan-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 debar-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 recap-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 repay-------\n",
      "reward 0 done True action 0\n",
      "episode 86 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.8244795993830032  steps 349  memory 24\n",
      "=========================episode 87 ridge======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 eerie-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 rinse-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 ridge-------\n",
      "reward 0 done True action 0\n",
      "episode 87 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8279551361769495  steps 353  memory 30\n",
      "=========================episode 88 glass======================\n",
      "------guess 0 0 riser-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 swamp-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 clash-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 blast-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 glass-------\n",
      "reward 0 done True action 0\n",
      "episode 88 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8322029389998141  steps 358  memory 34\n",
      "optimize_model_batch -1 39\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 49, 'total': -152, 'avg': -3.1020408163265305} {'count': 40, 'total': -118, 'avg': -2.95}\n",
      "{'count': 89, 'total': -181, 'avg': -2.033707865168539} {'count': 0}\n",
      "{'count': 87, 'total': -94, 'avg': -1.0804597701149425} {'count': 0}\n",
      "{'count': 62, 'total': -32, 'avg': -0.5161290322580645} {'count': 0}\n",
      "{'count': 23, 'total': -9, 'avg': -0.391304347826087} {'count': 0}\n",
      "{'count': 8, 'total': -1, 'avg': -0.125} {'count': 0}\n",
      "done 358 optimizations, 358 transitions added to memory\n",
      "=========================episode 89 stash======================\n",
      "------guess 0 0 heard-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 swath-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 stash-------\n",
      "reward 0 done True action 0\n",
      "episode 89 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8347011117784134  steps 361  memory 0\n",
      "=========================episode 90 pesto======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 pesto-------\n",
      "reward 0 done True action 0\n",
      "episode 90 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.836345863197296  steps 363  memory 3\n",
      "=========================episode 91 awash======================\n",
      "------guess 0 0 blush-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 harsh-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 awash-------\n",
      "reward 0 done True action 0\n",
      "episode 91 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8387823558702232  steps 366  memory 5\n",
      "=========================episode 92 gnash======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 quail-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 spawn-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 gnash-------\n",
      "reward 0 done True action 0\n",
      "episode 92 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8419746791103522  steps 370  memory 8\n",
      "=========================episode 93 spill======================\n",
      "------guess 0 0 jerky-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 boost-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shall-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 swill-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 spill-------\n",
      "reward 0 done True action 0\n",
      "episode 93 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8458763381848686  steps 375  memory 12\n",
      "=========================episode 94 place======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 usage-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 place-------\n",
      "reward 0 done True action 0\n",
      "episode 94 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8481709405705694  steps 378  memory 17\n",
      "=========================episode 95 gully======================\n",
      "------guess 0 0 bleep-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 naval-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 godly-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 gully-------\n",
      "reward 0 done True action 0\n",
      "episode 95 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8511773573778596  steps 382  memory 20\n",
      "=========================episode 96 spell======================\n",
      "------guess 0 0 cynic-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 droop-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lapel-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 spell-------\n",
      "reward 0 done True action 0\n",
      "episode 96 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8541242431437727  steps 386  memory 24\n",
      "optimize_model_batch -1 28\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 54, 'total': -166, 'avg': -3.074074074074074} {'count': 43, 'total': -124, 'avg': -2.883720930232558}\n",
      "{'count': 97, 'total': -193, 'avg': -1.9896907216494846} {'count': 0}\n",
      "{'count': 94, 'total': -99, 'avg': -1.053191489361702} {'count': 0}\n",
      "{'count': 66, 'total': -33, 'avg': -0.5} {'count': 0}\n",
      "{'count': 24, 'total': -9, 'avg': -0.375} {'count': 0}\n",
      "{'count': 8, 'total': -1, 'avg': -0.125} {'count': 0}\n",
      "done 386 optimizations, 386 transitions added to memory\n",
      "=========================episode 97 giant======================\n",
      "------guess 0 0 torch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 jetty-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 flint-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 giant-------\n",
      "reward 0 done True action 0\n",
      "episode 97 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8570127766619071  steps 390  memory 0\n",
      "=========================episode 98 awash======================\n",
      "------guess 0 0 lefty-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 swish-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 awash-------\n",
      "reward 0 done True action 0\n",
      "episode 98 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8591415790789549  steps 393  memory 4\n",
      "=========================episode 99 rusty======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 dirty-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 rusty-------\n",
      "reward 0 done True action 0\n",
      "episode 99 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8612386877570448  steps 396  memory 7\n",
      "=========================episode 100 borax======================\n",
      "------guess 0 0 allow-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 cobra-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 borax-------\n",
      "reward 0 done True action 0\n",
      "episode 100 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8633045745544762  steps 399  memory 10\n",
      "=========================episode 101 cried======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 grief-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 drier-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 pried-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 cried-------\n",
      "reward 0 done True action 0\n",
      "episode 101 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8666795966340506  steps 404  memory 13\n",
      "=========================episode 102 awash======================\n",
      "------guess 0 0 brief-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 husky-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shawl-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 awash-------\n",
      "reward 0 done True action 0\n",
      "episode 102 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8693195174959749  steps 408  memory 18\n",
      "=========================episode 103 drunk======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 prism-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 drunk-------\n",
      "reward 0 done True action 0\n",
      "episode 103 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8712650964121957  steps 411  memory 22\n",
      "=========================episode 104 cadet======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 facet-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 cadet-------\n",
      "reward 0 done True action 0\n",
      "episode 104 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8731817094320049  steps 414  memory 25\n",
      "optimize_model_batch -1 28\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 58, 'total': -176, 'avg': -3.0344827586206895} {'count': 47, 'total': -134, 'avg': -2.851063829787234}\n",
      "{'count': 105, 'total': -205, 'avg': -1.9523809523809523} {'count': 0}\n",
      "{'count': 102, 'total': -103, 'avg': -1.0098039215686274} {'count': 0}\n",
      "{'count': 69, 'total': -34, 'avg': -0.4927536231884058} {'count': 0}\n",
      "{'count': 25, 'total': -9, 'avg': -0.36} {'count': 0}\n",
      "{'count': 8, 'total': -1, 'avg': -0.125} {'count': 0}\n",
      "done 414 optimizations, 414 transitions added to memory\n",
      "=========================episode 105 blast======================\n",
      "------guess 0 0 metal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 adult-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 plant-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 blast-------\n",
      "reward 0 done True action 0\n",
      "episode 105 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8756928798342206  steps 418  memory 0\n",
      "=========================episode 106 musty======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 blitz-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 gusty-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 musty-------\n",
      "reward 0 done True action 0\n",
      "episode 106 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8781543257309197  steps 422  memory 4\n",
      "=========================episode 107 ample======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 blade-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 apple-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 ample-------\n",
      "reward 0 done True action 0\n",
      "episode 107 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8805670317332803  steps 426  memory 8\n",
      "=========================episode 108 swift======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 swift-------\n",
      "reward 0 done True action 0\n",
      "episode 108 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.8817554096233645  steps 428  memory 12\n",
      "=========================episode 109 straw======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 wrath-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 straw-------\n",
      "reward 0 done True action 0\n",
      "episode 109 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.883515842226503  steps 431  memory 14\n",
      "=========================episode 110 angel======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 ashen-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 angel-------\n",
      "reward 0 done True action 0\n",
      "episode 110 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8852500654027212  steps 434  memory 17\n",
      "=========================episode 111 north======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 north-------\n",
      "reward 0 done True action 0\n",
      "episode 111 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.8863918463292362  steps 436  memory 20\n",
      "=========================episode 112 index======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 bezel-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 hymen-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 unwed-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 index-------\n",
      "reward 0 done True action 0\n",
      "episode 112 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8891968416376661  steps 441  memory 22\n",
      "optimize_model_batch -1 27\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 59, 'total': -179, 'avg': -3.0338983050847457} {'count': 54, 'total': -150, 'avg': -2.7777777777777777}\n",
      "{'count': 113, 'total': -216, 'avg': -1.9115044247787611} {'count': 0}\n",
      "{'count': 108, 'total': -108, 'avg': -1.0} {'count': 0}\n",
      "{'count': 73, 'total': -35, 'avg': -0.4794520547945205} {'count': 0}\n",
      "{'count': 26, 'total': -9, 'avg': -0.34615384615384615} {'count': 0}\n",
      "{'count': 8, 'total': -1, 'avg': -0.125} {'count': 0}\n",
      "done 441 optimizations, 441 transitions added to memory\n",
      "=========================episode 113 radio======================\n",
      "------guess 0 0 slope-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 ought-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 axion-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 radio-------\n",
      "reward 0 done True action 0\n",
      "episode 113 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.891390891175042  steps 445  memory 0\n",
      "=========================episode 114 vicar======================\n",
      "------guess 0 0 eject-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 crumb-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 acrid-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 vicar-------\n",
      "reward 0 done True action 0\n",
      "episode 114 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8935414956207473  steps 449  memory 4\n",
      "=========================episode 115 shoal======================\n",
      "------guess 0 0 billy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 cruel-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shoal-------\n",
      "reward 0 done True action 0\n",
      "episode 115 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8951264562637131  steps 452  memory 8\n",
      "=========================episode 116 fetch======================\n",
      "------guess 0 0 gloss-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 farce-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 fetch-------\n",
      "reward 0 done True action 0\n",
      "episode 116 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8966878199168998  steps 455  memory 11\n",
      "=========================episode 117 beast======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 enact-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 least-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 feast-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 beast-------\n",
      "reward 0 done True action 0\n",
      "episode 117 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8992386067316963  steps 460  memory 14\n",
      "=========================episode 118 dense======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 spend-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 dense-------\n",
      "reward 0 done True action 0\n",
      "episode 118 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9007387484403544  steps 463  memory 19\n",
      "=========================episode 119 groin======================\n",
      "------guess 0 0 mouse-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 rayon-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 crown-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 groin-------\n",
      "reward 0 done True action 0\n",
      "episode 119 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9027042529104672  steps 467  memory 22\n",
      "=========================episode 120 stein======================\n",
      "------guess 0 0 smith-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 strip-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 stoic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 staid-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 stein-------\n",
      "reward 0 done True action 0\n",
      "episode 120 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9051064934653769  steps 472  memory 26\n",
      "optimize_model_batch -1 31\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 65, 'total': -196, 'avg': -3.0153846153846153} {'count': 56, 'total': -156, 'avg': -2.7857142857142856}\n",
      "{'count': 121, 'total': -231, 'avg': -1.9090909090909092} {'count': 0}\n",
      "{'count': 116, 'total': -115, 'avg': -0.9913793103448276} {'count': 0}\n",
      "{'count': 78, 'total': -37, 'avg': -0.47435897435897434} {'count': 0}\n",
      "{'count': 28, 'total': -9, 'avg': -0.32142857142857145} {'count': 0}\n",
      "{'count': 8, 'total': -1, 'avg': -0.125} {'count': 0}\n",
      "done 472 optimizations, 472 transitions added to memory\n",
      "=========================episode 121 verso======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 poker-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 2 0 verso-------\n",
      "reward 0 done True action 0\n",
      "episode 121 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9065192737219415  steps 475  memory 0\n",
      "=========================episode 122 ideal======================\n",
      "------guess 0 0 chunk-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 rigor-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 swill-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 impel-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 ideal-------\n",
      "reward 0 done True action 0\n",
      "episode 122 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9088273210774022  steps 480  memory 3\n",
      "=========================episode 123 shown======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 smoky-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 swoop-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 shown-------\n",
      "reward 0 done True action 0\n",
      "episode 123 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9106326610782468  steps 484  memory 8\n",
      "=========================episode 124 hussy======================\n",
      "------guess 0 0 charm-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 ninth-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 holly-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 hussy-------\n",
      "reward 0 done True action 0\n",
      "episode 124 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9124022529519423  steps 488  memory 12\n",
      "=========================episode 125 niche======================\n",
      "------guess 0 0 decry-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 cache-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 niche-------\n",
      "reward 0 done True action 0\n",
      "episode 125 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9137064135006295  steps 491  memory 16\n",
      "=========================episode 126 avian======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 happy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 annul-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 aging-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 avian-------\n",
      "reward 0 done True action 0\n",
      "episode 126 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9158370097426897  steps 496  memory 19\n",
      "=========================episode 127 chair======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 charm-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 chair-------\n",
      "reward 0 done True action 0\n",
      "episode 127 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9170900334248273  steps 499  memory 24\n",
      "=========================episode 128 admit======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 habit-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 audit-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 admit-------\n",
      "reward 0 done True action 0\n",
      "episode 128 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9187317607591083  steps 503  memory 27\n",
      "optimize_model_batch -1 31\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 68, 'total': -205, 'avg': -3.014705882352941} {'count': 61, 'total': -170, 'avg': -2.7868852459016393}\n",
      "{'count': 129, 'total': -246, 'avg': -1.9069767441860466} {'count': 0}\n",
      "{'count': 124, 'total': -122, 'avg': -0.9838709677419355} {'count': 0}\n",
      "{'count': 83, 'total': -39, 'avg': -0.46987951807228917} {'count': 0}\n",
      "{'count': 30, 'total': -9, 'avg': -0.3} {'count': 0}\n",
      "{'count': 8, 'total': -1, 'avg': -0.125} {'count': 0}\n",
      "done 503 optimizations, 503 transitions added to memory\n",
      "=========================episode 129 bleat======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 petal-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 cleat-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bleat-------\n",
      "reward 0 done True action 0\n",
      "episode 129 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.920340979714102  steps 507  memory 0\n",
      "=========================episode 130 cobra======================\n",
      "------guess 0 0 bleep-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 robot-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 cobra-------\n",
      "reward 0 done True action 0\n",
      "episode 130 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9215269480192793  steps 510  memory 4\n",
      "=========================episode 131 widow======================\n",
      "------guess 0 0 swear-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 width-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 widow-------\n",
      "reward 0 done True action 0\n",
      "episode 131 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9226952595567003  steps 513  memory 7\n",
      "=========================episode 132 vegan======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 gleam-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 vegan-------\n",
      "reward 0 done True action 0\n",
      "episode 132 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9238461772013897  steps 516  memory 10\n",
      "=========================episode 133 nanny======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 gawky-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sassy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 mammy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 handy-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 fancy-------\n",
      "reward -1 done True action 0\n",
      "episode 133 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9260968628024441  steps 522  memory 13\n",
      "=========================episode 134 couch======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 woody-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sonic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 pouch-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 couch-------\n",
      "reward 0 done True action 0\n",
      "episode 134 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9279215377612339  steps 527  memory 19\n",
      "=========================episode 135 shaft======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 staff-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shaft-------\n",
      "reward 0 done True action 0\n",
      "episode 135 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.928994646260363  steps 530  memory 24\n",
      "=========================episode 136 plain======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 affix-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 plain-------\n",
      "reward 0 done True action 0\n",
      "episode 136 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9300517782553447  steps 533  memory 27\n",
      "optimize_model_batch -1 30\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 70, 'total': -209, 'avg': -2.9857142857142858} {'count': 67, 'total': -189, 'avg': -2.8208955223880596}\n",
      "{'count': 137, 'total': -261, 'avg': -1.905109489051095} {'count': 0}\n",
      "{'count': 132, 'total': -129, 'avg': -0.9772727272727273} {'count': 0}\n",
      "{'count': 86, 'total': -43, 'avg': -0.5} {'count': 0}\n",
      "{'count': 32, 'total': -11, 'avg': -0.34375} {'count': 0}\n",
      "{'count': 9, 'total': -2, 'avg': -0.2222222222222222} {'count': 0}\n",
      "done 533 optimizations, 533 transitions added to memory\n",
      "=========================episode 137 lover======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 poser-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wooer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 cover-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 mover-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 hover-------\n",
      "reward -1 done True action 0\n",
      "episode 137 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9321190606282386  steps 539  memory 0\n",
      "=========================episode 138 doubt======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 shoot-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bigot-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 doubt-------\n",
      "reward 0 done True action 0\n",
      "episode 138 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9334631932849832  steps 543  memory 6\n",
      "=========================episode 139 singe======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 penne-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lunge-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 binge-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 hinge-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 singe-------\n",
      "reward 0 done True action 0\n",
      "episode 139 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9354296531068316  steps 549  memory 10\n",
      "=========================episode 140 proof======================\n",
      "------guess 0 0 welch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 guppy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 spank-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 pivot-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 proof-------\n",
      "reward 0 done True action 0\n",
      "episode 140 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9370239006519849  steps 554  memory 16\n",
      "=========================episode 141 imply======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 mimic-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 humid-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 blimp-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 imply-------\n",
      "reward 0 done True action 0\n",
      "episode 141 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9385787860849999  steps 559  memory 21\n",
      "=========================episode 142 crank======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 quark-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 frank-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 drank-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 prank-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 crank-------\n",
      "reward 0 done True action 0\n",
      "episode 142 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9403940572910606  steps 565  memory 26\n",
      "=========================episode 143 abled======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 annex-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 abled-------\n",
      "reward 0 done True action 0\n",
      "episode 143 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9412814741661277  steps 568  memory 32\n",
      "=========================episode 144 quiet======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 tweet-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 inlet-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 quiet-------\n",
      "reward 0 done True action 0\n",
      "episode 144 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9424441788791099  steps 572  memory 35\n",
      "optimize_model_batch -1 39\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 71, 'total': -213, 'avg': -3.0} {'count': 74, 'total': -217, 'avg': -2.9324324324324325}\n",
      "{'count': 145, 'total': -285, 'avg': -1.9655172413793103} {'count': 0}\n",
      "{'count': 140, 'total': -145, 'avg': -1.0357142857142858} {'count': 0}\n",
      "{'count': 93, 'total': -52, 'avg': -0.5591397849462365} {'count': 0}\n",
      "{'count': 37, 'total': -15, 'avg': -0.40540540540540543} {'count': 0}\n",
      "{'count': 12, 'total': -3, 'avg': -0.25} {'count': 0}\n",
      "done 572 optimizations, 572 transitions added to memory\n",
      "=========================episode 145 bosom======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 dowdy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 pooch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bosom-------\n",
      "reward 0 done True action 0\n",
      "episode 145 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9435838604962227  steps 576  memory 0\n",
      "=========================episode 146 judge======================\n",
      "------guess 0 0 nanny-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 flesh-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 equip-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 butte-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 judge-------\n",
      "reward 0 done True action 0\n",
      "episode 146 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9449767799435927  steps 581  memory 4\n",
      "=========================episode 147 groin======================\n",
      "------guess 0 0 great-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 grimy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 groin-------\n",
      "reward 0 done True action 0\n",
      "episode 147 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9457959689670266  steps 584  memory 9\n",
      "=========================episode 148 slung======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 silky-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 slump-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 slung-------\n",
      "reward 0 done True action 0\n",
      "episode 148 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9468692806936012  steps 588  memory 12\n",
      "=========================episode 149 bound======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 bosom-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bobby-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bough-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 bound-------\n",
      "reward 0 done True action 0\n",
      "episode 149 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9481810828272742  steps 593  memory 16\n",
      "=========================episode 150 truck======================\n",
      "------guess 0 0 carve-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 brick-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 truck-------\n",
      "reward 0 done True action 0\n",
      "episode 150 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9489525659958457  steps 596  memory 21\n",
      "=========================episode 151 large======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 barge-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 large-------\n",
      "reward 0 done True action 0\n",
      "episode 151 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9497125632764082  steps 599  memory 24\n",
      "=========================episode 152 spade======================\n",
      "------guess 0 0 rural-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 handy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 evade-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 spade-------\n",
      "reward 0 done True action 0\n",
      "episode 152 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9507083212395379  steps 603  memory 27\n",
      "optimize_model_batch -1 31\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 75, 'total': -224, 'avg': -2.986666666666667} {'count': 78, 'total': -229, 'avg': -2.9358974358974357}\n",
      "{'count': 153, 'total': -300, 'avg': -1.9607843137254901} {'count': 0}\n",
      "{'count': 148, 'total': -152, 'avg': -1.027027027027027} {'count': 0}\n",
      "{'count': 98, 'total': -54, 'avg': -0.5510204081632653} {'count': 0}\n",
      "{'count': 39, 'total': -15, 'avg': -0.38461538461538464} {'count': 0}\n",
      "{'count': 12, 'total': -3, 'avg': -0.25} {'count': 0}\n",
      "done 603 optimizations, 603 transitions added to memory\n",
      "=========================episode 153 thigh======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 pithy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shift-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 thing-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 thigh-------\n",
      "reward 0 done True action 0\n",
      "episode 153 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9519253371244049  steps 608  memory 0\n",
      "=========================episode 154 gusty======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 musty-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 dusty-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 gusty-------\n",
      "reward 0 done True action 0\n",
      "episode 154 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9528772792296721  steps 612  memory 5\n",
      "=========================episode 155 couch======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 sound-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 cough-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 couch-------\n",
      "reward 0 done True action 0\n",
      "episode 155 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9538103716183199  steps 616  memory 9\n",
      "=========================episode 156 grape======================\n",
      "------guess 0 0 wedge-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 agate-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 glaze-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 grave-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 grace-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 grape-------\n",
      "reward 0 done True action 0\n",
      "episode 156 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9551754814407332  steps 622  memory 13\n",
      "=========================episode 157 magic======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 papal-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 maxim-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 magic-------\n",
      "reward 0 done True action 0\n",
      "episode 157 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9560630663765926  steps 626  memory 19\n",
      "=========================episode 158 jumbo======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 dodgy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 snoop-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 limbo-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 jumbo-------\n",
      "reward 0 done True action 0\n",
      "episode 158 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9571478731329598  steps 631  memory 23\n",
      "=========================episode 159 rigid======================\n",
      "------guess 0 0 laugh-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 goofy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 egret-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bring-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 rigid-------\n",
      "reward 0 done True action 0\n",
      "episode 159 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9582058959150801  steps 636  memory 28\n",
      "=========================episode 160 vouch======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 mogul-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 pound-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 vouch-------\n",
      "reward 0 done True action 0\n",
      "episode 160 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9590334746239171  steps 640  memory 33\n",
      "optimize_model_batch -1 37\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 77, 'total': -233, 'avg': -3.0259740259740258} {'count': 84, 'total': -249, 'avg': -2.9642857142857144}\n",
      "{'count': 161, 'total': -321, 'avg': -1.9937888198757765} {'count': 0}\n",
      "{'count': 156, 'total': -165, 'avg': -1.0576923076923077} {'count': 0}\n",
      "{'count': 106, 'total': -59, 'avg': -0.5566037735849056} {'count': 0}\n",
      "{'count': 43, 'total': -16, 'avg': -0.37209302325581395} {'count': 0}\n",
      "{'count': 13, 'total': -3, 'avg': -0.23076923076923078} {'count': 0}\n",
      "done 640 optimizations, 640 transitions added to memory\n",
      "=========================episode 161 siege======================\n",
      "------guess 0 0 chain-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 guild-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 vigor-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 siege-------\n",
      "reward 0 done True action 0\n",
      "episode 161 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.959844666176376  steps 644  memory 0\n",
      "=========================episode 162 deity======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 empty-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 testy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 hefty-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 deity-------\n",
      "reward 0 done True action 0\n",
      "episode 162 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9608361049010129  steps 649  memory 4\n",
      "=========================episode 163 picky======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 whiny-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 silky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 picky-------\n",
      "reward 0 done True action 0\n",
      "episode 163 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9616116019824479  steps 653  memory 9\n",
      "=========================episode 164 tibia======================\n",
      "------guess 0 0 chess-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 taboo-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 tibia-------\n",
      "reward 0 done True action 0\n",
      "episode 164 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.962183130770675  steps 656  memory 13\n",
      "=========================episode 165 forte======================\n",
      "------guess 0 0 drive-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 purge-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 forte-------\n",
      "reward 0 done True action 0\n",
      "episode 165 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9627461506037842  steps 659  memory 16\n",
      "=========================episode 166 graze======================\n",
      "------guess 0 0 swamp-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 grace-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 grave-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 grade-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 graze-------\n",
      "reward 0 done True action 0\n",
      "episode 166 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.96366595142266  steps 664  memory 19\n",
      "=========================episode 167 stint======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 midst-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 swift-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 spilt-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 stint-------\n",
      "reward 0 done True action 0\n",
      "episode 167 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9645630422784014  steps 669  memory 24\n",
      "=========================episode 168 wooer======================\n",
      "------guess 0 0 virus-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 honor-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wooer-------\n",
      "reward 0 done True action 0\n",
      "episode 168 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9650906298452442  steps 672  memory 29\n",
      "optimize_model_batch -1 32\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 82, 'total': -246, 'avg': -3.0} {'count': 87, 'total': -260, 'avg': -2.9885057471264367}\n",
      "{'count': 169, 'total': -337, 'avg': -1.9940828402366864} {'count': 0}\n",
      "{'count': 164, 'total': -173, 'avg': -1.0548780487804879} {'count': 0}\n",
      "{'count': 111, 'total': -62, 'avg': -0.5585585585585585} {'count': 0}\n",
      "{'count': 46, 'total': -16, 'avg': -0.34782608695652173} {'count': 0}\n",
      "{'count': 13, 'total': -3, 'avg': -0.23076923076923078} {'count': 0}\n",
      "done 672 optimizations, 672 transitions added to memory\n",
      "=========================episode 169 scree======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 fried-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 renew-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 spree-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 scree-------\n",
      "reward 0 done True action 0\n",
      "episode 169 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9659525452654006  steps 677  memory 0\n",
      "=========================episode 170 heady======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 mealy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 beady-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 heady-------\n",
      "reward 0 done True action 0\n",
      "episode 170 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9666267300396739  steps 681  memory 5\n",
      "=========================episode 171 snaky======================\n",
      "------guess 0 0 envoy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 angry-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 inlay-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 snaky-------\n",
      "reward 0 done True action 0\n",
      "episode 171 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9672875650609802  steps 685  memory 9\n",
      "=========================episode 172 oddly======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 owing-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 2 0 oddly-------\n",
      "reward 0 done True action 0\n",
      "episode 172 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9677745897680832  steps 688  memory 13\n",
      "=========================episode 173 story======================\n",
      "------guess 0 0 first-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 stern-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 storm-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 story-------\n",
      "reward 0 done True action 0\n",
      "episode 173 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9684126956439092  steps 692  memory 16\n",
      "=========================episode 174 dingo======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 limbo-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 hippo-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 dingo-------\n",
      "reward 0 done True action 0\n",
      "episode 174 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9690381661768231  steps 696  memory 20\n",
      "=========================episode 175 deuce======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 nudge-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 deuce-------\n",
      "reward 0 done True action 0\n",
      "episode 175 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9694991278287826  steps 699  memory 24\n",
      "=========================episode 176 robin======================\n",
      "------guess 0 0 gross-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 offer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 court-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 rowdy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 robin-------\n",
      "reward 0 done True action 0\n",
      "episode 176 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9702521970459025  steps 704  memory 27\n",
      "optimize_model_batch -1 32\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 85, 'total': -256, 'avg': -3.011764705882353} {'count': 92, 'total': -274, 'avg': -2.9782608695652173}\n",
      "{'count': 177, 'total': -353, 'avg': -1.9943502824858756} {'count': 0}\n",
      "{'count': 172, 'total': -181, 'avg': -1.052325581395349} {'count': 0}\n",
      "{'count': 117, 'total': -64, 'avg': -0.5470085470085471} {'count': 0}\n",
      "{'count': 48, 'total': -16, 'avg': -0.3333333333333333} {'count': 0}\n",
      "{'count': 13, 'total': -3, 'avg': -0.23076923076923078} {'count': 0}\n",
      "done 704 optimizations, 704 transitions added to memory\n",
      "=========================episode 177 voice======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 coupe-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 voice-------\n",
      "reward 0 done True action 0\n",
      "episode 177 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9706950841329592  steps 707  memory 0\n",
      "=========================episode 178 shift======================\n",
      "------guess 0 0 panel-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 crook-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 muddy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 wight-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 shift-------\n",
      "reward 0 done True action 0\n",
      "episode 178 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9714186250837188  steps 712  memory 3\n",
      "=========================episode 179 verve======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 eerie-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 verve-------\n",
      "reward 0 done True action 0\n",
      "episode 179 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9718441463196998  steps 715  memory 8\n",
      "=========================episode 180 sappy======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 iliac-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 gaudy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 nanny-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 sassy-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 savvy-------\n",
      "reward -1 done True action 0\n",
      "episode 180 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9726762775527075  steps 721  memory 11\n",
      "=========================episode 181 spicy======================\n",
      "------guess 0 0 cargo-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 spice-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 spicy-------\n",
      "reward 0 done True action 0\n",
      "episode 181 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9730830747827719  steps 724  memory 17\n",
      "=========================episode 182 drone======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 grope-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 drone-------\n",
      "reward 0 done True action 0\n",
      "episode 182 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9734838155911059  steps 727  memory 20\n",
      "=========================episode 183 warty======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 party-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 warty-------\n",
      "reward 0 done True action 0\n",
      "episode 183 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9738785901460818  steps 730  memory 23\n",
      "=========================episode 184 dense======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 lunge-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sense-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 dense-------\n",
      "reward 0 done True action 0\n",
      "episode 184 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9743958287162874  steps 734  memory 26\n",
      "optimize_model_batch -1 30\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 87, 'total': -262, 'avg': -3.0114942528735633} {'count': 98, 'total': -291, 'avg': -2.9693877551020407}\n",
      "{'count': 185, 'total': -368, 'avg': -1.9891891891891893} {'count': 0}\n",
      "{'count': 180, 'total': -188, 'avg': -1.0444444444444445} {'count': 0}\n",
      "{'count': 120, 'total': -68, 'avg': -0.5666666666666667} {'count': 0}\n",
      "{'count': 50, 'total': -18, 'avg': -0.36} {'count': 0}\n",
      "{'count': 14, 'total': -4, 'avg': -0.2857142857142857} {'count': 0}\n",
      "done 734 optimizations, 734 transitions added to memory\n",
      "=========================episode 185 spiel======================\n",
      "------guess 0 0 gipsy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 spill-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 spiel-------\n",
      "reward 0 done True action 0\n",
      "episode 185 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9747770251647728  steps 737  memory 0\n",
      "=========================episode 186 fresh======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 breed-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 press-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 fresh-------\n",
      "reward 0 done True action 0\n",
      "episode 186 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9752764735296606  steps 741  memory 3\n",
      "=========================episode 187 brink======================\n",
      "------guess 0 0 guilt-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 dried-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 prior-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 briny-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 brink-------\n",
      "reward 0 done True action 0\n",
      "episode 187 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9758868995731831  steps 746  memory 7\n",
      "=========================episode 188 pivot======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 ought-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 pivot-------\n",
      "reward 0 done True action 0\n",
      "episode 188 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.976245896868695  steps 749  memory 12\n",
      "=========================episode 189 skimp======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 gummy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 blimp-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 skimp-------\n",
      "reward 0 done True action 0\n",
      "episode 189 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.976716259625103  steps 753  memory 15\n",
      "=========================episode 190 trace======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 trade-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 trace-------\n",
      "reward 0 done True action 0\n",
      "episode 190 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.977062909358071  steps 756  memory 19\n",
      "=========================episode 191 check======================\n",
      "------guess 0 0 krill-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 shook-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 whack-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 chuck-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 check-------\n",
      "reward 0 done True action 0\n",
      "episode 191 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9776292281438344  steps 761  memory 22\n",
      "=========================episode 192 warty======================\n",
      "------guess 0 0 fuzzy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 parry-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 tardy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 warty-------\n",
      "reward 0 done True action 0\n",
      "episode 192 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9780721991057384  steps 765  memory 27\n",
      "optimize_model_batch -1 31\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 91, 'total': -275, 'avg': -3.021978021978022} {'count': 102, 'total': -301, 'avg': -2.950980392156863}\n",
      "{'count': 193, 'total': -383, 'avg': -1.9844559585492227} {'count': 0}\n",
      "{'count': 188, 'total': -195, 'avg': -1.0372340425531914} {'count': 0}\n",
      "{'count': 125, 'total': -70, 'avg': -0.56} {'count': 0}\n",
      "{'count': 52, 'total': -18, 'avg': -0.34615384615384615} {'count': 0}\n",
      "{'count': 14, 'total': -4, 'avg': -0.2857142857142857} {'count': 0}\n",
      "done 765 optimizations, 765 transitions added to memory\n",
      "=========================episode 193 truer======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 trend-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 truer-------\n",
      "reward 0 done True action 0\n",
      "episode 193 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9783986615298241  steps 768  memory 0\n",
      "=========================episode 194 hobby======================\n",
      "------guess 0 0 rusty-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 bawdy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lobby-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 hobby-------\n",
      "reward 0 done True action 0\n",
      "episode 194 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9788263966898835  steps 772  memory 3\n",
      "=========================episode 195 entry======================\n",
      "------guess 0 0 sleek-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 caper-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 write-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 retro-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 entry-------\n",
      "reward 0 done True action 0\n",
      "episode 195 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9793491748182874  steps 777  memory 7\n",
      "=========================episode 196 write======================\n",
      "------guess 0 0 strip-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 irate-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 write-------\n",
      "reward 0 done True action 0\n",
      "episode 196 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9796566255508393  steps 780  memory 12\n",
      "=========================episode 197 kebab======================\n",
      "------guess 0 0 allay-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 bread-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 kebab-------\n",
      "reward 0 done True action 0\n",
      "episode 197 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.979959498938316  steps 783  memory 15\n",
      "=========================episode 198 foamy======================\n",
      "------guess 0 0 tower-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 comic-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 moldy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 foamy-------\n",
      "reward 0 done True action 0\n",
      "episode 198 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9803563274469347  steps 787  memory 18\n",
      "=========================episode 199 route======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 trope-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 route-------\n",
      "reward 0 done True action 0\n",
      "episode 199 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9806487836303224  steps 790  memory 22\n",
      "=========================episode 200 lumpy======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 dummy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 jumpy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 lumpy-------\n",
      "reward 0 done True action 0\n",
      "episode 200 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.98103196338757  steps 794  memory 25\n",
      "optimize_model_batch -1 29\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 96, 'total': -289, 'avg': -3.0104166666666665} {'count': 105, 'total': -308, 'avg': -2.933333333333333}\n",
      "{'count': 201, 'total': -396, 'avg': -1.9701492537313432} {'count': 0}\n",
      "{'count': 196, 'total': -200, 'avg': -1.0204081632653061} {'count': 0}\n",
      "{'count': 129, 'total': -71, 'avg': -0.5503875968992248} {'count': 0}\n",
      "{'count': 53, 'total': -18, 'avg': -0.33962264150943394} {'count': 0}\n",
      "{'count': 14, 'total': -4, 'avg': -0.2857142857142857} {'count': 0}\n",
      "done 794 optimizations, 794 transitions added to memory\n",
      "=========================episode 201 lobby======================\n",
      "------guess 0 0 usurp-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 exact-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bongo-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 hobby-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 lobby-------\n",
      "reward 0 done True action 0\n",
      "episode 201 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9815002858801808  steps 799  memory 0\n",
      "=========================episode 202 adult======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 swath-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 tidal-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 adult-------\n",
      "reward 0 done True action 0\n",
      "episode 202 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.981866604763199  steps 803  memory 5\n",
      "=========================episode 203 cluck======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 jumpy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 swung-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 chuck-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 cluck-------\n",
      "reward 0 done True action 0\n",
      "episode 203 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9823143198868206  steps 808  memory 9\n",
      "=========================episode 204 dwelt======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 inlet-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 elect-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 dwelt-------\n",
      "reward 0 done True action 0\n",
      "episode 204 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9826645198165338  steps 812  memory 14\n",
      "=========================episode 205 crony======================\n",
      "------guess 0 0 apple-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 quoth-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 fjord-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 wrong-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 crony-------\n",
      "reward 0 done True action 0\n",
      "episode 205 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9830925343472947  steps 817  memory 18\n",
      "=========================episode 206 aroma======================\n",
      "------guess 0 0 attic-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 azure-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 apron-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 aroma-------\n",
      "reward 0 done True action 0\n",
      "episode 206 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9834273245982388  steps 821  memory 23\n",
      "=========================episode 207 amuse======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 halve-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 amuse-------\n",
      "reward 0 done True action 0\n",
      "episode 207 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.983674059590559  steps 824  memory 27\n",
      "=========================episode 208 husky======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 spiny-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 musky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 husky-------\n",
      "reward 0 done True action 0\n",
      "episode 208 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9839973348701808  steps 828  memory 30\n",
      "optimize_model_batch -1 34\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 99, 'total': -300, 'avg': -3.0303030303030303} {'count': 110, 'total': -323, 'avg': -2.9363636363636365}\n",
      "{'count': 209, 'total': -414, 'avg': -1.9808612440191387} {'count': 0}\n",
      "{'count': 204, 'total': -210, 'avg': -1.0294117647058822} {'count': 0}\n",
      "{'count': 136, 'total': -74, 'avg': -0.5441176470588235} {'count': 0}\n",
      "{'count': 56, 'total': -18, 'avg': -0.32142857142857145} {'count': 0}\n",
      "{'count': 14, 'total': -4, 'avg': -0.2857142857142857} {'count': 0}\n",
      "done 828 optimizations, 828 transitions added to memory\n",
      "=========================episode 209 civil======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 wispy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 minim-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 vivid-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 civil-------\n",
      "reward 0 done True action 0\n",
      "episode 209 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9843924420800172  steps 833  memory 0\n",
      "=========================episode 210 dingy======================\n",
      "------guess 0 0 sassy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 lofty-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 kinky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 ninny-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 windy-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 dingy-------\n",
      "reward 0 done True action 0\n",
      "episode 210 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.984853715126953  steps 839  memory 5\n",
      "=========================episode 211 ledge======================\n",
      "------guess 0 0 prawn-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 husky-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 medic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 ledge-------\n",
      "reward 0 done True action 0\n",
      "episode 211 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9851536316619132  steps 843  memory 11\n",
      "=========================episode 212 adobe======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 alone-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 abode-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 adobe-------\n",
      "reward 0 done True action 0\n",
      "episode 212 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9854476094515838  steps 847  memory 15\n",
      "=========================episode 213 colon======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 bongo-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 colon-------\n",
      "reward 0 done True action 0\n",
      "episode 213 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9856642663209885  steps 850  memory 19\n",
      "=========================episode 214 world======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 dowry-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 world-------\n",
      "reward 0 done True action 0\n",
      "episode 214 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.985877697589836  steps 853  memory 22\n",
      "=========================episode 215 joint======================\n",
      "------guess 0 0 mafia-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 spice-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 joint-------\n",
      "reward 0 done True action 0\n",
      "episode 215 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9860879512810624  steps 856  memory 25\n",
      "=========================episode 216 aorta======================\n",
      "------guess 0 0 phone-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 folly-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 roast-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 aorta-------\n",
      "reward 0 done True action 0\n",
      "episode 216 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9863634283027184  steps 860  memory 28\n",
      "optimize_model_batch -1 32\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 103, 'total': -313, 'avg': -3.0388349514563107} {'count': 114, 'total': -334, 'avg': -2.9298245614035086}\n",
      "{'count': 217, 'total': -430, 'avg': -1.9815668202764978} {'count': 0}\n",
      "{'count': 212, 'total': -218, 'avg': -1.028301886792453} {'count': 0}\n",
      "{'count': 141, 'total': -77, 'avg': -0.5460992907801419} {'count': 0}\n",
      "{'count': 58, 'total': -19, 'avg': -0.3275862068965517} {'count': 0}\n",
      "{'count': 15, 'total': -4, 'avg': -0.26666666666666666} {'count': 0}\n",
      "done 860 optimizations, 860 transitions added to memory\n",
      "=========================episode 217 brute======================\n",
      "------guess 0 0 crush-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 gruel-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 prune-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 brute-------\n",
      "reward 0 done True action 0\n",
      "episode 217 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9866334505138721  steps 864  memory 0\n",
      "=========================episode 218 smoky======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 blown-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 smoky-------\n",
      "reward 0 done True action 0\n",
      "episode 218 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9868324525099202  steps 867  memory 4\n",
      "=========================episode 219 quilt======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 until-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 built-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 guilt-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 quilt-------\n",
      "reward 0 done True action 0\n",
      "episode 219 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9871575604158215  steps 872  memory 7\n",
      "=========================episode 220 villa======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 apply-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 caulk-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 villa-------\n",
      "reward 0 done True action 0\n",
      "episode 220 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.987411857757566  steps 876  memory 12\n",
      "=========================episode 221 amply======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 maxim-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 album-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 amply-------\n",
      "reward 0 done True action 0\n",
      "episode 221 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9876611196745695  steps 880  memory 16\n",
      "=========================episode 222 druid======================\n",
      "------guess 0 0 moist-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 filer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 druid-------\n",
      "reward 0 done True action 0\n",
      "episode 222 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.987844821670085  steps 883  memory 20\n",
      "=========================episode 223 easel======================\n",
      "------guess 0 0 allow-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 mealy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 valve-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 easel-------\n",
      "reward 0 done True action 0\n",
      "episode 223 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9880855103272104  steps 887  memory 23\n",
      "=========================episode 224 party======================\n",
      "------guess 0 0 skimp-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 penny-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 party-------\n",
      "reward 0 done True action 0\n",
      "episode 224 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9882628939690575  steps 890  memory 27\n",
      "optimize_model_batch -1 30\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 107, 'total': -323, 'avg': -3.0186915887850465} {'count': 118, 'total': -346, 'avg': -2.9322033898305087}\n",
      "{'count': 225, 'total': -444, 'avg': -1.9733333333333334} {'count': 0}\n",
      "{'count': 220, 'total': -224, 'avg': -1.018181818181818} {'count': 0}\n",
      "{'count': 146, 'total': -78, 'avg': -0.5342465753424658} {'count': 0}\n",
      "{'count': 59, 'total': -19, 'avg': -0.3220338983050847} {'count': 0}\n",
      "{'count': 15, 'total': -4, 'avg': -0.26666666666666666} {'count': 0}\n",
      "done 890 optimizations, 890 transitions added to memory\n",
      "=========================episode 225 spook======================\n",
      "------guess 0 0 eagle-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 hippy-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 2 0 scoop-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 spoof-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 spoon-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 spook-------\n",
      "reward 0 done True action 0\n",
      "episode 225 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9886097778754867  steps 896  memory 0\n",
      "=========================episode 226 talon======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 taboo-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 talon-------\n",
      "reward 0 done True action 0\n",
      "episode 226 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9887793561904109  steps 899  memory 6\n",
      "=========================episode 227 alone======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 above-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 awoke-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 anode-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 alone-------\n",
      "reward 0 done True action 0\n",
      "episode 227 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9890563948731684  steps 904  memory 9\n",
      "=========================episode 228 tempo======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 covet-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 extol-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 tempo-------\n",
      "reward 0 done True action 0\n",
      "episode 228 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9892730927734866  steps 908  memory 14\n",
      "=========================episode 229 filth======================\n",
      "------guess 0 0 blend-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 gully-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 valor-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 filth-------\n",
      "reward 0 done True action 0\n",
      "episode 229 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.989485499767887  steps 912  memory 18\n",
      "=========================episode 230 right======================\n",
      "------guess 0 0 butte-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 taffy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 midst-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 pivot-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 right-------\n",
      "reward 0 done True action 0\n",
      "episode 230 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.989745103703596  steps 917  memory 22\n",
      "=========================episode 231 crook======================\n",
      "------guess 0 0 river-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 agora-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 prowl-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 froth-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 crony-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 cross-------\n",
      "reward -1 done True action 0\n",
      "episode 231 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9900481816921516  steps 923  memory 27\n",
      "=========================episode 232 stoop======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 stoop-------\n",
      "reward 0 done True action 0\n",
      "episode 232 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9901472039388127  steps 925  memory 33\n",
      "optimize_model_batch -1 35\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 111, 'total': -341, 'avg': -3.0720720720720722} {'count': 122, 'total': -356, 'avg': -2.918032786885246}\n",
      "{'count': 233, 'total': -464, 'avg': -1.9914163090128756} {'count': 0}\n",
      "{'count': 227, 'total': -237, 'avg': -1.0440528634361232} {'count': 0}\n",
      "{'count': 152, 'total': -85, 'avg': -0.5592105263157895} {'count': 0}\n",
      "{'count': 63, 'total': -22, 'avg': -0.3492063492063492} {'count': 0}\n",
      "{'count': 17, 'total': -5, 'avg': -0.29411764705882354} {'count': 0}\n",
      "done 925 optimizations, 925 transitions added to memory\n",
      "=========================episode 233 blast======================\n",
      "------guess 0 0 weird-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 spank-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 chasm-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 boast-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 blast-------\n",
      "reward 0 done True action 0\n",
      "episode 233 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9903904703403303  steps 930  memory 0\n",
      "=========================episode 234 scone======================\n",
      "------guess 0 0 erase-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 spoke-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shove-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 scone-------\n",
      "reward 0 done True action 0\n",
      "episode 234 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9905807517764899  steps 934  memory 5\n",
      "=========================episode 235 skill======================\n",
      "------guess 0 0 prone-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 basic-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 whisk-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 skiff-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 skill-------\n",
      "reward 0 done True action 0\n",
      "episode 235 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9908133138437554  steps 939  memory 9\n",
      "=========================episode 236 mambo======================\n",
      "------guess 0 0 tidal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 shaky-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 rumba-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 mambo-------\n",
      "reward 0 done True action 0\n",
      "episode 236 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9909952224175634  steps 943  memory 14\n",
      "=========================episode 237 theft======================\n",
      "------guess 0 0 gipsy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 known-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 extra-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 duvet-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 cleft-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 theft-------\n",
      "reward 0 done True action 0\n",
      "episode 237 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9912613538145267  steps 949  memory 18\n",
      "=========================episode 238 threw======================\n",
      "------guess 0 0 title-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 tuber-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 threw-------\n",
      "reward 0 done True action 0\n",
      "episode 238 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9913914553067235  steps 952  memory 24\n",
      "=========================episode 239 roach======================\n",
      "------guess 0 0 wrist-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 polar-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 roach-------\n",
      "reward 0 done True action 0\n",
      "episode 239 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9915196198400468  steps 955  memory 27\n",
      "=========================episode 240 stole======================\n",
      "------guess 0 0 write-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 those-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 stove-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 stone-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 stoke-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 stole-------\n",
      "reward 0 done True action 0\n",
      "episode 240 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.99177025295098  steps 961  memory 30\n",
      "optimize_model_batch -1 36\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 119, 'total': -369, 'avg': -3.100840336134454} {'count': 122, 'total': -356, 'avg': -2.918032786885246}\n",
      "{'count': 241, 'total': -484, 'avg': -2.008298755186722} {'count': 0}\n",
      "{'count': 235, 'total': -249, 'avg': -1.0595744680851065} {'count': 0}\n",
      "{'count': 158, 'total': -91, 'avg': -0.5759493670886076} {'count': 0}\n",
      "{'count': 67, 'total': -24, 'avg': -0.3582089552238806} {'count': 0}\n",
      "{'count': 19, 'total': -5, 'avg': -0.2631578947368421} {'count': 0}\n",
      "done 961 optimizations, 961 transitions added to memory\n",
      "=========================episode 241 model======================\n",
      "------guess 0 0 raven-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 filet-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sleep-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 model-------\n",
      "reward 0 done True action 0\n",
      "episode 241 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9919332128609004  steps 965  memory 0\n",
      "=========================episode 242 flyer======================\n",
      "------guess 0 0 roomy-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 0 crypt-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 layer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 flyer-------\n",
      "reward 0 done True action 0\n",
      "episode 242 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9920929459484066  steps 969  memory 4\n",
      "=========================episode 243 fiend======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 spied-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 yield-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 fiend-------\n",
      "reward 0 done True action 0\n",
      "episode 243 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9922495161088634  steps 973  memory 8\n",
      "=========================episode 244 robin======================\n",
      "------guess 0 0 rigid-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 relic-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 ratio-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 robin-------\n",
      "reward 0 done True action 0\n",
      "episode 244 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9924029859724224  steps 977  memory 12\n",
      "=========================episode 245 brood======================\n",
      "------guess 0 0 shore-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 group-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 droit-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 broad-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 brood-------\n",
      "reward 0 done True action 0\n",
      "episode 245 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9925905569170853  steps 982  memory 16\n",
      "=========================episode 246 gross======================\n",
      "------guess 0 0 liver-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 round-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 crock-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 broth-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 gross-------\n",
      "reward 0 done True action 0\n",
      "episode 246 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9927734967186236  steps 987  memory 21\n",
      "=========================episode 247 crowd======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 prior-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 crowd-------\n",
      "reward 0 done True action 0\n",
      "episode 247 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9928810853359353  steps 990  memory 26\n",
      "=========================episode 248 minus======================\n",
      "------guess 0 0 icily-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 opium-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 minus-------\n",
      "reward 0 done True action 0\n",
      "episode 248 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9929870721674146  steps 993  memory 29\n",
      "optimize_model_batch -1 32\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 125, 'total': -388, 'avg': -3.104} {'count': 124, 'total': -361, 'avg': -2.911290322580645}\n",
      "{'count': 249, 'total': -500, 'avg': -2.0080321285140563} {'count': 0}\n",
      "{'count': 243, 'total': -257, 'avg': -1.0576131687242798} {'count': 0}\n",
      "{'count': 164, 'total': -93, 'avg': -0.5670731707317073} {'count': 0}\n",
      "{'count': 69, 'total': -24, 'avg': -0.34782608695652173} {'count': 0}\n",
      "{'count': 19, 'total': -5, 'avg': -0.2631578947368421} {'count': 0}\n",
      "done 993 optimizations, 993 transitions added to memory\n",
      "=========================episode 249 dully======================\n",
      "------guess 0 0 today-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 dilly-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 dully-------\n",
      "reward 0 done True action 0\n",
      "episode 249 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9930914810605455  steps 996  memory 0\n",
      "=========================episode 250 older======================\n",
      "------guess 0 0 slept-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 older-------\n",
      "reward 0 done True action 0\n",
      "episode 250 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9931602219725401  steps 998  memory 3\n",
      "=========================episode 251 poise======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 dodge-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 coupe-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 poise-------\n",
      "reward 0 done True action 0\n",
      "episode 251 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.993295658651771  steps 1002  memory 5\n",
      "=========================episode 252 eying======================\n",
      "------guess 0 0 filth-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 seize-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 crime-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 eking-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 eying-------\n",
      "reward 0 done True action 0\n",
      "episode 252 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9934611894294509  steps 1007  memory 9\n",
      "=========================episode 253 organ======================\n",
      "------guess 0 0 noisy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 ocean-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 organ-------\n",
      "reward 0 done True action 0\n",
      "episode 253 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9935585396361494  steps 1010  memory 14\n",
      "=========================episode 254 loser======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 wooer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 mover-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 poker-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 corer-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 boxer-------\n",
      "reward -1 done True action 0\n",
      "episode 254 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9937489135603714  steps 1016  memory 17\n",
      "=========================episode 255 cease======================\n",
      "------guess 0 0 miner-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 swept-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 cause-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 chase-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 cease-------\n",
      "reward 0 done True action 0\n",
      "episode 255 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9939032534344844  steps 1021  memory 23\n",
      "=========================episode 256 scamp======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 snack-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 scalp-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 scamp-------\n",
      "reward 0 done True action 0\n",
      "episode 256 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.994023977104994  steps 1025  memory 28\n",
      "optimize_model_batch -1 32\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 130, 'total': -401, 'avg': -3.0846153846153848} {'count': 127, 'total': -373, 'avg': -2.937007874015748}\n",
      "{'count': 257, 'total': -517, 'avg': -2.0116731517509727} {'count': 0}\n",
      "{'count': 250, 'total': -267, 'avg': -1.068} {'count': 0}\n",
      "{'count': 169, 'total': -98, 'avg': -0.5798816568047337} {'count': 0}\n",
      "{'count': 72, 'total': -26, 'avg': -0.3611111111111111} {'count': 0}\n",
      "{'count': 20, 'total': -6, 'avg': -0.3} {'count': 0}\n",
      "done 1025 optimizations, 1025 transitions added to memory\n",
      "=========================episode 257 tweak======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 bleat-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 tweak-------\n",
      "reward 0 done True action 0\n",
      "episode 257 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9941129484947884  steps 1028  memory 0\n",
      "=========================episode 258 query======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 mercy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 fiery-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 query-------\n",
      "reward 0 done True action 0\n",
      "episode 258 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.994229519924903  steps 1032  memory 3\n",
      "=========================episode 259 dingo======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 couch-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 limbo-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 dingo-------\n",
      "reward 0 done True action 0\n",
      "episode 259 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9943437830860469  steps 1036  memory 7\n",
      "=========================episode 260 sneak======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 navel-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sedan-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 sneak-------\n",
      "reward 0 done True action 0\n",
      "episode 260 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.994455783685008  steps 1040  memory 11\n",
      "=========================episode 261 puffy======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 bushy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 dumpy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 puffy-------\n",
      "reward 0 done True action 0\n",
      "episode 261 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9945655665235191  steps 1044  memory 15\n",
      "=========================episode 262 steel======================\n",
      "------guess 0 0 medic-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 prone-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 label-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 steel-------\n",
      "reward 0 done True action 0\n",
      "episode 262 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9946731755161796  steps 1048  memory 19\n",
      "=========================episode 263 jumbo======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 could-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 buxom-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 gumbo-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 jumbo-------\n",
      "reward 0 done True action 0\n",
      "episode 263 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9948046952812948  steps 1053  memory 23\n",
      "=========================episode 264 swoop======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 kiosk-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 spoon-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 scoop-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 sloop-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 swoop-------\n",
      "reward 0 done True action 0\n",
      "episode 264 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9949582397403091  steps 1059  memory 28\n",
      "optimize_model_batch -1 34\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 131, 'total': -404, 'avg': -3.0839694656488548} {'count': 134, 'total': -396, 'avg': -2.955223880597015}\n",
      "{'count': 265, 'total': -535, 'avg': -2.018867924528302} {'count': 0}\n",
      "{'count': 258, 'total': -277, 'avg': -1.073643410852713} {'count': 0}\n",
      "{'count': 176, 'total': -101, 'avg': -0.5738636363636364} {'count': 0}\n",
      "{'count': 74, 'total': -27, 'avg': -0.36486486486486486} {'count': 0}\n",
      "{'count': 21, 'total': -6, 'avg': -0.2857142857142857} {'count': 0}\n",
      "done 1059 optimizations, 1059 transitions added to memory\n",
      "=========================episode 265 chuck======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 squib-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 pluck-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 chuck-------\n",
      "reward 0 done True action 0\n",
      "episode 265 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9950580732823202  steps 1063  memory 0\n",
      "=========================episode 266 alien======================\n",
      "------guess 0 0 elate-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 clean-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 alien-------\n",
      "reward 0 done True action 0\n",
      "episode 266 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9951316489857702  steps 1066  memory 4\n",
      "=========================episode 267 lucid======================\n",
      "------guess 0 0 finer-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 quail-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 tulip-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 lucid-------\n",
      "reward 0 done True action 0\n",
      "episode 267 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9952280487946604  steps 1070  memory 7\n",
      "=========================episode 268 theta======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 theta-------\n",
      "reward 0 done True action 0\n",
      "episode 268 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9952755305024944  steps 1072  memory 11\n",
      "=========================episode 269 peril======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 reply-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 peril-------\n",
      "reward 0 done True action 0\n",
      "episode 269 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9953458686897168  steps 1075  memory 13\n",
      "=========================episode 270 quell======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 beefy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 spend-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 quell-------\n",
      "reward 0 done True action 0\n",
      "episode 270 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.995438026664265  steps 1079  memory 16\n",
      "=========================episode 271 grief======================\n",
      "------guess 0 0 awful-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 force-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 brief-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 grief-------\n",
      "reward 0 done True action 0\n",
      "episode 271 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9955283597886516  steps 1083  memory 20\n",
      "=========================episode 272 outgo======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 outgo-------\n",
      "reward 0 done True action 0\n",
      "episode 272 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9955728533521685  steps 1085  memory 24\n",
      "optimize_model_batch -1 26\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 134, 'total': -412, 'avg': -3.074626865671642} {'count': 139, 'total': -406, 'avg': -2.920863309352518}\n",
      "{'count': 273, 'total': -545, 'avg': -1.9963369963369964} {'count': 0}\n",
      "{'count': 264, 'total': -281, 'avg': -1.0643939393939394} {'count': 0}\n",
      "{'count': 180, 'total': -101, 'avg': -0.5611111111111111} {'count': 0}\n",
      "{'count': 74, 'total': -27, 'avg': -0.36486486486486486} {'count': 0}\n",
      "{'count': 21, 'total': -6, 'avg': -0.2857142857142857} {'count': 0}\n",
      "done 1085 optimizations, 1085 transitions added to memory\n",
      "=========================episode 273 depth======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 teeth-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 depth-------\n",
      "reward 0 done True action 0\n",
      "episode 273 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9956387649788475  steps 1088  memory 0\n",
      "=========================episode 274 trawl======================\n",
      "------guess 0 0 octet-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 thank-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 trail-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 trawl-------\n",
      "reward 0 done True action 0\n",
      "episode 274 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9957251232182873  steps 1092  memory 3\n",
      "=========================episode 275 sadly======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 panic-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 jazzy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 gawky-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 sally-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 sadly-------\n",
      "reward 0 done True action 0\n",
      "episode 275 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9958514649207167  steps 1098  memory 7\n",
      "=========================episode 276 aunty======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 tasty-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 amity-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 aunty-------\n",
      "reward 0 done True action 0\n",
      "episode 276 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9959336114191201  steps 1102  memory 13\n",
      "=========================episode 277 cavil======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 gawky-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 basic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 cavil-------\n",
      "reward 0 done True action 0\n",
      "episode 277 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9960141313078718  steps 1106  memory 17\n",
      "=========================episode 278 showy======================\n",
      "------guess 0 0 towel-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 arrow-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 owing-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 showy-------\n",
      "reward 0 done True action 0\n",
      "episode 278 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9960930567960009  steps 1110  memory 21\n",
      "=========================episode 279 rinse======================\n",
      "------guess 0 0 doing-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 sinew-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 rinse-------\n",
      "reward 0 done True action 0\n",
      "episode 279 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9961512236023895  steps 1113  memory 25\n",
      "=========================episode 280 bilge======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 since-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bilge-------\n",
      "reward 0 done True action 0\n",
      "episode 280 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9962085244178513  steps 1116  memory 28\n",
      "optimize_model_batch -1 31\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 137, 'total': -420, 'avg': -3.065693430656934} {'count': 144, 'total': -421, 'avg': -2.923611111111111}\n",
      "{'count': 281, 'total': -560, 'avg': -1.99288256227758} {'count': 0}\n",
      "{'count': 272, 'total': -288, 'avg': -1.0588235294117647} {'count': 0}\n",
      "{'count': 185, 'total': -103, 'avg': -0.5567567567567567} {'count': 0}\n",
      "{'count': 75, 'total': -28, 'avg': -0.37333333333333335} {'count': 0}\n",
      "{'count': 22, 'total': -6, 'avg': -0.2727272727272727} {'count': 0}\n",
      "done 1116 optimizations, 1116 transitions added to memory\n",
      "=========================episode 281 diode======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 solve-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 biome-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 diode-------\n",
      "reward 0 done True action 0\n",
      "episode 281 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9962836006645029  steps 1120  memory 0\n",
      "=========================episode 282 repay======================\n",
      "------guess 0 0 belle-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 neigh-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 mercy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 teary-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 repay-------\n",
      "reward 0 done True action 0\n",
      "episode 282 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9963753588910342  steps 1125  memory 4\n",
      "=========================episode 283 gauze======================\n",
      "------guess 0 0 alert-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 peace-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 waive-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 gauze-------\n",
      "reward 0 done True action 0\n",
      "episode 283 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9964471315937786  steps 1129  memory 9\n",
      "=========================episode 284 crisp======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 lurch-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 crisp-------\n",
      "reward 0 done True action 0\n",
      "episode 284 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9965000269131928  steps 1132  memory 13\n",
      "=========================episode 285 lurch======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 crump-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lurch-------\n",
      "reward 0 done True action 0\n",
      "episode 285 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9965521347238969  steps 1135  memory 16\n",
      "=========================episode 286 catty======================\n",
      "------guess 0 0 drake-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 canal-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 cacti-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 catty-------\n",
      "reward 0 done True action 0\n",
      "episode 286 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9966204070306233  steps 1139  memory 19\n",
      "=========================episode 287 warty======================\n",
      "------guess 0 0 mocha-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 raven-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 tardy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 party-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 warty-------\n",
      "reward 0 done True action 0\n",
      "episode 287 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9967038494783457  steps 1144  memory 23\n",
      "=========================episode 288 ankle======================\n",
      "------guess 0 0 magma-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 drake-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 ankle-------\n",
      "reward 0 done True action 0\n",
      "episode 288 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9967529227663894  steps 1147  memory 28\n",
      "optimize_model_batch -1 31\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 142, 'total': -436, 'avg': -3.0704225352112675} {'count': 147, 'total': -428, 'avg': -2.9115646258503403}\n",
      "{'count': 289, 'total': -575, 'avg': -1.9896193771626298} {'count': 0}\n",
      "{'count': 280, 'total': -295, 'avg': -1.0535714285714286} {'count': 0}\n",
      "{'count': 190, 'total': -105, 'avg': -0.5526315789473685} {'count': 0}\n",
      "{'count': 77, 'total': -28, 'avg': -0.36363636363636365} {'count': 0}\n",
      "{'count': 22, 'total': -6, 'avg': -0.2727272727272727} {'count': 0}\n",
      "done 1147 optimizations, 1147 transitions added to memory\n",
      "=========================episode 289 stork======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 robot-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 thorn-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 stork-------\n",
      "reward 0 done True action 0\n",
      "episode 289 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9968172192034903  steps 1151  memory 0\n",
      "=========================episode 290 fetus======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 exist-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 steed-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 fetus-------\n",
      "reward 0 done True action 0\n",
      "episode 290 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.996880242485835  steps 1155  memory 4\n",
      "=========================episode 291 tooth======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 sooth-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 booth-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 tooth-------\n",
      "reward 0 done True action 0\n",
      "episode 291 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9969420178235767  steps 1159  memory 8\n",
      "=========================episode 292 cacti======================\n",
      "------guess 0 0 zonal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 parry-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 taste-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 faith-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 cacti-------\n",
      "reward 0 done True action 0\n",
      "episode 292 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9970175196725284  steps 1164  memory 12\n",
      "=========================episode 293 triad======================\n",
      "------guess 0 0 flask-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 earth-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 triad-------\n",
      "reward 0 done True action 0\n",
      "episode 293 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9970619230197765  steps 1167  memory 17\n",
      "=========================episode 294 aisle======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 aisle-------\n",
      "reward 0 done True action 0\n",
      "episode 294 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9970911573741874  steps 1169  memory 20\n",
      "=========================episode 295 blind======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 fishy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 pupil-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 clink-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 blind-------\n",
      "reward 0 done True action 0\n",
      "episode 295 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9971629769545145  steps 1174  memory 22\n",
      "=========================episode 296 exist======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 sweet-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 upset-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 heist-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 exist-------\n",
      "reward 0 done True action 0\n",
      "episode 296 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9972330233030852  steps 1179  memory 27\n",
      "optimize_model_batch -1 32\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 144, 'total': -442, 'avg': -3.0694444444444446} {'count': 153, 'total': -446, 'avg': -2.915032679738562}\n",
      "{'count': 297, 'total': -591, 'avg': -1.9898989898989898} {'count': 0}\n",
      "{'count': 287, 'total': -304, 'avg': -1.0592334494773519} {'count': 0}\n",
      "{'count': 196, 'total': -108, 'avg': -0.5510204081632653} {'count': 0}\n",
      "{'count': 80, 'total': -28, 'avg': -0.35} {'count': 0}\n",
      "{'count': 22, 'total': -6, 'avg': -0.2727272727272727} {'count': 0}\n",
      "done 1179 optimizations, 1179 transitions added to memory\n",
      "=========================episode 297 array======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 sugar-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 array-------\n",
      "reward 0 done True action 0\n",
      "episode 297 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9972742182192658  steps 1182  memory 0\n",
      "=========================episode 298 fence======================\n",
      "------guess 0 0 vaunt-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 sonic-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bench-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 fence-------\n",
      "reward 0 done True action 0\n",
      "episode 298 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9973281923148005  steps 1186  memory 3\n",
      "=========================episode 299 idiom======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 limbo-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 idiom-------\n",
      "reward 0 done True action 0\n",
      "episode 299 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9973679703489868  steps 1189  memory 7\n",
      "=========================episode 300 matey======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 fetal-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 eaten-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 matey-------\n",
      "reward 0 done True action 0\n",
      "episode 300 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9974200880279728  steps 1193  memory 10\n",
      "=========================episode 301 fecal======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 essay-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 legal-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 decal-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 fecal-------\n",
      "reward 0 done True action 0\n",
      "episode 301 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9974837862815213  steps 1198  memory 14\n",
      "=========================episode 302 motor======================\n",
      "------guess 0 0 draft-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 worth-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 motor-------\n",
      "reward 0 done True action 0\n",
      "episode 302 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9975212478233336  steps 1201  memory 19\n",
      "=========================episode 303 troop======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 turbo-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 troll-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 troop-------\n",
      "reward 0 done True action 0\n",
      "episode 303 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9975703304049754  steps 1205  memory 22\n",
      "=========================episode 304 lemon======================\n",
      "------guess 0 0 demon-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 lemon-------\n",
      "reward 0 done True action 0\n",
      "episode 304 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9975945060213804  steps 1207  memory 26\n",
      "optimize_model_batch -1 28\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 147, 'total': -448, 'avg': -3.0476190476190474} {'count': 158, 'total': -460, 'avg': -2.911392405063291}\n",
      "{'count': 305, 'total': -603, 'avg': -1.977049180327869} {'count': 0}\n",
      "{'count': 294, 'total': -309, 'avg': -1.0510204081632653} {'count': 0}\n",
      "{'count': 200, 'total': -109, 'avg': -0.545} {'count': 0}\n",
      "{'count': 81, 'total': -28, 'avg': -0.345679012345679} {'count': 0}\n",
      "{'count': 22, 'total': -6, 'avg': -0.2727272727272727} {'count': 0}\n",
      "done 1207 optimizations, 1207 transitions added to memory\n",
      "=========================episode 305 group======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 prong-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 group-------\n",
      "reward 0 done True action 0\n",
      "episode 305 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9976303191610186  steps 1210  memory 0\n",
      "=========================episode 306 enjoy======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 woken-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 venom-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 enjoy-------\n",
      "reward 0 done True action 0\n",
      "episode 306 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.99767724198547  steps 1214  memory 3\n",
      "=========================episode 307 waste======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 caste-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 haste-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 baste-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 paste-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 waste-------\n",
      "reward 0 done True action 0\n",
      "episode 307 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9977458898592854  steps 1220  memory 7\n",
      "=========================episode 308 toddy======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 joint-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 botch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 toddy-------\n",
      "reward 0 done True action 0\n",
      "episode 308 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9977905242305842  steps 1224  memory 13\n",
      "=========================episode 309 funny======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 musky-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 dully-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 juicy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 funny-------\n",
      "reward 0 done True action 0\n",
      "episode 309 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9978450763817024  steps 1229  memory 17\n",
      "=========================episode 310 stake======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 tease-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 stave-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 3 0 stake-------\n",
      "reward 0 done True action 0\n",
      "episode 310 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9978877467282673  steps 1233  memory 22\n",
      "=========================episode 311 gloss======================\n",
      "------guess 0 0 neigh-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 groom-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 gloat-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 gloss-------\n",
      "reward 0 done True action 0\n",
      "episode 311 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9979295721453597  steps 1237  memory 26\n",
      "=========================episode 312 polka======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 vodka-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 polka-------\n",
      "reward 0 done True action 0\n",
      "episode 312 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9979603968003071  steps 1240  memory 30\n",
      "optimize_model_batch -1 33\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 148, 'total': -451, 'avg': -3.0472972972972974} {'count': 165, 'total': -482, 'avg': -2.9212121212121214}\n",
      "{'count': 313, 'total': -620, 'avg': -1.9808306709265175} {'count': 0}\n",
      "{'count': 302, 'total': -318, 'avg': -1.0529801324503312} {'count': 0}\n",
      "{'count': 206, 'total': -112, 'avg': -0.5436893203883495} {'count': 0}\n",
      "{'count': 83, 'total': -29, 'avg': -0.3493975903614458} {'count': 0}\n",
      "{'count': 23, 'total': -6, 'avg': -0.2608695652173913} {'count': 0}\n",
      "done 1240 optimizations, 1240 transitions added to memory\n",
      "=========================episode 313 slide======================\n",
      "------guess 0 0 young-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 shell-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 slice-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 slime-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 slide-------\n",
      "reward 0 done True action 0\n",
      "episode 313 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9980107547827348  steps 1245  memory 0\n",
      "=========================episode 314 charm======================\n",
      "------guess 0 0 pasty-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 glade-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 charm-------\n",
      "reward 0 done True action 0\n",
      "episode 314 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9980403707856738  steps 1248  memory 5\n",
      "=========================episode 315 habit======================\n",
      "------guess 0 0 faint-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 tacit-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 habit-------\n",
      "reward 0 done True action 0\n",
      "episode 315 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9980695458637723  steps 1251  memory 8\n",
      "=========================episode 316 smite======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 flute-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 smite-------\n",
      "reward 0 done True action 0\n",
      "episode 316 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.998098286581546  steps 1254  memory 11\n",
      "=========================episode 317 leach======================\n",
      "------guess 0 0 sever-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 tempo-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 leggy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 leach-------\n",
      "reward 0 done True action 0\n",
      "episode 317 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9981359430302217  steps 1258  memory 14\n",
      "=========================episode 318 nosey======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 covey-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 nosey-------\n",
      "reward 0 done True action 0\n",
      "episode 318 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9981636952229711  steps 1261  memory 18\n",
      "=========================episode 319 strut======================\n",
      "------guess 0 0 urine-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 spurt-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 strut-------\n",
      "reward 0 done True action 0\n",
      "episode 319 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9981910342393987  steps 1264  memory 21\n",
      "=========================episode 320 pleat======================\n",
      "------guess 0 0 tally-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 petal-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 pleat-------\n",
      "reward 0 done True action 0\n",
      "episode 320 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9982179662308985  steps 1267  memory 24\n",
      "optimize_model_batch -1 27\n",
      "monte weights\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7311, 0.2689]])\n",
      "{'count': 154, 'total': -466, 'avg': -3.0259740259740258} {'count': 167, 'total': -486, 'avg': -2.910179640718563}\n",
      "{'count': 321, 'total': -631, 'avg': -1.9657320872274144} {'count': 0}\n",
      "{'count': 310, 'total': -321, 'avg': -1.0354838709677419} {'count': 0}\n",
      "{'count': 208, 'total': -113, 'avg': -0.5432692307692307} {'count': 0}\n",
      "{'count': 84, 'total': -29, 'avg': -0.34523809523809523} {'count': 0}\n",
      "{'count': 23, 'total': -6, 'avg': -0.2608695652173913} {'count': 0}\n",
      "done 1267 optimizations, 1267 transitions added to memory\n",
      "=========================episode 321 floss======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 slosh-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 gloss-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 floss-------\n",
      "reward 0 done True action 0\n",
      "episode 321 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9982532528637389  steps 1271  memory 0\n",
      "=========================episode 322 staff======================\n",
      "------guess 0 0 swift-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 staff-------\n",
      "reward 0 done True action 0\n",
      "episode 322 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9982706332881428  steps 1273  memory 4\n",
      "=========================episode 323 wryly======================\n",
      "------guess 0 0 ankle-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 would-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wryly-------\n",
      "reward 0 done True action 0\n",
      "episode 323 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9982963802041974  steps 1276  memory 6\n",
      "=========================episode 324 wreck======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 merry-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 rinse-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 clerk-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-728535e37273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m plot_all(*run_experiment(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModelConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'avg_reward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrainConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-7f3cab67782e>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model, num_episodes, eps, value_function, training, seed)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0maction_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mchosen_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mguesses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'------guess {t} {action_idx} {guesses[-1]}-------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-272a8b44b025>\u001b[0m in \u001b[0;36mperform_action\u001b[0;34m(self, action_idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtactic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtactic_tuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# apply all the tactics in the given order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mnewdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtactic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnewdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#if that tactic produced no results, then quit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/wordle/environment.py\u001b[0m in \u001b[0;36mfind_words_matching_current_history\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# making this more efficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m#print(matching_words)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mmatching_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_words_matching_hint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/wordle/environment.py\u001b[0m in \u001b[0;36mfind_words_matching_hint\u001b[0;34m(self, df, guess, hint)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m#print(f'orange index {tuple(idx)}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mdf_matching_orange\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_matching_green\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    887\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;31m# we may have a nested tuples indexer here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_nested_tuple_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_nested_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;31m# we maybe be using a tuple to represent multiple dimensions here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_nested_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0mcurrent_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_nested_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m                 \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mget_locs\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m   3269\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m                         )\n\u001b[0;32m-> 3271\u001b[0;31m                         indexers = (idxrs if indexers is None else indexers).union(\n\u001b[0m\u001b[1;32m   3272\u001b[0m                             \u001b[0midxrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m                         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36munion\u001b[0;34m(self, other, sort)\u001b[0m\n\u001b[1;32m   2700\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_union_incompatible_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2702\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_union\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2704\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_setop_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36m_union\u001b[0;34m(self, other, sort)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_union\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_union\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_union\u001b[0;34m(self, other, sort)\u001b[0m\n\u001b[1;32m   2754\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m                 \u001b[0mother_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2756\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/dtypes/concat.py\u001b[0m in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mall_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_empties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0msingle_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0many_ea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many_ea\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/dtypes/concat.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mall_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_empties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0msingle_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0many_ea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many_ea\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_all(*run_experiment(\n",
    "    model=ModelConfig(name='avg_reward'),\n",
    "    num_episodes=500,\n",
    "    training=TrainConfig(optimizer='sgd', lr=0.01, batch_size=-1, train_interval=8, clear_memory=True),\n",
    "    seed=1\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "64c8cc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================episode 0 nanny======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 gaudy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 balmy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 happy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 snick-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 fanny-------\n",
      "reward -1 done True action 0\n",
      "episode 0 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.024690087971667385  steps 6  memory 0\n",
      "optimize_model_batch -1 6\n",
      "monte weights\n",
      "tensor([[ 0.0611, -6.0000],\n",
      "        [-5.0000,  0.1771],\n",
      "        [-4.0000,  0.1094],\n",
      "        [-3.0000,  0.7084],\n",
      "        [ 0.5798, -2.0000],\n",
      "        [-1.0000,  0.3295]], dtype=torch.float64)\n",
      "tensor([[0.9977, 0.0023],\n",
      "        [0.0056, 0.9944],\n",
      "        [0.0162, 0.9838],\n",
      "        [0.0239, 0.9761],\n",
      "        [0.9295, 0.0705],\n",
      "        [0.2092, 0.7908]], dtype=torch.float64)\n",
      "{'count': 0} {'count': 1, 'total': -6, 'avg': -6.0}\n",
      "{'count': 1, 'total': -5, 'avg': -5.0} {'count': 0}\n",
      "{'count': 1, 'total': -4, 'avg': -4.0} {'count': 0}\n",
      "{'count': 1, 'total': -3, 'avg': -3.0} {'count': 0}\n",
      "{'count': 0} {'count': 1, 'total': -2, 'avg': -2.0}\n",
      "{'count': 1, 'total': -1, 'avg': -1.0} {'count': 0}\n",
      "done 6 optimizations, 6 transitions added to memory\n",
      "=========================episode 1 shove======================\n",
      "------guess 0 0 irate-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 clons-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dumpy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bight-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 whose-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 flaky-------\n",
      "reward -1 done True action 1\n",
      "episode 1 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.05351485204651618  steps 12  memory 0\n",
      "=========================episode 2 pagan======================\n",
      "------guess 0 0 wider-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 loast-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 punch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 moggy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 pagan-------\n",
      "reward 0 done True action 0\n",
      "episode 2 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.07688365361336424  steps 17  memory 6\n",
      "=========================episode 3 nomad======================\n",
      "------guess 0 0 ruler-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 iotas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chynd-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gimpy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 nomad-------\n",
      "reward 0 done True action 0\n",
      "episode 3 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.09967547741373439  steps 22  memory 11\n",
      "=========================episode 4 prong======================\n",
      "------guess 0 0 tidal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 seron-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gawky-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 prong-------\n",
      "reward 0 done True action 0\n",
      "episode 4 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.1219045690794387  steps 27  memory 16\n",
      "=========================episode 5 happy======================\n",
      "------guess 0 0 sixth-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 realo-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gimps-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 happy-------\n",
      "reward 0 done True action 0\n",
      "episode 5 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.1435848225163865  steps 32  memory 21\n",
      "=========================episode 6 brave======================\n",
      "------guess 0 0 empty-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 soral-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cuing-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bundh-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 baker-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 waqfs-------\n",
      "reward -1 done True action 1\n",
      "episode 6 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.16889571614787435  steps 38  memory 26\n",
      "=========================episode 7 mania======================\n",
      "------guess 0 0 hitch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 realo-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dungs-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bumpy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 mania-------\n",
      "reward 0 done True action 0\n",
      "episode 7 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.18941575402981292  steps 43  memory 32\n",
      "=========================episode 8 batch======================\n",
      "------guess 0 0 milky-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dunsh-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 pubco-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 batch-------\n",
      "reward 0 done True action 0\n",
      "episode 8 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.20942915037126442  steps 48  memory 37\n",
      "=========================episode 9 soggy======================\n",
      "------guess 0 0 pinky-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 schul-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 midge-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 soggy-------\n",
      "reward 0 done True action 0\n",
      "episode 9 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.22894841419643375  steps 53  memory 42\n",
      "=========================episode 10 roger======================\n",
      "------guess 0 0 might-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 realo-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cuspy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bends-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 roger-------\n",
      "reward 0 done True action 0\n",
      "episode 10 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.24798574568061738  steps 58  memory 47\n",
      "=========================episode 11 spout======================\n",
      "------guess 0 0 recur-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 altos-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dying-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 spout-------\n",
      "reward 0 done True action 0\n",
      "episode 11 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.26655304377571076  steps 63  memory 52\n",
      "=========================episode 12 corny======================\n",
      "------guess 0 0 fanny-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 resto-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 lucid-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 corny-------\n",
      "reward 0 done True action 0\n",
      "episode 12 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.2846619136474401  steps 68  memory 57\n",
      "=========================episode 13 tapir======================\n",
      "------guess 0 0 throw-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 aisle-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gompa-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 tapir-------\n",
      "reward 0 done True action 0\n",
      "episode 13 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.302323673928969  steps 73  memory 62\n",
      "=========================episode 14 whole======================\n",
      "------guess 0 0 greed-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lotas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cumin-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 pawky-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 below-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 hafiz-------\n",
      "reward -1 done True action 1\n",
      "episode 14 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.32294312550183535  steps 79  memory 67\n",
      "=========================episode 15 being======================\n",
      "------guess 0 0 vigil-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 synch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 umped-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 eking-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 being-------\n",
      "reward 0 done True action 0\n",
      "episode 15 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.34295318018494325  steps 85  memory 73\n",
      "=========================episode 16 bunch======================\n",
      "------guess 0 0 leery-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 1 stoai-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dunch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gamps-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 hunch-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 bawks-------\n",
      "reward -1 done True action 1\n",
      "episode 16 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.36237184837822667  steps 91  memory 79\n",
      "optimize_model_batch -1 85\n",
      "monte weights\n",
      "tensor([[-4.5625, -6.0000],\n",
      "        [-5.0000, -3.5625],\n",
      "        [-4.0000, -2.5625],\n",
      "        [-3.0000, -1.5625],\n",
      "        [-0.5625, -2.0000],\n",
      "        [-0.5000, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.8081, 0.1919],\n",
      "        [0.1919, 0.8081],\n",
      "        [0.1919, 0.8081],\n",
      "        [0.1919, 0.8081],\n",
      "        [0.8081, 0.1919],\n",
      "        [0.6225, 0.3775]], dtype=torch.float64)\n",
      "{'count': 16, 'total': -73, 'avg': -4.5625} {'count': 1, 'total': -6, 'avg': -6.0}\n",
      "{'count': 1, 'total': -5, 'avg': -5.0} {'count': 16, 'total': -57, 'avg': -3.5625}\n",
      "{'count': 1, 'total': -4, 'avg': -4.0} {'count': 16, 'total': -41, 'avg': -2.5625}\n",
      "{'count': 1, 'total': -3, 'avg': -3.0} {'count': 16, 'total': -25, 'avg': -1.5625}\n",
      "{'count': 16, 'total': -9, 'avg': -0.5625} {'count': 1, 'total': -2, 'avg': -2.0}\n",
      "{'count': 2, 'total': -1, 'avg': -0.5} {'count': 4, 'total': -4, 'avg': -1.0}\n",
      "done 91 optimizations, 91 transitions added to memory\n",
      "=========================episode 17 swarm======================\n",
      "------guess 0 0 femur-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lotas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 pinch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gybed-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 swarm-------\n",
      "reward 0 done True action 0\n",
      "episode 17 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.3781149435349799  steps 96  memory 0\n",
      "=========================episode 18 silly======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gybed-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 wakfs-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 silly-------\n",
      "reward 0 done True action 0\n",
      "episode 18 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.39649442457295947  steps 102  memory 5\n",
      "=========================episode 19 taste======================\n",
      "------guess 0 0 crepe-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 amaze-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 toils-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 taste-------\n",
      "reward 0 done True action 0\n",
      "episode 19 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.4113950303216448  steps 107  memory 11\n",
      "=========================episode 20 aloof======================\n",
      "------guess 0 0 shown-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 alert-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cupid-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 moggy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 aloof-------\n",
      "reward 0 done True action 0\n",
      "episode 20 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.42592773880356405  steps 112  memory 16\n",
      "=========================episode 21 taint======================\n",
      "------guess 0 0 relax-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 oints-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 paint-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 duchy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 faint-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 gambe-------\n",
      "reward -1 done True action 1\n",
      "episode 21 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.4428941381878261  steps 118  memory 21\n",
      "=========================episode 22 probe======================\n",
      "------guess 0 0 debar-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toils-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 punch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 probe-------\n",
      "reward 0 done True action 0\n",
      "episode 22 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.4539255733602906  steps 122  memory 27\n",
      "=========================episode 23 cough======================\n",
      "------guess 0 0 meaty-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 ghoul-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 rinds-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 pubco-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 cough-------\n",
      "reward 0 done True action 0\n",
      "episode 23 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.4674081989931028  steps 127  memory 31\n",
      "=========================episode 24 viola======================\n",
      "------guess 0 0 preen-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 focal-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 duits-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 vughy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 viola-------\n",
      "reward 0 done True action 0\n",
      "episode 24 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.48055793741295183  steps 132  memory 36\n",
      "=========================episode 25 scour======================\n",
      "------guess 0 0 lurid-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 croup-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 nates-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 vughy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 scour-------\n",
      "reward 0 done True action 0\n",
      "episode 25 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.49338300763441045  steps 137  memory 41\n",
      "=========================episode 26 wreck======================\n",
      "------guess 0 0 solid-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 antre-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gawky-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 wreck-------\n",
      "reward 0 done True action 0\n",
      "episode 26 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.5058914257438583  steps 142  memory 46\n",
      "=========================episode 27 valet======================\n",
      "------guess 0 0 amend-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lirot-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cushy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gopik-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 valet-------\n",
      "reward 0 done True action 0\n",
      "episode 27 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.5180910099097975  steps 147  memory 51\n",
      "=========================episode 28 smite======================\n",
      "------guess 0 0 hilly-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dungs-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 chomp-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 smite-------\n",
      "reward 0 done True action 0\n",
      "episode 28 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.529989385269462  steps 152  memory 56\n",
      "=========================episode 29 tithe======================\n",
      "------guess 0 0 scoff-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 exalt-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 unrid-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 white-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 tithe-------\n",
      "reward 0 done True action 0\n",
      "episode 29 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.5415939886947765  steps 157  memory 61\n",
      "=========================episode 30 excel======================\n",
      "------guess 0 0 enter-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 coals-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 humid-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 pawky-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 excel-------\n",
      "reward 0 done True action 0\n",
      "episode 30 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.5529120734406436  steps 162  memory 66\n",
      "=========================episode 31 spurt======================\n",
      "------guess 0 0 shrug-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 telia-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 ycond-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 plumb-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 wakfs-------\n",
      "reward -1 done False action 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 5 1 vezir-------\n",
      "reward -1 done True action 1\n",
      "episode 31 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.5661255185670091  steps 168  memory 71\n",
      "=========================episode 32 slink======================\n",
      "------guess 0 0 ovine-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 slart-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 duchy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 grump-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 slink-------\n",
      "reward 0 done True action 0\n",
      "episode 32 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.5768379176822511  steps 173  memory 77\n",
      "optimize_model_batch -1 82\n",
      "monte weights\n",
      "tensor([[-4.3871, -5.5000],\n",
      "        [-3.3333, -3.4815],\n",
      "        [-4.0000, -2.3548],\n",
      "        [-1.3333, -1.4667],\n",
      "        [-0.3793, -1.6667],\n",
      "        [-0.3333, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.7527, 0.2473],\n",
      "        [0.5370, 0.4630],\n",
      "        [0.1618, 0.8382],\n",
      "        [0.5333, 0.4667],\n",
      "        [0.7837, 0.2163],\n",
      "        [0.6608, 0.3392]], dtype=torch.float64)\n",
      "{'count': 31, 'total': -136, 'avg': -4.387096774193548} {'count': 2, 'total': -11, 'avg': -5.5}\n",
      "{'count': 6, 'total': -20, 'avg': -3.3333333333333335} {'count': 27, 'total': -94, 'avg': -3.4814814814814814}\n",
      "{'count': 2, 'total': -8, 'avg': -4.0} {'count': 31, 'total': -73, 'avg': -2.3548387096774195}\n",
      "{'count': 3, 'total': -4, 'avg': -1.3333333333333333} {'count': 30, 'total': -44, 'avg': -1.4666666666666666}\n",
      "{'count': 29, 'total': -11, 'avg': -0.3793103448275862} {'count': 3, 'total': -5, 'avg': -1.6666666666666667}\n",
      "{'count': 3, 'total': -1, 'avg': -0.3333333333333333} {'count': 6, 'total': -6, 'avg': -1.0}\n",
      "done 173 optimizations, 173 transitions added to memory\n",
      "=========================episode 33 while======================\n",
      "------guess 0 0 hovel-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 lithe-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 carns-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 while-------\n",
      "reward 0 done True action 0\n",
      "episode 33 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.5852170883184187  steps 177  memory 0\n",
      "=========================episode 34 queen======================\n",
      "------guess 0 0 gully-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 furor-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bused-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 queen-------\n",
      "reward 0 done True action 0\n",
      "episode 34 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.5934303402594009  steps 181  memory 4\n",
      "=========================episode 35 nanny======================\n",
      "------guess 0 0 lever-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 yacht-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 dinos-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 grump-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 bawks-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 nanny-------\n",
      "reward 0 done True action 0\n",
      "episode 35 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.605446289628399  steps 187  memory 8\n",
      "=========================episode 36 nadir======================\n",
      "------guess 0 0 royal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 nites-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 nadir-------\n",
      "reward 0 done True action 0\n",
      "episode 36 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.611320429098247  steps 190  memory 14\n",
      "=========================episode 37 cress======================\n",
      "------guess 0 0 teary-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 noils-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 cress-------\n",
      "reward 0 done True action 0\n",
      "episode 37 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.6190168002606627  steps 194  memory 17\n",
      "=========================episode 38 glint======================\n",
      "------guess 0 0 storm-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 valet-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 cuing-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 hyped-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 glint-------\n",
      "reward 0 done True action 0\n",
      "episode 38 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.6284233089779543  steps 199  memory 21\n",
      "=========================episode 39 tardy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 tardy-------\n",
      "reward 0 done True action 0\n",
      "episode 39 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.6321205588285577  steps 201  memory 26\n",
      "=========================episode 40 agony======================\n",
      "------guess 0 0 suing-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 lymph-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 agony-------\n",
      "reward 0 done True action 0\n",
      "episode 40 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.6394050598269216  steps 205  memory 28\n",
      "=========================episode 41 icing======================\n",
      "------guess 0 0 ethic-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 soral-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 gundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 blimp-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 icing-------\n",
      "reward 0 done True action 0\n",
      "episode 41 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.6483081806219331  steps 210  memory 32\n",
      "=========================episode 42 sixth======================\n",
      "------guess 0 0 favor-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lites-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 tipsy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 sixth-------\n",
      "reward 0 done True action 0\n",
      "episode 42 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.6552721452327799  steps 214  memory 37\n",
      "=========================episode 43 daisy======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 daisy-------\n",
      "reward 0 done True action 0\n",
      "episode 43 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.6604044743550609  steps 217  memory 41\n",
      "=========================episode 44 flout======================\n",
      "------guess 0 0 arrow-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 teils-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 flout-------\n",
      "reward 0 done True action 0\n",
      "episode 44 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.668789117758019  steps 222  memory 44\n",
      "=========================episode 45 fella======================\n",
      "------guess 0 0 sauce-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 triol-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 nymph-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 fella-------\n",
      "reward 0 done True action 0\n",
      "episode 45 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.6753475326416503  steps 226  memory 49\n",
      "=========================episode 46 fever======================\n",
      "------guess 0 0 blade-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 fetch-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 roins-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 jumpy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 fewer-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 eking-------\n",
      "reward -1 done True action 1\n",
      "episode 46 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.6849424630965867  steps 232  memory 53\n",
      "=========================episode 47 ovary======================\n",
      "------guess 0 0 abled-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 tonga-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 cursi-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 humpy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 ovary-------\n",
      "reward 0 done True action 0\n",
      "episode 47 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.6927212613988687  steps 237  memory 59\n",
      "=========================episode 48 brave======================\n",
      "------guess 0 0 plain-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 estro-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 duchy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 frame-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 grave-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 brave-------\n",
      "reward 0 done True action 0\n",
      "episode 48 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.7018027205701126  steps 243  memory 64\n",
      "optimize_model_batch -1 70\n",
      "monte weights\n",
      "tensor([[-4.1778, -3.5000],\n",
      "        [-3.0000, -3.1667],\n",
      "        [-1.6667, -2.2619],\n",
      "        [-0.6000, -1.4722],\n",
      "        [-0.4000, -1.5000],\n",
      "        [-0.2000, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.3368, 0.6632],\n",
      "        [0.5416, 0.4584],\n",
      "        [0.6446, 0.3554],\n",
      "        [0.7052, 0.2948],\n",
      "        [0.7503, 0.2497],\n",
      "        [0.6900, 0.3100]], dtype=torch.float64)\n",
      "{'count': 45, 'total': -188, 'avg': -4.177777777777778} {'count': 4, 'total': -14, 'avg': -3.5}\n",
      "{'count': 13, 'total': -39, 'avg': -3.0} {'count': 36, 'total': -114, 'avg': -3.1666666666666665}\n",
      "{'count': 6, 'total': -10, 'avg': -1.6666666666666667} {'count': 42, 'total': -95, 'avg': -2.261904761904762}\n",
      "{'count': 10, 'total': -6, 'avg': -0.6} {'count': 36, 'total': -53, 'avg': -1.4722222222222223}\n",
      "{'count': 35, 'total': -14, 'avg': -0.4} {'count': 4, 'total': -6, 'avg': -1.5}\n",
      "{'count': 5, 'total': -1, 'avg': -0.2} {'count': 7, 'total': -7, 'avg': -1.0}\n",
      "done 243 optimizations, 243 transitions added to memory\n",
      "=========================episode 49 right======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 girth-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 right-------\n",
      "reward 0 done True action 0\n",
      "episode 49 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7062422996764672  steps 246  memory 0\n",
      "=========================episode 50 musky======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 pushy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 medic-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 musky-------\n",
      "reward 0 done True action 0\n",
      "episode 50 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.7134952031398099  steps 251  memory 3\n",
      "=========================episode 51 defer======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 lever-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 incus-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 hyped-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 defer-------\n",
      "reward 0 done True action 0\n",
      "episode 51 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.7205690317785927  steps 256  memory 8\n",
      "=========================episode 52 scuba======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 palsy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 scuba-------\n",
      "reward 0 done True action 0\n",
      "episode 52 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7247292169102477  steps 259  memory 13\n",
      "=========================episode 53 ankle======================\n",
      "------guess 0 0 filer-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 santo-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 angle-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 ankle-------\n",
      "reward 0 done True action 0\n",
      "episode 53 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7301799436153131  steps 263  memory 16\n",
      "=========================episode 54 broth======================\n",
      "------guess 0 0 comic-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 taler-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dunsh-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 broth-------\n",
      "reward 0 done True action 0\n",
      "episode 54 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.735522738700176  steps 267  memory 20\n",
      "=========================episode 55 amber======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 anger-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 amber-------\n",
      "reward 0 done True action 0\n",
      "episode 55 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7394602921400244  steps 270  memory 24\n",
      "=========================episode 56 ferry======================\n",
      "------guess 0 0 radio-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 spree-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 culty-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bhang-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 mawky-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 fauve-------\n",
      "reward -1 done True action 1\n",
      "episode 56 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.7471604041952535  steps 276  memory 27\n",
      "=========================episode 57 mania======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 anvil-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 cushy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 padma-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 mania-------\n",
      "reward 0 done True action 0\n",
      "episode 57 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.7534030360583935  steps 281  memory 33\n",
      "=========================episode 58 straw======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gibed-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 straw-------\n",
      "reward 0 done True action 0\n",
      "episode 58 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.7594915367916579  steps 286  memory 38\n",
      "=========================episode 59 ionic======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bodge-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 wakfs-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 ionic-------\n",
      "reward 0 done True action 0\n",
      "episode 59 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.7665996360988487  steps 292  memory 43\n",
      "=========================episode 60 until======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 unlit-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 psych-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 madge-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 until-------\n",
      "reward 0 done True action 0\n",
      "episode 60 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.7723623116161873  steps 297  memory 49\n",
      "=========================episode 61 spasm======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 spasm-------\n",
      "reward 0 done True action 0\n",
      "episode 61 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7768698398515702  steps 301  memory 54\n",
      "=========================episode 62 pixel======================\n",
      "------guess 0 0 cheer-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 novel-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 pixel-------\n",
      "reward 0 done True action 0\n",
      "episode 62 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7801918151522382  steps 304  memory 58\n",
      "=========================episode 63 clout======================\n",
      "------guess 0 0 choir-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 cloak-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 suent-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 clout-------\n",
      "reward 0 done True action 0\n",
      "episode 63 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7845443088302579  steps 308  memory 61\n",
      "=========================episode 64 swung======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 snuck-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 swung-------\n",
      "reward 0 done True action 0\n",
      "episode 64 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.7898639287992353  steps 313  memory 65\n",
      "optimize_model_batch -1 70\n",
      "monte weights\n",
      "tensor([[-4.1000, -3.4667],\n",
      "        [-2.6818, -3.0930],\n",
      "        [-1.1538, -2.2157],\n",
      "        [-0.4286, -1.4545],\n",
      "        [-0.3415, -1.5000],\n",
      "        [-0.1667, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.3468, 0.6532],\n",
      "        [0.6014, 0.3986],\n",
      "        [0.7430, 0.2570],\n",
      "        [0.7361, 0.2639],\n",
      "        [0.7611, 0.2389],\n",
      "        [0.6971, 0.3029]], dtype=torch.float64)\n",
      "{'count': 50, 'total': -205, 'avg': -4.1} {'count': 15, 'total': -52, 'avg': -3.466666666666667}\n",
      "{'count': 22, 'total': -59, 'avg': -2.6818181818181817} {'count': 43, 'total': -133, 'avg': -3.0930232558139537}\n",
      "{'count': 13, 'total': -15, 'avg': -1.1538461538461537} {'count': 51, 'total': -113, 'avg': -2.215686274509804}\n",
      "{'count': 14, 'total': -6, 'avg': -0.42857142857142855} {'count': 44, 'total': -64, 'avg': -1.4545454545454546}\n",
      "{'count': 41, 'total': -14, 'avg': -0.34146341463414637} {'count': 6, 'total': -9, 'avg': -1.5}\n",
      "{'count': 6, 'total': -1, 'avg': -0.16666666666666666} {'count': 8, 'total': -8, 'avg': -1.0}\n",
      "done 313 optimizations, 313 transitions added to memory\n",
      "=========================episode 65 admin======================\n",
      "------guess 0 0 serum-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 notal-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 manic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 admin-------\n",
      "reward 0 done True action 0\n",
      "episode 65 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7940249017951165  steps 317  memory 0\n",
      "=========================episode 66 booby======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 knock-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 goofy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 hilus-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 woozy-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 moody-------\n",
      "reward -1 done True action 0\n",
      "episode 66 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.8001123859248556  steps 323  memory 4\n",
      "=========================episode 67 winch======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 pulpy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 chins-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 madge-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 finch-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 bawks-------\n",
      "reward -1 done True action 1\n",
      "episode 67 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.8060199577091081  steps 329  memory 10\n",
      "=========================episode 68 lodge======================\n",
      "------guess 0 0 genie-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 fugue-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 badge-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 lodge-------\n",
      "reward 0 done True action 0\n",
      "episode 68 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8098610198984795  steps 333  memory 16\n",
      "=========================episode 69 quart======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 quart-------\n",
      "reward 0 done True action 0\n",
      "episode 69 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.81362602396059  steps 337  memory 20\n",
      "=========================episode 70 bride======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 prime-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 brine-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 schul-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 bribe-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 fudgy-------\n",
      "reward -1 done True action 1\n",
      "episode 70 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.8191342073828779  steps 343  memory 24\n",
      "=========================episode 71 truer======================\n",
      "------guess 0 0 stone-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 their-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 tamer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 truer-------\n",
      "reward 0 done True action 0\n",
      "episode 71 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8227155900301222  steps 347  memory 30\n",
      "=========================episode 72 nymph======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gibed-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 nymph-------\n",
      "reward 0 done True action 0\n",
      "episode 72 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8270927577082836  steps 352  memory 34\n",
      "=========================episode 73 fewer======================\n",
      "------guess 0 0 enemy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 rotal-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 fever-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 fewer-------\n",
      "reward 0 done True action 0\n",
      "episode 73 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8305165505005299  steps 356  memory 39\n",
      "=========================episode 74 bilge======================\n",
      "------guess 0 0 award-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 seize-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 untie-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bilge-------\n",
      "reward 0 done True action 0\n",
      "episode 74 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.833872547653167  steps 360  memory 43\n",
      "=========================episode 75 water======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 tamer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 later-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 hater-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 cater-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 eater-------\n",
      "reward -1 done True action 0\n",
      "episode 75 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.8387823558702232  steps 366  memory 47\n",
      "=========================episode 76 first======================\n",
      "------guess 0 0 ideal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 minty-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 hitch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bigot-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 first-------\n",
      "reward 0 done True action 0\n",
      "episode 76 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8427628336863724  steps 371  memory 53\n",
      "=========================episode 77 exist======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 islet-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 heist-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 gymps-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 exist-------\n",
      "reward 0 done True action 0\n",
      "episode 77 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.8474098942431161  steps 377  memory 58\n",
      "=========================episode 78 sleet======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 befit-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 eject-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 shuln-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 sleet-------\n",
      "reward 0 done True action 0\n",
      "episode 78 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8511773573778596  steps 382  memory 64\n",
      "=========================episode 79 manic======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 candy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 panic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 manic-------\n",
      "reward 0 done True action 0\n",
      "episode 79 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8541242431437727  steps 386  memory 69\n",
      "=========================episode 80 tiara======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 tiara-------\n",
      "reward 0 done True action 0\n",
      "episode 80 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8570127766619071  steps 390  memory 73\n",
      "optimize_model_batch -1 77\n",
      "monte weights\n",
      "tensor([[-4.0000, -3.9200],\n",
      "        [-2.9394, -3.0000],\n",
      "        [-1.5417, -2.2143],\n",
      "        [-0.4800, -1.5306],\n",
      "        [-0.4583, -1.4286],\n",
      "        [-0.3333, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4800, 0.5200],\n",
      "        [0.5151, 0.4849],\n",
      "        [0.6621, 0.3379],\n",
      "        [0.7409, 0.2591],\n",
      "        [0.7252, 0.2748],\n",
      "        [0.6608, 0.3392]], dtype=torch.float64)\n",
      "{'count': 56, 'total': -224, 'avg': -4.0} {'count': 25, 'total': -98, 'avg': -3.92}\n",
      "{'count': 33, 'total': -97, 'avg': -2.9393939393939394} {'count': 48, 'total': -144, 'avg': -3.0}\n",
      "{'count': 24, 'total': -37, 'avg': -1.5416666666666667} {'count': 56, 'total': -124, 'avg': -2.2142857142857144}\n",
      "{'count': 25, 'total': -12, 'avg': -0.48} {'count': 49, 'total': -75, 'avg': -1.530612244897959}\n",
      "{'count': 48, 'total': -22, 'avg': -0.4583333333333333} {'count': 7, 'total': -10, 'avg': -1.4285714285714286}\n",
      "{'count': 9, 'total': -3, 'avg': -0.3333333333333333} {'count': 10, 'total': -10, 'avg': -1.0}\n",
      "done 390 optimizations, 390 transitions added to memory\n",
      "=========================episode 81 quark======================\n",
      "------guess 0 0 crazy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 teloi-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 sharp-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 quark-------\n",
      "reward 0 done True action 0\n",
      "episode 81 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8598441133841846  steps 394  memory 0\n",
      "=========================episode 82 skulk======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bodge-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 skull-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 waqfs-------\n",
      "reward -1 done True action 1\n",
      "episode 82 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.8639863458331508  steps 400  memory 4\n",
      "=========================episode 83 munch======================\n",
      "------guess 0 0 fried-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 shoot-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bunch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 lunch-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 4 0 hunch-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 munch-------\n",
      "reward 0 done True action 0\n",
      "episode 83 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.8680061568121697  steps 406  memory 10\n",
      "=========================episode 84 purge======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 spire-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lunch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 purge-------\n",
      "reward 0 done True action 0\n",
      "episode 84 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8706198100226289  steps 410  memory 16\n",
      "=========================episode 85 tryst======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 tryst-------\n",
      "reward 0 done True action 0\n",
      "episode 85 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8725460301051793  steps 413  memory 20\n",
      "=========================episode 86 tiara======================\n",
      "------guess 0 0 butch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 realo-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 pyins-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 trait-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 dogma-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 tiara-------\n",
      "reward 0 done True action 0\n",
      "episode 86 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.8763128641825452  steps 419  memory 23\n",
      "=========================episode 87 flood======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 woody-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 sulci-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 nymph-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 flood-------\n",
      "reward 0 done True action 0\n",
      "episode 87 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8793667104468418  steps 424  memory 29\n",
      "=========================episode 88 query======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 buyer-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 query-------\n",
      "reward 0 done True action 0\n",
      "episode 88 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8823451569782208  steps 429  memory 34\n",
      "=========================episode 89 leper======================\n",
      "------guess 0 0 force-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 taker-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 elder-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 lever-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 leper-------\n",
      "reward 0 done True action 0\n",
      "episode 89 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8852500654027212  steps 434  memory 39\n",
      "=========================episode 90 feign======================\n",
      "------guess 0 0 icing-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 neigh-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 feign-------\n",
      "reward 0 done True action 0\n",
      "episode 90 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8869584693595501  steps 437  memory 44\n",
      "=========================episode 91 stint======================\n",
      "------guess 0 0 manic-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 inept-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lours-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 stint-------\n",
      "reward 0 done True action 0\n",
      "episode 91 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8891968416376661  steps 441  memory 47\n",
      "=========================episode 92 moult======================\n",
      "------guess 0 0 elate-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 twirl-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 conus-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 moult-------\n",
      "reward 0 done True action 0\n",
      "episode 92 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.891390891175042  steps 445  memory 51\n",
      "=========================episode 93 opium======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 opium-------\n",
      "reward 0 done True action 0\n",
      "episode 93 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8930078701468855  steps 448  memory 55\n",
      "=========================episode 94 parer======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 wager-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 baler-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 caper-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 payer-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 parer-------\n",
      "reward 0 done True action 0\n",
      "episode 94 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.896169965459203  steps 454  memory 58\n",
      "=========================episode 95 molar======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 manor-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 sulci-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 molar-------\n",
      "reward 0 done True action 0\n",
      "episode 95 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8982259378937163  steps 458  memory 64\n",
      "=========================episode 96 angle======================\n",
      "------guess 0 0 smile-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toran-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 duchy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 angle-------\n",
      "reward 0 done True action 0\n",
      "episode 96 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9002411993463814  steps 462  memory 68\n",
      "optimize_model_batch -1 72\n",
      "monte weights\n",
      "tensor([[-3.9375, -3.8485],\n",
      "        [-2.8571, -2.9455],\n",
      "        [-1.4839, -2.1538],\n",
      "        [-0.5556, -1.5490],\n",
      "        [-0.4815, -1.3750],\n",
      "        [-0.2500, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4778, 0.5222],\n",
      "        [0.5221, 0.4779],\n",
      "        [0.6615, 0.3385],\n",
      "        [0.7298, 0.2702],\n",
      "        [0.7096, 0.2904],\n",
      "        [0.6792, 0.3208]], dtype=torch.float64)\n",
      "{'count': 64, 'total': -252, 'avg': -3.9375} {'count': 33, 'total': -127, 'avg': -3.8484848484848486}\n",
      "{'count': 42, 'total': -120, 'avg': -2.857142857142857} {'count': 55, 'total': -162, 'avg': -2.9454545454545453}\n",
      "{'count': 31, 'total': -46, 'avg': -1.4838709677419355} {'count': 65, 'total': -140, 'avg': -2.1538461538461537}\n",
      "{'count': 36, 'total': -20, 'avg': -0.5555555555555556} {'count': 51, 'total': -79, 'avg': -1.5490196078431373}\n",
      "{'count': 54, 'total': -26, 'avg': -0.48148148148148145} {'count': 8, 'total': -11, 'avg': -1.375}\n",
      "{'count': 12, 'total': -3, 'avg': -0.25} {'count': 11, 'total': -11, 'avg': -1.0}\n",
      "done 462 optimizations, 462 transitions added to memory\n",
      "=========================episode 97 medic======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 mince-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 medic-------\n",
      "reward 0 done True action 0\n",
      "episode 97 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9017264143956385  steps 465  memory 0\n",
      "=========================episode 98 dairy======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 dairy-------\n",
      "reward 0 done True action 0\n",
      "episode 98 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9031895174735398  steps 468  memory 3\n",
      "=========================episode 99 chore======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 shore-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 unlid-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 chore-------\n",
      "reward 0 done True action 0\n",
      "episode 99 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9051064934653769  steps 472  memory 6\n",
      "=========================episode 100 unset======================\n",
      "------guess 0 0 frond-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 telia-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 unmet-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 unset-------\n",
      "reward 0 done True action 0\n",
      "episode 100 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9069855107893365  steps 476  memory 10\n",
      "=========================episode 101 unset======================\n",
      "------guess 0 0 savvy-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 1 reoil-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 unset-------\n",
      "reward 0 done True action 0\n",
      "episode 101 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9083703161224952  steps 479  memory 14\n",
      "=========================episode 102 guess======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 beefy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 linds-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 chess-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 guess-------\n",
      "reward 0 done True action 0\n",
      "episode 102 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9106326610782468  steps 484  memory 17\n",
      "=========================episode 103 bitty======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 sixty-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 kitty-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 lunch-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 bitty-------\n",
      "reward 0 done True action 0\n",
      "episode 103 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9128391485380187  steps 489  memory 22\n",
      "=========================episode 104 dairy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 fairy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 dairy-------\n",
      "reward 0 done True action 0\n",
      "episode 104 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9149911576283004  steps 494  memory 27\n",
      "=========================episode 105 shout======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 stock-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 spout-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 shout-------\n",
      "reward 0 done True action 0\n",
      "episode 105 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.916674445487917  steps 498  memory 32\n",
      "=========================episode 106 fewer======================\n",
      "------guess 0 0 noose-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 trial-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 duchy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 fewer-------\n",
      "reward 0 done True action 0\n",
      "episode 106 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9183244020147066  steps 502  memory 36\n",
      "=========================episode 107 snowy======================\n",
      "------guess 0 0 lingo-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 shown-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 react-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 dumpy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 bluff-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 snowy-------\n",
      "reward 0 done True action 0\n",
      "episode 107 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9207382807352684  steps 508  memory 40\n",
      "=========================episode 108 forty======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 north-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 sulci-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 forty-------\n",
      "reward 0 done True action 0\n",
      "episode 108 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9223077679326976  steps 512  memory 46\n",
      "=========================episode 109 bleat======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 meaty-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 agent-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 sulci-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 bleat-------\n",
      "reward 0 done True action 0\n",
      "episode 109 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9242259959771545  steps 517  memory 50\n",
      "=========================episode 110 topaz======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 total-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 today-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 topaz-------\n",
      "reward 0 done True action 0\n",
      "episode 110 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9257264217856661  steps 521  memory 55\n",
      "=========================episode 111 enemy======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 begun-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 kneed-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 enemy-------\n",
      "reward 0 done True action 0\n",
      "episode 111 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9271971371725645  steps 525  memory 59\n",
      "=========================episode 112 whine======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 badge-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 whine-------\n",
      "reward 0 done True action 0\n",
      "episode 112 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.928994646260363  steps 530  memory 63\n",
      "optimize_model_batch -1 68\n",
      "monte weights\n",
      "tensor([[-3.8971, -3.6889],\n",
      "        [-2.7692, -2.8525],\n",
      "        [-1.3500, -2.1111],\n",
      "        [-0.4889, -1.5273],\n",
      "        [-0.4407, -1.3333],\n",
      "        [-0.2308, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4481, 0.5519],\n",
      "        [0.5208, 0.4792],\n",
      "        [0.6816, 0.3184],\n",
      "        [0.7385, 0.2615],\n",
      "        [0.7094, 0.2906],\n",
      "        [0.6834, 0.3166]], dtype=torch.float64)\n",
      "{'count': 68, 'total': -265, 'avg': -3.8970588235294117} {'count': 45, 'total': -166, 'avg': -3.688888888888889}\n",
      "{'count': 52, 'total': -144, 'avg': -2.769230769230769} {'count': 61, 'total': -174, 'avg': -2.8524590163934427}\n",
      "{'count': 40, 'total': -54, 'avg': -1.35} {'count': 72, 'total': -152, 'avg': -2.111111111111111}\n",
      "{'count': 45, 'total': -22, 'avg': -0.4888888888888889} {'count': 55, 'total': -84, 'avg': -1.5272727272727273}\n",
      "{'count': 59, 'total': -26, 'avg': -0.4406779661016949} {'count': 9, 'total': -12, 'avg': -1.3333333333333333}\n",
      "{'count': 13, 'total': -3, 'avg': -0.23076923076923078} {'count': 11, 'total': -11, 'avg': -1.0}\n",
      "done 530 optimizations, 530 transitions added to memory\n",
      "=========================episode 113 crock======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 crowd-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 befog-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 crock-------\n",
      "reward 0 done True action 0\n",
      "episode 113 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9310931716053374  steps 536  memory 0\n",
      "=========================episode 114 madly======================\n",
      "------guess 0 0 chalk-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 viola-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 amble-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 runts-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 madly-------\n",
      "reward 0 done True action 0\n",
      "episode 114 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9327944872602503  steps 541  memory 6\n",
      "=========================episode 115 scary======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 scary-------\n",
      "reward 0 done True action 0\n",
      "episode 115 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9337950469929268  steps 544  memory 11\n",
      "=========================episode 116 singe======================\n",
      "------guess 0 0 nylon-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 brand-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sinew-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 mutch-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 gopik-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 singe-------\n",
      "reward 0 done True action 0\n",
      "episode 116 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9357516990554969  steps 550  memory 14\n",
      "=========================episode 117 cloud======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 block-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 cloud-------\n",
      "reward 0 done True action 0\n",
      "episode 117 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9370239006519849  steps 554  memory 20\n",
      "=========================episode 118 dimly======================\n",
      "------guess 0 0 amaze-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 0 rumor-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 limit-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 dimly-------\n",
      "reward 0 done True action 0\n",
      "episode 118 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9382709109690412  steps 558  memory 24\n",
      "=========================episode 119 wrath======================\n",
      "------guess 0 0 brash-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 teloi-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 wrath-------\n",
      "reward 0 done True action 0\n",
      "episode 119 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9391899373747821  steps 561  memory 28\n",
      "=========================episode 120 mucky======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 mucky-------\n",
      "reward 0 done True action 0\n",
      "episode 120 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9403940572910606  steps 565  memory 31\n",
      "=========================episode 121 gauge======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 gauze-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 gauge-------\n",
      "reward 0 done True action 0\n",
      "episode 121 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9418657332601785  steps 570  memory 35\n",
      "=========================episode 122 uncle======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 siege-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lunch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 uncle-------\n",
      "reward 0 done True action 0\n",
      "episode 122 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.943016868867966  steps 574  memory 40\n",
      "=========================episode 123 lupus======================\n",
      "------guess 0 0 drunk-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 stout-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lupus-------\n",
      "reward 0 done True action 0\n",
      "episode 123 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9438652371658662  steps 577  memory 44\n",
      "=========================episode 124 homer======================\n",
      "------guess 0 0 unset-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 boxer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 alcid-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 mower-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 homer-------\n",
      "reward 0 done True action 0\n",
      "episode 124 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9452512093985097  steps 582  memory 47\n",
      "=========================episode 125 koala======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 koala-------\n",
      "reward 0 done True action 0\n",
      "episode 125 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9457959689670266  steps 584  memory 52\n",
      "=========================episode 126 rebel======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 filer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 repel-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 rebel-------\n",
      "reward 0 done True action 0\n",
      "episode 126 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9468692806936012  steps 588  memory 54\n",
      "=========================episode 127 cable======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 cable-------\n",
      "reward 0 done True action 0\n",
      "episode 127 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9479213394240343  steps 592  memory 58\n",
      "=========================episode 128 demur======================\n",
      "------guess 0 0 bring-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 stoae-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 duply-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 demur-------\n",
      "reward 0 done True action 0\n",
      "episode 128 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9489525659958457  steps 596  memory 62\n",
      "optimize_model_batch -1 66\n",
      "monte weights\n",
      "tensor([[-3.8400, -3.5741],\n",
      "        [-2.6833, -2.7681],\n",
      "        [-1.2917, -2.0633],\n",
      "        [-0.4727, -1.5263],\n",
      "        [-0.4194, -1.2727],\n",
      "        [-0.2000, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4339, 0.5661],\n",
      "        [0.5212, 0.4788],\n",
      "        [0.6839, 0.3161],\n",
      "        [0.7415, 0.2585],\n",
      "        [0.7013, 0.2987],\n",
      "        [0.6900, 0.3100]], dtype=torch.float64)\n",
      "{'count': 75, 'total': -288, 'avg': -3.84} {'count': 54, 'total': -193, 'avg': -3.574074074074074}\n",
      "{'count': 60, 'total': -161, 'avg': -2.683333333333333} {'count': 69, 'total': -191, 'avg': -2.7681159420289854}\n",
      "{'count': 48, 'total': -62, 'avg': -1.2916666666666667} {'count': 79, 'total': -163, 'avg': -2.0632911392405062}\n",
      "{'count': 55, 'total': -26, 'avg': -0.4727272727272727} {'count': 57, 'total': -87, 'avg': -1.5263157894736843}\n",
      "{'count': 62, 'total': -26, 'avg': -0.41935483870967744} {'count': 11, 'total': -14, 'avg': -1.2727272727272727}\n",
      "{'count': 15, 'total': -3, 'avg': -0.2} {'count': 11, 'total': -11, 'avg': -1.0}\n",
      "done 596 optimizations, 596 transitions added to memory\n",
      "=========================episode 129 voice======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 diode-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 voice-------\n",
      "reward 0 done True action 0\n",
      "episode 129 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9499633729134137  steps 600  memory 0\n",
      "=========================episode 130 eying======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 slime-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 eking-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 duchy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 eying-------\n",
      "reward 0 done True action 0\n",
      "episode 130 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.951198781637987  steps 605  memory 4\n",
      "=========================episode 131 remit======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 rivet-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 shuln-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 remit-------\n",
      "reward 0 done True action 0\n",
      "episode 131 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9521651105058017  steps 609  memory 9\n",
      "=========================episode 132 havoc======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bodge-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 havoc-------\n",
      "reward 0 done True action 0\n",
      "episode 132 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9533461581355284  steps 614  memory 13\n",
      "=========================episode 133 whiny======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 unify-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chomp-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 whiny-------\n",
      "reward 0 done True action 0\n",
      "episode 133 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9544980455953784  steps 619  memory 18\n",
      "=========================episode 134 yield======================\n",
      "------guess 0 0 bathe-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 loirs-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 pixel-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 gowfs-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 yield-------\n",
      "reward 0 done True action 0\n",
      "episode 134 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9558428315803071  steps 625  memory 23\n",
      "=========================episode 135 bused======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 widen-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bleed-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 3 0 bused-------\n",
      "reward 0 done True action 0\n",
      "episode 135 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9567172020980341  steps 629  memory 29\n",
      "=========================episode 136 femur======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 lemur-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 chins-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 podgy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 femur-------\n",
      "reward 0 done True action 0\n",
      "episode 136 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9577858581858936  steps 634  memory 33\n",
      "=========================episode 137 oaken======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 ocean-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 oaken-------\n",
      "reward 0 done True action 0\n",
      "episode 137 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9584143448788268  steps 637  memory 38\n",
      "=========================episode 138 inept======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 swept-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 inept-------\n",
      "reward 0 done True action 0\n",
      "episode 138 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9590334746239171  steps 640  memory 41\n",
      "=========================episode 139 belie======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 siege-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lunch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 dumpy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 belie-------\n",
      "reward 0 done True action 0\n",
      "episode 139 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9600449417393461  steps 645  memory 44\n",
      "=========================episode 140 yield======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 midge-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wield-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 yield-------\n",
      "reward 0 done True action 0\n",
      "episode 140 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9608361049010129  steps 649  memory 49\n",
      "=========================episode 141 nerdy======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 miser-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 perky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 nerdy-------\n",
      "reward 0 done True action 0\n",
      "episode 141 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9616116019824479  steps 653  memory 53\n",
      "=========================episode 142 feast======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 feast-------\n",
      "reward 0 done True action 0\n",
      "episode 142 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.962183130770675  steps 656  memory 57\n",
      "=========================episode 143 paint======================\n",
      "------guess 0 0 lower-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 tunic-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 shady-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 faint-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 gymps-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 nikab-------\n",
      "reward -1 done True action 1\n",
      "episode 143 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9633007881636134  steps 662  memory 60\n",
      "=========================episode 144 moldy======================\n",
      "------guess 0 0 gayly-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 moldy-------\n",
      "reward 0 done True action 0\n",
      "episode 144 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.96366595142266  steps 664  memory 66\n",
      "optimize_model_batch -1 68\n",
      "monte weights\n",
      "tensor([[-3.8462, -3.4925],\n",
      "        [-2.6056, -2.7568],\n",
      "        [-1.2586, -2.0714],\n",
      "        [-0.4754, -1.4921],\n",
      "        [-0.3881, -1.3077],\n",
      "        [-0.1875, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4125, 0.5875],\n",
      "        [0.5377, 0.4623],\n",
      "        [0.6927, 0.3073],\n",
      "        [0.7343, 0.2657],\n",
      "        [0.7150, 0.2850],\n",
      "        [0.6926, 0.3074]], dtype=torch.float64)\n",
      "{'count': 78, 'total': -300, 'avg': -3.8461538461538463} {'count': 67, 'total': -234, 'avg': -3.4925373134328357}\n",
      "{'count': 71, 'total': -185, 'avg': -2.6056338028169015} {'count': 74, 'total': -204, 'avg': -2.7567567567567566}\n",
      "{'count': 58, 'total': -73, 'avg': -1.2586206896551724} {'count': 84, 'total': -174, 'avg': -2.0714285714285716}\n",
      "{'count': 61, 'total': -29, 'avg': -0.47540983606557374} {'count': 63, 'total': -94, 'avg': -1.492063492063492}\n",
      "{'count': 67, 'total': -26, 'avg': -0.3880597014925373} {'count': 13, 'total': -17, 'avg': -1.3076923076923077}\n",
      "{'count': 16, 'total': -3, 'avg': -0.1875} {'count': 12, 'total': -12, 'avg': -1.0}\n",
      "done 664 optimizations, 664 transitions added to memory\n",
      "=========================episode 145 truck======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 truck-------\n",
      "reward 0 done True action 0\n",
      "episode 145 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9642068949323447  steps 667  memory 0\n",
      "=========================episode 146 grill======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 frill-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 grill-------\n",
      "reward 0 done True action 0\n",
      "episode 146 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9650906298452442  steps 672  memory 3\n",
      "=========================episode 147 leafy======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 leafy-------\n",
      "reward 0 done True action 0\n",
      "episode 147 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9656103626565273  steps 675  memory 8\n",
      "=========================episode 148 sheik======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 seedy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sheik-------\n",
      "reward 0 done True action 0\n",
      "episode 148 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9661223576543256  steps 678  memory 11\n",
      "=========================episode 149 cough======================\n",
      "------guess 0 0 brave-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toils-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 couch-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 cough-------\n",
      "reward 0 done True action 0\n",
      "episode 149 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.966958799624113  steps 683  memory 14\n",
      "=========================episode 150 chili======================\n",
      "------guess 0 0 sniff-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 quick-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 chili-------\n",
      "reward 0 done True action 0\n",
      "episode 150 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.967613059227093  steps 687  memory 19\n",
      "=========================episode 151 snake======================\n",
      "------guess 0 0 basin-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 slant-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 snake-------\n",
      "reward 0 done True action 0\n",
      "episode 151 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.968095237957392  steps 690  memory 23\n",
      "=========================episode 152 outgo======================\n",
      "------guess 0 0 proxy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 telia-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 junto-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 outdo-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 outgo-------\n",
      "reward 0 done True action 0\n",
      "episode 152 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9688829693389391  steps 695  memory 26\n",
      "=========================episode 153 brace======================\n",
      "------guess 0 0 pride-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tolas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 brave-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 brake-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 munch-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 brace-------\n",
      "reward 0 done True action 0\n",
      "episode 153 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9698026165776815  steps 701  memory 31\n",
      "=========================episode 154 exist======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 exist-------\n",
      "reward 0 done True action 0\n",
      "episode 154 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.970400564832108  steps 705  memory 37\n",
      "=========================episode 155 aptly======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 tally-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 aptly-------\n",
      "reward 0 done True action 0\n",
      "episode 155 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9711313774903149  steps 710  memory 41\n",
      "=========================episode 156 owner======================\n",
      "------guess 0 0 phase-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 newer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 owner-------\n",
      "reward 0 done True action 0\n",
      "episode 156 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9715611752858155  steps 713  memory 46\n",
      "=========================episode 157 trial======================\n",
      "------guess 0 0 etude-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 cacti-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 shorl-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 trial-------\n",
      "reward 0 done True action 0\n",
      "episode 157 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.972124301744753  steps 717  memory 49\n",
      "=========================episode 158 essay======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 essay-------\n",
      "reward 0 done True action 0\n",
      "episode 158 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9725393168239839  steps 720  memory 53\n",
      "=========================episode 159 modem======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 dopey-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 modem-------\n",
      "reward 0 done True action 0\n",
      "episode 159 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9729481531336496  steps 723  memory 56\n",
      "=========================episode 160 shrug======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 scrub-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shrug-------\n",
      "reward 0 done True action 0\n",
      "episode 160 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9733509026636445  steps 726  memory 59\n",
      "optimize_model_batch -1 62\n",
      "monte weights\n",
      "tensor([[-3.8000, -3.3816],\n",
      "        [-2.4935, -2.7024],\n",
      "        [-1.1690, -2.0460],\n",
      "        [-0.4925, -1.4769],\n",
      "        [-0.3662, -1.2857],\n",
      "        [-0.1765, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.3969, 0.6031],\n",
      "        [0.5520, 0.4480],\n",
      "        [0.7062, 0.2938],\n",
      "        [0.7280, 0.2720],\n",
      "        [0.7149, 0.2851],\n",
      "        [0.6950, 0.3050]], dtype=torch.float64)\n",
      "{'count': 85, 'total': -323, 'avg': -3.8} {'count': 76, 'total': -257, 'avg': -3.3815789473684212}\n",
      "{'count': 77, 'total': -192, 'avg': -2.4935064935064934} {'count': 84, 'total': -227, 'avg': -2.7023809523809526}\n",
      "{'count': 71, 'total': -83, 'avg': -1.1690140845070423} {'count': 87, 'total': -178, 'avg': -2.045977011494253}\n",
      "{'count': 67, 'total': -33, 'avg': -0.4925373134328358} {'count': 65, 'total': -96, 'avg': -1.476923076923077}\n",
      "{'count': 71, 'total': -26, 'avg': -0.36619718309859156} {'count': 14, 'total': -18, 'avg': -1.2857142857142858}\n",
      "{'count': 17, 'total': -3, 'avg': -0.17647058823529413} {'count': 12, 'total': -12, 'avg': -1.0}\n",
      "done 726 optimizations, 726 transitions added to memory\n",
      "=========================episode 161 joist======================\n",
      "------guess 0 0 guilt-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 taint-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wrist-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 hoist-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 pecky-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 imbed-------\n",
      "reward -1 done True action 1\n",
      "episode 161 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9741385025168343  steps 732  memory 0\n",
      "=========================episode 162 gaffe======================\n",
      "------guess 0 0 horde-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 litas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 bungy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 clomp-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 wakfs-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 vizir-------\n",
      "reward -1 done True action 1\n",
      "episode 162 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9749028252765859  steps 738  memory 6\n",
      "=========================episode 163 merry======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 ferry-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 merry-------\n",
      "reward 0 done True action 0\n",
      "episode 163 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9752764735296606  steps 741  memory 12\n",
      "=========================episode 164 guess======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 segue-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 guess-------\n",
      "reward 0 done True action 0\n",
      "episode 164 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9757660321543089  steps 745  memory 15\n",
      "=========================episode 165 onion======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 onion-------\n",
      "reward 0 done True action 0\n",
      "episode 165 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9760071641632908  steps 747  memory 19\n",
      "=========================episode 166 flier======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 idler-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 liner-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 plier-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 cushy-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 flier-------\n",
      "reward 0 done True action 0\n",
      "episode 166 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.976716259625103  steps 753  memory 21\n",
      "=========================episode 167 spicy======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 skull-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sissy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 spiny-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 spicy-------\n",
      "reward 0 done True action 0\n",
      "episode 167 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9772911372232687  steps 758  memory 27\n",
      "=========================episode 168 wight======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 wight-------\n",
      "reward 0 done True action 0\n",
      "episode 168 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9776292281438344  steps 761  memory 32\n",
      "=========================episode 169 mouth======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 booth-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 mouth-------\n",
      "reward 0 done True action 0\n",
      "episode 169 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9780721991057384  steps 765  memory 35\n",
      "=========================episode 170 chili======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 flick-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 child-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 chili-------\n",
      "reward 0 done True action 0\n",
      "episode 170 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9786135984388429  steps 770  memory 39\n",
      "=========================episode 171 scarf======================\n",
      "------guess 0 0 caste-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 scary-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 scarf-------\n",
      "reward 0 done True action 0\n",
      "episode 171 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9789320004769586  steps 773  memory 44\n",
      "=========================episode 172 pride======================\n",
      "------guess 0 0 junta-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 comfy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 slier-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 drive-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 4 1 peghs-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 pride-------\n",
      "reward 0 done True action 0\n",
      "episode 172 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9795546539620623  steps 779  memory 47\n",
      "=========================episode 173 deity======================\n",
      "------guess 0 0 match-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 forte-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 piety-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 deity-------\n",
      "reward 0 done True action 0\n",
      "episode 173 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.979959498938316  steps 783  memory 53\n",
      "=========================episode 174 aunty======================\n",
      "------guess 0 0 crash-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toile-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 aunty-------\n",
      "reward 0 done True action 0\n",
      "episode 174 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9802578631285073  steps 786  memory 57\n",
      "=========================episode 175 match======================\n",
      "------guess 0 0 conch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 later-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 batch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 patch-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 muids-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 match-------\n",
      "reward 0 done True action 0\n",
      "episode 175 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9808413314503566  steps 792  memory 60\n",
      "=========================episode 176 olden======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 olden-------\n",
      "reward 0 done True action 0\n",
      "episode 176 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9811265668648486  steps 795  memory 66\n",
      "optimize_model_batch -1 69\n",
      "monte weights\n",
      "tensor([[-3.8261, -3.3294],\n",
      "        [-2.4941, -2.6739],\n",
      "        [-1.1905, -2.0787],\n",
      "        [-0.5789, -1.5000],\n",
      "        [-0.3562, -1.3158],\n",
      "        [-0.1500, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.3783, 0.6217],\n",
      "        [0.5448, 0.4552],\n",
      "        [0.7085, 0.2915],\n",
      "        [0.7153, 0.2847],\n",
      "        [0.7230, 0.2770],\n",
      "        [0.7006, 0.2994]], dtype=torch.float64)\n",
      "{'count': 92, 'total': -352, 'avg': -3.8260869565217392} {'count': 85, 'total': -283, 'avg': -3.3294117647058825}\n",
      "{'count': 85, 'total': -212, 'avg': -2.4941176470588236} {'count': 92, 'total': -246, 'avg': -2.6739130434782608}\n",
      "{'count': 84, 'total': -100, 'avg': -1.1904761904761905} {'count': 89, 'total': -185, 'avg': -2.0786516853932584}\n",
      "{'count': 76, 'total': -44, 'avg': -0.5789473684210527} {'count': 66, 'total': -99, 'avg': -1.5}\n",
      "{'count': 73, 'total': -26, 'avg': -0.3561643835616438} {'count': 19, 'total': -25, 'avg': -1.3157894736842106}\n",
      "{'count': 20, 'total': -3, 'avg': -0.15} {'count': 14, 'total': -14, 'avg': -1.0}\n",
      "done 795 optimizations, 795 transitions added to memory\n",
      "=========================episode 177 tweet======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 fetch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 tweed-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 tweet-------\n",
      "reward 0 done True action 0\n",
      "episode 177 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9815925535892828  steps 800  memory 0\n",
      "=========================episode 178 slosh======================\n",
      "------guess 0 0 surge-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 scion-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lathy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 umped-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 slosh-------\n",
      "reward 0 done True action 0\n",
      "episode 178 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9820470350604972  steps 805  memory 5\n",
      "=========================episode 179 stood======================\n",
      "------guess 0 0 dunce-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tolar-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 idiot-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 stood-------\n",
      "reward 0 done True action 0\n",
      "episode 179 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9824025275843766  steps 809  memory 10\n",
      "=========================episode 180 untie======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 untie-------\n",
      "reward 0 done True action 0\n",
      "episode 180 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9826645198165338  steps 812  memory 14\n",
      "=========================episode 181 leaky======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 leaky-------\n",
      "reward 0 done True action 0\n",
      "episode 181 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9829226114925153  steps 815  memory 17\n",
      "=========================episode 182 kitty======================\n",
      "------guess 0 0 woozy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 alter-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 bitty-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 ditty-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 snuck-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 kitty-------\n",
      "reward 0 done True action 0\n",
      "episode 182 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9834273245982388  steps 821  memory 20\n",
      "=========================episode 183 pasty======================\n",
      "------guess 0 0 jumbo-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 agent-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 ratty-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 clips-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 khadi-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 pasty-------\n",
      "reward 0 done True action 0\n",
      "episode 183 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9839171211774116  steps 827  memory 26\n",
      "=========================episode 184 husky======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 bushy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 husky-------\n",
      "reward 0 done True action 0\n",
      "episode 184 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9842355835151455  steps 831  memory 32\n",
      "=========================episode 185 dusty======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 musty-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 linch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 gusty-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 bipod-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 dusty-------\n",
      "reward 0 done True action 0\n",
      "episode 185 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9847014924332744  steps 837  memory 36\n",
      "=========================episode 186 rodeo======================\n",
      "------guess 0 0 lower-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tinas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 rodeo-------\n",
      "reward 0 done True action 0\n",
      "episode 186 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9849292575379109  steps 840  memory 42\n",
      "=========================episode 187 giant======================\n",
      "------guess 0 0 amber-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 flash-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 ontic-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 giant-------\n",
      "reward 0 done True action 0\n",
      "episode 187 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9852276782329125  steps 844  memory 45\n",
      "=========================episode 188 shady======================\n",
      "------guess 0 0 knead-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 caddy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lirot-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 humps-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 shady-------\n",
      "reward 0 done True action 0\n",
      "episode 188 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9855924081568876  steps 849  memory 49\n",
      "=========================episode 189 safer======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 safer-------\n",
      "reward 0 done True action 0\n",
      "episode 189 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9858069092544223  steps 852  memory 54\n",
      "=========================episode 190 lunar======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 karma-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 briar-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 shuln-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 lunar-------\n",
      "reward 0 done True action 0\n",
      "episode 190 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9861573379135204  steps 857  memory 57\n",
      "=========================episode 191 sandy======================\n",
      "------guess 0 0 worth-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 plank-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 naive-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 dumbs-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 sandy-------\n",
      "reward 0 done True action 0\n",
      "episode 191 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9864991144581977  steps 862  memory 62\n",
      "=========================episode 192 grime======================\n",
      "------guess 0 0 pizza-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 thick-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 loser-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 reign-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 dumpy-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 oxbow-------\n",
      "reward -1 done True action 1\n",
      "episode 192 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9868981259270083  steps 868  memory 67\n",
      "optimize_model_batch -1 73\n",
      "monte weights\n",
      "tensor([[-3.8416, -3.3152],\n",
      "        [-2.5699, -2.6100],\n",
      "        [-1.2000, -2.0957],\n",
      "        [-0.6265, -1.4789],\n",
      "        [-0.3333, -1.3043],\n",
      "        [-0.1304, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.3714, 0.6286],\n",
      "        [0.5100, 0.4900],\n",
      "        [0.7101, 0.2899],\n",
      "        [0.7011, 0.2989],\n",
      "        [0.7253, 0.2747],\n",
      "        [0.7047, 0.2953]], dtype=torch.float64)\n",
      "{'count': 101, 'total': -388, 'avg': -3.8415841584158414} {'count': 92, 'total': -305, 'avg': -3.3152173913043477}\n",
      "{'count': 93, 'total': -239, 'avg': -2.5698924731182795} {'count': 100, 'total': -261, 'avg': -2.61}\n",
      "{'count': 95, 'total': -114, 'avg': -1.2} {'count': 94, 'total': -197, 'avg': -2.095744680851064}\n",
      "{'count': 83, 'total': -52, 'avg': -0.6265060240963856} {'count': 71, 'total': -105, 'avg': -1.4788732394366197}\n",
      "{'count': 78, 'total': -26, 'avg': -0.3333333333333333} {'count': 23, 'total': -30, 'avg': -1.3043478260869565}\n",
      "{'count': 23, 'total': -3, 'avg': -0.13043478260869565} {'count': 15, 'total': -15, 'avg': -1.0}\n",
      "done 868 optimizations, 868 transitions added to memory\n",
      "=========================episode 193 bound======================\n",
      "------guess 0 0 clump-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 dough-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 retia-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 bound-------\n",
      "reward 0 done True action 0\n",
      "episode 193 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9871575604158215  steps 872  memory 0\n",
      "=========================episode 194 glean======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 angle-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 glean-------\n",
      "reward 0 done True action 0\n",
      "episode 194 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9873487594319947  steps 875  memory 4\n",
      "=========================episode 195 tease======================\n",
      "------guess 0 0 sepia-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 tease-------\n",
      "reward 0 done True action 0\n",
      "episode 195 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9874746413789256  steps 877  memory 7\n",
      "=========================episode 196 regal======================\n",
      "------guess 0 0 felon-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 jewel-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 legal-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 regal-------\n",
      "reward 0 done True action 0\n",
      "episode 196 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9877226600969315  steps 881  memory 9\n",
      "=========================episode 197 tough======================\n",
      "------guess 0 0 octal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 rines-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 youth-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 dimps-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 tough-------\n",
      "reward 0 done True action 0\n",
      "episode 197 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9880257886991963  steps 886  memory 13\n",
      "=========================episode 198 build======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 debug-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 build-------\n",
      "reward 0 done True action 0\n",
      "episode 198 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9883214330296045  steps 891  memory 18\n",
      "=========================episode 199 raven======================\n",
      "------guess 0 0 bison-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 later-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 duchy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 guimp-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 raven-------\n",
      "reward 0 done True action 0\n",
      "episode 199 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9886097778754867  steps 896  memory 23\n",
      "=========================episode 200 erase======================\n",
      "------guess 0 0 fecal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 rosit-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dungy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 share-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 erase-------\n",
      "reward 0 done True action 0\n",
      "episode 200 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9888910034617577  steps 901  memory 28\n",
      "=========================episode 201 cream======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 brace-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 whump-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 cream-------\n",
      "reward 0 done True action 0\n",
      "episode 201 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9891652855635639  steps 906  memory 33\n",
      "=========================episode 202 beady======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 glade-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 incus-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 heady-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 beady-------\n",
      "reward 0 done True action 0\n",
      "episode 202 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9894327956161474  steps 911  memory 38\n",
      "=========================episode 203 buyer======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 jerky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 buyer-------\n",
      "reward 0 done True action 0\n",
      "episode 203 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9896420402823863  steps 915  memory 43\n",
      "=========================episode 204 quest======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 steep-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 chest-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 quest-------\n",
      "reward 0 done True action 0\n",
      "episode 204 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9898977792190211  steps 920  memory 47\n",
      "=========================episode 205 steer======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 timer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 utter-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 steer-------\n",
      "reward 0 done True action 0\n",
      "episode 205 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9900978165930326  steps 924  memory 52\n",
      "=========================episode 206 semen======================\n",
      "------guess 0 0 moose-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 semen-------\n",
      "reward 0 done True action 0\n",
      "episode 206 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9901963449641782  steps 926  memory 56\n",
      "=========================episode 207 goose======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 goose-------\n",
      "reward 0 done True action 0\n",
      "episode 207 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9902938929616504  steps 928  memory 58\n",
      "=========================episode 208 relic======================\n",
      "------guess 0 0 lipid-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 snail-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 2 0 folio-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 relic-------\n",
      "reward 0 done True action 0\n",
      "episode 208 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9904860867580364  steps 932  memory 60\n",
      "optimize_model_batch -1 64\n",
      "monte weights\n",
      "tensor([[-3.7706, -3.3000],\n",
      "        [-2.4608, -2.6262],\n",
      "        [-1.2039, -2.0808],\n",
      "        [-0.6044, -1.4533],\n",
      "        [-0.3059, -1.3043],\n",
      "        [-0.1304, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.3845, 0.6155],\n",
      "        [0.5413, 0.4587],\n",
      "        [0.7062, 0.2938],\n",
      "        [0.7003, 0.2997],\n",
      "        [0.7308, 0.2692],\n",
      "        [0.7047, 0.2953]], dtype=torch.float64)\n",
      "{'count': 109, 'total': -411, 'avg': -3.770642201834862} {'count': 100, 'total': -330, 'avg': -3.3}\n",
      "{'count': 102, 'total': -251, 'avg': -2.4607843137254903} {'count': 107, 'total': -281, 'avg': -2.6261682242990654}\n",
      "{'count': 103, 'total': -124, 'avg': -1.203883495145631} {'count': 99, 'total': -206, 'avg': -2.080808080808081}\n",
      "{'count': 91, 'total': -55, 'avg': -0.6043956043956044} {'count': 75, 'total': -109, 'avg': -1.4533333333333334}\n",
      "{'count': 85, 'total': -26, 'avg': -0.3058823529411765} {'count': 23, 'total': -30, 'avg': -1.3043478260869565}\n",
      "{'count': 23, 'total': -3, 'avg': -0.13043478260869565} {'count': 15, 'total': -15, 'avg': -1.0}\n",
      "done 932 optimizations, 932 transitions added to memory\n",
      "=========================episode 209 click======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 lying-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 chill-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 click-------\n",
      "reward 0 done True action 0\n",
      "episode 209 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9906744748622717  steps 936  memory 0\n",
      "=========================episode 210 widow======================\n",
      "------guess 0 0 drape-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 child-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 windy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 widow-------\n",
      "reward 0 done True action 0\n",
      "episode 210 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9908591326321099  steps 940  memory 4\n",
      "=========================episode 211 share======================\n",
      "------guess 0 0 manic-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 loyal-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 trues-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 share-------\n",
      "reward 0 done True action 0\n",
      "episode 211 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9910401339331211  steps 944  memory 8\n",
      "=========================episode 212 shack======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 amass-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 shack-------\n",
      "reward 0 done True action 0\n",
      "episode 212 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9912175511682391  steps 948  memory 12\n",
      "=========================episode 213 belch======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 lunge-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 spicy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 welch-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 belch-------\n",
      "reward 0 done True action 0\n",
      "episode 213 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9914343906025019  steps 953  memory 16\n",
      "=========================episode 214 enact======================\n",
      "------guess 0 0 shown-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 taler-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 enact-------\n",
      "reward 0 done True action 0\n",
      "episode 214 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9915619159125485  steps 956  memory 21\n",
      "=========================episode 215 stuff======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 stuff-------\n",
      "reward 0 done True action 0\n",
      "episode 215 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9916875426180769  steps 959  memory 24\n",
      "=========================episode 216 brute======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 berth-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 brute-------\n",
      "reward 0 done True action 0\n",
      "episode 216 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.99185214030232  steps 963  memory 27\n",
      "=========================episode 217 stead======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 dealt-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 stead-------\n",
      "reward 0 done True action 0\n",
      "episode 217 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9919734461296048  steps 966  memory 31\n",
      "=========================episode 218 fibre======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 scree-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 rifle-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 gundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 fibre-------\n",
      "reward 0 done True action 0\n",
      "episode 218 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9921716224507742  steps 971  memory 34\n",
      "=========================episode 219 shelf======================\n",
      "------guess 0 0 trace-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 impel-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 welsh-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 oundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 shelf-------\n",
      "reward 0 done True action 0\n",
      "episode 219 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.99236490578114  steps 976  memory 39\n",
      "=========================episode 220 spunk======================\n",
      "------guess 0 0 clown-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 retia-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 funky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 skunk-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 spunk-------\n",
      "reward 0 done True action 0\n",
      "episode 220 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9925534169290756  steps 981  memory 44\n",
      "=========================episode 221 awake======================\n",
      "------guess 0 0 abbot-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 riles-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 awake-------\n",
      "reward 0 done True action 0\n",
      "episode 221 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9926642821075864  steps 984  memory 49\n",
      "=========================episode 222 epoxy======================\n",
      "------guess 0 0 putty-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 realo-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 epoxy-------\n",
      "reward 0 done True action 0\n",
      "episode 222 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9927734967186236  steps 987  memory 52\n",
      "=========================episode 223 realm======================\n",
      "------guess 0 0 amass-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 mealy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 realm-------\n",
      "reward 0 done True action 0\n",
      "episode 223 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9928810853359353  steps 990  memory 55\n",
      "=========================episode 224 swash======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 swamp-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 swash-------\n",
      "reward 0 done True action 0\n",
      "episode 224 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9930220492908998  steps 994  memory 58\n",
      "optimize_model_batch -1 62\n",
      "monte weights\n",
      "tensor([[-3.7009, -3.2778],\n",
      "        [-2.4364, -2.5565],\n",
      "        [-1.1538, -2.0693],\n",
      "        [-0.5758, -1.4416],\n",
      "        [-0.2921, -1.3043],\n",
      "        [-0.1304, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.3958, 0.6042],\n",
      "        [0.5300, 0.4700],\n",
      "        [0.7141, 0.2859],\n",
      "        [0.7039, 0.2961],\n",
      "        [0.7335, 0.2665],\n",
      "        [0.7047, 0.2953]], dtype=torch.float64)\n",
      "{'count': 117, 'total': -433, 'avg': -3.700854700854701} {'count': 108, 'total': -354, 'avg': -3.2777777777777777}\n",
      "{'count': 110, 'total': -268, 'avg': -2.4363636363636365} {'count': 115, 'total': -294, 'avg': -2.5565217391304347}\n",
      "{'count': 117, 'total': -135, 'avg': -1.1538461538461537} {'count': 101, 'total': -209, 'avg': -2.0693069306930694}\n",
      "{'count': 99, 'total': -57, 'avg': -0.5757575757575758} {'count': 77, 'total': -111, 'avg': -1.4415584415584415}\n",
      "{'count': 89, 'total': -26, 'avg': -0.29213483146067415} {'count': 23, 'total': -30, 'avg': -1.3043478260869565}\n",
      "{'count': 23, 'total': -3, 'avg': -0.13043478260869565} {'count': 15, 'total': -15, 'avg': -1.0}\n",
      "done 994 optimizations, 994 transitions added to memory\n",
      "=========================episode 225 inlet======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 unset-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 inlet-------\n",
      "reward 0 done True action 0\n",
      "episode 225 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9931259374425038  steps 997  memory 0\n",
      "=========================episode 226 merge======================\n",
      "------guess 0 0 crypt-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 1 aloes-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 weird-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 revue-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 bhang-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 merge-------\n",
      "reward 0 done True action 0\n",
      "episode 226 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9933290966937447  steps 1003  memory 3\n",
      "=========================episode 227 mania======================\n",
      "------guess 0 0 fishy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 twirl-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 inane-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 admin-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 mania-------\n",
      "reward 0 done True action 0\n",
      "episode 227 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9934938018832267  steps 1008  memory 9\n",
      "=========================episode 228 knack======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 knack-------\n",
      "reward 0 done True action 0\n",
      "episode 228 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9935906665537436  steps 1011  memory 14\n",
      "=========================episode 229 medic======================\n",
      "------guess 0 0 trade-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 noils-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 dicey-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 medic-------\n",
      "reward 0 done True action 0\n",
      "episode 229 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9937175798591988  steps 1015  memory 17\n",
      "=========================episode 230 acorn======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 hoard-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 flora-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 acorn-------\n",
      "reward 0 done True action 0\n",
      "episode 230 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9938419801128311  steps 1019  memory 21\n",
      "=========================episode 231 molar======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 molar-------\n",
      "reward 0 done True action 0\n",
      "episode 231 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9939336610848368  steps 1022  memory 25\n",
      "=========================episode 232 medic======================\n",
      "------guess 0 0 excel-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 scare-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 tondi-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 medic-------\n",
      "reward 0 done True action 0\n",
      "episode 232 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.994053782643528  steps 1026  memory 28\n",
      "=========================episode 233 ounce======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 opine-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 ounce-------\n",
      "reward 0 done True action 0\n",
      "episode 233 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9941423102866643  steps 1029  memory 32\n",
      "=========================episode 234 abuse======================\n",
      "------guess 0 0 vocal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 eager-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 apnea-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 amuse-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 abuse-------\n",
      "reward 0 done True action 0\n",
      "episode 234 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9942869371609974  steps 1034  memory 35\n",
      "=========================episode 235 cigar======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 marsh-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 unlid-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 vicar-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 pawky-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 befog-------\n",
      "reward -1 done True action 1\n",
      "episode 235 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.994455783685008  steps 1040  memory 40\n",
      "=========================episode 236 adapt======================\n",
      "------guess 0 0 magic-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tores-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 adapt-------\n",
      "reward 0 done True action 0\n",
      "episode 236 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9945383263123592  steps 1043  memory 46\n",
      "=========================episode 237 sooty======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 sooty-------\n",
      "reward 0 done True action 0\n",
      "episode 237 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9946464746973401  steps 1047  memory 49\n",
      "=========================episode 238 truss======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 wrist-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lunch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 truss-------\n",
      "reward 0 done True action 0\n",
      "episode 238 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9947524816008186  steps 1051  memory 53\n",
      "=========================episode 239 gipsy======================\n",
      "------guess 0 0 spiel-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 gipsy-------\n",
      "reward 0 done True action 0\n",
      "episode 239 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9948046952812948  steps 1053  memory 57\n",
      "=========================episode 240 vomit======================\n",
      "------guess 0 0 drone-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 logic-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 motif-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 vomit-------\n",
      "reward 0 done True action 0\n",
      "episode 240 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9949075692073008  steps 1057  memory 59\n",
      "optimize_model_batch -1 63\n",
      "monte weights\n",
      "tensor([[-3.6640, -3.2500],\n",
      "        [-2.4083, -2.5207],\n",
      "        [-1.1328, -2.0571],\n",
      "        [-0.5872, -1.4416],\n",
      "        [-0.2857, -1.3200],\n",
      "        [-0.1250, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.3980, 0.6020],\n",
      "        [0.5281, 0.4719],\n",
      "        [0.7159, 0.2841],\n",
      "        [0.7015, 0.2985],\n",
      "        [0.7377, 0.2623],\n",
      "        [0.7058, 0.2942]], dtype=torch.float64)\n",
      "{'count': 125, 'total': -458, 'avg': -3.664} {'count': 116, 'total': -377, 'avg': -3.25}\n",
      "{'count': 120, 'total': -289, 'avg': -2.408333333333333} {'count': 121, 'total': -305, 'avg': -2.520661157024793}\n",
      "{'count': 128, 'total': -145, 'avg': -1.1328125} {'count': 105, 'total': -216, 'avg': -2.057142857142857}\n",
      "{'count': 109, 'total': -64, 'avg': -0.5871559633027523} {'count': 77, 'total': -111, 'avg': -1.4415584415584415}\n",
      "{'count': 91, 'total': -26, 'avg': -0.2857142857142857} {'count': 25, 'total': -33, 'avg': -1.32}\n",
      "{'count': 24, 'total': -3, 'avg': -0.125} {'count': 16, 'total': -16, 'avg': -1.0}\n",
      "done 1057 optimizations, 1057 transitions added to memory\n",
      "=========================episode 241 judge======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 fudge-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 judge-------\n",
      "reward 0 done True action 0\n",
      "episode 241 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9950084060930898  steps 1061  memory 0\n",
      "=========================episode 242 frill======================\n",
      "------guess 0 0 smith-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 realo-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 krill-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 gawps-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 frill-------\n",
      "reward 0 done True action 0\n",
      "episode 242 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.995155929987751  steps 1067  memory 4\n",
      "=========================episode 243 favor======================\n",
      "------guess 0 0 clump-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 shiny-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 ardor-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 favor-------\n",
      "reward 0 done True action 0\n",
      "episode 243 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9952755305024944  steps 1072  memory 10\n",
      "=========================episode 244 masse======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 masse-------\n",
      "reward 0 done True action 0\n",
      "episode 244 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9953458686897168  steps 1075  memory 15\n",
      "=========================episode 245 rodeo======================\n",
      "------guess 0 0 throw-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 radio-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 rodeo-------\n",
      "reward 0 done True action 0\n",
      "episode 245 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9954151596777595  steps 1078  memory 18\n",
      "=========================episode 246 fancy======================\n",
      "------guess 0 0 elide-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 baron-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 chuts-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 pigmy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 fancy-------\n",
      "reward 0 done True action 0\n",
      "episode 246 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9955283597886516  steps 1083  memory 21\n",
      "=========================episode 247 quoth======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 thong-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 quoth-------\n",
      "reward 0 done True action 0\n",
      "episode 247 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9955949338381916  steps 1086  memory 26\n",
      "=========================episode 248 gripe======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 dress-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 prune-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 hylic-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 gambo-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 gripe-------\n",
      "reward 0 done True action 0\n",
      "episode 248 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9957251232182873  steps 1092  memory 29\n",
      "=========================episode 249 proxy======================\n",
      "------guess 0 0 conch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 taler-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 group-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 proxy-------\n",
      "reward 0 done True action 0\n",
      "episode 249 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9958097714500154  steps 1096  memory 35\n",
      "=========================episode 250 light======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 uncut-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shift-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 duply-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 light-------\n",
      "reward 0 done True action 0\n",
      "episode 250 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.995913228561536  steps 1101  memory 39\n",
      "=========================episode 251 venom======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gybed-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 wakfs-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 venom-------\n",
      "reward 0 done True action 0\n",
      "episode 251 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9960340109109089  steps 1107  memory 44\n",
      "=========================episode 252 dirge======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 crude-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 gowfs-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 vodka-------\n",
      "reward -1 done True action 1\n",
      "episode 252 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9961512236023895  steps 1113  memory 50\n",
      "=========================episode 253 smart======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 start-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 budge-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 smart-------\n",
      "reward 0 done True action 0\n",
      "episode 253 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.996264972135312  steps 1119  memory 56\n",
      "=========================episode 254 rhyme======================\n",
      "------guess 0 0 adopt-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 riles-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 rerun-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 rhyme-------\n",
      "reward 0 done True action 0\n",
      "episode 254 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.996338930642269  steps 1123  memory 62\n",
      "=========================episode 255 exult======================\n",
      "------guess 0 0 blink-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 smelt-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 exult-------\n",
      "reward 0 done True action 0\n",
      "episode 255 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9964114246726681  steps 1127  memory 66\n",
      "=========================episode 256 skirt======================\n",
      "------guess 0 0 ladle-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 rotis-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 first-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 punch-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 skirt-------\n",
      "reward 0 done True action 0\n",
      "episode 256 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9965000269131928  steps 1132  memory 70\n",
      "optimize_model_batch -1 75\n",
      "monte weights\n",
      "tensor([[-3.6541, -3.2984],\n",
      "        [-2.4286, -2.5344],\n",
      "        [-1.1439, -2.0909],\n",
      "        [-0.5826, -1.4643],\n",
      "        [-0.2737, -1.3000],\n",
      "        [-0.1071, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4120, 0.5880],\n",
      "        [0.5264, 0.4736],\n",
      "        [0.7205, 0.2795],\n",
      "        [0.7072, 0.2928],\n",
      "        [0.7362, 0.2638],\n",
      "        [0.7095, 0.2905]], dtype=torch.float64)\n",
      "{'count': 133, 'total': -486, 'avg': -3.654135338345865} {'count': 124, 'total': -409, 'avg': -3.2983870967741935}\n",
      "{'count': 126, 'total': -306, 'avg': -2.4285714285714284} {'count': 131, 'total': -332, 'avg': -2.5343511450381677}\n",
      "{'count': 139, 'total': -159, 'avg': -1.143884892086331} {'count': 110, 'total': -230, 'avg': -2.090909090909091}\n",
      "{'count': 115, 'total': -67, 'avg': -0.5826086956521739} {'count': 84, 'total': -123, 'avg': -1.4642857142857142}\n",
      "{'count': 95, 'total': -26, 'avg': -0.2736842105263158} {'count': 30, 'total': -39, 'avg': -1.3}\n",
      "{'count': 28, 'total': -3, 'avg': -0.10714285714285714} {'count': 17, 'total': -17, 'avg': -1.0}\n",
      "done 1132 optimizations, 1132 transitions added to memory\n",
      "=========================episode 257 semen======================\n",
      "------guess 0 0 lanky-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 stung-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 scorn-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 imped-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 howbe-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 semen-------\n",
      "reward 0 done True action 0\n",
      "episode 257 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.996603466750368  steps 1138  memory 0\n",
      "=========================episode 258 llama======================\n",
      "------guess 0 0 press-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 talon-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 album-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 dicky-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 fight-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 vrouw-------\n",
      "reward -1 done True action 1\n",
      "episode 258 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9967038494783457  steps 1144  memory 6\n",
      "=========================episode 259 ninth======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 sixth-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 ninth-------\n",
      "reward 0 done True action 0\n",
      "episode 259 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9967529227663894  steps 1147  memory 12\n",
      "=========================episode 260 equip======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 2 0 medic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 equip-------\n",
      "reward 0 done True action 0\n",
      "episode 260 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9968172192034903  steps 1151  memory 15\n",
      "=========================episode 261 draft======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 tract-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 graft-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 kawed-------\n",
      "reward -1 done True action 1\n",
      "episode 261 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9969112845917633  steps 1157  memory 19\n",
      "=========================episode 262 askew======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 pedal-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 annex-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 cuish-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 askew-------\n",
      "reward 0 done True action 0\n",
      "episode 262 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.996987545246912  steps 1162  memory 25\n",
      "=========================episode 263 bleep======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 excel-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bleep-------\n",
      "reward 0 done True action 0\n",
      "episode 263 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9970471958476266  steps 1166  memory 30\n",
      "=========================episode 264 gnash======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 shank-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 cupid-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 gnash-------\n",
      "reward 0 done True action 0\n",
      "episode 264 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9971201008419117  steps 1171  memory 34\n",
      "=========================episode 265 froze======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 horde-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 broke-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 grope-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 froze-------\n",
      "reward 0 done True action 0\n",
      "episode 265 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9972052147249632  steps 1177  memory 39\n",
      "=========================episode 266 gamma======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 gamma-------\n",
      "reward 0 done True action 0\n",
      "episode 266 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9972468236569344  steps 1180  memory 45\n",
      "=========================episode 267 femur======================\n",
      "------guess 0 0 ninth-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 realo-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 verge-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 femur-------\n",
      "reward 0 done True action 0\n",
      "episode 267 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9973013402011476  steps 1184  memory 48\n",
      "=========================episode 268 vivid======================\n",
      "------guess 0 0 unwed-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 braid-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 vivid-------\n",
      "reward 0 done True action 0\n",
      "episode 268 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9973415180112236  steps 1187  memory 52\n",
      "=========================episode 269 parse======================\n",
      "------guess 0 0 bobby-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 erupt-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 pearl-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 parer-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 parse-------\n",
      "reward 0 done True action 0\n",
      "episode 269 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9974071561653977  steps 1192  memory 55\n",
      "=========================episode 270 begun======================\n",
      "------guess 0 0 brine-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 begun-------\n",
      "reward 0 done True action 0\n",
      "episode 270 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9974329553926143  steps 1194  memory 60\n",
      "=========================episode 271 thyme======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 smite-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lunch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 theme-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 thyme-------\n",
      "reward 0 done True action 0\n",
      "episode 271 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9974963359497979  steps 1199  memory 62\n",
      "=========================episode 272 outgo======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 outgo-------\n",
      "reward 0 done True action 0\n",
      "episode 272 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9975336106513909  steps 1202  memory 67\n",
      "optimize_model_batch -1 70\n",
      "monte weights\n",
      "tensor([[-3.6475, -3.3134],\n",
      "        [-2.4328, -2.5324],\n",
      "        [-1.1711, -2.1071],\n",
      "        [-0.6066, -1.4773],\n",
      "        [-0.2700, -1.3333],\n",
      "        [-0.1000, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4173, 0.5827],\n",
      "        [0.5249, 0.4751],\n",
      "        [0.7183, 0.2817],\n",
      "        [0.7049, 0.2951],\n",
      "        [0.7433, 0.2567],\n",
      "        [0.7109, 0.2891]], dtype=torch.float64)\n",
      "{'count': 139, 'total': -507, 'avg': -3.647482014388489} {'count': 134, 'total': -444, 'avg': -3.3134328358208953}\n",
      "{'count': 134, 'total': -326, 'avg': -2.4328358208955225} {'count': 139, 'total': -352, 'avg': -2.5323741007194243}\n",
      "{'count': 152, 'total': -178, 'avg': -1.1710526315789473} {'count': 112, 'total': -236, 'avg': -2.107142857142857}\n",
      "{'count': 122, 'total': -74, 'avg': -0.6065573770491803} {'count': 88, 'total': -130, 'avg': -1.4772727272727273}\n",
      "{'count': 100, 'total': -27, 'avg': -0.27} {'count': 33, 'total': -44, 'avg': -1.3333333333333333}\n",
      "{'count': 30, 'total': -3, 'avg': -0.1} {'count': 19, 'total': -19, 'avg': -1.0}\n",
      "done 1202 optimizations, 1202 transitions added to memory\n",
      "=========================episode 273 prick======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 crimp-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 prick-------\n",
      "reward 0 done True action 0\n",
      "episode 273 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9975703304049754  steps 1205  memory 0\n",
      "=========================episode 274 toxin======================\n",
      "------guess 0 0 hurry-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 stoae-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 joint-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 clamp-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 toxin-------\n",
      "reward 0 done True action 0\n",
      "episode 274 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9976303191610186  steps 1210  memory 3\n",
      "=========================episode 275 haute======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 taste-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 linch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 haute-------\n",
      "reward 0 done True action 0\n",
      "episode 275 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.99767724198547  steps 1214  memory 8\n",
      "=========================episode 276 agree======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 agree-------\n",
      "reward 0 done True action 0\n",
      "episode 276 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9977003538138751  steps 1216  memory 12\n",
      "=========================episode 277 batty======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 fatty-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 batty-------\n",
      "reward 0 done True action 0\n",
      "episode 277 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9977571322805142  steps 1221  memory 14\n",
      "=========================episode 278 bingo======================\n",
      "------guess 0 0 rowdy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 gusto-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 mango-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 lingo-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 cheap-------\n",
      "reward -1 done False action 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 5 0 bingo-------\n",
      "reward 0 done True action 0\n",
      "episode 278 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9978234190392848  steps 1227  memory 19\n",
      "=========================episode 279 title======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 setup-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 linch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 title-------\n",
      "reward 0 done True action 0\n",
      "episode 279 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9978665182299623  steps 1231  memory 25\n",
      "=========================episode 280 theta======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 least-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 acute-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 theta-------\n",
      "reward 0 done True action 0\n",
      "episode 280 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9979087639994849  steps 1235  memory 29\n",
      "=========================episode 281 stein======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 quiet-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 stein-------\n",
      "reward 0 done True action 0\n",
      "episode 281 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9979398984473649  steps 1238  memory 33\n",
      "=========================episode 282 showy======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 smoky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 showy-------\n",
      "reward 0 done True action 0\n",
      "episode 282 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9979806911912298  steps 1242  memory 36\n",
      "=========================episode 283 sneer======================\n",
      "------guess 0 0 sheet-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 sneer-------\n",
      "reward 0 done True action 0\n",
      "episode 283 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9980007836495889  steps 1244  memory 40\n",
      "=========================episode 284 beast======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 feast-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 yeast-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 linch-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 beast-------\n",
      "reward 0 done True action 0\n",
      "episode 284 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9980501444771549  steps 1249  memory 42\n",
      "=========================episode 285 blast======================\n",
      "------guess 0 0 fully-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 slant-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 blast-------\n",
      "reward 0 done True action 0\n",
      "episode 285 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9980887542033674  steps 1253  memory 47\n",
      "=========================episode 286 lunch======================\n",
      "------guess 0 0 froze-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 amply-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 suint-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 lunch-------\n",
      "reward 0 done True action 0\n",
      "episode 286 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9981265994057775  steps 1257  memory 51\n",
      "=========================episode 287 sumac======================\n",
      "------guess 0 0 rival-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 seton-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 squad-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 psych-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 sumac-------\n",
      "reward 0 done True action 0\n",
      "episode 287 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9981728538312551  steps 1262  memory 55\n",
      "=========================episode 288 stair======================\n",
      "------guess 0 0 woken-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 liart-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 stair-------\n",
      "reward 0 done True action 0\n",
      "episode 288 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9982000564937694  steps 1265  memory 60\n",
      "optimize_model_batch -1 63\n",
      "monte weights\n",
      "tensor([[-3.6233, -3.2797],\n",
      "        [-2.3819, -2.5241],\n",
      "        [-1.1728, -2.0776],\n",
      "        [-0.5923, -1.4615],\n",
      "        [-0.2596, -1.3235],\n",
      "        [-0.0968, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4149, 0.5851],\n",
      "        [0.5355, 0.4645],\n",
      "        [0.7119, 0.2881],\n",
      "        [0.7046, 0.2954],\n",
      "        [0.7434, 0.2566],\n",
      "        [0.7116, 0.2884]], dtype=torch.float64)\n",
      "{'count': 146, 'total': -529, 'avg': -3.6232876712328768} {'count': 143, 'total': -469, 'avg': -3.2797202797202796}\n",
      "{'count': 144, 'total': -343, 'avg': -2.3819444444444446} {'count': 145, 'total': -366, 'avg': -2.524137931034483}\n",
      "{'count': 162, 'total': -190, 'avg': -1.1728395061728396} {'count': 116, 'total': -241, 'avg': -2.0775862068965516}\n",
      "{'count': 130, 'total': -77, 'avg': -0.5923076923076923} {'count': 91, 'total': -133, 'avg': -1.4615384615384615}\n",
      "{'count': 104, 'total': -27, 'avg': -0.25961538461538464} {'count': 34, 'total': -45, 'avg': -1.3235294117647058}\n",
      "{'count': 31, 'total': -3, 'avg': -0.0967741935483871} {'count': 19, 'total': -19, 'avg': -1.0}\n",
      "done 1265 optimizations, 1265 transitions added to memory\n",
      "=========================episode 289 daily======================\n",
      "------guess 0 0 zesty-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 rally-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 gaily-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 daily-------\n",
      "reward 0 done True action 0\n",
      "episode 289 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9982356977631657  steps 1269  memory 0\n",
      "=========================episode 290 hymen======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 deign-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 hymen-------\n",
      "reward 0 done True action 0\n",
      "episode 290 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9982619648014261  steps 1272  memory 4\n",
      "=========================episode 291 yacht======================\n",
      "------guess 0 0 picky-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 yacht-------\n",
      "reward 0 done True action 0\n",
      "episode 291 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9982792585406017  steps 1274  memory 7\n",
      "=========================episode 292 waist======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 daunt-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 clips-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 waist-------\n",
      "reward 0 done True action 0\n",
      "episode 292 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9983133315043938  steps 1278  memory 9\n",
      "=========================episode 293 bleed======================\n",
      "------guess 0 0 wiser-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 excel-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bleed-------\n",
      "reward 0 done True action 0\n",
      "episode 293 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.998338442726826  steps 1281  memory 13\n",
      "=========================episode 294 abhor======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 flora-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 apron-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 abhor-------\n",
      "reward 0 done True action 0\n",
      "episode 294 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9983713437652117  steps 1285  memory 16\n",
      "=========================episode 295 crown======================\n",
      "------guess 0 0 charm-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 crown-------\n",
      "reward 0 done True action 0\n",
      "episode 295 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9983875491655133  steps 1287  memory 20\n",
      "=========================episode 296 blimp======================\n",
      "------guess 0 0 vying-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 skiff-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 blimp-------\n",
      "reward 0 done True action 0\n",
      "episode 296 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9984194778312638  steps 1291  memory 22\n",
      "=========================episode 297 rinse======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 rifle-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 2 1 synch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 rinse-------\n",
      "reward 0 done True action 0\n",
      "episode 297 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9984507742670728  steps 1295  memory 26\n",
      "=========================episode 298 elbow======================\n",
      "------guess 0 0 swish-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 clung-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 elbow-------\n",
      "reward 0 done True action 0\n",
      "episode 298 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9984814509919321  steps 1299  memory 30\n",
      "=========================episode 299 trick======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 trick-------\n",
      "reward 0 done True action 0\n",
      "episode 299 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9985115202769406  steps 1303  memory 34\n",
      "=========================episode 300 belly======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 weedy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 penny-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 jelly-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 cuish-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 belly-------\n",
      "reward 0 done True action 0\n",
      "episode 300 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9985555115009794  steps 1309  memory 38\n",
      "=========================episode 301 vapor======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 badge-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 vapor-------\n",
      "reward 0 done True action 0\n",
      "episode 301 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9985911760490943  steps 1314  memory 44\n",
      "=========================episode 302 canoe======================\n",
      "------guess 0 0 assay-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 trail-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 ounce-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 canoe-------\n",
      "reward 0 done True action 0\n",
      "episode 302 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9986190726323995  steps 1318  memory 49\n",
      "=========================episode 303 gloss======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 gloss-------\n",
      "reward 0 done True action 0\n",
      "episode 303 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.998646416826345  steps 1322  memory 53\n",
      "=========================episode 304 bylaw======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 bylaw-------\n",
      "reward 0 done True action 0\n",
      "episode 304 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9986665690543867  steps 1325  memory 57\n",
      "optimize_model_batch -1 60\n",
      "monte weights\n",
      "tensor([[-3.5621, -3.2697],\n",
      "        [-2.3312, -2.5033],\n",
      "        [-1.1598, -2.0244],\n",
      "        [-0.5643, -1.4565],\n",
      "        [-0.2571, -1.3143],\n",
      "        [-0.0938, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4274, 0.5726],\n",
      "        [0.5429, 0.4571],\n",
      "        [0.7036, 0.2964],\n",
      "        [0.7094, 0.2906],\n",
      "        [0.7421, 0.2579],\n",
      "        [0.7122, 0.2878]], dtype=torch.float64)\n",
      "{'count': 153, 'total': -545, 'avg': -3.5620915032679736} {'count': 152, 'total': -497, 'avg': -3.2697368421052633}\n",
      "{'count': 154, 'total': -359, 'avg': -2.331168831168831} {'count': 151, 'total': -378, 'avg': -2.5033112582781456}\n",
      "{'count': 169, 'total': -196, 'avg': -1.1597633136094674} {'count': 123, 'total': -249, 'avg': -2.024390243902439}\n",
      "{'count': 140, 'total': -79, 'avg': -0.5642857142857143} {'count': 92, 'total': -134, 'avg': -1.4565217391304348}\n",
      "{'count': 105, 'total': -27, 'avg': -0.2571428571428571} {'count': 35, 'total': -46, 'avg': -1.3142857142857143}\n",
      "{'count': 32, 'total': -3, 'avg': -0.09375} {'count': 19, 'total': -19, 'avg': -1.0}\n",
      "done 1325 optimizations, 1325 transitions added to memory\n",
      "=========================episode 305 elide======================\n",
      "------guess 0 0 plunk-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dishy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 glide-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 elide-------\n",
      "reward 0 done True action 0\n",
      "episode 305 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.998699491581738  steps 1330  memory 0\n",
      "=========================episode 306 baron======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 apron-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 baron-------\n",
      "reward 0 done True action 0\n",
      "episode 306 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9987188536296158  steps 1333  memory 5\n",
      "=========================episode 307 gaffe======================\n",
      "------guess 0 0 stack-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 alive-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 badge-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 gauze-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 gaffe-------\n",
      "reward 0 done True action 0\n",
      "episode 307 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9987504852462051  steps 1338  memory 8\n",
      "=========================episode 308 pagan======================\n",
      "------guess 0 0 niche-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 prank-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 pagan-------\n",
      "reward 0 done True action 0\n",
      "episode 308 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9987690880973266  steps 1341  memory 13\n",
      "=========================episode 309 straw======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 straw-------\n",
      "reward 0 done True action 0\n",
      "episode 309 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9987874139880768  steps 1344  memory 16\n",
      "=========================episode 310 blink======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 cling-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 blind-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 blink-------\n",
      "reward 0 done True action 0\n",
      "episode 310 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9988173528433845  steps 1349  memory 19\n",
      "=========================episode 311 mammy======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 axial-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 synch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 mammy-------\n",
      "reward 0 done True action 0\n",
      "episode 311 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9988407708260955  steps 1353  memory 24\n",
      "=========================episode 312 beast======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 beast-------\n",
      "reward 0 done True action 0\n",
      "episode 312 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9988523053490985  steps 1355  memory 28\n",
      "=========================episode 313 crone======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 snore-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 prone-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 ludic-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 crone-------\n",
      "reward 0 done True action 0\n",
      "episode 313 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9988806420309939  steps 1360  memory 30\n",
      "=========================episode 314 acrid======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 braid-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 acrid-------\n",
      "reward 0 done True action 0\n",
      "episode 314 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9988973071000423  steps 1363  memory 35\n",
      "=========================episode 315 bread======================\n",
      "------guess 0 0 slash-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 0 wager-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 tonic-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 azure-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 dream-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 bread-------\n",
      "reward 0 done True action 0\n",
      "episode 315 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9989298966003604  steps 1369  memory 38\n",
      "=========================episode 316 aphid======================\n",
      "------guess 0 0 ebony-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 liart-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chums-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 aphid-------\n",
      "reward 0 done True action 0\n",
      "episode 316 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9989510860673723  steps 1373  memory 44\n",
      "=========================episode 317 harsh======================\n",
      "------guess 0 0 large-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 tardy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 baron-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 marsh-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 cupid-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 harsh-------\n",
      "reward 0 done True action 0\n",
      "episode 317 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9989820861590045  steps 1379  memory 48\n",
      "=========================episode 318 rerun======================\n",
      "------guess 0 0 legal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 seedy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 intro-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 rerun-------\n",
      "reward 0 done True action 0\n",
      "episode 318 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9990022422035156  steps 1383  memory 54\n",
      "=========================episode 319 shoot======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 shoot-------\n",
      "reward 0 done True action 0\n",
      "episode 319 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9990170968818513  steps 1386  memory 58\n",
      "=========================episode 320 shown======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 shown-------\n",
      "reward 0 done True action 0\n",
      "episode 320 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9990365596676015  steps 1390  memory 61\n",
      "optimize_model_batch -1 65\n",
      "monte weights\n",
      "tensor([[-3.5688, -3.2298],\n",
      "        [-2.3171, -2.4841],\n",
      "        [-1.1517, -2.0000],\n",
      "        [-0.5772, -1.4516],\n",
      "        [-0.2545, -1.3056],\n",
      "        [-0.0882, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4161, 0.5839],\n",
      "        [0.5417, 0.4583],\n",
      "        [0.7002, 0.2998],\n",
      "        [0.7057, 0.2943],\n",
      "        [0.7410, 0.2590],\n",
      "        [0.7134, 0.2866]], dtype=torch.float64)\n",
      "{'count': 160, 'total': -571, 'avg': -3.56875} {'count': 161, 'total': -520, 'avg': -3.229813664596273}\n",
      "{'count': 164, 'total': -380, 'avg': -2.317073170731707} {'count': 157, 'total': -390, 'avg': -2.484076433121019}\n",
      "{'count': 178, 'total': -205, 'avg': -1.151685393258427} {'count': 129, 'total': -258, 'avg': -2.0}\n",
      "{'count': 149, 'total': -86, 'avg': -0.5771812080536913} {'count': 93, 'total': -135, 'avg': -1.4516129032258065}\n",
      "{'count': 110, 'total': -28, 'avg': -0.2545454545454545} {'count': 36, 'total': -47, 'avg': -1.3055555555555556}\n",
      "{'count': 34, 'total': -3, 'avg': -0.08823529411764706} {'count': 19, 'total': -19, 'avg': -1.0}\n",
      "done 1390 optimizations, 1390 transitions added to memory\n",
      "=========================episode 321 beret======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 greet-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 beret-------\n",
      "reward 0 done True action 0\n",
      "episode 321 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9990509034254591  steps 1393  memory 0\n",
      "=========================episode 322 knack======================\n",
      "------guess 0 0 ethic-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 soral-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 aback-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 knack-------\n",
      "reward 0 done True action 0\n",
      "episode 322 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999069696796795  steps 1397  memory 3\n",
      "=========================episode 323 detox======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 comet-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 dough-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 detox-------\n",
      "reward 0 done True action 0\n",
      "episode 323 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9990926660647225  steps 1402  memory 7\n",
      "=========================episode 324 drier======================\n",
      "------guess 0 0 river-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 crier-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 tolas-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 dungy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 drier-------\n",
      "reward 0 done True action 0\n",
      "episode 324 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9991150682194042  steps 1407  memory 12\n",
      "=========================episode 325 about======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 abbot-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 about-------\n",
      "reward 0 done True action 0\n",
      "episode 325 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999132591042693  steps 1411  memory 17\n",
      "=========================episode 326 swell======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 venue-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shell-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 dicky-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 pygmy-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 swell-------\n",
      "reward 0 done True action 0\n",
      "episode 326 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9991582268516215  steps 1417  memory 21\n",
      "=========================episode 327 trunk======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 grunt-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chomp-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 trunk-------\n",
      "reward 0 done True action 0\n",
      "episode 327 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9991790103047071  steps 1422  memory 27\n",
      "=========================episode 328 ruder======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 decry-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 limns-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 ruder-------\n",
      "reward 0 done True action 0\n",
      "episode 328 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9991952669898754  steps 1426  memory 32\n",
      "=========================episode 329 motif======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 notch-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 pilus-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 motif-------\n",
      "reward 0 done True action 0\n",
      "episode 329 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9992112017711097  steps 1430  memory 36\n",
      "=========================episode 330 cameo======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 cameo-------\n",
      "reward 0 done True action 0\n",
      "episode 330 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9992190504446256  steps 1432  memory 40\n",
      "=========================episode 331 cruel======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 clerk-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 cruel-------\n",
      "reward 0 done True action 0\n",
      "episode 331 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9992345142819025  steps 1436  memory 42\n",
      "=========================episode 332 churn======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 scrum-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 churn-------\n",
      "reward 0 done True action 0\n",
      "episode 332 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9992459108795064  steps 1439  memory 46\n",
      "=========================episode 333 chime======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 chime-------\n",
      "reward 0 done True action 0\n",
      "episode 333 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9992608428445372  steps 1443  memory 49\n",
      "=========================episode 334 title======================\n",
      "------guess 0 0 bluff-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 title-------\n",
      "reward 0 done True action 0\n",
      "episode 334 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9992718474609106  steps 1446  memory 53\n",
      "=========================episode 335 clean======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 lease-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bleak-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 cumin-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 clean-------\n",
      "reward 0 done True action 0\n",
      "episode 335 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9992898256111574  steps 1451  memory 56\n",
      "=========================episode 336 incur======================\n",
      "------guess 0 0 miser-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tolan-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 incur-------\n",
      "reward 0 done True action 0\n",
      "episode 336 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9993003987303509  steps 1454  memory 61\n",
      "optimize_model_batch -1 64\n",
      "monte weights\n",
      "tensor([[-3.5488, -3.2197],\n",
      "        [-2.3023, -2.4606],\n",
      "        [-1.1481, -1.9774],\n",
      "        [-0.5548, -1.4388],\n",
      "        [-0.2456, -1.2973],\n",
      "        [-0.0857, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4185, 0.5815],\n",
      "        [0.5395, 0.4605],\n",
      "        [0.6962, 0.3038],\n",
      "        [0.7076, 0.2924],\n",
      "        [0.7411, 0.2589],\n",
      "        [0.7139, 0.2861]], dtype=torch.float64)\n",
      "{'count': 164, 'total': -582, 'avg': -3.548780487804878} {'count': 173, 'total': -557, 'avg': -3.2196531791907512}\n",
      "{'count': 172, 'total': -396, 'avg': -2.302325581395349} {'count': 165, 'total': -406, 'avg': -2.4606060606060605}\n",
      "{'count': 189, 'total': -217, 'avg': -1.1481481481481481} {'count': 133, 'total': -263, 'avg': -1.9774436090225564}\n",
      "{'count': 155, 'total': -86, 'avg': -0.5548387096774193} {'count': 98, 'total': -141, 'avg': -1.4387755102040816}\n",
      "{'count': 114, 'total': -28, 'avg': -0.24561403508771928} {'count': 37, 'total': -48, 'avg': -1.2972972972972974}\n",
      "{'count': 35, 'total': -3, 'avg': -0.08571428571428572} {'count': 19, 'total': -19, 'avg': -1.0}\n",
      "done 1454 optimizations, 1454 transitions added to memory\n",
      "=========================episode 337 brass======================\n",
      "------guess 0 0 ovary-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 islet-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dunch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 brass-------\n",
      "reward 0 done True action 0\n",
      "episode 337 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9993142517636462  steps 1458  memory 0\n",
      "=========================episode 338 saucy======================\n",
      "------guess 0 0 faith-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 orles-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 sappy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 saucy-------\n",
      "reward 0 done True action 0\n",
      "episode 338 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9993278304885036  steps 1462  memory 4\n",
      "=========================episode 339 using======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 dingy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 schul-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 using-------\n",
      "reward 0 done True action 0\n",
      "episode 339 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9993411403365939  steps 1466  memory 8\n",
      "=========================episode 340 maybe======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 budge-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 maybe-------\n",
      "reward 0 done True action 0\n",
      "episode 340 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9993574076396444  steps 1471  memory 12\n",
      "=========================episode 341 civic======================\n",
      "------guess 0 0 river-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 civil-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 civic-------\n",
      "reward 0 done True action 0\n",
      "episode 341 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.999366974593516  steps 1474  memory 17\n",
      "=========================episode 342 bunny======================\n",
      "------guess 0 0 throb-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 baggy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lenis-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 bunny-------\n",
      "reward 0 done True action 0\n",
      "episode 342 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999379509336395  steps 1478  memory 20\n",
      "=========================episode 343 bossy======================\n",
      "------guess 0 0 churn-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 boast-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bossy-------\n",
      "reward 0 done True action 0\n",
      "episode 343 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9993887472388704  steps 1481  memory 24\n",
      "=========================episode 344 surly======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 brick-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 myrrh-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 surly-------\n",
      "reward 0 done True action 0\n",
      "episode 344 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9994008508544857  steps 1485  memory 27\n",
      "=========================episode 345 sauna======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 sauna-------\n",
      "reward 0 done True action 0\n",
      "episode 345 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999412714802454  steps 1489  memory 31\n",
      "=========================episode 346 wacky======================\n",
      "------guess 0 0 nylon-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 retia-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 cabby-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 wacky-------\n",
      "reward 0 done True action 0\n",
      "episode 346 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9994243438285128  steps 1493  memory 35\n",
      "=========================episode 347 timid======================\n",
      "------guess 0 0 surge-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tonal-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 timid-------\n",
      "reward 0 done True action 0\n",
      "episode 347 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9994329142323617  steps 1496  memory 39\n",
      "=========================episode 348 shift======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gibed-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 shift-------\n",
      "reward 0 done True action 0\n",
      "episode 348 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9994469156298522  steps 1501  memory 42\n",
      "=========================episode 349 plier======================\n",
      "------guess 0 0 serve-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 treat-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wooer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 linch-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 plier-------\n",
      "reward 0 done True action 0\n",
      "episode 349 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9994605713316068  steps 1506  memory 47\n",
      "=========================episode 350 icing======================\n",
      "------guess 0 0 locus-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 retia-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 winch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 icing-------\n",
      "reward 0 done True action 0\n",
      "episode 350 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9994712527348975  steps 1510  memory 52\n",
      "=========================episode 351 sweet======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 eight-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 scent-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 3 1 duply-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 sweet-------\n",
      "reward 0 done True action 0\n",
      "episode 351 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9994843075513876  steps 1515  memory 56\n",
      "=========================episode 352 pansy======================\n",
      "------guess 0 0 algae-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tiros-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 scamp-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 pansy-------\n",
      "reward 0 done True action 0\n",
      "episode 352 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9994945189460358  steps 1519  memory 61\n",
      "optimize_model_batch -1 65\n",
      "monte weights\n",
      "tensor([[-3.5057, -3.2291],\n",
      "        [-2.2905, -2.4425],\n",
      "        [-1.1357, -1.9496],\n",
      "        [-0.5244, -1.4216],\n",
      "        [-0.2373, -1.2973],\n",
      "        [-0.0857, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4313, 0.5687],\n",
      "        [0.5379, 0.4621],\n",
      "        [0.6930, 0.3070],\n",
      "        [0.7104, 0.2896],\n",
      "        [0.7427, 0.2573],\n",
      "        [0.7139, 0.2861]], dtype=torch.float64)\n",
      "{'count': 174, 'total': -610, 'avg': -3.5057471264367814} {'count': 179, 'total': -578, 'avg': -3.2290502793296088}\n",
      "{'count': 179, 'total': -410, 'avg': -2.2905027932960893} {'count': 174, 'total': -425, 'avg': -2.442528735632184}\n",
      "{'count': 199, 'total': -226, 'avg': -1.135678391959799} {'count': 139, 'total': -271, 'avg': -1.9496402877697843}\n",
      "{'count': 164, 'total': -86, 'avg': -0.524390243902439} {'count': 102, 'total': -145, 'avg': -1.4215686274509804}\n",
      "{'count': 118, 'total': -28, 'avg': -0.23728813559322035} {'count': 37, 'total': -48, 'avg': -1.2972972972972974}\n",
      "{'count': 35, 'total': -3, 'avg': -0.08571428571428572} {'count': 19, 'total': -19, 'avg': -1.0}\n",
      "done 1519 optimizations, 1519 transitions added to memory\n",
      "=========================episode 353 trout======================\n",
      "------guess 0 0 ladle-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 rosit-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 punch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 grout-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 trout-------\n",
      "reward 0 done True action 0\n",
      "episode 353 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9995069993177262  steps 1524  memory 0\n",
      "=========================episode 354 expel======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 helix-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 excel-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 dungs-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 expel-------\n",
      "reward 0 done True action 0\n",
      "episode 354 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9995191715479416  steps 1529  memory 5\n",
      "=========================episode 355 jazzy======================\n",
      "------guess 0 0 miner-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 altos-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 duchy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 jazzy-------\n",
      "reward 0 done True action 0\n",
      "episode 355 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9995286925892042  steps 1533  memory 10\n",
      "=========================episode 356 plait======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 stank-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 await-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 plait-------\n",
      "reward 0 done True action 0\n",
      "episode 356 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9995380251012184  steps 1537  memory 14\n",
      "=========================episode 357 whack======================\n",
      "------guess 0 0 giver-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lotas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 happy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 whack-------\n",
      "reward 0 done True action 0\n",
      "episode 357 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9995471728171132  steps 1541  memory 18\n",
      "=========================episode 358 showy======================\n",
      "------guess 0 0 omega-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 pouch-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shook-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 shown-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 showy-------\n",
      "reward 0 done True action 0\n",
      "episode 358 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9995583531600947  steps 1546  memory 22\n",
      "=========================episode 359 willy======================\n",
      "------guess 0 0 prawn-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 teloi-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 willy-------\n",
      "reward 0 done True action 0\n",
      "episode 359 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9995649284249213  steps 1549  memory 27\n",
      "=========================episode 360 total======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 total-------\n",
      "reward 0 done True action 0\n",
      "episode 360 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.999571405796808  steps 1552  memory 30\n",
      "=========================episode 361 grunt======================\n",
      "------guess 0 0 ditto-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lears-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 thrum-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 brunt-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 grunt-------\n",
      "reward 0 done True action 0\n",
      "episode 361 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.999581987825389  steps 1557  memory 33\n",
      "=========================episode 362 satyr======================\n",
      "------guess 0 0 rebel-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 juror-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 cigar-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 satyr-------\n",
      "reward 0 done True action 0\n",
      "episode 362 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9995902650210202  steps 1561  memory 38\n",
      "=========================episode 363 cheer======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 upper-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 cheer-------\n",
      "reward 0 done True action 0\n",
      "episode 363 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9995983783171967  steps 1565  memory 42\n",
      "=========================episode 364 cried======================\n",
      "------guess 0 0 basin-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 recto-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 price-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 crier-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 cried-------\n",
      "reward 0 done True action 0\n",
      "episode 364 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9996082943918764  steps 1570  memory 46\n",
      "=========================episode 365 rusty======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 rusty-------\n",
      "reward 0 done True action 0\n",
      "episode 365 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.999614126128628  steps 1573  memory 51\n",
      "=========================episode 366 ditch======================\n",
      "------guess 0 0 groin-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 slide-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 ditch-------\n",
      "reward 0 done True action 0\n",
      "episode 366 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9996198710421306  steps 1576  memory 54\n",
      "=========================episode 367 demur======================\n",
      "------guess 0 0 sumac-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 unmet-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 femur-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 demur-------\n",
      "reward 0 done True action 0\n",
      "episode 367 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9996273980998108  steps 1580  memory 57\n",
      "=========================episode 368 early======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 relay-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 early-------\n",
      "reward 0 done True action 0\n",
      "episode 368 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.999636597673505  steps 1585  memory 61\n",
      "optimize_model_batch -1 66\n",
      "monte weights\n",
      "tensor([[-3.4891, -3.2216],\n",
      "        [-2.2865, -2.4239],\n",
      "        [-1.1274, -1.9437],\n",
      "        [-0.5200, -1.4175],\n",
      "        [-0.2258, -1.2973],\n",
      "        [-0.0857, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4335, 0.5665],\n",
      "        [0.5343, 0.4657],\n",
      "        [0.6935, 0.3065],\n",
      "        [0.7104, 0.2896],\n",
      "        [0.7449, 0.2551],\n",
      "        [0.7139, 0.2861]], dtype=torch.float64)\n",
      "{'count': 184, 'total': -642, 'avg': -3.489130434782609} {'count': 185, 'total': -596, 'avg': -3.2216216216216216}\n",
      "{'count': 185, 'total': -423, 'avg': -2.2864864864864867} {'count': 184, 'total': -446, 'avg': -2.4239130434782608}\n",
      "{'count': 212, 'total': -239, 'avg': -1.1273584905660377} {'count': 142, 'total': -276, 'avg': -1.943661971830986}\n",
      "{'count': 175, 'total': -91, 'avg': -0.52} {'count': 103, 'total': -146, 'avg': -1.4174757281553398}\n",
      "{'count': 124, 'total': -28, 'avg': -0.22580645161290322} {'count': 37, 'total': -48, 'avg': -1.2972972972972974}\n",
      "{'count': 35, 'total': -3, 'avg': -0.08571428571428572} {'count': 19, 'total': -19, 'avg': -1.0}\n",
      "done 1585 optimizations, 1585 transitions added to memory\n",
      "=========================episode 369 wound======================\n",
      "------guess 0 0 scold-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 gonad-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 found-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 wound-------\n",
      "reward 0 done True action 0\n",
      "episode 369 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999643793521693  steps 1589  memory 0\n",
      "=========================episode 370 stalk======================\n",
      "------guess 0 0 tribe-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 1 loans-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 shalt-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 stall-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 stalk-------\n",
      "reward 0 done True action 0\n",
      "episode 370 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9996525882909785  steps 1594  memory 4\n",
      "=========================episode 371 plunk======================\n",
      "------guess 0 0 death-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 silly-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 cornu-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gompa-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 bawks-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 plunk-------\n",
      "reward 0 done True action 0\n",
      "episode 371 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9996628558586775  steps 1600  memory 9\n",
      "=========================episode 372 fight======================\n",
      "------guess 0 0 glove-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 raits-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 wight-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 tight-------\n",
      "reward -1 done True action 0\n",
      "episode 372 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9996728199738916  steps 1606  memory 15\n",
      "=========================episode 373 kayak======================\n",
      "------guess 0 0 wince-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tolar-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 pudsy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 kayak-------\n",
      "reward 0 done True action 0\n",
      "episode 373 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9996792985724761  steps 1610  memory 21\n",
      "=========================episode 374 birch======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 prism-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lurid-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 birch-------\n",
      "reward 0 done True action 0\n",
      "episode 374 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9996856488862135  steps 1614  memory 25\n",
      "=========================episode 375 loath======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 loath-------\n",
      "reward 0 done True action 0\n",
      "episode 375 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9996887767320568  steps 1616  memory 29\n",
      "=========================episode 376 lodge======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 slope-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 cumin-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 lodge-------\n",
      "reward 0 done True action 0\n",
      "episode 376 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9996949393656599  steps 1620  memory 31\n",
      "=========================episode 377 modal======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 modal-------\n",
      "reward 0 done True action 0\n",
      "episode 377 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9996979747696881  steps 1622  memory 35\n",
      "=========================episode 378 tilde======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 quite-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 tilde-------\n",
      "reward 0 done True action 0\n",
      "episode 378 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9997024713395585  steps 1625  memory 37\n",
      "=========================episode 379 elder======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 hyper-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 linds-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 elder-------\n",
      "reward 0 done True action 0\n",
      "episode 379 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997083628017644  steps 1629  memory 40\n",
      "=========================episode 380 turbo======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 court-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 defog-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 turbo-------\n",
      "reward 0 done True action 0\n",
      "episode 380 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9997169819835557  steps 1635  memory 44\n",
      "=========================episode 381 fable======================\n",
      "------guess 0 0 ideal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 latte-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 eagle-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 fable-------\n",
      "reward 0 done True action 0\n",
      "episode 381 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997225861157594  steps 1639  memory 50\n",
      "=========================episode 382 payee======================\n",
      "------guess 0 0 bayou-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 payer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lints-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 chowk-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 payee-------\n",
      "reward 0 done True action 0\n",
      "episode 382 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9997294354889659  steps 1644  memory 54\n",
      "=========================episode 383 moral======================\n",
      "------guess 0 0 friar-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 stray-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 clone-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 moral-------\n",
      "reward 0 done True action 0\n",
      "episode 383 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997347930252404  steps 1648  memory 59\n",
      "=========================episode 384 stoic======================\n",
      "------guess 0 0 since-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 stoic-------\n",
      "reward 0 done True action 0\n",
      "episode 384 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9997374318787302  steps 1650  memory 63\n",
      "optimize_model_batch -1 65\n",
      "monte weights\n",
      "tensor([[-3.4922, -3.1979],\n",
      "        [-2.2487, -2.4468],\n",
      "        [-1.1330, -1.9396],\n",
      "        [-0.5027, -1.4393],\n",
      "        [-0.2362, -1.2821],\n",
      "        [-0.1053, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4269, 0.5731],\n",
      "        [0.5494, 0.4506],\n",
      "        [0.6914, 0.3086],\n",
      "        [0.7184, 0.2816],\n",
      "        [0.7400, 0.2600],\n",
      "        [0.7099, 0.2901]], dtype=torch.float64)\n",
      "{'count': 193, 'total': -674, 'avg': -3.4922279792746114} {'count': 192, 'total': -614, 'avg': -3.1979166666666665}\n",
      "{'count': 197, 'total': -443, 'avg': -2.248730964467005} {'count': 188, 'total': -460, 'avg': -2.4468085106382977}\n",
      "{'count': 218, 'total': -247, 'avg': -1.1330275229357798} {'count': 149, 'total': -289, 'avg': -1.9395973154362416}\n",
      "{'count': 183, 'total': -92, 'avg': -0.5027322404371585} {'count': 107, 'total': -154, 'avg': -1.439252336448598}\n",
      "{'count': 127, 'total': -30, 'avg': -0.23622047244094488} {'count': 39, 'total': -50, 'avg': -1.2820512820512822}\n",
      "{'count': 38, 'total': -4, 'avg': -0.10526315789473684} {'count': 19, 'total': -19, 'avg': -1.0}\n",
      "done 1650 optimizations, 1650 transitions added to memory\n",
      "=========================episode 385 knack======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 glass-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 chaff-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 quack-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 aback-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 windy-------\n",
      "reward -1 done True action 1\n",
      "episode 385 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9997451919394614  steps 1656  memory 0\n",
      "=========================episode 386 stool======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 posit-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 stool-------\n",
      "reward 0 done True action 0\n",
      "episode 386 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9997489855372564  steps 1659  memory 6\n",
      "=========================episode 387 heist======================\n",
      "------guess 0 0 detox-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lairs-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 heist-------\n",
      "reward 0 done True action 0\n",
      "episode 387 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9997527226557382  steps 1662  memory 9\n",
      "=========================episode 388 curve======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 drive-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 verve-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 curve-------\n",
      "reward 0 done True action 0\n",
      "episode 388 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997576190752158  steps 1666  memory 12\n",
      "=========================episode 389 chart======================\n",
      "------guess 0 0 noose-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 drawl-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 2 0 chart-------\n",
      "reward 0 done True action 0\n",
      "episode 389 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.999761227657063  steps 1669  memory 16\n",
      "=========================episode 390 tenor======================\n",
      "------guess 0 0 gamut-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 oriel-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 synch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bipod-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 wakfs-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 avyze-------\n",
      "reward -1 done True action 1\n",
      "episode 390 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9997682844462619  steps 1675  memory 19\n",
      "=========================episode 391 level======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 guess-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 linch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 dumpy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 level-------\n",
      "reward 0 done True action 0\n",
      "episode 391 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9997740055236681  steps 1680  memory 25\n",
      "=========================episode 392 vegan======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 haven-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 vegan-------\n",
      "reward 0 done True action 0\n",
      "episode 392 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997784805141249  steps 1684  memory 30\n",
      "=========================episode 393 vapid======================\n",
      "------guess 0 0 stake-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 ranch-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 vapid-------\n",
      "reward 0 done True action 0\n",
      "episode 393 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9997817785096096  steps 1687  memory 34\n",
      "=========================episode 394 boast======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 boast-------\n",
      "reward 0 done True action 0\n",
      "episode 394 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9997839498497185  steps 1689  memory 37\n",
      "=========================episode 395 flare======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 glare-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 blare-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 flare-------\n",
      "reward 0 done True action 0\n",
      "episode 395 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9997903350966368  steps 1695  memory 39\n",
      "=========================episode 396 clock======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 mogul-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 whack-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 block-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 flock-------\n",
      "reward -1 done True action 0\n",
      "episode 396 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9997965316309894  steps 1701  memory 45\n",
      "=========================episode 397 trump======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 burst-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 truth-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 lindy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 truck-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 trump-------\n",
      "reward 0 done True action 0\n",
      "episode 397 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9998025450300753  steps 1707  memory 51\n",
      "=========================episode 398 jerky======================\n",
      "------guess 0 0 lunar-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toise-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 daych-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 perky-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 jerky-------\n",
      "reward 0 done True action 0\n",
      "episode 398 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.999807420210653  steps 1712  memory 57\n",
      "=========================episode 399 filer======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 wiser-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 miner-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 piper-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 gulch-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 filer-------\n",
      "reward 0 done True action 0\n",
      "episode 399 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9998131118035766  steps 1718  memory 62\n",
      "=========================episode 400 tatty======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 patty-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 batty-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 catty-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 humid-------\n",
      "reward -1 done True action 1\n",
      "episode 400 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.999818635184508  steps 1724  memory 68\n",
      "optimize_model_batch -1 74\n",
      "monte weights\n",
      "tensor([[-3.4848, -3.2512],\n",
      "        [-2.2524, -2.4872],\n",
      "        [-1.1739, -1.9539],\n",
      "        [-0.5344, -1.4732],\n",
      "        [-0.2836, -1.2927],\n",
      "        [-0.1190, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4419, 0.5581],\n",
      "        [0.5584, 0.4416],\n",
      "        [0.6857, 0.3143],\n",
      "        [0.7189, 0.2811],\n",
      "        [0.7328, 0.2672],\n",
      "        [0.7070, 0.2930]], dtype=torch.float64)\n",
      "{'count': 198, 'total': -690, 'avg': -3.484848484848485} {'count': 203, 'total': -660, 'avg': -3.251231527093596}\n",
      "{'count': 206, 'total': -464, 'avg': -2.2524271844660193} {'count': 195, 'total': -485, 'avg': -2.4871794871794872}\n",
      "{'count': 230, 'total': -270, 'avg': -1.173913043478261} {'count': 152, 'total': -297, 'avg': -1.9539473684210527}\n",
      "{'count': 189, 'total': -101, 'avg': -0.5343915343915344} {'count': 112, 'total': -165, 'avg': -1.4732142857142858}\n",
      "{'count': 134, 'total': -38, 'avg': -0.2835820895522388} {'count': 41, 'total': -53, 'avg': -1.2926829268292683}\n",
      "{'count': 42, 'total': -5, 'avg': -0.11904761904761904} {'count': 22, 'total': -22, 'avg': -1.0}\n",
      "done 1724 optimizations, 1724 transitions added to memory\n",
      "=========================episode 401 inlet======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 beget-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 inlet-------\n",
      "reward 0 done True action 0\n",
      "episode 401 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998222264484702  steps 1728  memory 0\n",
      "=========================episode 402 fussy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 skunk-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 music-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 pushy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 godly-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 fussy-------\n",
      "reward 0 done True action 0\n",
      "episode 402 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9998274804509348  steps 1734  memory 4\n",
      "=========================episode 403 ruddy======================\n",
      "------guess 0 0 islet-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 nanny-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 moody-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 ruddy-------\n",
      "reward 0 done True action 0\n",
      "episode 403 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998308965668868  steps 1738  memory 10\n",
      "=========================episode 404 where======================\n",
      "------guess 0 0 human-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 perch-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 toils-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 where-------\n",
      "reward 0 done True action 0\n",
      "episode 404 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998342450392109  steps 1742  memory 14\n",
      "=========================episode 405 eclat======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 meant-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 2 1 sulci-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 hyped-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 eclat-------\n",
      "reward 0 done True action 0\n",
      "episode 405 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9998383375437745  steps 1747  memory 18\n",
      "=========================episode 406 speed======================\n",
      "------guess 0 0 femme-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tolar-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 sweep-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 cuing-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 speed-------\n",
      "reward 0 done True action 0\n",
      "episode 406 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9998423290040405  steps 1752  memory 23\n",
      "=========================episode 407 axiom======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 shoal-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 cumin-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 podgy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 bawks-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 axiom-------\n",
      "reward 0 done True action 0\n",
      "episode 407 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9998469888862008  steps 1758  memory 28\n",
      "=========================episode 408 stave======================\n",
      "------guess 0 0 exile-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 ratos-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 stave-------\n",
      "reward 0 done True action 0\n",
      "episode 408 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9998492669249045  steps 1761  memory 34\n",
      "=========================episode 409 clamp======================\n",
      "------guess 0 0 mucus-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 crimp-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 oaten-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 clamp-------\n",
      "reward 0 done True action 0\n",
      "episode 409 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999852251639768  steps 1765  memory 37\n",
      "=========================episode 410 atoll======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 boast-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 atoll-------\n",
      "reward 0 done True action 0\n",
      "episode 410 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9998544513262787  steps 1768  memory 41\n",
      "=========================episode 411 vapor======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 vapor-------\n",
      "reward 0 done True action 0\n",
      "episode 411 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998573333831168  steps 1772  memory 44\n",
      "=========================episode 412 wheel======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 spiel-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 excel-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 dungy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 bevel-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 wheel-------\n",
      "reward 0 done True action 0\n",
      "episode 412 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9998615498188592  steps 1778  memory 48\n",
      "=========================episode 413 woven======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 woken-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 woven-------\n",
      "reward 0 done True action 0\n",
      "episode 413 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9998649681660112  steps 1783  memory 54\n",
      "=========================episode 414 stack======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 stack-------\n",
      "reward 0 done True action 0\n",
      "episode 414 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998676419754701  steps 1787  memory 59\n",
      "=========================episode 415 shall======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 shall-------\n",
      "reward 0 done True action 0\n",
      "episode 415 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9998696125297333  steps 1790  memory 63\n",
      "=========================episode 416 chant======================\n",
      "------guess 0 0 strap-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 latte-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 afoot-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 mucin-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 hedgy-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 bawks-------\n",
      "reward -1 done True action 1\n",
      "episode 416 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.999873466061849  steps 1796  memory 66\n",
      "optimize_model_batch -1 72\n",
      "monte weights\n",
      "tensor([[-3.4853, -3.2676],\n",
      "        [-2.2824, -2.4726],\n",
      "        [-1.1891, -1.9312],\n",
      "        [-0.5279, -1.4872],\n",
      "        [-0.2826, -1.2955],\n",
      "        [-0.1111, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4458, 0.5542],\n",
      "        [0.5474, 0.4526],\n",
      "        [0.6775, 0.3225],\n",
      "        [0.7230, 0.2770],\n",
      "        [0.7336, 0.2664],\n",
      "        [0.7087, 0.2913]], dtype=torch.float64)\n",
      "{'count': 204, 'total': -711, 'avg': -3.485294117647059} {'count': 213, 'total': -696, 'avg': -3.267605633802817}\n",
      "{'count': 216, 'total': -493, 'avg': -2.2824074074074074} {'count': 201, 'total': -497, 'avg': -2.472636815920398}\n",
      "{'count': 238, 'total': -283, 'avg': -1.1890756302521008} {'count': 160, 'total': -309, 'avg': -1.93125}\n",
      "{'count': 197, 'total': -104, 'avg': -0.5279187817258884} {'count': 117, 'total': -174, 'avg': -1.4871794871794872}\n",
      "{'count': 138, 'total': -39, 'avg': -0.2826086956521739} {'count': 44, 'total': -57, 'avg': -1.2954545454545454}\n",
      "{'count': 45, 'total': -5, 'avg': -0.1111111111111111} {'count': 23, 'total': -23, 'avg': -1.0}\n",
      "done 1796 optimizations, 1796 transitions added to memory\n",
      "=========================episode 417 cumin======================\n",
      "------guess 0 0 whelp-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 savvy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 occur-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 teind-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 gombo-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 cumin-------\n",
      "reward 0 done True action 0\n",
      "episode 417 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.999877205704879  steps 1802  memory 0\n",
      "=========================episode 418 pagan======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 panic-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 pagan-------\n",
      "reward 0 done True action 0\n",
      "episode 418 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9998790338737612  steps 1805  memory 6\n",
      "=========================episode 419 sober======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 cover-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lower-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 homer-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 nidus-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 grapy-------\n",
      "reward -1 done True action 1\n",
      "episode 419 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9998826089630809  steps 1811  memory 9\n",
      "=========================episode 420 which======================\n",
      "------guess 0 0 press-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 oddly-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 thick-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 which-------\n",
      "reward 0 done True action 0\n",
      "episode 420 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998849334613538  steps 1815  memory 15\n",
      "=========================episode 421 dunce======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 venue-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 dunce-------\n",
      "reward 0 done True action 0\n",
      "episode 421 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999887211931477  steps 1819  memory 19\n",
      "=========================episode 422 inlet======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 thief-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 islet-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 inlet-------\n",
      "reward 0 done True action 0\n",
      "episode 422 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998894452848689  steps 1823  memory 23\n",
      "=========================episode 423 tease======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 stake-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 tease-------\n",
      "reward 0 done True action 0\n",
      "episode 423 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998916344149007  steps 1827  memory 27\n",
      "=========================episode 424 shock======================\n",
      "------guess 0 0 blimp-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 squad-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sooth-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 shorn-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 gryce-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 shock-------\n",
      "reward 0 done True action 0\n",
      "episode 424 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.99989483710195  steps 1833  memory 31\n",
      "=========================episode 425 chart======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 trait-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 apart-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 chart-------\n",
      "reward 0 done True action 0\n",
      "episode 425 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998969194668503  steps 1837  memory 37\n",
      "=========================episode 426 pupal======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 album-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 pupal-------\n",
      "reward 0 done True action 0\n",
      "episode 426 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998989605981629  steps 1841  memory 41\n",
      "=========================episode 427 puppy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 dumpy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chowk-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 guppy-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 puppy-------\n",
      "reward 0 done True action 0\n",
      "episode 427 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9999019467637748  steps 1847  memory 45\n",
      "=========================episode 428 clued======================\n",
      "------guess 0 0 harsh-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toile-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 clued-------\n",
      "reward 0 done True action 0\n",
      "episode 428 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999038883479386  steps 1851  memory 51\n",
      "=========================episode 429 found======================\n",
      "------guess 0 0 medal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 dowry-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bound-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 hound-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 found-------\n",
      "reward 0 done True action 0\n",
      "episode 429 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999062613530831  steps 1856  memory 55\n",
      "=========================episode 430 cello======================\n",
      "------guess 0 0 perch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 loast-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 cello-------\n",
      "reward 0 done True action 0\n",
      "episode 430 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.99990765693972  steps 1859  memory 60\n",
      "=========================episode 431 rebus======================\n",
      "------guess 0 0 bread-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 ember-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 toils-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 rebus-------\n",
      "reward 0 done True action 0\n",
      "episode 431 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999094854548244  steps 1863  memory 63\n",
      "=========================episode 432 radio======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 radio-------\n",
      "reward 0 done True action 0\n",
      "episode 432 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999108330408397  steps 1866  memory 67\n",
      "optimize_model_batch -1 70\n",
      "monte weights\n",
      "tensor([[-3.4882, -3.2703],\n",
      "        [-2.3022, -2.4567],\n",
      "        [-1.2063, -1.9198],\n",
      "        [-0.5288, -1.4958],\n",
      "        [-0.2857, -1.2979],\n",
      "        [-0.1042, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4457, 0.5543],\n",
      "        [0.5386, 0.4614],\n",
      "        [0.6712, 0.3288],\n",
      "        [0.7245, 0.2755],\n",
      "        [0.7334, 0.2666],\n",
      "        [0.7101, 0.2899]], dtype=torch.float64)\n",
      "{'count': 211, 'total': -736, 'avg': -3.4881516587677726} {'count': 222, 'total': -726, 'avg': -3.27027027027027}\n",
      "{'count': 225, 'total': -518, 'avg': -2.3022222222222224} {'count': 208, 'total': -511, 'avg': -2.456730769230769}\n",
      "{'count': 252, 'total': -304, 'avg': -1.2063492063492063} {'count': 162, 'total': -311, 'avg': -1.9197530864197532}\n",
      "{'count': 208, 'total': -110, 'avg': -0.5288461538461539} {'count': 119, 'total': -178, 'avg': -1.495798319327731}\n",
      "{'count': 140, 'total': -40, 'avg': -0.2857142857142857} {'count': 47, 'total': -61, 'avg': -1.297872340425532}\n",
      "{'count': 48, 'total': -5, 'avg': -0.10416666666666667} {'count': 24, 'total': -24, 'avg': -1.0}\n",
      "done 1866 optimizations, 1866 transitions added to memory\n",
      "=========================episode 433 cider======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 crier-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 budge-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 cider-------\n",
      "reward 0 done True action 0\n",
      "episode 433 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9999134683227429  steps 1872  memory 0\n",
      "=========================episode 434 cough======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 bough-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 cough-------\n",
      "reward 0 done True action 0\n",
      "episode 434 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999151817647536  steps 1876  memory 6\n",
      "=========================episode 435 motel======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 motel-------\n",
      "reward 0 done True action 0\n",
      "episode 435 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999164445437626  steps 1879  memory 10\n",
      "=========================episode 436 setup======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 setup-------\n",
      "reward 0 done True action 0\n",
      "episode 436 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999180990526486  steps 1883  memory 13\n",
      "=========================episode 437 ghoul======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 spoil-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 ogham-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 bawks-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 ghoul-------\n",
      "reward 0 done True action 0\n",
      "episode 437 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9999205195914495  steps 1889  memory 17\n",
      "=========================episode 438 bible======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 siege-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wince-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bible-------\n",
      "reward 0 done True action 0\n",
      "episode 438 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999220934089849  steps 1893  memory 23\n",
      "=========================episode 439 ovoid======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 owing-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 schul-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 ovoid-------\n",
      "reward 0 done True action 0\n",
      "episode 439 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999236360628451  steps 1897  memory 27\n",
      "=========================episode 440 atoll======================\n",
      "------guess 0 0 nerdy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 salto-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 octal-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 atoll-------\n",
      "reward 0 done True action 0\n",
      "episode 440 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999251481701124  steps 1901  memory 31\n",
      "=========================episode 441 paint======================\n",
      "------guess 0 0 woken-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 0 faint-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 saint-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 curly-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 paint-------\n",
      "reward 0 done True action 0\n",
      "episode 441 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9999273603760076  steps 1907  memory 35\n",
      "=========================episode 442 lodge======================\n",
      "------guess 0 0 lasso-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 nitre-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 lodge-------\n",
      "reward 0 done True action 0\n",
      "episode 442 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999284418391168  steps 1910  memory 41\n",
      "=========================episode 443 equip======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 seven-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bicep-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 equip-------\n",
      "reward 0 done True action 0\n",
      "episode 443 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999929858785638  steps 1914  memory 44\n",
      "=========================episode 444 grasp======================\n",
      "------guess 0 0 shirk-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 roast-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 brass-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 uncle-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 grasp-------\n",
      "reward 0 done True action 0\n",
      "episode 444 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.999931590578391  steps 1919  memory 48\n",
      "=========================episode 445 motto======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 motto-------\n",
      "reward 0 done True action 0\n",
      "episode 445 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999326090619917  steps 1922  memory 53\n",
      "=========================episode 446 arose======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 arose-------\n",
      "reward 0 done True action 0\n",
      "episode 446 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9999332796130286  steps 1924  memory 56\n",
      "=========================episode 447 risen======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 creek-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shrew-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 risen-------\n",
      "reward 0 done True action 0\n",
      "episode 447 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999346007652081  steps 1928  memory 58\n",
      "=========================episode 448 mower======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 poser-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 cover-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 foyer-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 unlid-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 mower-------\n",
      "reward 0 done True action 0\n",
      "episode 448 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9999365336046988  steps 1934  memory 62\n",
      "optimize_model_batch -1 68\n",
      "monte weights\n",
      "tensor([[-3.4884, -3.2650],\n",
      "        [-2.3120, -2.4372],\n",
      "        [-1.2053, -1.9217],\n",
      "        [-0.5253, -1.5000],\n",
      "        [-0.2837, -1.2745],\n",
      "        [-0.0962, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4444, 0.5556],\n",
      "        [0.5313, 0.4687],\n",
      "        [0.6718, 0.3282],\n",
      "        [0.7260, 0.2740],\n",
      "        [0.7293, 0.2707],\n",
      "        [0.7117, 0.2883]], dtype=torch.float64)\n",
      "{'count': 215, 'total': -750, 'avg': -3.488372093023256} {'count': 234, 'total': -764, 'avg': -3.264957264957265}\n",
      "{'count': 234, 'total': -541, 'avg': -2.3119658119658117} {'count': 215, 'total': -524, 'avg': -2.437209302325581}\n",
      "{'count': 263, 'total': -317, 'avg': -1.2053231939163498} {'count': 166, 'total': -319, 'avg': -1.9216867469879517}\n",
      "{'count': 217, 'total': -114, 'avg': -0.5253456221198156} {'count': 122, 'total': -183, 'avg': -1.5}\n",
      "{'count': 141, 'total': -40, 'avg': -0.28368794326241137} {'count': 51, 'total': -65, 'avg': -1.2745098039215685}\n",
      "{'count': 52, 'total': -5, 'avg': -0.09615384615384616} {'count': 24, 'total': -24, 'avg': -1.0}\n",
      "done 1934 optimizations, 1934 transitions added to memory\n",
      "=========================episode 449 matey======================\n",
      "------guess 0 0 pesky-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 rotal-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 matey-------\n",
      "reward 0 done True action 0\n",
      "episode 449 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999374784962252  steps 1937  memory 0\n",
      "=========================episode 450 siren======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 fiber-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 siren-------\n",
      "reward 0 done True action 0\n",
      "episode 450 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999384093201494  steps 1940  memory 3\n",
      "=========================episode 451 heard======================\n",
      "------guess 0 0 truer-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 shear-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 colin-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 heard-------\n",
      "reward 0 done True action 0\n",
      "episode 451 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999396288973225  steps 1944  memory 6\n",
      "=========================episode 452 leaky======================\n",
      "------guess 0 0 elope-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 stair-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 mealy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 bough-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 wakfs-------\n",
      "reward -1 done True action 1\n",
      "episode 452 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9999414131330512  steps 1950  memory 10\n",
      "=========================episode 453 faint======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 taint-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 faint-------\n",
      "reward 0 done True action 0\n",
      "episode 453 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999425732307435  steps 1954  memory 16\n",
      "=========================episode 454 leaky======================\n",
      "------guess 0 0 tenet-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 soral-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 pudic-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 fella-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 mealy-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 leaky-------\n",
      "reward 0 done True action 0\n",
      "episode 454 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.999944270448269  steps 1960  memory 20\n",
      "=========================episode 455 since======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 snide-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 singe-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 since-------\n",
      "reward 0 done True action 0\n",
      "episode 455 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9999459175054359  steps 1966  memory 26\n",
      "=========================episode 456 abode======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 awoke-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 abode-------\n",
      "reward 0 done True action 0\n",
      "episode 456 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999469884105793  steps 1970  memory 32\n",
      "=========================episode 457 issue======================\n",
      "------guess 0 0 cheer-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lotas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 duing-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 issue-------\n",
      "reward 0 done True action 0\n",
      "episode 457 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999480381103799  steps 1974  memory 36\n",
      "=========================episode 458 aside======================\n",
      "------guess 0 0 knoll-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 rider-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 fetid-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 abide-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 4 1 cushy-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 aside-------\n",
      "reward 0 done True action 0\n",
      "episode 458 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9999495738163034  steps 1980  memory 40\n",
      "=========================episode 459 parry======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 array-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 harry-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 carry-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 marry-------\n",
      "reward -1 done True action 0\n",
      "episode 459 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9999510641352577  steps 1986  memory 46\n",
      "=========================episode 460 booze======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 vogue-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 booze-------\n",
      "reward 0 done True action 0\n",
      "episode 460 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999522723660632  steps 1991  memory 52\n",
      "=========================episode 461 flack======================\n",
      "------guess 0 0 bible-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 focal-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 flack-------\n",
      "reward 0 done True action 0\n",
      "episode 461 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999529829379599  steps 1994  memory 57\n",
      "=========================episode 462 mayor======================\n",
      "------guess 0 0 canal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tores-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 razor-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 major-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 mayor-------\n",
      "reward 0 done True action 0\n",
      "episode 462 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999541437933578  steps 1999  memory 60\n",
      "=========================episode 463 rogue======================\n",
      "------guess 0 0 cairn-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 sever-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 probe-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 gorge-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 fluyt-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 hamed-------\n",
      "reward -1 done True action 1\n",
      "episode 463 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9999554990490785  steps 2005  memory 65\n",
      "=========================episode 464 qualm======================\n",
      "------guess 0 0 evoke-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 flirt-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 qualm-------\n",
      "reward 0 done True action 0\n",
      "episode 464 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999561615819237  steps 2008  memory 71\n",
      "optimize_model_batch -1 74\n",
      "monte weights\n",
      "tensor([[-3.5022, -3.2792],\n",
      "        [-2.3125, -2.4667],\n",
      "        [-1.2255, -1.9294],\n",
      "        [-0.5702, -1.4959],\n",
      "        [-0.2966, -1.2909],\n",
      "        [-0.1071, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4445, 0.5555],\n",
      "        [0.5385, 0.4615],\n",
      "        [0.6691, 0.3309],\n",
      "        [0.7162, 0.2838],\n",
      "        [0.7299, 0.2701],\n",
      "        [0.7095, 0.2905]], dtype=torch.float64)\n",
      "{'count': 225, 'total': -788, 'avg': -3.502222222222222} {'count': 240, 'total': -787, 'avg': -3.279166666666667}\n",
      "{'count': 240, 'total': -555, 'avg': -2.3125} {'count': 225, 'total': -555, 'avg': -2.466666666666667}\n",
      "{'count': 275, 'total': -337, 'avg': -1.2254545454545454} {'count': 170, 'total': -328, 'avg': -1.9294117647058824}\n",
      "{'count': 228, 'total': -130, 'avg': -0.5701754385964912} {'count': 123, 'total': -184, 'avg': -1.4959349593495934}\n",
      "{'count': 145, 'total': -43, 'avg': -0.296551724137931} {'count': 55, 'total': -71, 'avg': -1.290909090909091}\n",
      "{'count': 56, 'total': -6, 'avg': -0.10714285714285714} {'count': 26, 'total': -26, 'avg': -1.0}\n",
      "done 2008 optimizations, 2008 transitions added to memory\n",
      "=========================episode 465 dance======================\n",
      "------guess 0 0 spilt-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 fugue-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 brake-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 ycond-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 dance-------\n",
      "reward 0 done True action 0\n",
      "episode 465 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999572439563225  steps 2013  memory 0\n",
      "=========================episode 466 woken======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 dozen-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 woken-------\n",
      "reward 0 done True action 0\n",
      "episode 466 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999578805108831  steps 2016  memory 5\n",
      "=========================episode 467 reset======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 reset-------\n",
      "reward 0 done True action 0\n",
      "episode 467 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999585075883809  steps 2019  memory 8\n",
      "=========================episode 468 lurch======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 brisk-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 churn-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 lurch-------\n",
      "reward 0 done True action 0\n",
      "episode 468 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999593291931786  steps 2023  memory 11\n",
      "=========================episode 469 sunny======================\n",
      "------guess 0 0 rebel-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 shout-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 squad-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 sunny-------\n",
      "reward 0 done True action 0\n",
      "episode 469 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999601345291115  steps 2027  memory 15\n",
      "=========================episode 470 inept======================\n",
      "------guess 0 0 idiom-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 artel-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 synch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 inept-------\n",
      "reward 0 done True action 0\n",
      "episode 470 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999609239183243  steps 2031  memory 19\n",
      "=========================episode 471 raise======================\n",
      "------guess 0 0 tunic-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 igloo-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 eyras-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 arise-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 fyked-------\n",
      "reward -1 done True action 1\n",
      "episode 471 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9999620787910692  steps 2037  memory 23\n",
      "=========================episode 472 toxic======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 topic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 humid-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 befog-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 toxic-------\n",
      "reward 0 done True action 0\n",
      "episode 472 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9999631995321664  steps 2043  memory 29\n",
      "=========================episode 473 bench======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 dunce-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bench-------\n",
      "reward 0 done True action 0\n",
      "episode 473 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999639282302524  steps 2047  memory 35\n",
      "=========================episode 474 since======================\n",
      "------guess 0 0 gourd-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 femme-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 spite-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 lanch-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 since-------\n",
      "reward 0 done True action 0\n",
      "episode 474 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999648188454208  steps 2052  memory 39\n",
      "=========================episode 475 pause======================\n",
      "------guess 0 0 shave-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 caste-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lapse-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 pause-------\n",
      "reward 0 done True action 0\n",
      "episode 475 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999655154789561  steps 2056  memory 44\n",
      "=========================episode 476 chump======================\n",
      "------guess 0 0 newly-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 shock-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 charm-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 chump-------\n",
      "reward 0 done True action 0\n",
      "episode 476 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999661983182231  steps 2060  memory 48\n",
      "=========================episode 477 bawdy======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 wacky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bawdy-------\n",
      "reward 0 done True action 0\n",
      "episode 477 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999668676363668  steps 2064  memory 52\n",
      "=========================episode 478 billy======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 billy-------\n",
      "reward 0 done True action 0\n",
      "episode 478 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999675237011232  steps 2068  memory 56\n",
      "=========================episode 479 spoil======================\n",
      "------guess 0 0 duvet-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 morph-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 spoil-------\n",
      "reward 0 done True action 0\n",
      "episode 479 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999680072102223  steps 2071  memory 60\n",
      "=========================episode 480 quote======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 smote-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 linch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 quote-------\n",
      "reward 0 done True action 0\n",
      "episode 480 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999686407099045  steps 2075  memory 63\n",
      "optimize_model_batch -1 67\n",
      "monte weights\n",
      "tensor([[-3.5021, -3.2702],\n",
      "        [-2.3120, -2.4589],\n",
      "        [-1.2195, -1.9253],\n",
      "        [-0.5588, -1.4921],\n",
      "        [-0.2925, -1.2982],\n",
      "        [-0.1053, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4423, 0.5577],\n",
      "        [0.5367, 0.4633],\n",
      "        [0.6695, 0.3305],\n",
      "        [0.7177, 0.2823],\n",
      "        [0.7322, 0.2678],\n",
      "        [0.7099, 0.2901]], dtype=torch.float64)\n",
      "{'count': 233, 'total': -816, 'avg': -3.5021459227467813} {'count': 248, 'total': -811, 'avg': -3.2701612903225805}\n",
      "{'count': 250, 'total': -578, 'avg': -2.312} {'count': 231, 'total': -568, 'avg': -2.4588744588744587}\n",
      "{'count': 287, 'total': -350, 'avg': -1.2195121951219512} {'count': 174, 'total': -335, 'avg': -1.9252873563218391}\n",
      "{'count': 238, 'total': -133, 'avg': -0.5588235294117647} {'count': 126, 'total': -188, 'avg': -1.492063492063492}\n",
      "{'count': 147, 'total': -43, 'avg': -0.2925170068027211} {'count': 57, 'total': -74, 'avg': -1.2982456140350878}\n",
      "{'count': 57, 'total': -6, 'avg': -0.10526315789473684} {'count': 27, 'total': -27, 'avg': -1.0}\n",
      "done 2075 optimizations, 2075 transitions added to memory\n",
      "=========================episode 481 favor======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 abhor-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 major-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 vapor-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 favor-------\n",
      "reward 0 done True action 0\n",
      "episode 481 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9999695675169916  steps 2081  memory 0\n",
      "=========================episode 482 idler======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 ruler-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 filer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 idler-------\n",
      "reward 0 done True action 0\n",
      "episode 482 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999701701205297  steps 2085  memory 6\n",
      "=========================episode 483 willy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 imply-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 billy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 hilly-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 willy-------\n",
      "reward 0 done True action 0\n",
      "episode 483 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9999710517267018  steps 2091  memory 10\n",
      "=========================episode 484 sepia======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 sepia-------\n",
      "reward 0 done True action 0\n",
      "episode 484 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999714827103431  steps 2094  memory 16\n",
      "=========================episode 485 brink======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 grind-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 brink-------\n",
      "reward 0 done True action 0\n",
      "episode 485 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999720473905119  steps 2098  memory 19\n",
      "=========================episode 486 quick======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 cubic-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 juicy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 linds-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 quick-------\n",
      "reward 0 done True action 0\n",
      "episode 486 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999727375428993  steps 2103  memory 23\n",
      "=========================episode 487 flown======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 flown-------\n",
      "reward 0 done True action 0\n",
      "episode 487 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999731434280071  steps 2106  memory 28\n",
      "=========================episode 488 thyme======================\n",
      "------guess 0 0 eater-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 loins-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 hefty-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 cupid-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 thyme-------\n",
      "reward 0 done True action 0\n",
      "episode 488 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999738065191323  steps 2111  memory 31\n",
      "=========================episode 489 tonga======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 tango-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 tonga-------\n",
      "reward 0 done True action 0\n",
      "episode 489 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999743251848041  steps 2115  memory 36\n",
      "=========================episode 490 krill======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 usurp-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 briny-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 child-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 gowfs-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 krill-------\n",
      "reward 0 done True action 0\n",
      "episode 490 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9999750839902685  steps 2121  memory 40\n",
      "=========================episode 491 miser======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 riser-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 miser-------\n",
      "reward 0 done True action 0\n",
      "episode 491 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999755773603171  steps 2125  memory 46\n",
      "=========================episode 492 spent======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 scent-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 spent-------\n",
      "reward 0 done True action 0\n",
      "episode 492 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999761803574394  steps 2130  memory 50\n",
      "=========================episode 493 drift======================\n",
      "------guess 0 0 visor-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 leant-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 duchy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 drift-------\n",
      "reward 0 done True action 0\n",
      "episode 493 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999766520179634  steps 2134  memory 55\n",
      "=========================episode 494 lowly======================\n",
      "------guess 0 0 house-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 polyp-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 intra-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 coyly-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 lowly-------\n",
      "reward 0 done True action 0\n",
      "episode 494 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999772284816939  steps 2139  memory 59\n",
      "=========================episode 495 frank======================\n",
      "------guess 0 0 stoke-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 0 kappa-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 clank-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 murid-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 frank-------\n",
      "reward 0 done True action 0\n",
      "episode 495 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.999977790712484  steps 2144  memory 64\n",
      "=========================episode 496 sixth======================\n",
      "------guess 0 0 chock-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 glyph-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wrath-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 fifth-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 dunes-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 sixth-------\n",
      "reward 0 done True action 0\n",
      "episode 496 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9999784470961269  steps 2150  memory 69\n",
      "optimize_model_batch -1 75\n",
      "monte weights\n",
      "tensor([[-3.5126, -3.2819],\n",
      "        [-2.3320, -2.4564],\n",
      "        [-1.2425, -1.9205],\n",
      "        [-0.5668, -1.4809],\n",
      "        [-0.2922, -1.2881],\n",
      "        [-0.0984, -1.0000]], dtype=torch.float64)\n",
      "tensor([[0.4426, 0.5574],\n",
      "        [0.5311, 0.4689],\n",
      "        [0.6633, 0.3367],\n",
      "        [0.7138, 0.2862],\n",
      "        [0.7303, 0.2697],\n",
      "        [0.7113, 0.2887]], dtype=torch.float64)\n",
      "{'count': 238, 'total': -836, 'avg': -3.5126050420168067} {'count': 259, 'total': -850, 'avg': -3.281853281853282}\n",
      "{'count': 256, 'total': -597, 'avg': -2.33203125} {'count': 241, 'total': -592, 'avg': -2.4564315352697097}\n",
      "{'count': 301, 'total': -374, 'avg': -1.2425249169435215} {'count': 176, 'total': -338, 'avg': -1.9204545454545454}\n",
      "{'count': 247, 'total': -140, 'avg': -0.5668016194331984} {'count': 131, 'total': -194, 'avg': -1.4809160305343512}\n",
      "{'count': 154, 'total': -45, 'avg': -0.2922077922077922} {'count': 59, 'total': -76, 'avg': -1.2881355932203389}\n",
      "{'count': 61, 'total': -6, 'avg': -0.09836065573770492} {'count': 27, 'total': -27, 'avg': -1.0}\n",
      "done 2150 optimizations, 2150 transitions added to memory\n",
      "=========================episode 497 inane======================\n",
      "------guess 0 0 puffy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 stoke-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 niece-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 whine-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 inane-------\n",
      "reward 0 done True action 0\n",
      "episode 497 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999789792392195  steps 2155  memory 0\n",
      "=========================episode 498 whelp======================\n",
      "------guess 0 0 savoy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 mulch-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 inter-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 whelp-------\n",
      "reward 0 done True action 0\n",
      "episode 498 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999793954781712  steps 2159  memory 5\n",
      "=========================episode 499 frown======================\n",
      "------guess 0 0 lower-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 wrong-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 aitus-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 drown-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 crown-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 brown-------\n",
      "reward -1 done True action 0\n",
      "episode 499 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9999800044338203  steps 2165  memory 9\n",
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEWCAYAAABv+EDhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAACOV0lEQVR4nO2dd5gcxZn/P2/P7K4yiigHJDIiixxscrKNccI5G+dsnMPZgM9nc8cP2+eAjTM4HcZkY7IBkxFJgAAJoZzDrsKGma7fH52qu6vDzM7srrT9fZ59pre7ulJX1VtvLFFKUaBAgQIFBh+s/q5AgQIFChToHxQEoECBAgUGKQoCUKBAgQKDFAUBKFCgQIFBioIAFChQoMAgRUEAChQoUGCQoiAABQqkQERuEZH3NDptgQIDAVL4ARTY1SAiW7V/hwFdQNX9/8NKqav6vlYFCgw8FASgwC4NEVkCfFApdbvhWVkpVen7WhUoMDBQiIAKDBqIyKtFZLmIfElEVgO/FpExInKjiKwTkU3u9TTtnbtF5IPu9XtF5D4RudRN+7KInFVn2j1E5F8i0iEit4vI/4rIH/qwOwoUKAhAgUGHScBYYCZwAc4c+LX7/wxgB/DjlPePAhYC44HvA1eKiNSR9mrgYWAc8B/Au+puUYECdaIgAAUGG2zgW0qpLqXUDqXUBqXUNUqp7UqpDuAS4FUp77+ilPqFUqoK/BaYDEysJa2IzACOAL6plOpWSt0HXN+oBhYokBcFASgw2LBOKdXp/SMiw0Tk5yLyioi0A/8CRotIKeH91d6FUmq7ezmixrRTgI3aPYBlNbajQIFeoyAABQYbolYPnwf2AY5SSo0CTnTvJ4l1GoFVwFgRGabdm97E8goUMKIgAAUGO0biyP03i8hY4FvNLlAp9QrwKPAfItIqIscAr212uQUKRFEQgAKDHf8PGAqsBx4E/tFH5b4DOAbYAFwM/BnHXwFwfBlE5AT3+gTdt0FEvioit/RRPQvswij8AAoUGAAQkT8Dzyulms6BFCjgoeAAChToB4jIESIyR0QsETkTOBf4ez9Xq8AgQ7m/K1CgwCDFJOBvOH4Ay4GPKqXm92+VCgw2FCKgAgUKFBikKERABQoUKDBIsVOJgMaPH69mzZrV39UoUKBAgZ0Kjz322Hql1ITo/Z2KAMyaNYtHH320v6tRoECBAjsVROQV0/1CBFSgQIECgxQFAShQoECBQYqCABQoUKDAIEVBAAoUKFBgkKIgAAUKFCgwSNEvBEBE3iwiC0TEFpF5/VGHAgUKFBjs6C8O4BngDTiHbxQoUKBAgX5AvxAApdRzSqmF/VF2M/D40k08u7K9v6vRMHT2VLnmseXkDRPy1PLNPLV8c01l3L1wLcs2bs9OmIGX1nbw4OINxme3PL2KX967GNtuTLiTx17ZyHOrGvOd739pPUvWbwOgaiv+8ugyKlXbf37X82tZuXlH6J3rn1zJlu09vLS2g4cS2qyjp2rzl0eX5Wp/d8Xmr48uy/3Ne4uHFm/g1gWreWBR0I5tXRWunb88lrZStfnLI8uoNug71orlm7Zz18K1/VJ2szHgHcFE5AKcw7uZMWNGP9fGjDf85N8ALPneOf1ck8bgkpue4/cPvsLEUUM4fq/xmelf9+P7gdra/95fP8KQFovnLzqr7noC/OSuRTyxbDN3fuHVsWcfvepxAE7cewJ7TxzZq3IA3vjTB4DGfOd3/PIhP68/PryUr//9Gdp39PDBE2YD8L7fPMKYYS3M/+bpAGzY2sWn/jifS86by9eufSZXPa7412J+cOtCBHjzvPQDx35054v86M6XGNZa5pyDJveyddk4/4oHAZg5bhj3XHgSAN+8bgHXPL6cGWOHc/jMMX7ah5ds5IvXPMWc3UeE7vcVzrjsX2zrru4y81tH0wiAiNyOE/Ewiq8ppa7Lm49S6grgCoB58+YVkev6AGvanSNzt3b1NLWczh47O1EGuio2PXZ6PpXqwB42m7Z1O7/bu8P3twf93+1yB7W0Zf1W53yZLTuyv+O6Didte2dzv3kU3ZXg263a4nA8O7qroTRdFa/tvR8v9WBbpD67EppGAJRSpzYr7wLNhbin4e4MgWIrtk3G+o89wBvi1U5SjiH2Fv5a2uIlFWnm8ca9Q0UT6wT1DafxRFgD+yvunCjMQAvE4C1EO8OEq9pkyq0H+PqfuPDp8Bb+esTgA3f5J6SfUO6Ii/aDRyQG+nfcGdFfZqDnichynDNRbxKRW/ujHgXMGMAbxhiqtp25KA50DsCD1+0mghYsgrW3ZSB/T50D8C6jnFDV5wB2ju+4M6FflMBKqWuBa/uj7AL5sTOsmxVbZS7wA50ARBc2U3W9RbA2EdDAbjcQtuxJ4IR8IjHwm7PToRABFYjB1wHsBDOuaqscHEDf1KVe+Ou02/GmRT7QAdSQr5dtL+rWbFQ0BY4vAoqkqbpp+vsz7gwEtVYUBKBADGnKyEagkROpYqscOoCdY+J6vW5a5OvhAPx8B7AMqGpUAofr6xG//v6M/V1+M1AQgAKJaNaAb2S+1QQRkL7oD3gOIPK/kQPwdsG1cAADvN0QsQJyf60IvRooOoCBLkqsBwUBKBCHLwJqDho5kSoJIiC9iAE/cVXY+iVVB1ADNUuyqhlIUCpok63M9R0oVkADfSNRDwoCUCCGZq8XjZxIjhVQPEM7xAHsHDPXE72ZOYBd0wwUTAt8khVQ/2JnGUe1oCAABRLRLNl5QzmAqjLuDEPGJQN83uYRAdVnBdSbWvUdogt8MgfQvw3aWfqzFhQEoEAMzVYa9oUOYGfiAKKOYKZdfj2LYLChHtg8gG8J5ImAIs8HihXQQB9H9aAgAAViaL4IqHETKVkJrJfXsOKaijRHMG8R3BVFQFEOwIpaAQ0QP4CCABQYVGjWeO8LJfBOxQFEVjYjB9CLWEADHZUMJXDVMwPtdyugfi2+KSgIQIEYmu0I1lglsNkPQF8o+1t2nIW4CChNB1BTzqF8ByqqESVw1A9loFgBDfRxVA8KAlAghnrXi7wTpLGOYOZYQPq9rGihAwWS5gncm1hAA1wIFF3gYxzAACEABQdQYFCh1gmX98SmRnMA2Y5gA3vmRmvXuFhAvahUHyIQ8ZhRsdOf9xUG+jiqBwUBKBCDtxOtdbxXchOAxuoAlIrvjEMcwACft9HuaJQfQJ4w01l16QsEXs7mwqsZz/sKBQEoMCjgW6PU+F5+DqCBVkAJcWJ2Jh1AFOZYQJ4V0M7bLg/RemeNm4HCAeyk3Z2KggAUiKNOkXFeDqCRMzlpcRjIZqBZC7cp3INJEZp3QcrzOftSURytd7Rt0ecDRwcwwAZSA1AQgAKJqHWHmTdOTaN1AE6e4UwHsg4gWp1ozJ40HUAt7epvs8kkROsdDfYWrXewsehvEVC/Ft8UFASgQAz1HgnZPzqAuGjE+b855TUCSbVJjQVkOA8gq7vr0QH0BaL1zjLzTBLz9TVqCcS3s6AgAAViqHfB6GsdgK05gaXrABpSXMMQa38OJbCJ08nbjwPNDDTOAYSJeKKIqPlVS8VAG0eNQEEACiSjZiugfAb3jZpI1ZTFcCB7Aiet/3liAdUS5G5gtTpAbIGPmIFG651EGPoaA1Wk1hsUBKBADPXuF/uaA9DLixbdaCVwIy1ukhaSPLGAatIB+JSl5io2FUk6AK9bou2vRHQE/YVdUAJUEIACcdQrAsqvA6gv/7Ty0jiARizejdx9xjiAFP2Fh2i8HMi/w6/lc/bFIhv9VlERT7QG1TpOQ2sGBhon2QgUBKBAImpdDPqTA1AR6VOjzwNo5OSPEwDnNy0WkG0QATXDCqgvdrnRMqq+iMdceFRE1F/YWf0u0lAQgAIx+FZAteoAqvleaNREqubkABqxeDdyYUwWAYWtgHROzMgBZKlcfMKSnwfoi0Uu5ggWsXBK9gMoRECNRkEACsTQfCug+vKPQlc6p/sB9L6sRnIAMX1F5HkQFTOAyRmqGSKJvjB1TDQDTRAC5XYwbAIGsj9JI1AQgAKJqHW457UC6gslcKP9ABqrA4gSK+c3TQRk4gCyRUD50unoGxGQWQk8ED2BQ2NsJ4kqWwsKAlAghjSP1DTk5gAaNJF0kVNckdpYJXBDdQCZZTm/uujGdB5AtiNY2LomD/pilxtXAoeVvNEa+M/7QQuQZmiwK6AgAAUMSPZITUOtnsC99VBN5QA0IjPQREBR2X38RDC3f7R7Jo/n3Ocv1LBw9sUal7TDT8JA4QB2wfW/IAAFklHrzjkvB2CScdeDvGagA10JHIiAPOV7vDBzLKCscvKl09E/HEBYvJXoCdwPC3DBARQYdEjzSE1D7RxA70hAmhXQgHYEy8gqEAEF9/xYQCHOJkMHkCBTT0vbL2agMR1Ago6g6TWLI22M7QooCECBRNQ64Ks1KoF7zwEE5UWr2ngdQK+z0PIyZ+bV02SJ05tYQLWIgPqEA4i0L2oFFNMB+MHg+kMHoFua9XnxTUdBAAokomYOIKcfgGmHWw/61g+geUpgFRF9NDoWUG2niDV/lYvpAKoRJXASh9DsihkQ1gHsehSgXwiAiPxARJ4XkadE5FoRGd0f9ShgRlpMmjTk1wF4HEDvKEBYPht+Vou1TB401RPY/w3vhPX+qes8gFpkQAl1awayQkFE4e/C+0MHUE0eY7sC+osDuA2Yq5Q6CHgB+Eo/1aOh2FV2CGn26GmoORZQEzmARjvwNNQPIGEli63XIU/guBVQXiVwLVXvXz+AMAGMPe8HCrCr6wDK/VGoUuqf2r8PAm/qj3r0Fr+5/2XmL9vs///MinY+/9cnuOajxzJySAuf/fMTrNi0g/bOHg6fOYarH17K995wIOcfMQOAi298ltayxRfP3Lemci/43aN0V21+874j+dxfnmDphu1s7apw5B5jOW3/ibz3149wwYmz+f0Dr/DpU/biQyfONuZz7fzlfPbPT/L8RWdy8Lf/yVfO2pcRQ1r4w4NLAfNiYNuKU//nHrZ3V7n7wldzxCW3+88++cf5fO3ap/naOfvx10eX85cPH8MNT63k0396guGtJapKceEZ+3LRjc8C0F2xOevye3n7kdP5xnUL+OTJe/KjO18C4OZPncAv713Mzc+s4pqPHsusccN5w0/+zTuPnsE3rlvAvV88KcMPAO2Z89tTtTnp0rtZvmkHADd+8niueugVrnlsBd2uGOIjr5rD7x5YwllzJ3PN48sRgXccNYPrn1gZyv9r1z7NXx9bTnfF5lOn7MXnTts71lf/efNz3LpgNXdfeBIADy7ewFuveDCUZvZXbmL62GF+nVds3sE7fvkQEKz/x33vTlZsdup818J1WhuDRq7t6OTIS+7w/28pCbsNbQXgm9ctYOSQMucePJV9v/EPuqs2rz14Cj9626GxPrrs9he47PYXANh30kj+8ZkT+cGtz/O/dy0CYP43TuPMy//FW4+YwWcNbb7yvpe56MZn+fHbD+U1B03h3P+9n6UbtnHXF17N6GGtfjt1RK183v6Lh/xn//7yybmsgD5+1ePc9PQqhrRYPH/RWdzzwjouu+0FDp62G/cv2sDtn3tV7J35Szdx3k/+DcCnT9mLy+94kds+eyJ7TRzp1uNBjpk9zk9/0Y3P8sKaDn73/qM4Zs64UF6PvbKRb/x9ASfuPYGf3bOItrLFGw6byn++4aBYuTc+tZJPXD2fZ79zBi+t3cqFf32K0w+YyO8ffIUnvnl6ciObgIGgA3g/cEvSQxG5QEQeFZFH161bl5SsX/DU8i08/PJG///nVrXzwpqtrOvoAuDa+St4eMlGnl/dwVUPLUUp+N4tz/vpH1u6iflLN9dc7j+fXcPd7kLwt8dX8Ogrm3h+dQe/e+AVXlq7laqtePjljWztqnDJzc8l5vODfywEYF1HF10Vm/+44VmeWbHFf27a8fTYNovXb2N1eyftnT10dFZCz9s7K9z+3FoefWUTFVvxP7c5i8m27iqdPTZ/fmRpKP1zq9q56Canjt7iD3DdEyu47smVdPbYLN2wnXUdXSxc08G3b3CIx30vrc/wBNaeuQ+3d1f9xd8rY8HKdn/xB/jZPYvY3l3lmseXA86i84cHl9KutVMpxa0L1tBdcd774R0vxvoJ4Of/WsySDdv9/3/77yWxNLaCV9w0CsX9L62PpfEW/yh0ovf4K5tCz3qqivVbu/z/L731BSq28tt6w5NhgmbaXT+/ugPAX/wBnlvdzpr2Li5PaPPzq9oBeGHNVgCeXLaZTdt7WNsR1KUWK58HFm3IpQO46elVAHT22Ni24tmV7TyxbDO/deeECX96eJl/7bXnlmdWB2Uv3sBT2nxYsLKdnqpi8fp4fs+v7uDZVe387B6nr7oqNrcuWGMs9zJ3TqzcvIOFqztYuKaDH935Epu396S0sDloGgcgIrcDkwyPvqaUus5N8zWgAlyVlI9S6grgCoB58+YNKB5M4ewqPXiTK42NLllhuW5euXleJJ2Ra4KXQq9DmmVN9F6S0U9PNRBXWBFNb/R/gEo1npEivDB4xVYS6pquBPbqHk5jidTF1tuqPgW2ZaW/FK1KVhm16jnS2tqoYZjU12my9GCHH69EyZKa/QCqSuWySLMytr9Khee3n7+hs0z9l0ck3N8LWtMIgFLq1LTnIvJe4DXAKWonFZ4rpejRBnaPb82Q3Bx9AaxUFRWrsQFGfGuRGma0frJWOPaJaaCbF2AdPZpVR3QRM9n+Z4c0SHeOcuoafyda52g5IlJXWIp6ZcGljBU92sYsJXktlk4i6TqaRsm3fVPWhF2++VnyxsmypGYdQNVWufRRaX4oXjtMBMBk7WYan7mmYD+vfP2iAxCRM4EvAq9SSm3PSj9QYUd2CD0DiAPIMwG8MRviADKsHvR7PQlmnz2VYBGIcwCZ1XLrFl4w0kwjvTThesb1A9E0ltS38NW7WGa1vdZsaw13UU0x023UFiyJ2KZxa6kcgIjPIeatYyXnvEr7Hr7eqJK+8fCQtVlKQn8rlvtLB/BjYCRwm4g8ISI/66d69AqK8ILZUzUvNDpCHIBtNzzUrVefPBPA21HpabOsHvR7pt0R6KIwFZtkJhGQsW5a0UkS4LQ4LSbxSJwASF0LX71zNlMEFPk/WwQUJ3JJcDiAZHYnt1NZRrKkvk77VtWUA19KVu1+ANVqPg4gbSx6b3ebOIDcIqDMKvQ3A9BvVkB79ke5jYZSih5tUnlKwbTJ1HwOwKmDaeAmv6OLddIXFT2QmdfeKHROqF4OIFSmUsbJVGssoGgefc0BZImAovlmdZVJzJUEQVLHWt5hmDVes+L56Gliz0wiIBHteb5KVmw7JwdQnwjIpF/I2iyZYCuDT4hSvQ6RUgsGghXQTgsV+YA9OVhVnQBUcsoqa4GXX1ePU5e0sWQSAaVZ1jj3sjkAXRcSHcx5B7detFLmulRrPBAmtsD2QglcC7y6ZHE/NYuAQpZO2ekboQPIWli9bGxbhb5B2rhK2+GXrOAb5eYAbJXLKz3tc3h1NOoADH1g6r6sPq1UlWHjkvpKw1EQgF4gqpTSrV+SoO+Am6kD6HJ353nYXF0JnCarjd5L1AFoR/zFRUDJdQ/VLSQCUkYFYJq+Ql8QAx1AtC71iYBqJRpeubWLgBqrBE4ba3ntMLI2LLoOQE+ahwMwtcGqwwrI0QHksAJKnRseBxAv1GwFlE8sFM0nmqSvdQIFAegFot+qp2peaHTEOYDmWAF1VapAvgVXX0izOYDgOlEHUNF1ANlmoFmIclqmuqYdCOMvSpEG1SsCyjyLNwLvG5cyzQ5rEwHpzclqhpDBAeRsU9I3D+oULOZ631ZD5sXhenjPTG0Q7X5eIpXXCiiPEtgk5syvA8jgAGw71uiCAOxEiH6s7lwcQEQHkDOAWl5EOYB0UzfnV5/UmToA7V6SnqGnEUpg9AXc3Ke1xgKK6QAsqYvlrj1KanNEQLWGu0jbFSe9HyWa3sYiOZ+gbiGT4Tx+AAYuTyVcpyG/FVBtc8NDIzmAaJq+NgoqCEAvEOMAKtl+ACEOoNoEKyBPCeyLgNJSe2xuMMizrYCC654MJbBS9cf8D4mAEpTAtcYCiusA+kYJXMlLAKJLnKSPJRORS4LoytSMvHRE3/F0S0nQxW161dP8S1JP/KqBywnyyzevUjdHhrnhIb8fQBYHoFI5175AQQB6geinGkh+AB7y7Lj1AZ3tBxDczNYBxDmAegJ6Jb2RHg5ae1+Z09SvA6gtvcfllTLkcdF8JaOsmnQApIfrTiI00fHUlUD0g3oE9Qk7DSaPqzQlsD5eGs8BJD8LOIB4PmYroOQ8kmDWAaS/02gUBKAXiE4af+FL+YphP4AmWAFV44tcEkxsbiP8ANLMQOtpblScYKpr9LFRBxAVAbkcQNbCbKpPLQg4gKx803UZUdR66E26Gaj5WVRHlS0CCvpaLy5NX2MKde2XnxLwLwmVBvgBeO3IawVUz869YhABFRzAToTotxpIsYA8pJqBur892ju1xAJK0gHo4SjiBCBfe6OLu+m12v0A4sTRVoqWUm0EoGYOwCMAmVZA4YUry0xVf5RZp8xQEOb7MQ4gQwSUqANI4QDSrHzq2SBVc1sBJT/zSjWVnzcWUBaqth0bk7UaGPQWBQHoBZJEQKk6AO3g72ZaAXnIJwJqLAegy3SjxeedKCFlNGb2P+wHEH5mWhxjIhZXBNSSZZ4TQe06ANcKKIcSuBoiAOlihFpFQPVxALWJgPSwG/piluazkSYC0sdY3m6v2Hn9ALK5Y1Ofmf0A6uAADHUsOICdCNGPlUcH4EUgtFMGWG9QEwdgYHPTdtXOveA6SQmsv6+X31KSGtj48IIRV/L2PhaQJ2NvrYMA1DJP81sBxReudBFQvIw0pG02koqJ6wBqEQElcQDhPNNiAYVEQDUEg8vTH6bP4VUhbZzmtQICszjYu+NYAeX/3s1AQQB6gbgVkHmh0eGJgLzJWCuLm8u2WEMeDqCnJj8AnQNIr0vUD6BsWQ0VAaX7AWjXdlAfHZZrZVOuUQRU6xytRQcQ4gDIrwTOU6e+4AD0vg77ASTX1fcDMORXzwYpb4wt09zwnCLT+jOvH4CeX1I+cd1VcrnNQEEAeoGYCChlIHvwBp0uJqkldHNW0rgVUHJaL2WSCMjsBxBc92SIrxRhnUfZym91ExUBRXs1Gt44mq/JDDSaRnwdQG3TwCTaSoP3fbN0AHaEq3FEVMkdVosfgEh6LKCk16NjMyn+U6weKjxW03by3jNTHXoydFLGOtj5CIdJ+e+1N+3tWiJ/murhlWqrOE/T15HxCwLQCyQdepGHAwjF36nho2fpDOIioBw6AL0uOgdgKEpvc5acNRoLqFzK73gVakeCyCWNW/HSO7b+4Xs66hUB1QKvfzN1AIR3zZkcQA3hoE06gDwEJIkDSGqKl40jJjPnHx1XaYt1mHDkg8MBZOvWTG1IE0fp+UeRlDyNE6lUCw5gp0ZMBFSDEjgpAFsWstLGlcDJab1qdterA8gMCxAuP2tHq6MnpAMwT4ywz0JUBOT873AdZsLsiSnqUQLnaYbX9txWQCpOVNMdwfJzABAfGxEaa0TUmiYIMWJuS29iAZlQjxI4tw7AEGwj7XAaPf8okrj4NE//QgewkyPKwPlmoCnrouXrALSddA0EICttLY5g3uJSWyyg4GZWyOmoDkDIP8CjISnMJ4Ilx5fxXtejSZqcxZSClnLtZqB5CFkp8q3zKIH1NuncS1I9/OuMcWEKBpcV+M9JE+EAetI9zJNjASWPq1QOICQKzD926vWvSQtLYaqTh6Ti0jiRRvkT9AYFAegFkjiAVBGQiQOoIR5QVtremoFWUhZViCiBDaclhdLaUQ6gsWag6bGAPA7ASjQD9WzVa9cBmB3Togj0PXnCcjhtDH+/LD8AbQxl6QCIh4LIMvmFOEeSFWNKF7clxQKKiU5TxSTN4wBSnQtr5QBq0AEEzwx+AH27/hcEoDeImYH6VkDJ70R3hc51fl+AmjmAlC/spexO5ADiZYWUwDk4gPBCkT/+fiUmAkqZrIa6ehMrFE/eMNnqEwHlI2T+t85J4KNWQE5ZCsHmEHmJCWyO1cNDngUvKs5JI6BJ+WZFmQ35AYTql+yzkea0lWVpZkJePwCj2amdPYfzfk89v6RnSRuXvkJBAHqBenQAngiomrDoZqF2HUC2GVAlUQcQfyWPI5ifvYpzALmtgKI7RsN7eaKB6pZHpslWrxI4z0SNcntZb9gq6gns9NerrCf5e9s3+UPrd2PpPWRtDETiC1c1R5iFJCVwsg4gqFutfgDm8tM5UhOqtp3r+5iKDY6nTNu5N4oD6H8lcL8cCbmrIPqtcoWCcOeNPrBr0wFkWQHV7gcQsgJKUaw694Lr5uoAwnmb3spzHoBJB7A7m+ikxZfl1x4KIqcSOMLtZb2jiPsByIYX2V9eAWAfazmCjXL3bUky9iTEdQD5OACdcAc6gNqUwGncWm4roBo2D3nmlGks5vlWpjmYV4cSfRYlNH3NARQEoBeIB4PLcR6AyQy0kRxAZJeXJxZQkhWQqRm9cQSrJfxydMeY5AnsLU4mBS84HECYACj+3PodHlP7sEYdjq1qDwVhKs+EqMlv1jtOm4JvMVstZfffvpEvtgRpJrORlYz303vII5aoSwdg21givo7BEwEljatAB5DMAUSLSqt7Tx1moPl1AKZ3s+dwLbGA0sRb5vMA+pYAFCKgXiAuAsqe6J5YYGBZAeWPBaQP0OxQEOGFQpAaTp4KLxjRqigcixlv8Y7m6+sANN8DpWB/eYU9rDVMZX2gBC43RwRkGb51GhwroCDtLFb41z2qBMAca2WoHh6ygp+ZHMEqKXJ5gBYqtG16ISTGyxIBhc8DMG9yauIA6nAEyxtjK00HkM4BpM+LrLT+s2p8YPe1CKggAL1A9FulHmzhwugIVoMSOGtnU4snsIfQeQCZZwIH19k6gLASWDIOONERMvEk3te2curtye+T/QCskGLyNOsxAMZIB1X3RL7adQB5lcDhtmS1Xanwt5im1vjXt9rzAJgjOgEI3s3UARjSZHl9v6V0N4fddA7TZZ1/ryvjoKGwGahev2RikyUm8etYSyygHBxRlmFBWv6xvBKmgvnwGC8fuzgTeGdGYgCoHCKgujmAlIEdDY8A+Q6F766aJ6dRCazdzNYBROqXkKcJUScvk5VP1Q7k90nKtJJ27KOt4LSSRgDcl+rTAeQQAUU4gKy2O1yNYhTb2ENWMVMFHMDfqifQroYxW1aF6sGOTbBhUQOsgOLv7y+vIMrmVOtR/15XT5YjWPCb7AcQJUQptvL1RgOtUwSUdkB9NE04L3P6tGiijhVQZONShIPeeZA0RtKVwGHbcKjNrCxtopdcNl/f0eYJeZtUvtkPILjOYwYaCm2QEd9eRywGTHSBdyd5SyYHEJTZsnUFc60ldKihjKGDatVZzOrzA8hOF9X3ZDXdVs6i8POWy7ir7fMcaC/0n91vz2WRmhLiAJRS8NPj4UeH5bMCStUBxN/xiM0pohGATD8Ar60qtJjV7wegcwD5ULXtXvsBpH2rWnQAaecJmK2ACg5gp0HSp8rlll+nGWiabNOyhIpt06bJtHOJgBLyNFUrpAPIoQROi9KZhigLH7eWwOUALP//cD2dX50DGLf8dgBuqB5Nq1SxerYBDgHYW5Yxim256hbd3SYh6geQLMJQzJPnUa7ycp7lLPyzWMGGo77MQZ2/oItWFqvJHFdawH7yCvvLEqau/Ce0LwdgSPem1LqIxPs0LZQGwGxrJQrhcJ5nN7Y677idmewHEOTXCE9g/bCivCxAXg7AlF3gCZyWvykWUC0cQBAJOPq0j9f/ggD0BkkfPTWCIwH191CLCChtsliuu39bi04A0kRATl7dCQt573UAYZa2Fh2APvFtW8VYY8dm3qa1nMAB2AEH4JU5Zs0DLLEn8pi9DwBt7qLZVlL8s+1L/K71e7nqZtq5mRD1A0j6dEfIQv6v7TvM7fgXFdtmkZriP+uYcw7tDAfgKXs2ALe0fYWb277K8fM/76cb27k0sz7pOoBw2hFsZ6JsZvWkkyiLzdHWs6HnmWagdsRKKUUElNsTODFVGNVqTisg4+48hxVQDQe5mOqhcwBFLKCdGPWIgHyxS0gJ3DgRUMVWtJVL/r08weCSZLBGHYDW6DyhgcMioPyTODrxTTulsA7AzGnofgDD2xfxnJrBRkYC0Na9GYBxFUfZeoi1yH9/CuuZrYlbQnnn/F4xfU/CgNnHWgbAge3/YnzXMva1lvGP6hGcWfoFXaP28NP9rnoaz9vTwy+/+3oA9tv6INM0ZW0UQpYVUPiZJ/5ZPuUMIKx8hnwcgL6/zcsBTJO1oXZErcHyIK8VkFEHkBKaWs8/T16QpQOwYwO7jxmAggD0BkksfWr8Fvc3zAE0xgrIEqFaVf6uGMgVuD5JlJMZCyiHElivrtQSCiKyOzU5eoV1AOZ6ljxP4GoPQ7cuY7GazCblEIAh3RsB2L0rvnu+t+3T3Nn2BUxTMi/HFtX3JL3lLa77bX2QS5a/F4CFahrrZUyovxQWD9j7+/8/sefHYdbxUGrlrE1XcV/bpxPrkq0DCD/z6rR+1H6sYWzI/NTJL0sHELVSSvbodTgq5959bZ8JtSP0Xi9OBMsay/q7Xmlp+efJC8xz2+MgqgYRUMEB7ERIWrebyQGkLT7eJNd1AGlbGe9J0kJuelW/l0Q4RrCdw2VhTAcgkn/3HLcCCj+P6wDiE14kOPidTUuwVIVF9hTWqDEADO9eDyjmrbzKf28IXYylnZI4+R0gS2J1y/u98ngCj2Ibby/dQVUJw+0OrX2WUdfQheMV9vPKOTy5x4fAKsHYOf7zg+WlxPqkWgFpjyxsLijfRFUJW4ZMYwlTmaNZH0G+8wASdQCJYhEDsa2bA4iOB1Ndk4l72ic2+wGY06ZyAFUV64vCEWwnQtKnSv+IHvWvLxREqgjIcth8nQCkZu0Ro5p0ANkcwNWtl3BN27eRnu1hERD5J3FIPq1XVquHbvFkIhCWiEsAgPUvALBYTWEduwEwomcdR1vPMW3zI/5702Udh1sv+P8fbT0Xq1ve7xU9D8DUn+8q3UabVPi7fTw7rOH+/UfUPjhhsMPp76geBsA/qkfi937bSP/5dW3fNNalFj+AM6xH2M9ayiI1hQplFskM9pFltNGttS0rFESY+CeFnfD9YpRiPO2x/Hrq0AH0VG2D46CprvF79VsBJXEABmKn0jiA5HKbgX4hACJykYg8JSJPiMg/RWRK9lsDD0kLfdouN5C750sfRdriU7Icl31dB5AujnKeJS3k2UpgU96Kg6yXAWjZtjYsAqrTDBTDQuj7AZSTdAAKS5xoqEopWP8iAIvVZCqUWadGccTGm7igdCMAn+z+BABj6WCSbPTzmSibABhKJ8dZTwP5HfeiTn+mlu9lLadDDeULPR/m67P/wnsmXsNenb/j3/ZcFPFv8Ijalz07f8d8tVfiYjGELgDKVHhT6R6HKxCJjTN/Idu6ltdVbmUK6wE4vfQoXaqFc7svomor/m0dxlDp5jjrGf/d5FAQwQ5aLy5J3KT3ka5zEQJLGQ95Nw8m3VStIqBmBoPzlcCGcV3LWtAI9BcH8AOl1EFKqUOAGwHztmUnRT4RUL0cQPLi47n761ZAebJOKj9LCWwiHNNkvX/dumNNjAPI21R9YpiEA7Yiww/A6Y+AA3iRzrZxvkWNwmJMZS0nl57g5Ymn85KaCjgOYhNlExVlsdSe4BOAH7RcwVWt/8lkNtTAAWSLgObISubbe6Kw6LSGsZVh9LghuqJydA8V/7n78MgPhZ6PxRElvdp6kktbfs41rf9BSVWTOYD7L+fL1Z/zjZbfA3CM9Sy32EewgyFUbMUT1gF0qKG+F3UaAn13WLyRZHFU1sRkB1mL/fsj2e7cr9auA/DiFeloPgdgThsXRQX6CXMwuORym4F+CQanlNJ5veH0vfI7F25/dg0n7j0hrFQFNm3r5vonV7J4ndlu/I7n1/D2o2YYn5nMQB9+eSOHTh/NQy9vZEhLSWOfhTPnTqK9s4fr5q/AsiS0u49iXYez89NFQEop1rR3csvTq9hroiMqeGntVk7aZ3d/kL+0dqsxv1VbdvCr+15mn0kjGT2shf0nj+LWZ1b7z7fs6AmlnyfPM8cKZMUd65by9Iq2IEENweB0dPZUuf25NaF7ngjIpARe8uzDbF/+CpaMYHrPEiZueJAtHf9ihbvIA+wumwF4Y9e3OO/gc9n4yr8BlwCwibWMZhXjfG7gKFcUNEE2c+8LAZHz8PzqdvadNIrF67Zy74vred3BU0K729ufXWPYmSpmyyr+4pqltu/o4bFXNvlPt+zo4XcPLEnslwcXb2BYa5kz576ewzqHcab1CD9r/X+MkQ5WqvHsJY4ncVlsWlY/zpIhR4fe395d5Y7n1nD8qudoA060nmIcW5gkm1hoO+P3gUUbWN5hc0/LwZxaepyvVpxopLZS3L1wLUNaSkwfO4ynl29mxeZOfww+uXwLf3goUK53b1nNc/ffwH7HvZZbngnGiNdH/3h6te+lDTBWOmhXI8Jcpnb50OINdFVslm7czhsPmxZqV5eBA/jdA05E1Rljh7GmvZOZ44bx0MsbYuk2bOvmdw8s4cU14TlhaYcZdVdtbl2wmiNnjeWGp1Zy/J7jE6UBdz2/lsNmjGbxum3YSoXm2opNO1ixaUco/T+fXU1XpUpbucSMccOYOnooC1ZuYURbmZnjhkez7zX6LRqoiFwCvBvYApyUku4C4AKAGTPMi2oz8MCiDXzwd49ywYmz+erZ+4WeXfP4ci6+KS4b9nD/Sxu4+KZnjc9MSuAr73uZK+972Zj+2e+cwT+eXs03rlsAwGsOmpxZ98NmjuH259YCzkL5m38v4ad3LwqleXZeeybVXbZxB9+5MWjHD950EH+bv8KYVrD5v7bvhO79+4kFbK7OAuCY2eNY29FZl6PLL+6N943DAdi+GWgoiNpfTuM7wP/Jn/lgx0+ZXZkPFfh95VA/zZWVs3hny108pvbmPKvMZkYAMAaHA1irxrBGjeFAcXalw+kEYJJs5M+PLovV56t/e5q/few4Lv3nQm5+ejUVW/k6gPteWs//3PZC7J09ZQXDpYuFyjHtvPfFOGH52+NBf7/h0Kmh/r/9ubXc/txaHn55AyCsV6OcNshWUE7guB2qlaHSzTy1gP99aa9Q3pfc9Cwrt3Ty8PAFtKlh7CbbeWfJcZZbrCa7ZTiE95/Vw3lN6UEOlZd4XO3Nso07eO+vHyENNzzpiHRaSxaf2/Jf7Hfbs3Tss4DHl27205y2/0T+9vgKvnLNfBa2vcBz9nT2s5Yxlg6WMNnnlFtKEhqv51/xoH89fkRrqNzOnjgHcNGN5vkYxfqtXXzTnWs6ypYVCn3y4d8/xqEzRjN/6WbOOGCicec+vLXEtfNXsLWrwm3Prok9f2LZ5ti9X9+/hF/fv8T/f8n3zuHCvz7FXhNHcPlbD42l7y2aJgISkdtF5BnD37kASqmvKaWmA1cBn0jKRyl1hVJqnlJq3oQJE5pV3Ri27HAUXq9siO/yTTuMKJZuDFP2y84/mImj2oxmoGmo2CrE0uple7uOj716DmfNnQTAxFFtfOzVe/L8RWf6A9OL4a4jGsfHRFie/NbpTBo1xP9/rbu7i0PxgdIt/n87VCvbVRtHWc9xqLzIkXuM5Y8XHB3SAew7aWRCXvngKUiDaKDx/nyndSt7sILuA97CXa9/lEsrbwHg3i+exE+HfICPz7wRcMRE/7zwdLapNt5dvo3929Zy4H77ceJhBzJRNgOKYeK0/ayZ5vrscPvY6+uuStUndhu2Bv02rDXg4E53RSp3Vw8O5fXo10/lA8fvEbr3hw8cxf+cfwhLvncOS753Di9cfBZXf+goADo6KwBscv0bPBHQbFe8tFKN5U2le5gtK5k2Zii3ffZEAFZu6aSNbsZX13BV9VRoHclnR90FwEtqCu89dhYHTHGIyvjDXoOyylx94kbOO9ThpMaxhVdZT5o7RENLSdjDcjnHF24F4PLje1hy4b4cPnOMm1c7ZbF52nV2u/BEZ657Bgp6UL/obrurYjNqSJn3HjuLybsNSTRqOOOAibF7U0cPZeroof7/I9nOGdYjvKN0Ox8q3chEHA6wZHB8WO7u3jt7zAfQPPaN0xg/opV2jVN+3cFTeObbZzB36ihjHU3o7Kka53Aj0DQOQCl1as6kVwE3A99qVl3qgfg23PFneRbv6HgZ1lp2B7Hzf+4QwXayyah3OaSl5IuphreV/XstJcsVlcQbUbHDVhpDW+Kipd2GtoQOTE+y/DhAXuHrLYEp5b32gewtyzmt9DinlR7nrfIPIHwgTJ6DatLgHcpSds+89PvIDojlV/kVbIPWKXMZNmqsWwNHgSlajHtLHB+F4dLFcLqgAoydRbU0gWHSxUESyKbHqUBBrMPrY3/cVAPprr426K0+1HqRF+yprGZcKK+SCNHeiY6n1rLFqCGOSahHzD3/hjHSASjmyEqut4/FUoqjree4ufUrnC5/DS1mB8piLBQvlPaEuWPg8d/S0TKBpZ0TaWux/HHVXR6JTD+KIcv/TeuYNwNwZeulHGItYm7nL9nKMGO/ALSULborZRAoLX8YeB3nPvoeeBSssx3FuqdreU45XP6Qro3AGHpsm5IloUNpomttpeqMBc/sNylIYZr41MOlLT/jjFIQ+2i0bOUHlbf6ugodtmEu6hjSUoqN86EtJUa0lWsa/6agcY1Cf1kB6bzoucDz/VGPNHhOPGmnBuV534P3wX0dQIYTlQcvQqQHkzWFs4CFy/GulUoKSBUORZsUE/9I+ylmymrG0M6c9XfEnp9tPcjXy3/w/z+u83I+3PNZfzcKcPJ2Z9enHwqfdlZxHtgqsPX3zF8B2OaIUa6tHhckHr835VK4XyzNMcoSiVu17HU6lTHObvT6tm/4t49d80eGuuIgHV5eXj46gdX7WXegGiftvk+CDlN9TI5X3i1PGb/FVXB/sHQzE9jCbrKdxWoyY1yOYIj0YElANMGJjtpDmYflYHjt5fDVVfzk0L/Tg7NIeQufJQIT9oUVj7L/1vuBwHN6Dwn0QiYMs6q+d6/VsdK38HHyhcPkBZ+TeNp2OJ8hXU76SlU5BICgH6Oj2TOnFJx+S7JqM+3ibXcMeTjAWhJ6Ps41TS0ZIsZWtbUhSQfgbDa0OpS8TUh+AmAyF20U+ssK6HuuOOgp4HTg0/1Uj0R4g8VsKpa9eFuRwWZ5A6FWDiCygIc8Q91Lz9rFK0cv01OWRhFlk40x8bu28t3OS/hM+Ro+Vb6W05+50LfOABjPFn7S+kOOKTny1fVqFCsYj8JiowoIwAWbL4M1C9D3tXl3QGlx55X7vGRJ0Ecdjtz5H9UjWSzToXUkTD6EkrboBf4BwaItAtdUjwdgQ3kizDyW6thgn7K0ZQ7sfSZl1c0bS/fG6hO1HtEnbdQZzsNotvq6Bx1ixfvH1A9eGk9RWqXEJjWC6dY6Xl+6D4BFago/rrwegHY1FEtEW8yc8xHml+bSVRruVK51GGKV/TJLOgEYvzcA71nyZcZqNvtJITP859Ya37HO2rbGF1EBCIqft17GF1r+CsBSNZGNagRDO9f4bStbgohoHEB47HrE1nI5gCQHxSQCkDQWn7enO/oUyMEBmMu0RELjPiCoxuRGVOy4X0Oj0C8EQCn1RqXUXNcU9LVKKbNmsR/hjYk0T740RD+wt6urVQcQXcBNERwtEUr08PbSHYxXm2D+VXD/Dzmk419+yIQoogHNRqoO3ly6G1Ccbj3CDFkDi++ijW72lBW+hcbHytfRQoWj5Dk+U/6/UJ7zun6Gx4vEFrbnbw4tfkd1P8jM0M5R8TrrfsaxJfRaOSFUs2MiqRCcXapPlDucPFepsbyr9XL48lIYNTk0gb2FwutL59sIn+/5GLM6r+bivf4CpRbsUYF1yUVTfwJv+xOb2qZyuhYf30MQQ8b5rWj9G/KF0N4ZKx0hQhnUT4jKgKIbCj8d4R3vm7odSerprhhjsZrCDfax/KjyeobRRYkqQ5ffz8dLf+eL5T8z21rNfdaRocUx2EyIzy2IAGNm+Wl+3PJD//rClr/QQoVjrAXsL0s4x3qQyQQWNrNda6TH7T1p3biQ15fu95+N3/w0E8T55lUlrGc31qgxDO10OQBPBETAPUeHs3MIvCcCSuEADAu9954DFdrgbFQjOdmaz0GyyEgk9Hok7Qmjb4UIak7ooTIajVQdgIjcQIqJplLqdQ2v0QBBKgeQI35/dLchrpxZXyDyQBEJHW3gACyB4zb+nde3XAntV8J1zv33Ale1XUXVHhvLN1r+2UsvZb+W29iihnNF62WsVaPh+bMBOFBjiz9avoHFajI/aLkCgOVqPE/be9ChwjLgTSpCAF65D3CUlqPp4GvtF/Hh1lEu0XBCLvyw9X/5e/VYPtMT2AS0WKL5nwaw7UDuG+IAVj+NrYRlagKjypYva9K/h7jEuKqJbfSv5c1Nq1TmnupBLFaTUVIGERbvdjSHdt4cq0/U21cXsekMvMf6l6gyWraFRGUePJ1E9J4pHYQdn15RE+lRJY6wXqBdDWOFcvQLa9QYymIzhg5G3XkRF7YEISPuKR1FWUksXxEJL1jTjoC2UdDVzrGlwKpmmqznHOtB/l/rT/x7z9kzOKvbia46C4dDeMDen8Osl/hGSyAynLrmTv96IyOxsVirxjCl07Fiq1SdgH86QY0KRDx7eo8TTgpSaCKiSim/p8fRzm7iEICrKycxSrbTIlWub/sGR8vfYu/mOVNZ1zVBvRxA/4mALgX+G3gZ2AH8wv3bCixKeW+nh68DMIylrMV7mqzjsK3/Ct2rlwNQKixyCjnXaBzAnO1PGt//Vs9l/sEnOvTy95Wl7LfhNid9y+8A107+hX/QRWvs3U+VrvWvn7Nn8tGez/LFyodDaTxnpkt73swDw0+B9S9xUs89TJO1nGQ9AcB4aedk63EA/16ZoK4lSxJ3SrZy+lJcObWq9sBDV8DT/8d8tSebGBVa9I0cgKYDiOpOvN/39HyZb1fe4xOF9rZJjJQdDIvoAaIxZCqOkgIIKy0tcSJevqf0T4BEDiC6QJh1AHEOoEKZZcqxoLnLPgTlTvG1ajQA5/XciLU92J2f3fVd1jM2LON28xUiC9bwcfCVZVx0yN1+0kM6f856NYrPl/8aqtt+1lIsbEaxlXd3/ZFVaiw7VBtRTF9+k3+9RDmWbKvVWNp2rPXbVrKsEDmMrrVVbTOQpgMwinFU8L29AHjv6f4SX618iC3aJsYyLMF+4DtDnTxE41+VfI6qBg6g2jwOIJUAKKXuUUrdAxynlDpfKXWD+/d24ISm1GiAwLfmSHEXT8K1rd/gg6v+Ayuk7JJQLJxaDgpPOj7S40REYNb2Z8IvHvtJOkpjON5+lNnb5sfy1T2RP1H+u38diseyYyN/H/YmNqvhPG3P8m9Ptxz2fIMayeXVN5jr7U5ZhbC6ZTq0L+dL2y7lty3/xZFWoPP/z5ZfItgc7CoU9YlW0rXbEXjOcg4HYHHAhn/CLRfC+oXcVj0cCE/4qIjDOzsB4oo6L6m+XniX21qdxdWzWvEQjSMf1gFo+Yjw25b/4puu1+0mAwGI1sercxRe/XqqYUXmnfahbFNtXFMNpuizahYAb+m6BqtzE2vVaB6o7s+zaia2UiHFsF4Pk8jCLrVyReUc/lo5kc2M5I7qYf6Y6FQtfrpD5UXOLj1MmSqP2ntzi30kthXeUAzrXM3/Vl7HWjWa7/a8A4B17EZb13oEm4qt6wDiBBUCcZu4Jr216gC8jzvbdWL0zmMYIoH57lhp9/sk9C6u13OKElifs/VyAM3yEM6rAxguIrO9f0RkD6DxbmkDCL4IqA4dwAR3sOgnTDlKYNE4gLxWQMmspkechlQ6GFndxL3Vuc6Dee+H0y/m0n3/RBctzO24nyj0POfISl4ZdzyzOq9mn67fsk/nb9im2qDUyk0j3sQhXb/g7d1fD71/b3Uuh3f9nIXBsAjBa6mgWN0aOPDNsVbxtvJdPNdyAJ/t/igTZTMHysuMFUcxqMfhKVtxc0i/X5Q36Z10szsCufxttkMAdMVv2aAEDlkBaXl7i130QHuAbW0TYvWEeLiHkMhCFwGoashb2iwCkpwioIAD0IndxZV3cUDXr/mXfbB/b7mawNu7v0rJ3ZT8oPIW3tbzdXBDdJsWR8C3ntL7whLhu5V3cGHlI0DQ37dXD2Xfrt9yYOcv6VYlTis9xhxZSRdtfKrnEyxSU3noHc8zq/Nq7p33Yz+/qyuncGTXT5ivHKX7JjUSUTYj2U7VVoEZqJs+KhCp+iIgT7eTIAIyyfHtQAQ0R1bSqVp8sZmurN6D5bE8dLFfIgGIhECvWweQO3VtyEsAPgPcLSJ3i8g9wF0MQMudRsLTPdZrBQT4ixq4cmfCSsJoiAkTolZAJpPQMduXAHBV9VSeL+8Le54GQE95OE/L3uzRlRzRUrDZQ1bRMSJYyLtodRyDDns3PWWHzncQOMvMt/fk6uopgHlXBfB/1RPpVC3cYB/D4rb9YeQUKgR22KtapvEv+yAAjrCe900VvRANXt4muS0EIiDLlVPP2uaKwPY6g0VuyIcQB6CJOMRyj0h0v6OnBPafGyyqvAV5e9vuTj2JcgARHUA1iPOij6BDJDjnd5Uay4v2VKIwiYDMHEBAAJK+g46H7X3ZKs731M1Pq+4u2wSPiEaty3Tcax/Ik/Zs/g/H9aeDYTyl5nCo9RKzZRWrWqb6oiiP82wftReMmMSaSa9iBWEHT08s5s2fcinMPSf5AXiWdkkn3JUNppxKEwEdbr3A82q6X9efVgIV5zTlWCXpimTf9cROjuGjc5pA2Kw2JxwroH4QAQGIiAXsBuyFs+h/CthHKfXPptRogME0lvKKb8ZoOwhLAF0HUFW05Ji0USsg0/XoHUsAeF5N56tj/wf2PdsvczXj2a2ygddb97G3LIu9+/7SLQyRHraOmBUq97uVd8A5/61NmqCu53V/h1tsR6HbkmDQv0hNZd+u3/KKmsTG0nj4/HOcN+56ftDzFj+/DezGRjWCObLKn+zTZD3z5HneVrqDmbJWK1XxwdJNjHFFVN6uSwSGWd2M6VkDr/4KvOMv/hvJOoAoB5AkAjJwAAkioEqEAOgcgD5eXqUepku1sH/nrzim68esIa6gd8ZKeGyY1gvvnmMqmb2ZqFDmsdZ5gCNn99BTTeEADAtWdPHqopVzuy/m/tIR/r2Vahy7s4k5spI1LcEpZp58fsfwafCFhTx+3M9jZUY9mkueCIhwH3twrICUJgLKxwGMYhuf5fccV3mQCWzmEFnkh9sGeFjtxz6dvwFghlrJBaUbKFvxvE1nX3sYxg7esP2vlKgyhC7mrfgt9HTmOafJydsV/zTLDDTTE1gpZYvIF5VSfwGebE41Bh58E74EE8qUN/2rsdLh/2t54gxtUciza1OE5fUhAuBWcvfNT9BpDWOZ2p3xkYm6Vo1hTHU9/93yU/5uH8fnez7mlO9Stg+VHYuWTeOPAI1gedDruGziqfxtRdiF3eQgE4Vub/+X6qt5TelBbh9xLmx05K17WcsZxXbm23tyqPUS/9lyJXtZK3hK7c17re8CsI8s4+stV3Fa6THO7/6mPykEmMlqR3cwPhzrJlkHEPYY9bgzvd/0X6/uANWWEWxVQ5gU0wGElcBVzXZbF0kcoF7iCTWH7QwhCdH6ROvi3/MiaVbtRHPZKP4x5GxeNX4bSxcHYREqERGSjkBkEa6fCbovyRo1hjOt9bRKlcfbzvHve/J5f1thyGuj7tGsAlFgYAUUhmclI+IYfSWJgKJd9CrrSd4vN9C1/VY6S+/GEsVt9rxQmi5a2axG8Laev0ELrLSnciOHhdI4JsnGIvlU1y84s3In91q7c7j1Iscs/js8tSeW7G9+IQJvjjdLCJRXBHS7iHxBRKaLyFjvryk1GiAIZPX5dQAT2Mwl5V/5/4+WIPKfs6kLdjFVW+WatCrKAehmoNs38a3yb5mx5nZeGHk0VUqhnYUAaxlLCZuSqNCpTlVbMZwdTJJNfL/nLezYzSzL1xeGew79Hy6rvCnxeRI8LkqAdYzmrO7vsazNOcVqsT2Fw+RFLFFcWz2OB6r7s5fl2I0fxAt80b6S0XQwyrXPPsp6nq+Wr6JU7XSVwMJMz41kXJgAWAkcgOcxGvgBmOX9hPoyWAjXqDHsbiAAStsJ6qZ7uhnv7mojK1U49IMOr+zoumhac3UlcJ7NBMDzbQfCh+6gIoFFTk9VhUVtmrK1ZKhQ0u61JUIAWsWx6Fow4lj/fkUzXEjKyzuz2XPCKllWWAcQmX6+FRDOd0pWAofnm8fFtdHN91p+yTJ7As+r6bH31kkgLhsn8UNr0nQAR1Ud/5mD5GU+6RlbbN/of7sPlG7iu+VfcGpCqO084al7g7wE4Hzg48C/gMfcv7g3zC4EO8LS60jyAziz9DDvKN/BBhVmYUHXATj/5+YAlDNpvKQ6R9K2+DbeV76VqjWEx8a/zi9HL3M1weB1Dvr2FihH9g+Os1ASMdJ3niY2N18bPAoQFyMsUDN9L9HNaiQbIw5kb1W3cFrpsZA+5YLyTezXfq9v+ndQ9Vm6pTWVA9AXOHEX/KovAgrL3E1e1R4xsCxhjRoTEwGBM1kDDiAgBkFsGsV4NrJGJe+dTNyH6X/9XndOHYD+jp6+O4UDsAwcQFJRuozd0zEstSewbmhwZGVF07vovzr8mEbu/Cm78lN/+EWGoc9VuN8xKRZQ1BEs+g1/Uz0Dk9nZWk1MN8sQ9sJ0ZKmHMWoLAJ8oXxvc3PASlgjTZC3faLmK80t38+2W38QbRly02GjkIgBKqT0Mf+Yt4y6CpN0GmE1DwbEi6FBDObzrZ/RIq286BoGcOQgVkDzpQvVQYW5BL7u08UUqyuLGk/7By6OO8MsJynREQAAdaiijZDsTXE/batXmopbfAI4YpjVBlKNPalOr88iefRGQds+r5512wE5vZKTRLHKOrHIDnMHxXZezXo1i//b7HbZfwdGVh3l2yOHQMjREpNJ1AFosICvseOWtEyERkPZsDWOYxCb2kaW8ww2fDOH4P1HT3f1lCR8vXUcrFda4Nvkm+E5YCfd16OtZnrGk5xNNHyIgvhWUWR+SpMCMioAAbrPn0aIFYfOctII+juezjSHYVotP9D0rIFJ0AF6eafb1XvUsbL5SvsoXfwJ0qRaurJ5tfG+dRgBmEw9aoEiIBVQNooC2SpXrq8eweuwR8MRVTO15xT9g56fV1zFVNpjPn/Y9zBOb1SvkDgUhInNF5C0i8m7vrzlVGhjwF+oa/ABmyyo3jrqwqW0qc7UP6pn2BSKgfJYACscPwFMY6wZILZsX8YqaCKXWhGBw8IKaxjPluXy/cj7gWNwAjKuu41DrJbpUC0vUpBD7rkNnm03tNllWxNpg6C6vnsvVBK6vHsNz9nQW2tN99n+JPZHHSgexkgnMlpWMwREHrFejeMDen5nbn0YpxcjKeibaa3l6iENI9Cpm6QBCETyNHECYm/LurVFj2V028Y7SHVzS8iv/CEZ9J6iH2qjaiitbL+XCFkdBbQoAFy0nLgJK5gCi7UuD74kcSZ9EyE3cUNIiq4+h59UMHrL35U/Vk2jVIspGxafmOSD0DN2dybLBrVu6DqDHt2iLW0/p8Mby3rKcD5cdB7R1ajfmlw/hHd1fSXzvAetQVlmOk9pU1sae2yphh749bCp8W/Vwlk8+A4Azt/yZudYSVqqx/KHiWE/pZ1F7CHQAzUEuAiAi3wJ+5P6dBHwf2GXDQACJFgeQrAOYY630nUheHH08x5UW8LaSE0HT9wTWOYCci6dz9q3LAWhlt2x6icVqSmjnEyIAlrBVDeFLo77H1dVT2KhG8KnytfxPy084t+KEaH5Pz5fooZxIAPRF1GRdkWfh0ZXAHvRF5FM9n+Ss7v9iHaN978sH7f348vCLWShzmCMrGSMd7FCtdNLGi/Y0xvasYQxbOH/RlwBYXnJ8DXSFeZgDiPoBhKOBmkQcUX2K92yNGk2bVNjHcqyqZruitCgHoCvuqsR3xyZ4ZUeHXZoIyGlfjRxA5HsnfcegLyR2Lwo9dHg7wzm/+5u8qKaFxpanoLUSCJ2Hzt1m+/0aDwcd7pwgz/RNlVcNXfQzQbbwjd0u5lG1b+J7d1jH8cHRv+R3ldMYzybeXLqbwzVzXpUkAtI8rrtVibvtQ3h5j7fCgW/h2K3/5I2le1mlxrGasXSooX57Q23zxnM/cwBvAk4BViul3gccjGMaussi3QoovhAOpZOpsoHFtnOwyjMTHMsH76AUb1z6isGcOgAnmJsdj3uPorVjGa+o3X3iopfjXdsuAalS4o7qYexrLeMNpft4d9WJbbLIdghWMgegEwADB5CrDW59tHtJr9luqm5aKFnCQms2e8hq9pFlPnfgnVb1Mf7KlG2Oj8OyktOOMJdiXrTiOoC4o5P+673j3fMW8IPF8V72Jm61qoxWQABblGN/v8DamxcMisZo2VHO0+wIFlz3RgcAyd/RuLHIwQEk3e+OKIGT8uryCYBy/QB0M9Bw2h4tzzQC4D3zFPj3Vw/gE92fTEwfvBd899Fs5QctV3BN27f954lK4B0OB3CnHMWV1bPpYJiz6Zv3Pj+JM5aExWqykQBE/UsajbwEYIdSygYqIjIKWAskj+JdAGkiIM+S4VjrGV8GPNtVDnkcwKZhe/CHyim+JZDnbKSLBXLpACJpvYEwkh1YlR2sVmNDMuz4eQBBKInbNXk7QLsaxjqXjutsug69jqYgW1HLCtNCpHwOIMcignO6VTdlyiXhfmselihOsJ729QNeHx+m7cLWuYeqJHFnUeV4lAMQQ9qwI1jwzLOhHyKOjNeLIaMf3FGphg33dpdNXF05iY8O+T4dKYeneP0S3XiY+ktvUx5djJ5Pqg7AkD6PEjgPAfB266bxqqNz9J6MkE4msimwAvJFQOG+6dHNeVOm1OT2J/lA6WYmuad8va/ni9xoH+PnazJ59epoiaP7McG2E2T0Lgfwc3kz/1V5m1uGBTOP5b7dnA2it5lYpKYwx4qH1fajzCY3q1fISwAeFZHROIHgHgMeBx5oUp0GBPzdRsqJYFe3fpdLWn4F7ulLEOxOLXGUmmPoQLDdRdrJGTwOIJ8nsCMCklDZ3i5mrRoTEmFEJ6rHAQDcbR/CbdXDuKfqeOA6Jm/OC/k4ABMBSE7vwcgBJDT9L9VX86/qgVxReQ0ly2KxNYsbq0fzoprKzVXH+exlN2jYvuIcOn7DyPOpeIQ1R6RW8HQA5p2j2REsWBzWRhYCL4ZMkhVQmQoTpJ01amyqjNqrC8R3uaaFrR4OwMsnxgEkiCON4rAcSuDw/SC97nyn/0bRPdqxMZljrQx0AN7DSN9UcnIAp83/BN9o+QMHWi+zQY2km5bQc69Pon3jcYhR0V3Z3awkcgAuAdhoB5ZtHuHdUnY8yrvcOiywZzFVNjBNwjqGwAy0f62APqaU2qyU+hlwGvAeVxS0y8J3807QAXxCi4g5U9bwvZZfAEFEQxHHrLEkilFsN+gAcnIAylMCh3UAnhxzjRoT2vlEOQBPhASOU8uHer7A/fYBADxrz/TTJhEAPT8TAYi6LJkjLqbrAHRsZiTv7vkKaxnjTHxL+ETPpzij+/v8pHouAJ20OYe2AEt2O5K/jf2g3y95vbR1AmBFdo4m+bRoz9ZGrHhm+xyAjckPYHc2A84OMisKZLIIKP5eSAeQQ5+kvxPnABK+v5tOr06yCChbNBTs1nF/ze90j94TcMRrviewPyfDaXs0rsKy4AzrEX7achnz5Hkub/kxHyldD0Cl5IQzOdmaHzLF9fL1+iRaJ49jXB0x353unnKmMpTAG7Sooh5x6So5IsE2HC7Si6d0Vct3adMCoEejzDYauc4EFpHf4/gA3KuUGnDHNzYD3kQ2Wb5UbcUHNROyN5fuYZh08ZC9rx8+2RIJeTT6ZqDuO7V4AjtmoGEOYKIbi2YNo0My7Kiow/Mj0HFt9XiOLr/Ajyvn+feSCICOJAcbHekcQLYIKJpXUrL20ljGVdawevi+lCzLb2PeMNumBT/430ujEW1tx6rvHBfYM31ZdVUTAVW9YEXAePfAk/Vqt8TgdtGy84iA6rEC8pLl1wG49QkRAHPeiSKgsi4C8jIyi1s82MMnsVUNYY6sZINHhPzYShERUIST+0D5Zo60FnKo9RKTZBPnlv7N1dWT6W4ZxbCudSxU0/m7dmSol1uiCMg9oW2p2j10f5qs42U12eEATK4HW5bRLiPZUW0BN8y518+PjD6L4ase5OeV1wDOSWjP2TPYz1rK/vKKHxjP5wDM3dRr5BUB/QqYDPxIRBaLyDUi8ukm1WlAwOtw03oyrLKZ0bKNKyqOHO8T5esA+GREoeTFNJkjK9n9rgsZaW/VCEt+P4CKrfzJ5e0MJ2kcgL6DNclqowv3Osbw4coXWK/p8ZPYdx1JDjY6TG0KHMHidcvKK9Hm3N4BwOIxJ7gngnk773yB+qIiH5O4R0/nEa/o7vAv1VczXLqYzMZQ2F6dA/A8WjeqkZkxYHwdQA4lsJ5XfisgjwPIawUUr08iB5AQ3DDEAdiBxQ6QGOxPLEcxOkdWBhsBTwcQEwEFeYqIf0axHq7jJOsJhnat47eV0zin+z/5RfU1sTKTArV5saOiZ2P8sOXH7CXLObznMd7eEz8whvUvsaI0Ley743EA5RF8uOdzrCbwCv9yzweBcASBwAqof0VAdwGXAN/A0QPMAz7alBoNEHiLlom1m1JxzP8esPfnCTvwclzLaO394FSsL5T/yqjn/shru24IhQfIawUUcgRzV5jDrYV0Dp/GDoY4Az9BCQxm0U1UVNKSoATW0ZNw0pIOkyjB7AiWkwNIePa7CZ/jz9VXs3rUXEol8SdKXg5Ar2ZUeWjSB0RFbF/veR/f7HmPr/OZJusiHEAgDvI8WjcxMlHk4Y0F/xyKSFc33w8giQA4v0nnGuvIowPoqYQNApKqbYnwtD2bw6wXaaMnxD1H56QuAhqhtvpHTAL8snIWa9VoXlt6gLaedqMXtte2IPJpnAB4tz4//Lv8X/VEwCHsP2m5nHO7b+Yj1av8QIU+1r/A8vL0SDRQcxkQhMDQIwhEY0w1Gnn9AO4A7scJCbEQOEKpFMPZXQC6rD4Eu8qXt/83AC+pKZzf/Q3tYfBRbaX8D7qf5Sgrz9xxMxeuvhD+dgFvaP9Dbj8A3RGsaiuG0MXx1jOsm3qyU6rOAWhfNOAA4gt3lK7lsSIx6gAiTTAfnh1Pm2P99w8CMWFR2/58qecCkFKEA8ivAwiuk01UfdFapN5/qJ7G76pn+IrBibLJD0sM4RjunkfrRjUykaBFDwrJwwHo9/JaAXn1j469bA4gfi+KJCISsgLynO/8+iSXe5t9GCOkk48tvxBRwUIdHbu6Geh7NlwOwCLXHPvW6hHcXj3UP3EuzQfDq2a0SrpyeUHLgXyh5yP+s1GyjWn2CkrYnOyWMUPW8OuW/4Jtax0OQOs87zOZWr1ZD4Lnt83pr2YFg8ulAwCeAg4H5gJbgM0i8oBSakdTajUAECicIh2/cTET1TqW2RNYriagsLio552xM3CrSoV2G5VR01m1fRQzexbBU09wPnDf6DgbGqsHiqptM6wlkDvvIasZIj1sHu8ojnQrIFNc+6TwuDpKlvg77qRFtBYdQElblAMOIM6dlC1JLM8z/zMhsOCR0JnA+XUA4bpEHeiCZ1768P8eVmsEIKoD8IbOaOmgqoR2hjEpUYFq0VWxU0RAjeEAatcBmERA5rxziYC8AHxeWIZEAgD/tueyyJ7MnO1Psu+QRSjmGdPqROWQHY5x4jcr7+Uc6yEeU3uzrTqEWbKG2RN348Hl+5krT/Lu3BJJrG8LFcYpR+R0WukxrrFP5BTrcU4qPQmzTuCx9iNzlQHOmRs9qhSKe9XV4xKA/uQAlFKfVUqdCLwB2AD8GlzThl0U3oCPOYKtfxGAT/Z80j844srq2fzNPjH8vq3oocx65YRP3nDWz/namB/w8NDgmL55nQ9m1sNT4no7thmyhqtbLwFg2xDHEiZbBJQ9eixxFoU0ZXAuHUBJ/Lz0NkBU8er8ppWXdiJYVcszxAHkNgPVryWRO8nSAbQznE7V4nAAblx6CHsCj6WDTYxEkUzQPAsar15RQmb2Awiua9cBRDmAJCsw5zfEASSUlSQC0glDT8wPwFxPEaGbFt7U/S1shMs7v857l38LVs7HVoo5soL/bvkJrfT4YqXW6jbaVBeX9Lyd++0D+Wrlg9hYPKtm8faer3P/Mb+MHT4T7gPvG8f7IMmBbqxspYzNBnbjROsp2uhmtqxiixoG77mBlS0zQ+l9RbOxq4RNjGS0JgLqqnhHjSZWu1fIKwL6hIj8GZgPnIujFD6rOVUaGPD6O+YItt6J1+HJfpPgfbAPdH+B31ROpzrpEERgTXmKn2aP7njsj1g9lOsH4E6ud5Ru95WKO9zDSbKUwHngHa6eZMoH+TmJsmWFyjaZgXoTKq28UilZBOQRZkEcK6AaOYCol2+Sk1rUJDS+EDuOYT4H4HaRzgGMkQ42RzjEKDwdj2nHDSCGmaqL/nrtCZzoB+DcD+sAkriYJMIQ3Pdj9Sf2p3ff+d3EKJ4ecxpD6eTQrffAn96BUvCLlv/mjaX7OECW+Irl4d2OWWaSmCdJShY1A43XJRiHXpIPd3+Wh+xACv5XTmeYdDFN1jFH3JAwEt/AJJmaetioRjJWUwJ3VapuHftRCQwMAf4H2FcpdapS6ttKqTubUqMBgiSbY9a/yHpG055xJLK3ED2p9uQ/Ku/FskoIsF2C907suJl3lm5Lr4drXuhMLuVHEATYPmQ8EF7A8rjsm+Dt2tOOqcxDAMquKEkv2yQC8uqbVp5jBWR+podxqM8KSL+OsvzBtfcoSQQEbnRQ2RiPBeSOnbFs9fVBiRY0kZ1htBnJC6W7o8/pB+DrAHJbAbn1ySECSuIiwlZA3ncz77aDMoIHN834YvCgeysKmG05YpeZsoZKVdFKD2c98n4g7qhnytNc/2QxWNRq6Vb7CN7ffaGf5mEc35pJspE51koWu97q0TKTTE09bGZESAfQlcPwojfIKwK6FGgB3gUgIhPcg+F3WSiTCEgpePkeFjAn4a0AJiWeiHD/sJPh8PfyUMkJy3Bxy68z8nEWk3LJYo6s9Ac+QMW1R9dDGejjqob1H8vnAFIIQCW+C4kWUbKsmPlmvSIgRydhboTuxVuygoPA69IBRKpgJqJxAuvhOXsGB8liVPf2kCcwOIeNHGgt5kV7ml9fEzwxSS2xgPT7ebzK9fxr1wHE84gi6VOaQ0Gk5xXaQLRENlvd2/3L2dZKeqo2c+VlhvYEptEmJO26PVFdGhH0+03LYxtD+XbPu/hS+UJWuyGjj7UWMFE2B9aBkSzLpeRxBPCQvW/IQdPTAfRrLCA3GuiXAC9magvwh6bUaIDAKAJaswC2LOMOjjC+oyPGwruLdKcMgddezkbZzX9mkUzlvRPBRqjtXNv6zdAzoydrys42DZarTO21DsASV3QT3DMN3kAElEIAJNkRrOqLlSSkcA4rlJMnTRoHYIp8GeUEdNxuH85Q6Wburedju1v3StUxAz3aeo4R0ul7eia1J2qDnscRTK9rTgYgUQmctRDn4QASrYN0M9CcweD026FjR7u2Ym0LNkFzZCU9VcVMWePfSxQBJdTbFwGliMGshPr+unoWd8rRrHe9wz9edryOb3fPFk4SASW1+7LKm/l25T3+/4EIyFz33iKvCOg8nPDP25zKqJVA/OSOXQhB6Fnt5jrHCXq+vVf8hQiiG1GHAwjy+0XpreywHLnwVNel3FgPHLHG9MoSRskO7q8ewMe6P8Wnuj8RjmbpKSkTImBmwdtJR+W4uvlZfh1AVATklRGvW5roIu1Z2La6disgk62/6f9ACRx/z8OD9n5sUCMZuWkBI9VWvx4K2EuWA/C4O2aSOBpPJONlH+UAkkUlzm/zOADnV69O0k468b7W5rxK4Ohxnl8Z+i1eHrIfqCqt6xf4z2bLKiq27cdjunXsOxPPW05adL2mpSnCk85pAGeTtk0FR2z+sXKS7+AVFwGFv3MWPBFQk9b/3ASgWzkyEQUgIukC8F0ARrvbdifmywrbvMPQYdrB6SFtV6oJ/HrmfwFO/I8zrIcBmC5ruL71a3y5fLVTD1cJPFI5csHvVd7GzfbRXG8fqylXJbZThWRrDRMcEZCVLgLKyQHoOyYwO4J5E8qx9TfnFdUl6NC5n5Il4RAMOZDk+Zv0LG3HWqHMN3reB8CH7D/zxfKffII0STayXbXR7kYATTahjHAAsQ1E+g49rxWQJKQvZQSD08dzluI2Dfo5zHp90vIqWRaPthzODWPeC0DreicE+OP2nsyW1VxcvZz3lP5J+7CZ3LL7BxPLzqpfmhgsiXMC70CY4P+vVII6RJuXxQFEEVgB9ZMISJwvdKOI/BwYLSIfAm7H8QjeZWFcRzpWQ8sw2u1gh5EkNzSa8WkcQFUpVg7fj6srJzNe2n1HlfOs+znIepm3lu4CgmBwo2zHy3CTxnh567HHXUSRFXgsXL/AFyCUh7ZsG00sDUqufDqAYCIkTbxyLj+ANA4guf2mugT/x6+zdqxeoLC3qlt4Z+k2/zyAibLJ9RUwUGgNgX24838ePwD9ftICHk/v/Ob3BHbuq9C9pLyzxTk9MSug7Ly8TcLmkrOrbt3ocOKP2vvQJj28Ru5jpRrHgj0vSF1YE3UAvidw/HnJNURI4pwgiAb6qe5PcEH3Z9HHXbTILCVwFH4I9iaxAJmOYEopJSJvBj4HtAP7AN9USqWbr+zkMJpddaxCjZxEJVDS01IS464zFs7XDQft6xZshZTb+GrlgxxqveQ7f5xSehyAVjfUrFKK71cvZc9NjixQdzjzxASWFZip6eOqFhGQtxCn7STz6ABKng6gqhOAOAeg7wBLlhh9FUzB4LzFXucqSpblRGS0Vd2ewDqMsYAydqy65cko2cEYexOnV1/gtaUHedAOnI+SejdYGFwOILaBML/nVadZfgBmR7D6OQD9+Ma0vEI6ANcYYHPZIbIjX3ZOs3vM3htwjnb8bfV0Dpr2OmTJpsSys0RApj4MOFpvHBgIgGvxdb19bLwdCdFya+UAmiUCyusJ/DiwWSl1YWbKXRkdq2Bk2P6/xbLoNChxTTs4EVBu0krV9if9JuWYfpWosp+8AsAw6WIIXZS3reZ0eQg6oEuV2abJN21dB2DYYNaiBPZ0AGn25LX5AQRpjToAKyBYzu43nrcpGJzn9auLgDxdgXO/EWagceIgkf+jiIaInmOt4jvVy506u5Eg096PxgIyGRGYkLYzNaa3vPLCC352LCC9Lua883CceuA25ze9XV7dRGCrjAqleVzTxa1WYzlE0olQVheZ+rClZIWMLEyMVmI4aJI5gLzc+UDxAzgKeEBEFonIU95fbwsXkc+LiBKR8b3Nq9EwftD2FdgjJoVuJSkq4yIgIofCB+cBbGQkR1gv8L8tP6RVqjxq7w3AGLbStvklPw9H/BOUV/HFIGZzydqUwOIv3knI41Hs5WP2A9DTBb9Ji5cpGJzXZ1EzUO9ePRxAdC7q1YmG2U5asLppoat1DMuV45w3R1ayGYdb82K+6/lEUfLzx21LrmYEyvTe6gAyRED5OIDsOuindzm/5nSmMBcqkngdu/kc8Vo1xj0UPrkOic88KyATB+BatOURAZkQ/d5RUV8Wmu0JnJcDOKPRBYvIdOB0YGmj824EYt9z0xLYvJTq4WElU/RwbQ+JHIB7u2IrX27rHXV4ZukRwJFtzrNeYIx0MKQ9OFjaS+eXYTADNTlb5UW5lMEB5HBKsSTuwBVwAHq6YAFI1gFIbIXwF3utf733K7ZddyygcBt0TiX8Xpqxzfz9vsj/zu/iV1zEFFnPdjWE0bKVz/Z8LCg34d2YCCjnji9YmPJaAbnllaILUzoH0CgRUCVqBppRrlc3/0CYN/+GNS8/y/f/3Q7uWbqHy4uOnkXSv0/G+m/sQ4ebNcfa8hBVAofKjP6fEQMpCj8WUH8Gg1NKvdKEsi8Dvghc14S8Y3hmxRY+/PvH6K7aDGmxEIQdPQFrfup+u/PpU/bmrMv/RcmyWL+1y392xCW389bqjXweOP+ecDjZpPgnNz4VPuBZ3LXs0Vc2cdz37qSrEpwH0B45I9bnAKSD+/79KBNKQym3tLKpO0wALrnZsYawNNY3JDuN7HKz1pSyZcU4mhFDgiHS0VWJvRMdxiVXJKNPlNHDWmKpdeVqEhdVioSUgMBv4JUN2918gsl50qV3hzwnRw1JHt76Z4tNxgRC5fwmT9zFU17DI48vYJ2M9u3Bf1J5HYvU1FB+o4aUae8M92U0FtCItnx7s6QdfRJ8/4sUDmB4awmAYa0lhrWW3euyltac9/CEOuve3rHzABKqrfdzwAkqvvvKvmzcMZtrbMe8drGawkFqMRsZiR6yQfcN8ZC16Jr6sK1shTjakiEP07nhktA+79+8HMA1jzvtbJYfQF4OoKEQkXOBFUqpJ7N2qSJyAXABwIwZM+ou8/nVHazYvIMZY4exdKOzeJw1dxKjh7Xy70XreXDxRvadtJpN23tC75249wSmjh7K6xc9yYrumczvCBOAs+ZOYuqYoRwzZxwLV3cwYUQbb//lQ/7zKbsN4b3HzaKtXPJ35ys2O0FUS5bF7Z87kXt/+FsAOlULl1bewhLlBHkbRwcnWE/xuL0XHfu8lz8/GVdwffjE2ew7aRQPLd4Ye3bi3hN477GzAFi0biv3vrieccNb+dbrDuBTf5wfS/+50/amtWzxhsOmcuBUx1HtUyfvxYi2Mr97YAlr2h2i+LN3HkZbS4kRbWUuuckhQh951Rz22n0EM8YNY2tXhW9d59hqj2gr89v3OxERTRyAJfDN1xzAx69+PFSXdx09k9cePJl7XgifkfofrzuAF9Z08KM7X/LzPO2ASSxev80XUY0b3sqIIWXeflR4vPztY8eycatz3N7bj5pJuWQxYUQbE0e1hdLpC0HgBxAXAf32/Udy4V+fZG2H0y9V28ZWjkJ4Cg7ntk4FDn9uRlz/ieO598V1dHRVeO1BU7jnhXU8uWyz2x4n/4vOncvcqaM4Zb+JzF+6mSToVj23f+5EHli8kW1dFc48YBIPv7yRPSeO4A0/+XesPW+eN52tXVV/gdGJ8PuO24OqUrz32D0oWcKajk7ed+we/vOjZ4/jfcfNYupo54jF1Vs6OWj6aM6eO4n2zh5ef8hUbnlmNSfsNZ7nVrVz6PTRfP2c/fj+rQs1b/J4f/7wbYf641JfIPVD4e98fi3btI3Iyv0+wJef2c8JtKe9V85JAP7xmRP4yO+d8ComS6rPnrY3U0cP5f8eW+73cxTRckqWcOtnnOCQ+vr2yZP3ZOSQltj94a0lPn3qXgxtKfENd9585FVz+Nk9i/w0Ox0BEJHbgUmGR18Dvooj/smEUuoK4AqAefPm1d0NHgt7yPTRPgH49Kl7se+kUXz6T/N5YtlmI1W+5PVzmT6sAv/1JEv3+5CjDifYUY8f2cb7jnMmx76THCXV6GEtbHYJyadO2Yu3HjnDf0dH2RL23H0kC8eMgg74Qs9HuNE+hnFsAeBI6zn2sNZwZc/ZTJ3wah7iBaLK0q+cvV8ob72MCSPb+I/XOTFKPvvnJwB4//F7sPvI8ILn4cS945ESh7aW+PhJezK0pcR3bnwWgDPnxgPhzZ4wnDcePs3//yLLSfvOo2f6C4XefF+mbgnnHDSZj18dzu+i188NpfPw2oOnsHl7d0AAgKmjh/Kdc+ca26TjsBlj/OtDpo/mkOmjjen0SR7tV32M7D1xBOcdOpWf/2sxgB8LyJaSn6ZCcO3Vd9b44cwaH7jSvPPomSxYuSWU/27DWrjgRCecwJwJyYHkdKuePXcfyZ67B1yiV8b+k0fx7Kr2UDvmTt2NS86b6xMAXfzRWrb42Kv39P/XrwFGD2vlW689wFgfL+0HjnfmxN4Tnfp88ITZ/Pr+Jb5S0zReX3fwFI0AhLlFkeB4VF0XNW72IVz2VNnPS/cwj8bRic7vE/Yaz76TRqVaAZ2w13gmjhrC39x+Mu1XowTgvEOnsufuzjfTk7/z6JlaXcIZXXDiHJRSPgH40Al7sLa9k7/NXwE0TwncNAKglDrVdF9EDgT2ALzd/zTgcRE5Uim12vROg+oDmHd3ljiORMZTlyyB9hWgqmwfu79/vyRCRSkj0TDHkonDW2iu2+2dPL6xlZvtowBHKVwtDeEN6j4AbqsezgesdLYxqHs6R5Vmd5+GrGBjMVGQwd45zAG46TI4QFNVTdZEjYSuCE/zBI7uBqvukZAjcTi8e6tz+Wv1VaE0yXF04jviPPCtU2o8FD56Xc+YqBW6ua8+90yIcouCuD4xdijgX7Q9PkE09UdGE31ls8Hiye/nHP1k2ujoeTh1NbwXaUsopHpmqfUhrxVQw6CUeloptbtSapZSahawHDismYs/BEqaUogAOL8iTvRF02AUgO0OO18ZMkZ7NywaiL1j+CduEeD832UN48rqOdju51BYdO02m2HSxZP2bNYw1mGD0xybEp+EYUl+k0EdWe9E22Za0EwHwmQt4FnWTc1YtpLGiP4LDqHQJ6bnn7BRnHHytcoH6CTMbSWt72kHhaQhjydwkhNXWMzSfAJQtkQLBeHVIYEARJypfA6gqkLGCNENhpedyZot0Q8gxQooKvrL2rB49TBdh40L0hd33bwZmucJ3C86gP6A14F6p+qmfSphNy+CTwCqQ8aCK56xLKBqntChAYD5GpIPoADo3G02wzY+y21VJ4hYWsgEPY+s8emFfKgVWbFiYukjSs1o2rwcgGmFt5JmWINg1AEYdqwlS0KsuRMADr475NPs3f4gS11djo6k6qaNhTQEO9Pkb5oUy78/OICYFVBCsXEOIDgetUcTuSRZcJnOJkh2BPM8geN9GFX+57GsCxGvhPL1bExru1jmQ5UajX4nAC4X0HSYOYBgkbKVeYBYIhoBGINHANIWrqRJZtIBRNN46BrtyFK9KJJpcXH0PLKGp9TNAaQTjRhxM0yY8Lrt7qgy6pItYkt9vS6UDJsE0441umh64o2O8jj+Wn21Me+kb1irh2g0v9x+APp1H3MAJUs0K6D8C6plASKaDiDgAKKEwlcCGwlAejmmPtTXCKcNmdVN3vUn3DchulHrb0/gnR6BDkCX73q/ng4g/p6ATwDsIWOBJf47SUiaZLFF0jsFypDHhn3fwaUPdbJQTXfrnSYAyr9zjLKWeZG1wETLtwwLWqNEQOE+bTYH4BcU/h+PAwj+9xamJNPgNKQfFZgM3QqoVngniimV/1D53qBckthOtjYOQIUO2vGe6e8EZq6m3XwCB2DYHPrvRMrJpQNIYFBN0XDBbOMfFdX2tyfwTg/PacrEAYhIIgeAANs3QesIpCWQ53oLl5F9yzEAQD8eLp5HddjuXGOfiDcES5bkEnhni4CapQOIlhPeOTmJwvWA7Dj2pvakcVWNgHGMEIwVD2VLQlPXIwBpEVWTFqFmcgBpa0etoSR6A52LDERA5nKjDo1esphppxV+x/eLqIEDSNUBRAh/PudK8/hM4gBM3ydqrNHf5wHs9LANH1n/uEop4+7LEoGta2Do2JhzShKSLC1iHIBPAJJZTw/OYes5dh9ZVkBWnVZANe7Ufe7KMrc/kF1ns8Lxe+brRsHEJZpk1tG6eyKgtHOOk+qb15M3irz9mFWferjCWpFkgWdCdOF0OID4kZ+6tYwlWntqUAJ7MFlSRWX/tSuBE9aCjHyiotpdxgqov+Apgc06AEcEZBogLSsfgWf+D4aONsrzTOxb0qdN0gGY0kfTes4wSci7QxBJD/eQhMTzUlPKcX7j95z38u14MzmAJoiAwn4A4W8UncR6v3fn4QAS7nsLcK3WHqlmjy7Swgjk1cU0Amn+FVHotz0PX+987FA6CZ+FUY8S2EM6B5C/nyThOkkfkGgFpCXq1yMhdwWY2LyoEtiE8pqnnYtXfTFi0SKhfHVIZJHQnoTS1WL5kaUD8EMuJ7K5QUC2euS9SQPf9+uMPDYumFra3uxcU7q0IUh3BAsXGDoxrVK/CMjLN28so+h7aYtb2trhvZVnZ9tbhLhv0se+RMZNwAFECAB62wNRkSlGV7Ss4NQ/d3NoqEwwjs15mOue0I4QV5NOAYQw91yIgHqJgAMwsffJHIC1bTVICfY5py7rk7RkPgHIUHR6aWsN7mZC1MEkL2p9x6QDMFW/Vv+C6L1mLFtpoSCSFhEIFqc0EVAiB2B5HEBtdfUXvDpFSH2rA4gvhsk6AO3a1QHYShmUyHqs/mBspFn0RJEWDC5qrFCzo55+HSIA6e/FdQCFH0Cv4Lt7J/gB4CqBh9BFqxu+t4NhlLaugZGTICKCybtjymUGmqR7iKTNM0eTkoi2INenA8gwA43U10tu5AC0dPWYgYafN37hSnMESysvTQnscZmJ4aADmWJNqHkBjyTrPx2A95tAACKLpWA+eEk3atDNQI3fIINGen0Q3sGHf/OJgMwbxdp1AIUZaMNg1gEEv7ZSDN/2Ck+1fZBWceKVXFM9AdlacggA5g9o+jBhx5vgfvST+wdE5+QA0va7eQeIJZI7bEC8/DiScjLZeesKtbxKtayaNkNyETYU8DgAB2mLiE8AyvFEXmyapPrWrQOw4nWOIi3HWv0IeoPwDjvOIeqIKU8FLZBcOJ2/SKO1pxZHsFQz0PDOP5chRoiAxLnJ6LVRjxjjADKLrQuDRgSUqgOwHDPQ3TY9TatU+WHl9Txhz+ZweQFr62r/FLCoF6ieb6gs7TqJBQzVxTCm4kfJWbHdiKl9eXYWfRELSOc4oml0UpbpB5CjPY2GaZNAwgKgE3vPCsjkB9Ca4vOhl1mvEjiNqKeJD4KdbR/4ARh1K9kf0HKPU41aAEGYAxDJsgIy5+8twHnMQGvlwvXrJHFo0ucp/AAaiHQ/AJcDaF9MVQk/rpzHPfYhzLLWYG1aDKOmuOmD/PKy3CbLl2geWaaOXtpgcMdZ1bxolg4gWhcji68RMH/hyWhEf4iA0oPBJb8XiIDiiTyuIMsTuHYdQO928B4B7hMOQOuXWr6bt8uvGE6ks0S009QCztL0DbKIjZEDiIzjfI5gcQ4yT/lR6Juuwgy0lzD6AXjno2IzUa1n5JaFLFO7000Li2xn0ZdqN8x0Dns2afRN7FvS+alJHIBpWMTSliSVHc07QBwOoHGxgPx8Y34AJg5A/N+8HEBz1LzpMC1USTtWvd+7U6yAWgzy5VCZ7jepdafndV/awpRHBNRXweA81FKa4wksxjOpLUv7JqKLgBobDC7rSNAkRDkIY/kJ9/VvUgSD6yW8DrQMHMCZi/+TL7bcAKvgNnUYAC9qpzix56lu+uCWt+swi4A0HYB23yzXT1oU4txCVBGl756zzEB11DPX6+UAjGZwEtzPipqQ1Z5GWEZFYRRVJPgtmEJBmAmAFcovqcxaOYBAhp/SkamewOHymwmTFVAeeK+Zznt2/Frcay1t9MQzPZ8o0qyA4iKgPByAdu2XnUKgExb3QgfQQCg31o++aFoC7NjMgetu5D57Lo8f8h2+U3kXAM+pGXy4+zN0vesmaBvppg/ezbtjSnNaCiJmZg9WxwoovFszzfk8jlH1LJpJC0xSXqYdk7b+B0r5XouA0p/XgyQxYVZ5vg7AoAT2dQAJ7a1fBxCvcy3oS0cwk/4tD6waRED1KIFN9Yu+E8y97PoaY17VMef6wgpo0BAAL9ZPTBN/xasRFL+pnMHL09/IMj+Er3CrfSRqxjHh9N7TVIqOlk57EOMAkhWDSfH19etmyL+TkMkBRP43Kc10JbZn0ldPMLhantcDk7li0k4u5AjmcgCmhaQlQwncTB1AugjIK7/5S0H9RMr5M4qANG5S1y3lcQTzkC8YnPsbSaP3u0k3p4/5JCR9n77wAxhEBEC5gyW4J9VO2PQyq0YeyB32oamHO0evvfFl+jAhKyADO+gh3QoomjawAvJ2PGERULy8RqLmaKBGDkD8X18kl1HhbBFQ+vN6kMYBRMvLGwqipezlk84BNEUHkJJnHiuiRqF+EZCjAzCJgHSjBiHY4JlFQEmFulZARsWx92vedJk2ZqE9n78RyrdhTMq7EAH1Ep4TTogD2Oic5frElLeisBIcTbT0+sfOOYLTrADSrYDiaeMioOQdS6ORvXsLP48unPq1wwHkyzeLQDRDcqHvhqPBwPI4gplEQB5RSKpvM2MB5Xq/T0RAceuqPPBEQCYOQESfRxpHU4MS2IPZCij83aPzPpsDCOpWK0IcQO2v58KgIQDeiV86p2ttdA4W3zJ8JpCgZNKuLcOHNSqBdRFQQl5QoxWQQQms1yct4FcjkOkHIOb/TZ7QArk5gGyK1viFy+gH4P8fvqH3uueoZDQDzfQDcJ7XrwRO2WGmvB8dU81Er5XACToAPy9JN2tNVAKnWAFF341uuowcgEHvVZ8OIHinCAbXS3ixfkI7+g0vArBl2CwnTYKVgZ/eoAQ2fxbdEzh50NcSDK5kSWwwmVjEZomA6vUEDouWgwkS+GWkl5vJdzSFA4h/8yQlcF4roCwlcKADqG2iBwt42pGQye8n7WybAVMwuDzwPMfNjmCBEjjrPIDEA2Hc37Q+NJk1O+VYsevQpk/Cv7Ug5AfQpP3dIDID9XYL2iCc+0YYvxf2umGAmQMwKTGhllhAwXX0I6YdBB5TNpXiFg6m95phFgk5YgFF/jfRC50DqOa2Aurd83oQMhX2TQzju7soUnUAmX4AyRxlal17KcLxxCbZ/hi9RxpnlQZLnDHTY+AAEkVANXgCe0jrwyROycQB6JMhGkyuFkQJkmPJ2NjvNKg4AJHIIBg3Bw44z79XNewwss73zRYBaVQ8kq6UsihEb5VE/Ju62VtS3o1GrVE7vbrpXSrahZ3XCihjvDd72YqeaxCvbtwKyBQKIhABNZYDyKUEThkdTtTJvlkGQgtsTQRAEseBENbTpBHEZEeweJSApHdNQRqj16ZD4evZqETb0AwuYNAQAGUwA/Xg3TNxAKZ0oIuA8lsBRa0xgg9s2smH/w+JgNz3jCKg5Or3CtmewJH/PQJgCIxXCweQ1Z5mSy7ioSCSJ6V/Ilg5XikvFEQWB1C3EjjVCij5fX0H3WyEjoSsYaQ6VkBp+bp56hxALZ7A7m8uHUCCIYd+3SglcPS7NGOTN2gIgGcGmiaaqBpYTB36u3knjT75YhyAQZkblBXdaVixyW7cuDVpLtfrCWzihkTEtwLK4gD6QwQUzt/5NSm1o6j65wEk6wASrYA8JXCcCU1Fbx25HA6gbwhAORRiI/97Iumit5K2yKbGAspY7VI5AH/TFb5v5gC0Mv3x0wgOoPEkYJARAPOhKnk5AJNJp1kEFNysplCAtKBuMRFQSWKLUFgE1FwhUKISOIk1d+8bOQAxh+c2Z5RRsT7jANzfyIwxfX/TgmoSD4TKSfErSa+f85vuB5D2vvSJ/B+iVkCN4wCCvOoVATm/aZZuNfkB6ByAH0Ikuf5JiH6XWi3EcpXR+CwHJkx+AB4CHUANHIC3wzWk0+/plkXRRdpKWxQit5wjIcO7PaMjWJNWxExRTYwD8EQaWhrt1+vrbBFQ70REvUXUiiPNE9iDaVedJQIq99IMtDdetn3GAYSsgPLDCfiW8lzbbKSLgMzvBzqANCsg7zfOmUevQzqAHJxjEmIcQBM2eYOGAKgUEZC3ENejAzBtr/Rb+g44bgWUxgHEdxr+YEp7r0lzudaQDWYdgC4CapASuOkiIIn8H35u2l3r3qkeWjOCwdWtA/APhEkzA01XAvedDiC+MOaB8w1SREBe39nBsa61HAqfTwfg7uQj3ZzNAaSXnYaYDqDgAOqHbScrgb1FxGQFpCMWRyhPuboEKPIBazoPQBNfpbH9fTOVDYhxAM6vacwKejC49Gyz1qZmr12BDiD5WznPtXes+GISmIGa3/fS1zrHe60DMNS1WTCdtJYHjmw/7XnAbXrpTAQxq8h0K6BwWR50sZF/pKT+XspmLQt9YZ01eAiAIRaQB+/jZusA9HeSJ2xIB5AiAkr7wPEzduPCkJAOoFmeIhlIlGn7OhKzDsAXAdXIWdT6vLeIWgFFx4/XupZI+Ihou7I9geP9VUv9enMkZF/EAYKIFVANRUqGDiAgAAEHUFM00ByewEmE1uwHoBG6rLJTEC2rGd7Ag4gApOkAPA6gDjNQkxI4VG6yCMgwXnyYhouXzssnTACS8+oLxImT86vrQETTApjOZzDmmykCqqGSdSDuB2Bmy8uRQ2SiMujM8wD8WEC11c/b1KT1Y7oZaP/4AdTy2dL8ACCYi9WQCKh2M9DG+QFo8MdNYtaJKPwAGgilFJaVLm7J1gFo1zm/aIgARJ6liRXyBoiLotk74iREOZZAB6DfC35zK4FrVD43Gj6R9v83Fxj1co3pADKOhOyNH0BvRDimujYLpiireWBJ+ri2tL7zlcBGK6D89Ut6t1YroCTCkQeFH0ADEcQCij/zdQCZfgDhSQ4JmnntVkgElJC9cWgY6xnOXm9L/wiAAiSJp0JKYO03rx9AJgfQVyKgiP7Fg+lAcaMVkEE+rCPwA6g9FlDWAp7tCdw3BEDnkmpVAue1Agr8AEw6gAQOIEdgwiRrq0wrIL/s5PonISrG2mVEQCLyHyKyQkSecP/ObnaZplhAHvL7AQTX6UdC6uWqhCfmfFPv+dnExSf9LgKKlGsyktI5gLwngmU1p884AP83RgGAsNmhaVEuuec5ZJ8HUGv9skU46X4A/cMB1BYMLv07e2Ooagffq5bw2Hm6PBABRsrOsgJK4BzyIM3rvFHoz2BwlymlLu2rwoyxgFwEfgDpVkChuEB5RUBalkkfMK8IKHaegClNrlo1EAkF6my5n9RXqEpuJXB/ewIHdU5HSwYHYEk4pHcUvTkSsjcLuPQlB9ALM9C8IiBvTtSj10jnMiRUlocsHUBvRECxNwodQP1QilDgKB3erceXbs6dX5qZY5IncOL3S9vt6/diIiCNA+hnIVDcD8D5NTqCSdAvA10J7PdxlgIxogSOLsrevWSrKee3HkewrAU83Qqon2IB1UgA0iiwbnDgFWHyA0hCHprri4Bq1AH0RgQUxS4jAnLxCRF5SkR+JSJjkhKJyAUi8qiIPLpu3bq6C0vTAXgfd+nG7bnzO3bOeACOc3916J/pwKm7BfcTPqBpUUgTAc0aNxyA1x4yxX92zOxxzq+hPgCn7e+cdTzXrY9er30njTS+Y8LB00cb70fre+JeEwA4Ypb2aSX4Od2tz/6TR8XqMHfqKP96/Ig2/3rUkDjD2sila/eRbYxoC5cRVQJ7eMu8aUDQrwdPGx3USeI7UEtg6uihTBk9xFi25yj29qNm1FTnybsNZcrooalp3nrEdP/6+D3D42NKjvcbhbTzAPYYPzzxPUuSd9DTxw7j7AMnA7D3pJFMGjWUsiVMHGXuZwjmyjkHOe+982inz8cMawXgrUfM4NX7TAi9M3n0EFpLFuNGtIbu7z4qGJ9lk6+HGO4RHi/nzwu+z/SxQ/1+Gjmkxf11xmQztnhNEwGJyO3AJMOjrwE/BS7CadNFwH8D7zflo5S6ArgCYN68eXX3QVosoOi9R752KkdccntqfvNmjWHhxWfSVi4lprnyPfPYb3KwmHmV//6bDuK8Q6f699OIEsCLl5wVujdtzFAWXnxmKOzwUbPHpdbn7AMnh57//ePHOWIxsi1t9HokOkJF/j9uz/Gx+ujB4M49ZCpnzp3kP7/pUyf4BFKvzydO2pM3Hj6NiSPbMKGRnsAPfOWUGJE2OfK8eMlZ/k7Q69cr73uZG59aBTgLXXRXLSL84zMnJuo8yiWLFy4+q6adK8AnT96Tj500JzXN507bm0+evBcKFRsfP3jzwX3mQ5J0HsBLl5yV+h2TxFT3f/lkJo4aEhtLC75zRuI88L5dj2378+erZ+/HhWfsS2s5+AZKhbn3w2aM4elvn05HZ8W/9+8vn8ya9k7+8OBSt33J4Sei9d9/yigWXnymwxlqbb/7Cyf532Noa4mFF5/Jnx5exreuX9CU79Q0AqCUOjVPOhH5BXBjs+rhwfMSTNMBeDCd6Rp/RxIHmfedhrSUjPdbShKyUshaw6I25GXLXHYaMYo+L1lCqcb9s8mywochq2h9ou2M1seUiWUJU1N2qI0UAZnq4EuAtPvRfmgrlyKyYMsoAkrtP/KNuygsS7CynOVEaDWEqIbkfm8GkoLBmeL26EgSU+kbIH0spc0D7xu0WdrGROufVi1mU7Rf28olthIQgCmjh7JxW3fQDqMIyNMBxOtiqmf0e7SVS3WLB/Ogv6yAJmv/ngc80+wyleFISA9Z8V5MSFPqePL4BIOR2Lt5RUAeAUkLWtXXqGXpaKQ8tJ7y60FgBpqeTv8mJQMH0Edi9gGNsBVQfiTpOfrD4i1miGHSAZiCwfVmAHgWh00QAvWXFdD3ReQQnDVxCfDhZhdoKzIdwYL/sz9WPUTCJOJIystUB08JVIuJW18hj1lfhj61LvTZeQAZ6UIcQMlkBTTwvllfozdWQCYOoD/6NFoNoxWQxNP35sxlv4hdxQxUKfWuvi4z0AHEnyUdZ5iGNJmlKVRDOP9YZvH8De9VfQ5g51xMfB1AA/ftfWUFlM0BhHeCcR1Aw6u206He8wAkIWBdf3SpKUpv9FpPkRVEsJYydxkRUH8gTywgD3m+VdoabPLUhWTCYMrKNEE8L9G+sttuNJrBATTbE1j3XUhDdCcY5dIKDkDzlK2xKxwOoPbonk1BjAPQPYGTNwu9kdoG5t+7lhlon8I/D8DQ4vpEQLVzCd4HzFOeaY3PfYpWPyDP4JTIbyPQfA7AKyg9XZwDiJiBDpqZloy08OdpsMQs9mz2WRBJddGh+3+UDKEgentgj15mEQyuF7BrUALnGVepaRLCMgQfMLs80+DO6z3bl6hpDibYRPdZ+fXk74ut0lEuhQlAlEvrryB9AwmmePl5ICSd49GAStVal6gSOGTNFOcAfCVwQ0RABQdQN2zbcyiJP4t+m97qALLyidYh79BQO70OIPzbmDyb2xe+Ejjje2dZARUSILOnbB6IDCQdQBjG8wAM6Xu16Sk4gN5D4UQKTAsGF/yfnV+6DsAs6knUAeQcG55jys6uAxjoeeoIzm1OR2gnaFmFFZABQaycWkVAAUHVfSX6QwQULdJsBSSx9L0x3Gvm2Bk0BMCJBpov8FpvdvdpaXzCEOn16KEjSQh0AAPws+XYnTRjt978YHDh3yRkWQEVBKB+DsDSOIBw2O2GVa2GukREQJEYUBDeLDRCB+C9WXAAvYBKjQVUe36pjmAZOoD44Snub0aZA9EKqNawvg0vv9kcQE7iHLMCKhzBYuiVFVApvpAOBL1Klh+Ah95wK96rhQ6gF/DOA8gTZjkP0l5J8vjN8gTOqkd1AFsB5UEzat3snggcwTJ0ABElcJRL6w9xxUCDyVM2D3QdQL3OZI1CtMwQ52dQcvtnCTeAABQngvUC3nkARhvdBnMAiWl8HYC5/Kx6eGcLDCQOoBY0hwNobl8UHEDj4PVJrX0hmh+APqf6gwDEzwQ2+QHExVS9MwN13m1GMLhBRACSOYB64nSkKoFVghLYVw4niYDS6zGQ/QDyoBmLddPNQHMWENMBFI5gMZRM4ZJzQhev1MtJNALREvWpWDKIuLzLRnz+whO4F/AdwXI6XWUhPRicg5gjWIJuwB/IGfXw/AAGYiyg/jqOps9EQBkzuGyFrVNiHMCgmWnJMJ2YlRdZB6/0FeL6O4MOwPC8t6e2OSg4gLqR51D4WpDnlTgH4N03cwCZIqCBGA20hq5rxoRtfjC4fItW/Azg5IVisKI3C7dJ2ToQgsHpKAW7hVj6RgSDK6yAegHbJrcfQB7UEwwuEA2ZF4e8IqCdVgfQhP16862A8pUT/SZxT+ACgRVQ7b2RFXStr5BWdyOH4+uQesEBFMHgeg/bFwHFnzVrPU22Agqny1v8QAwFUQuaogQeIMHg4hxAYQUURV5iaoIu9kwzt0xCX3R/2pnAGWfepCKwAipEQHVDpSmBmzQ68voB5F3Pd34OoAl5Np0DyLfYRPUyBQcQh6cbqWe+hUNt1M9JNBNBrKOgXl4Vi2Bw/QxbqcQDYZo1jqLWRYFyOFp+vgrYA5gDyDM4d05HMLecjHTRBX8gfqOBgJJVH88W1QEMsLUfMFsB2QmbvtrgiYAKDqBuOH4AghjDQTdnNMXWAO9EsMjtvMUHsYAGzmeriQ1vig6gj5TAGcVERT4xDmAALlj9gXoX76gOoNYs+qL7TToAf9PWCEewggOoH/0hAkrSAaSZkqUhsALaOVeTRnZzXsupRpWTtYTEOICISGgghC0YCChZZkOMLESP3ByIfhUmHUAjfHeKYHANQH8ogRN1ANF0OfOzB7AfQH+h+eGg83IAEQIwABeogYB6RUAxDmAAdq/3zfUWeoYbvamv92ohAuoFGh0LKA+SooHGdQD58tvpYwE1sJ+9nJquA7DC5SUhSwcwEBes/kDJsur0AwiHXKg9nlDzP0DJoDDyOYBCBNS/aHQsoDyI+wE4v9HBm5fF8w+EGYCrSS1HQjYCeUNo9xYBB5BeUHTBL6yAzKjXCkhXsdRLRJoNia//vti2nnAzHvxYQHXnkJJ3E/IckOgfHUC8DmAKBVEbBhIH0O/hoPvMDyAdMRFQbwy/d2HUbwUU4QAGzhTwYdosNEIE5HVYIQLqBQIdQN8RgPih8Enpast3Z9UBNJQD8H6bzgHkKyeLAyhYAAflUn1K4LgVUI0ioJpLrB2msCGqESIgP6+6s0jEICMASbGAmlNmnANI0AHUODwHEgdQC5pxGHyzeyJ/OOjwVIrpAAoKANQ/dncGPwDTZqHqhnAvgsH1M2yVEguoSQtqEmcRXQxq5gAGkB+Ah752BPP6sPnB4MLlJSFTBzAAF6z+QNmSuiKjRjmAgWgGatJLeWKb3tS38ARuALxw0Cb0uRI4ZgW083IAtTmC9W/59eWfj9UoPIHzoWRZdXFDoVhApTocwfrgc5g2C40gAEUwuAbAMwM1oc9iASWZgdaY784aC6jBLID702wOIJ8SOMpFRrm0nfSLNRz1im/KIQ7AGpAd6o2BsAjIM92uP9/ADLQQAdUNO4UDaJ4OIIEDiJqB1vgVdtbdZVOUwE0ewXkPhImiOA/AjHrFN6WIFdBAFAGZpmUjzEB9AlB3DskYPATAVomTsM/MQN3f3iqBd1YOoDlmoM1FXg4gip31GzUb5QYEg6vHE7gvlPCBDqBZIqCCA6gbqh9EQEkHwkRLq7X4gcgB5BmajZyEvmi+yTvBoJza3ovFAhp4n6xfULKkLqqtj/l6iUizYdosVBsYDK4ZLMCgIQBpIqA+iwWUcL/WRWxnFSc0wwqo7ziA3nFpO+cXazzqDeQW5QAGsgjIaAVUeAKHISKfFJHnRWSBiHy/2eXZqnnmnkmILdT+Fxyci8PO2M68fgBRDEQubSDAsQKqHdHD12te//vECii+WfACOPZmOHhtbYYIqNzwHHNARE4CzgUOVkp1icjuzS7TiwVkftbs0h0kcwB9U35/o6EcQBMVYzryHggTRcwKaJB84yw0wonLUQgPvA41iQsbEcDRlwDtQiKgjwLfU0p1ASil1jazsB/d8SJdFTuRjW+GeZUJQ1pKQFwe6O0cWss7n0SurWxukwle/zdidzystW/2Lnn9AKKItnEgiiz6A/WKb7xXhrSUXCug2t4f1lqqucxaYdIBeBuB1l7YgUoTRUD9wgEAewMniMglQCfwBaXUI6aEInIBcAHAjBkz6ipswsg2zjloMuccOBmAi18/l7lTd/OfjxvRxoVn7EOlqjh85hgAfvbOw4wL8h8+cBQbtnWllnfLp0/ggUUbYveveNfhXDt/BTPHDQvdnzdrDG84dCrH7zWeSlUxe8JwAP7f+Yew+8g2P931nziOJ5dtztfoPsL33nggv75/BMfOGZeZ9tg9x/H6Q6ZwxgGTel3uXz58NLcuWMOItuYO4UNnjObDJ87m0OljMtN+/00HMWuc8+3mTh3Fh0+czflHTOfv81dwyPTRTa3nzoJ3HzOTjdu6E59f8a7D/QXvN+87gm1dVQDGDW/lwjP24ZwDJ7NhWxeHzhidWdZl5x/MxFFDeHr5Fk7Zb2JD6g/w/Tce5M9RgL9+5BheXreNvXYfwUdeNYdj54z3n33+9L1pK1u84bBpdZc3ZlgLZx84iXHDW3tVbxOkWbtfEbkdMM30rwGXAHcBnwKOAP4MzFYZlZk3b5569NFHG13VAgUKFNilISKPKaXmRe83bfuklDo1pTIfBf7mLvgPi4gNjAfWNas+BQoUKFAgjP4SOv8dOAlARPYGWoH1/VSXAgUKFBiU6C8dwK+AX4nIM0A38J4s8U+BAgUKFGgs+oUAKKW6gXf2R9kFChQoUMDBzmd3WKBAgQIFGoKCABQoUKDAIEVBAAoUKFBgkKIgAAUKFCgwSNE0R7BmQETWAa/U+fp4Bp+padHmwYGizYMDvWnzTKXUhOjNnYoA9AYi8qjJE25XRtHmwYGizYMDzWhzIQIqUKBAgUGKggAUKFCgwCDFYCIAV/R3BfoBRZsHB4o2Dw40vM2DRgdQoECBAgXCGEwcQIECBQoU0FAQgAIFChQYpBgUBEBEzhSRhSLykoh8ub/r0yiIyK9EZK0bVdW7N1ZEbhORF93fMe59EZEfun3wlIgc1n81rw8iMl1E7hKRZ0VkgYh82r2/y7YZQESGiMjDIvKk2+5vu/f3EJGH3Pb9WURa3ftt7v8vuc9n9WsD6oSIlERkvojc6P6/S7cXQESWiMjTIvKEiDzq3mva+N7lCYCIlID/Bc4C9gfeJiL792+tGobfAGdG7n0ZuEMptRdwh/s/OO3fy/27APhpH9WxkagAn1dK7Q8cDXzc/Za7cpsBuoCTlVIHA4cAZ4rI0cB/AZcppfYENgEfcNN/ANjk3r/MTbcz4tPAc9r/u3p7PZyklDpEs/lv3vhWSu3Sf8AxwK3a/18BvtLf9Wpg+2YBz2j/LwQmu9eTgYXu9c+Bt5nS7ax/wHXAaYOszcOAx4GjcLxCy+59f5wDtwLHuNdlN530d91rbOc0d7E7GbgR56z1Xba9WruXAOMj95o2vnd5DgCYCizT/l/u3ttVMVEptcq9Xg14p2HvUv3gsvmHAg8xCNrsikOeANYCtwGLgM1KqYqbRG+b3273+RZgXJ9WuPf4f8AXAdv9fxy7dns9KOCfIvKYiFzg3mva+O6vE8EK9AGUUkpEdjk7XxEZAVwDfEYp1S4i/rNdtc1KqSpwiIiMBq4F9u3fGjUPIvIaYK1S6jEReXU/V6evcbxSaoWI7A7cJiLP6w8bPb4HAwewApiu/T/NvberYo2ITAZwf9e693eJfhCRFpzF/yql1N/c27t0m3UopTYDd+GIQEaLiLeJ09vmt9t9vhuwoW9r2iscB7xORJYAf8IRA13OrtteH0qpFe7vWhxCfyRNHN+DgQA8AuzlWhC0Am8Fru/nOjUT1wPvca/fgyMn9+6/27UcOBrYorGVOwXE2epfCTynlPof7dEu22YAEZng7vwRkaE4eo/ncAjBm9xk0XZ7/fEm4E7lCol3BiilvqKUmqaUmoUzX+9USr2DXbS9HkRkuIiM9K6B04FnaOb47m+lRx8pVs4GXsCRm36tv+vTwHb9EVgF9ODI/z6AI/u8A3gRuB0Y66YVHGuoRcDTwLz+rn8d7T0eR0b6FPCE+3f2rtxmtx0HAfPddj8DfNO9Pxt4GHgJ+CvQ5t4f4v7/kvt8dn+3oRdtfzVw42Bor9u+J92/Bd5a1czxXYSCKFCgQIFBisEgAipQoECBAgYUBKBAgQIFBikKAlCgQIECgxQFAShQoECBQYqCABQoUKDAIEVBAAoUyAkR+Y6InNqAfLY2oj4FCvQWhRlogQJ9DBHZqpQa0d/1KFCg4AAKDGqIyDvdWPtPiMjP3aBrW0XkMjf2/h0iMsFN+xsReZN7/T1xziV4SkQude/NEpE73Xt3iMgM9/4eIvKAG+f94kj5F4rII+473+7r9hcY3CgIQIFBCxHZDzgfOE4pdQhQBd4BDAceVUodANwDfCvy3jjgPOAApdRBgLeo/wj4rXvvKuCH7v3LgZ8qpQ7E8dz28jkdJ5b7kThx/g8XkRMb39ICBcwoCECBwYxTgMOBR9xQy6fguOPbwJ/dNH/ACUGhYwvQCVwpIm8Atrv3jwGudq9/r713HE7YDu++h9Pdv/k4Mf73xSEIBQr0CYpw0AUGMwRnx/6V0E2Rb0TShRRlSqmKiByJQzDeBHwCJ2JlGkzKNgH+Uyn185pqXaBAg1BwAAUGM+4A3uTGXvfOXp2JMy+8qJNvB+7TX3LPI9hNKXUz8FngYPfRv3GiV4IjSrrXvb4/ct/DrcD73fwQkaleXQoU6AsUHECBQQul1LMi8nWcE5gsnKiqHwe2AUe6z9bi6Al0jASuE5EhOLv4z7n3Pwn8WkQuBNYB73Pvfxq4WkS+RBDKF6XUP109xAPuoTZbgXcSxHsvUKCpKMxACxSIoDDTLDBYUIiAChQoUGCQouAAChQoUGCQouAAChQoUGCQoiAABQoUKDBIURCAAgUKFBikKAhAgQIFCgxSFASgQIECBQYp/j/vanbudn88hQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_all(*run_experiment(\n",
    "    model=ModelConfig(name='avg_reward'),\n",
    "    num_episodes=500,\n",
    "    training=TrainConfig(optimizer='sgd', lr=0.01, batch_size=-1, train_interval=16, clear_memory=True),\n",
    "    seed=1\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "59bbee53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[0.0611, 0.2246],\n",
      "        [0.2343, 0.1771],\n",
      "        [0.5561, 0.1094],\n",
      "        [0.4609, 0.7084],\n",
      "        [0.5798, 0.4967],\n",
      "        [0.5104, 0.3295]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.4592, 0.5408],\n",
      "        [0.5143, 0.4857],\n",
      "        [0.6098, 0.3902],\n",
      "        [0.4385, 0.5615],\n",
      "        [0.5208, 0.4792],\n",
      "        [0.5451, 0.4549]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "=========================episode 0 nanny======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 gaudy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 balmy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 happy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 snick-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 fanny-------\n",
      "reward -1 done True action 0\n",
      "episode 0 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.024690087971667385  steps 6  memory 0\n",
      "optimize_model_batch -1 6\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[0.0939, 0.1918],\n",
      "        [0.2089, 0.2024],\n",
      "        [0.5362, 0.1293],\n",
      "        [0.4460, 0.7233],\n",
      "        [0.5899, 0.4865],\n",
      "        [0.5052, 0.3348]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.4755, 0.5245],\n",
      "        [0.5016, 0.4984],\n",
      "        [0.6003, 0.3997],\n",
      "        [0.4311, 0.5689],\n",
      "        [0.5258, 0.4742],\n",
      "        [0.5425, 0.4575]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 0} {'count': 1, 'total': -6, 'avg': -6.0}\n",
      "{'count': 1, 'total': -5, 'avg': -5.0} {'count': 0}\n",
      "{'count': 1, 'total': -4, 'avg': -4.0} {'count': 0}\n",
      "{'count': 1, 'total': -3, 'avg': -3.0} {'count': 0}\n",
      "{'count': 0} {'count': 1, 'total': -2, 'avg': -2.0}\n",
      "{'count': 1, 'total': -1, 'avg': -1.0} {'count': 0}\n",
      "done 6 optimizations, 6 transitions added to memory\n",
      "=========================episode 1 shove======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gibed-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 wakfs-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 avyze-------\n",
      "reward -1 done True action 1\n",
      "episode 1 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.05351485204651618  steps 12  memory 0\n",
      "=========================episode 2 joust======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 tough-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 mount-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 clips-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 byked-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 joust-------\n",
      "reward 0 done True action 0\n",
      "episode 2 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.08148771559854262  steps 18  memory 6\n",
      "=========================episode 3 hotly======================\n",
      "------guess 0 0 snout-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 loath-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 ricey-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 padma-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 befog-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 hotly-------\n",
      "reward 0 done True action 0\n",
      "episode 3 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.10863385609316867  steps 24  memory 12\n",
      "=========================episode 4 cheap======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 waxen-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 pedal-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 speak-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 cheap-------\n",
      "reward 0 done True action 0\n",
      "episode 4 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.13064176460119414  steps 29  memory 18\n",
      "=========================episode 5 agree======================\n",
      "------guess 0 0 waive-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 adore-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 argue-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 agree-------\n",
      "reward 0 done True action 0\n",
      "episode 5 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.14785621103378865  steps 33  memory 23\n",
      "=========================episode 6 blown======================\n",
      "------guess 0 0 betel-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 noria-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 blond-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 blown-------\n",
      "reward 0 done True action 0\n",
      "episode 6 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.164729788588728  steps 37  memory 27\n",
      "=========================episode 7 strip======================\n",
      "------guess 0 0 borne-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 alist-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 strip-------\n",
      "reward 0 done True action 0\n",
      "episode 7 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.1771653419439816  steps 40  memory 31\n",
      "=========================episode 8 sheep======================\n",
      "------guess 0 0 otter-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 slain-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 duchy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 sheep-------\n",
      "reward 0 done True action 0\n",
      "episode 8 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.19345855982267313  steps 44  memory 34\n",
      "=========================episode 9 bushy======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 gummy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 linds-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 hussy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 pubco-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 wakfs-------\n",
      "reward -1 done True action 1\n",
      "episode 9 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.21729546175813186  steps 50  memory 38\n",
      "=========================episode 10 fetus======================\n",
      "------guess 0 0 vigor-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 flack-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 femme-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 nutsy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 fetus-------\n",
      "reward 0 done True action 0\n",
      "episode 10 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.23662050566314685  steps 55  memory 44\n",
      "=========================episode 11 humid======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 vivid-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 humid-------\n",
      "reward 0 done True action 0\n",
      "episode 11 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.25173643242143473  steps 59  memory 49\n",
      "=========================episode 12 vying======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 duchy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 vinyl-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 gimps-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 bawks-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 vying-------\n",
      "reward 0 done True action 0\n",
      "episode 12 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.27385096292630906  steps 65  memory 53\n",
      "=========================episode 13 bland======================\n",
      "------guess 0 0 gaily-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 roset-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dunch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 bland-------\n",
      "reward 0 done True action 0\n",
      "episode 13 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.28822967723739035  steps 69  memory 59\n",
      "=========================episode 14 gooey======================\n",
      "------guess 0 0 gloom-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 retia-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 goose-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 wakfs-------\n",
      "reward -1 done True action 1\n",
      "episode 14 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.3092656693626453  steps 75  memory 63\n",
      "=========================episode 15 epoxy======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 epoxy-------\n",
      "reward 0 done True action 0\n",
      "episode 15 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.3195493637954123  steps 78  memory 69\n",
      "=========================episode 16 heath======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 heath-------\n",
      "reward 0 done True action 0\n",
      "episode 16 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.3296799539643607  steps 81  memory 72\n",
      "optimize_model_batch -1 75\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[0.1260, 0.1596],\n",
      "        [0.1416, 0.2697],\n",
      "        [0.5420, 0.1236],\n",
      "        [0.4810, 0.6883],\n",
      "        [0.7790, 0.2974],\n",
      "        [0.5781, 0.2618]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.4916, 0.5084],\n",
      "        [0.4680, 0.5320],\n",
      "        [0.6031, 0.3969],\n",
      "        [0.4484, 0.5516],\n",
      "        [0.6181, 0.3819],\n",
      "        [0.5784, 0.4216]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 8, 'total': -29, 'avg': -3.625} {'count': 9, 'total': -39, 'avg': -4.333333333333333}\n",
      "{'count': 8, 'total': -30, 'avg': -3.75} {'count': 9, 'total': -21, 'avg': -2.3333333333333335}\n",
      "{'count': 12, 'total': -21, 'avg': -1.75} {'count': 5, 'total': -13, 'avg': -2.6}\n",
      "{'count': 8, 'total': -7, 'avg': -0.875} {'count': 6, 'total': -13, 'avg': -2.1666666666666665}\n",
      "{'count': 2, 'total': 0, 'avg': 0.0} {'count': 7, 'total': -11, 'avg': -1.5714285714285714}\n",
      "{'count': 4, 'total': -1, 'avg': -0.25} {'count': 3, 'total': -3, 'avg': -1.0}\n",
      "done 81 optimizations, 81 transitions added to memory\n",
      "=========================episode 17 skill======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 skill-------\n",
      "reward 0 done True action 0\n",
      "episode 17 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.33965971929501715  steps 84  memory 0\n",
      "=========================episode 18 otter======================\n",
      "------guess 0 0 allow-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tries-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 fungi-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 otter-------\n",
      "reward 0 done True action 0\n",
      "episode 18 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.35917572396768127  steps 90  memory 3\n",
      "=========================episode 19 glory======================\n",
      "------guess 0 0 shove-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 trail-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gimps-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 glory-------\n",
      "reward 0 done True action 0\n",
      "episode 19 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.3749977317172992  steps 95  memory 9\n",
      "=========================episode 20 broad======================\n",
      "------guess 0 0 demur-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lotas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 broad-------\n",
      "reward 0 done True action 0\n",
      "episode 20 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.38430280323571486  steps 98  memory 14\n",
      "=========================episode 21 stoop======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 stoop-------\n",
      "reward 0 done True action 0\n",
      "episode 21 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.39649442457295947  steps 102  memory 17\n",
      "=========================episode 22 egret======================\n",
      "------guess 0 0 dogma-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 binge-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 crust-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 egret-------\n",
      "reward 0 done True action 0\n",
      "episode 22 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.4084446356331849  steps 106  memory 21\n",
      "=========================episode 23 girly======================\n",
      "------guess 0 0 sadly-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 noter-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 humic-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gopik-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 bwazi-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 girly-------\n",
      "reward 0 done True action 0\n",
      "episode 23 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.42592773880356405  steps 112  memory 25\n",
      "=========================episode 24 scamp======================\n",
      "------guess 0 0 odder-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 alist-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 sumac-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 nymph-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 scamp-------\n",
      "reward 0 done True action 0\n",
      "episode 24 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.44010163343459796  steps 117  memory 31\n",
      "=========================episode 25 acrid======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gybed-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 acrid-------\n",
      "reward 0 done True action 0\n",
      "episode 25 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.4539255733602906  steps 122  memory 36\n",
      "=========================episode 26 undue======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 whine-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 sculp-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 venue-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 undue-------\n",
      "reward 0 done True action 0\n",
      "episode 26 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.4674081989931028  steps 127  memory 41\n",
      "=========================episode 27 stunk======================\n",
      "------guess 0 0 satyr-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 sheet-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sting-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 could-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 stunk-------\n",
      "reward 0 done True action 0\n",
      "episode 27 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.48055793741295183  steps 132  memory 46\n",
      "=========================episode 28 roomy======================\n",
      "------guess 0 0 delta-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 jiffy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bunny-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 smoky-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 roomy-------\n",
      "reward 0 done True action 0\n",
      "episode 28 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.49338300763441045  steps 137  memory 51\n",
      "=========================episode 29 dully======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 quill-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 synch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 imped-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 dully-------\n",
      "reward 0 done True action 0\n",
      "episode 29 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.5058914257438583  steps 142  memory 56\n",
      "=========================episode 30 whelp======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 begin-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 excel-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 pudsy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 whelp-------\n",
      "reward 0 done True action 0\n",
      "episode 30 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.5180910099097975  steps 147  memory 61\n",
      "=========================episode 31 stung======================\n",
      "------guess 0 0 gleam-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 icing-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wrung-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 toshy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 bipod-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 stung-------\n",
      "reward 0 done True action 0\n",
      "episode 31 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.5323335729900908  steps 153  memory 66\n",
      "=========================episode 32 fewer======================\n",
      "------guess 0 0 aunty-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 floor-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 fiber-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chads-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 fewer-------\n",
      "reward 0 done True action 0\n",
      "episode 32 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.5438802982143608  steps 158  memory 72\n",
      "optimize_model_batch -1 77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[0.0271, 0.2585],\n",
      "        [0.1702, 0.2411],\n",
      "        [0.6492, 0.0163],\n",
      "        [0.6226, 0.5466],\n",
      "        [0.8713, 0.2051],\n",
      "        [0.6044, 0.2355]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.4424, 0.5576],\n",
      "        [0.4823, 0.5177],\n",
      "        [0.6531, 0.3469],\n",
      "        [0.5190, 0.4810],\n",
      "        [0.6607, 0.3393],\n",
      "        [0.5912, 0.4088]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 18, 'total': -69, 'avg': -3.8333333333333335} {'count': 15, 'total': -60, 'avg': -4.0}\n",
      "{'count': 16, 'total': -54, 'avg': -3.375} {'count': 17, 'total': -42, 'avg': -2.4705882352941178}\n",
      "{'count': 20, 'total': -34, 'avg': -1.7} {'count': 13, 'total': -29, 'avg': -2.230769230769231}\n",
      "{'count': 12, 'total': -9, 'avg': -0.75} {'count': 16, 'total': -26, 'avg': -1.625}\n",
      "{'count': 11, 'total': 0, 'avg': 0.0} {'count': 10, 'total': -14, 'avg': -1.4}\n",
      "{'count': 7, 'total': -1, 'avg': -0.14285714285714285} {'count': 3, 'total': -3, 'avg': -1.0}\n",
      "done 158 optimizations, 158 transitions added to memory\n",
      "=========================episode 33 crisp======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 prism-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 duchy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 crisp-------\n",
      "reward 0 done True action 0\n",
      "episode 33 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.5551419337770589  steps 163  memory 0\n",
      "=========================episode 34 timer======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 timer-------\n",
      "reward 0 done True action 0\n",
      "episode 34 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.5617650075350508  steps 166  memory 5\n",
      "=========================episode 35 bowel======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 dowel-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 vowel-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 bowel-------\n",
      "reward 0 done True action 0\n",
      "episode 35 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.5747168089177259  steps 172  memory 8\n",
      "=========================episode 36 tripe======================\n",
      "------guess 0 0 taken-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 tribe-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 trice-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 lousy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 tripe-------\n",
      "reward 0 done True action 0\n",
      "episode 36 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.5852170883184187  steps 177  memory 14\n",
      "=========================episode 37 power======================\n",
      "------guess 0 0 ovate-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 gooey-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 cower-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 sower-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 rower-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 power-------\n",
      "reward 0 done True action 0\n",
      "episode 37 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.597475775966364  steps 183  memory 19\n",
      "=========================episode 38 groan======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 groan-------\n",
      "reward 0 done True action 0\n",
      "episode 38 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.605446289628399  steps 187  memory 25\n",
      "=========================episode 39 crawl======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 crawl-------\n",
      "reward 0 done True action 0\n",
      "episode 39 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.611320429098247  steps 190  memory 29\n",
      "=========================episode 40 urine======================\n",
      "------guess 0 0 quake-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 triol-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 synch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 urine-------\n",
      "reward 0 done True action 0\n",
      "episode 40 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.6190168002606627  steps 194  memory 32\n",
      "=========================episode 41 girth======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 dirty-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 shuln-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 compo-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 befog-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 wonks-------\n",
      "reward -1 done True action 1\n",
      "episode 41 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.6302765554559411  steps 200  memory 36\n",
      "=========================episode 42 plate======================\n",
      "------guess 0 0 child-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 bleat-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 pungs-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 plate-------\n",
      "reward 0 done True action 0\n",
      "episode 42 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.6394050598269216  steps 205  memory 42\n",
      "=========================episode 43 mecca======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bodge-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 mecca-------\n",
      "reward 0 done True action 0\n",
      "episode 43 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.6483081806219331  steps 210  memory 47\n",
      "=========================episode 44 adult======================\n",
      "------guess 0 0 lager-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 oints-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 adult-------\n",
      "reward 0 done True action 0\n",
      "episode 44 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.6535441896699425  steps 213  memory 52\n",
      "=========================episode 45 dally======================\n",
      "------guess 0 0 hippo-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 ratel-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dungs-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 dally-------\n",
      "reward 0 done True action 0\n",
      "episode 45 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.6604044743550609  steps 217  memory 55\n",
      "=========================episode 46 dully======================\n",
      "------guess 0 0 fully-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chins-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 dumps-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 dully-------\n",
      "reward 0 done True action 0\n",
      "episode 46 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.668789117758019  steps 222  memory 59\n",
      "=========================episode 47 rover======================\n",
      "------guess 0 0 cinch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 plums-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 boxer-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 rower-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 rover-------\n",
      "reward 0 done True action 0\n",
      "episode 47 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.6785778786656087  steps 228  memory 64\n",
      "=========================episode 48 dingy======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 ninny-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 begad-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 dingy-------\n",
      "reward 0 done True action 0\n",
      "episode 48 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.6880773379673533  steps 234  memory 70\n",
      "optimize_model_batch -1 76\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[-0.0232,  0.3088],\n",
      "        [ 0.2431,  0.1683],\n",
      "        [ 0.7571, -0.0916],\n",
      "        [ 0.7162,  0.4530],\n",
      "        [ 0.9117,  0.1648],\n",
      "        [ 0.6742,  0.1657]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.4177, 0.5823],\n",
      "        [0.5187, 0.4813],\n",
      "        [0.7003, 0.2997],\n",
      "        [0.5654, 0.4346],\n",
      "        [0.6785, 0.3215],\n",
      "        [0.6245, 0.3755]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 26, 'total': -99, 'avg': -3.8076923076923075} {'count': 23, 'total': -91, 'avg': -3.9565217391304346}\n",
      "{'count': 19, 'total': -66, 'avg': -3.473684210526316} {'count': 30, 'total': -75, 'avg': -2.5}\n",
      "{'count': 28, 'total': -46, 'avg': -1.6428571428571428} {'count': 21, 'total': -46, 'avg': -2.1904761904761907}\n",
      "{'count': 18, 'total': -15, 'avg': -0.8333333333333334} {'count': 23, 'total': -36, 'avg': -1.565217391304348}\n",
      "{'count': 19, 'total': -3, 'avg': -0.15789473684210525} {'count': 12, 'total': -17, 'avg': -1.4166666666666667}\n",
      "{'count': 11, 'total': -1, 'avg': -0.09090909090909091} {'count': 4, 'total': -4, 'avg': -1.0}\n",
      "done 234 optimizations, 234 transitions added to memory\n",
      "=========================episode 49 avail======================\n",
      "------guess 0 0 heron-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 alist-------\n",
      "reward -1 done False action 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 2 1 ducky-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 avail-------\n",
      "reward 0 done True action 0\n",
      "episode 49 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.6942538205012883  steps 238  memory 0\n",
      "=========================episode 50 fishy======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 pupil-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 icing-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 whiff-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 fishy-------\n",
      "reward 0 done True action 0\n",
      "episode 50 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.7018027205701126  steps 243  memory 4\n",
      "=========================episode 51 fried======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 drier-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 fried-------\n",
      "reward 0 done True action 0\n",
      "episode 51 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7062422996764672  steps 246  memory 9\n",
      "=========================episode 52 ferry======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 derby-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 jerky-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 ferry-------\n",
      "reward 0 done True action 0\n",
      "episode 52 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.7149241517755465  steps 252  memory 12\n",
      "=========================episode 53 apron======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 apron-------\n",
      "reward 0 done True action 0\n",
      "episode 53 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7205690317785927  steps 256  memory 18\n",
      "=========================episode 54 rouse======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 rogue-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 rouse-------\n",
      "reward 0 done True action 0\n",
      "episode 54 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7247292169102477  steps 259  memory 22\n",
      "=========================episode 55 drunk======================\n",
      "------guess 0 0 myrrh-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toeas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 krill-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 drunk-------\n",
      "reward 0 done True action 0\n",
      "episode 55 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7301799436153131  steps 263  memory 25\n",
      "=========================episode 56 cross======================\n",
      "------guess 0 0 creme-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 altos-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 unhip-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 cross-------\n",
      "reward 0 done True action 0\n",
      "episode 56 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.735522738700176  steps 267  memory 29\n",
      "=========================episode 57 frill======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 syrup-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 brink-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 frill-------\n",
      "reward 0 done True action 0\n",
      "episode 57 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7407597393541085  steps 271  memory 33\n",
      "=========================episode 58 spelt======================\n",
      "------guess 0 0 china-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 estro-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 duply-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gambo-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 wakfs-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 spelt-------\n",
      "reward 0 done True action 0\n",
      "episode 58 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.7484214469402435  steps 277  memory 37\n",
      "=========================episode 59 loyal======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 loyal-------\n",
      "reward 0 done True action 0\n",
      "episode 59 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7534030360583935  steps 281  memory 43\n",
      "=========================episode 60 sumac======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 swash-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 pudic-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 sumac-------\n",
      "reward 0 done True action 0\n",
      "episode 60 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.7594915367916579  steps 286  memory 47\n",
      "=========================episode 61 apron======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 baron-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 fudgy-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 apron-------\n",
      "reward 0 done True action 0\n",
      "episode 61 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.7665996360988487  steps 292  memory 52\n",
      "=========================episode 62 adorn======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 adorn-------\n",
      "reward 0 done True action 0\n",
      "episode 62 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.7689220085226698  steps 294  memory 58\n",
      "=========================episode 63 fatal======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 fatal-------\n",
      "reward 0 done True action 0\n",
      "episode 63 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7723623116161873  steps 297  memory 60\n",
      "=========================episode 64 gusto======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 budge-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 gusto-------\n",
      "reward 0 done True action 0\n",
      "episode 64 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.7779827061680505  steps 302  memory 63\n",
      "optimize_model_batch -1 68\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.0403,  0.2453],\n",
      "        [ 0.4287, -0.0173],\n",
      "        [ 0.8073, -0.1418],\n",
      "        [ 0.8459,  0.3234],\n",
      "        [ 0.9785,  0.0980],\n",
      "        [ 0.6762,  0.1638]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.4489, 0.5511],\n",
      "        [0.6097, 0.3903],\n",
      "        [0.7209, 0.2791],\n",
      "        [0.6277, 0.3723],\n",
      "        [0.7069, 0.2931],\n",
      "        [0.6254, 0.3746]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 30, 'total': -113, 'avg': -3.7666666666666666} {'count': 35, 'total': -129, 'avg': -3.6857142857142855}\n",
      "{'count': 24, 'total': -73, 'avg': -3.0416666666666665} {'count': 41, 'total': -104, 'avg': -2.5365853658536586}\n",
      "{'count': 37, 'total': -58, 'avg': -1.5675675675675675} {'count': 27, 'total': -55, 'avg': -2.037037037037037}\n",
      "{'count': 25, 'total': -16, 'avg': -0.64} {'count': 28, 'total': -44, 'avg': -1.5714285714285714}\n",
      "{'count': 23, 'total': -4, 'avg': -0.17391304347826086} {'count': 14, 'total': -19, 'avg': -1.3571428571428572}\n",
      "{'count': 14, 'total': -1, 'avg': -0.07142857142857142} {'count': 4, 'total': -4, 'avg': -1.0}\n",
      "done 302 optimizations, 302 transitions added to memory\n",
      "=========================episode 65 ovate======================\n",
      "------guess 0 0 singe-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 horde-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 evoke-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 ovate-------\n",
      "reward 0 done True action 0\n",
      "episode 65 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7823789431347671  steps 306  memory 0\n",
      "=========================episode 66 ocean======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 omega-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 ocean-------\n",
      "reward 0 done True action 0\n",
      "episode 66 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.785618898573022  steps 309  memory 4\n",
      "=========================episode 67 minty======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 filth-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 dungs-------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1 done False action 1\n",
      "------guess 3 0 minty-------\n",
      "reward 0 done True action 0\n",
      "episode 67 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.7898639287992353  steps 313  memory 7\n",
      "=========================episode 68 sugar======================\n",
      "------guess 0 0 gruff-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 stoae-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 sugar-------\n",
      "reward 0 done True action 0\n",
      "episode 68 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7929924473188473  steps 316  memory 11\n",
      "=========================episode 69 tacky======================\n",
      "------guess 0 0 atoll-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 risen-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 tacky-------\n",
      "reward 0 done True action 0\n",
      "episode 69 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7960743882657866  steps 319  memory 14\n",
      "=========================episode 70 flown======================\n",
      "------guess 0 0 smear-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lotic-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 flown-------\n",
      "reward 0 done True action 0\n",
      "episode 70 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.7991104450897679  steps 322  memory 17\n",
      "=========================episode 71 noise======================\n",
      "------guess 0 0 semen-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tolar-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 noose-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 pudic-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 vughy-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 bawks-------\n",
      "reward -1 done True action 1\n",
      "episode 71 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.8050476287008175  steps 328  memory 20\n",
      "=========================episode 72 olive======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 opine-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 olive-------\n",
      "reward 0 done True action 0\n",
      "episode 72 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8079500913792459  steps 331  memory 26\n",
      "=========================episode 73 geese======================\n",
      "------guess 0 0 using-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 ghost-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 clear-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 dampy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 bawks-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 geese-------\n",
      "reward 0 done True action 0\n",
      "episode 73 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.81362602396059  steps 337  memory 29\n",
      "=========================episode 74 slash======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 chaff-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 gnash-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 pilum-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 slash-------\n",
      "reward 0 done True action 0\n",
      "episode 74 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8182276138246325  steps 342  memory 35\n",
      "=========================episode 75 hutch======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 witch-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 dutch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 sonly-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 butch-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 hutch-------\n",
      "reward 0 done True action 0\n",
      "episode 75 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.82359979971366  steps 348  memory 40\n",
      "=========================episode 76 relax======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 regal-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 relax-------\n",
      "reward 0 done True action 0\n",
      "episode 76 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8279551361769495  steps 353  memory 46\n",
      "=========================episode 77 aging======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 sauna-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 china-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 aping-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 aging-------\n",
      "reward 0 done True action 0\n",
      "episode 77 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8322029389998141  steps 358  memory 51\n",
      "=========================episode 78 bevel======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 bleep-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bevel-------\n",
      "reward 0 done True action 0\n",
      "episode 78 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8355255434228451  steps 362  memory 56\n",
      "=========================episode 79 crump======================\n",
      "------guess 0 0 skunk-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 druid-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 gruff-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 crump-------\n",
      "reward 0 done True action 0\n",
      "episode 79 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8395864322248272  steps 367  memory 60\n",
      "=========================episode 80 holly======================\n",
      "------guess 0 0 winch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 alpha-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 hotly-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 holly-------\n",
      "reward 0 done True action 0\n",
      "episode 80 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8427628336863724  steps 371  memory 65\n",
      "optimize_model_batch -1 69\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.0428,  0.2429],\n",
      "        [ 0.4806, -0.0692],\n",
      "        [ 0.8387, -0.1732],\n",
      "        [ 1.0171,  0.1522],\n",
      "        [ 1.0882, -0.0118],\n",
      "        [ 0.7612,  0.0787]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.4501, 0.5499],\n",
      "        [0.6341, 0.3659],\n",
      "        [0.7334, 0.2666],\n",
      "        [0.7037, 0.2963],\n",
      "        [0.7503, 0.2497],\n",
      "        [0.6643, 0.3357]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 38, 'total': -140, 'avg': -3.6842105263157894} {'count': 43, 'total': -156, 'avg': -3.627906976744186}\n",
      "{'count': 33, 'total': -95, 'avg': -2.878787878787879} {'count': 48, 'total': -120, 'avg': -2.5}\n",
      "{'count': 50, 'total': -74, 'avg': -1.48} {'count': 30, 'total': -61, 'avg': -2.033333333333333}\n",
      "{'count': 32, 'total': -19, 'avg': -0.59375} {'count': 32, 'total': -52, 'avg': -1.625}\n",
      "{'count': 28, 'total': -5, 'avg': -0.17857142857142858} {'count': 16, 'total': -22, 'avg': -1.375}\n",
      "{'count': 16, 'total': -1, 'avg': -0.0625} {'count': 5, 'total': -5, 'avg': -1.0}\n",
      "done 371 optimizations, 371 transitions added to memory\n",
      "=========================episode 81 began======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 label-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 incus-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 began-------\n",
      "reward 0 done True action 0\n",
      "episode 81 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8458763381848686  steps 375  memory 0\n",
      "=========================episode 82 shrug======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 incur-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shrug-------\n",
      "reward 0 done True action 0\n",
      "episode 82 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8481709405705694  steps 378  memory 4\n",
      "=========================episode 83 slide======================\n",
      "------guess 0 0 llama-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 slide-------\n",
      "reward 0 done True action 0\n",
      "episode 83 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.8496816649535996  steps 380  memory 7\n",
      "=========================episode 84 trend======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 erupt-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 trend-------\n",
      "reward 0 done True action 0\n",
      "episode 84 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8519196134045375  steps 383  memory 9\n",
      "=========================episode 85 civil======================\n",
      "------guess 0 0 sappy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 bigot-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 filer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 dunch-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 mawks-------\n",
      "reward -1 done False action 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 5 1 vozhd-------\n",
      "reward -1 done True action 1\n",
      "episode 85 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.856296050222297  steps 389  memory 12\n",
      "=========================episode 86 tempo======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 depot-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 tempo-------\n",
      "reward 0 done True action 0\n",
      "episode 86 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8591415790789549  steps 393  memory 18\n",
      "=========================episode 87 focal======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 zonal-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 scudi-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 lymph-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 befog-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 focal-------\n",
      "reward 0 done True action 0\n",
      "episode 87 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.8633045745544762  steps 399  memory 22\n",
      "=========================episode 88 gaffe======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 masse-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 gaffe-------\n",
      "reward 0 done True action 0\n",
      "episode 88 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8653397043044941  steps 402  memory 28\n",
      "=========================episode 89 lyric======================\n",
      "------guess 0 0 drift-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 minor-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lyric-------\n",
      "reward 0 done True action 0\n",
      "episode 89 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8673445349198783  steps 405  memory 31\n",
      "=========================episode 90 riper======================\n",
      "------guess 0 0 donut-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 shark-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 flyer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chimp-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 riper-------\n",
      "reward 0 done True action 0\n",
      "episode 90 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8706198100226289  steps 410  memory 34\n",
      "=========================episode 91 coast======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 coast-------\n",
      "reward 0 done True action 0\n",
      "episode 91 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8725460301051793  steps 413  memory 39\n",
      "=========================episode 92 flask======================\n",
      "------guess 0 0 shady-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 oiler-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cunit-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 psalm-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 flask-------\n",
      "reward 0 done True action 0\n",
      "episode 92 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8756928798342206  steps 418  memory 42\n",
      "=========================episode 93 gloss======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 spool-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 dutch-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 embog-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 gloss-------\n",
      "reward 0 done True action 0\n",
      "episode 93 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.8793667104468418  steps 424  memory 47\n",
      "=========================episode 94 strip======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 strip-------\n",
      "reward 0 done True action 0\n",
      "episode 94 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8817554096233645  steps 428  memory 53\n",
      "=========================episode 95 gravy======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 brass-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 drain-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 wrack-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 graph-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 gravy-------\n",
      "reward 0 done True action 0\n",
      "episode 95 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.8852500654027212  steps 434  memory 57\n",
      "=========================episode 96 dumpy======================\n",
      "------guess 0 0 crack-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 spelt-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 phony-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 guppy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 dumpy-------\n",
      "reward 0 done True action 0\n",
      "episode 96 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.8880832513826711  steps 439  memory 63\n",
      "optimize_model_batch -1 68\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.0667,  0.2189],\n",
      "        [ 0.4337, -0.0224],\n",
      "        [ 0.8861, -0.2206],\n",
      "        [ 1.1639,  0.0054],\n",
      "        [ 1.2299, -0.1535],\n",
      "        [ 0.8499, -0.0100]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.4620, 0.5380],\n",
      "        [0.6121, 0.3879],\n",
      "        [0.7515, 0.2485],\n",
      "        [0.7610, 0.2390],\n",
      "        [0.7995, 0.2005],\n",
      "        [0.7026, 0.2974]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 44, 'total': -161, 'avg': -3.659090909090909} {'count': 53, 'total': -188, 'avg': -3.547169811320755}\n",
      "{'count': 45, 'total': -122, 'avg': -2.7111111111111112} {'count': 52, 'total': -130, 'avg': -2.5}\n",
      "{'count': 60, 'total': -88, 'avg': -1.4666666666666666} {'count': 35, 'total': -69, 'avg': -1.9714285714285715}\n",
      "{'count': 38, 'total': -23, 'avg': -0.6052631578947368} {'count': 36, 'total': -60, 'avg': -1.6666666666666667}\n",
      "{'count': 32, 'total': -6, 'avg': -0.1875} {'count': 19, 'total': -26, 'avg': -1.368421052631579}\n",
      "{'count': 19, 'total': -1, 'avg': -0.05263157894736842} {'count': 6, 'total': -6, 'avg': -1.0}\n",
      "done 439 optimizations, 439 transitions added to memory\n",
      "=========================episode 97 corer======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 goner-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 power-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 loser-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 rover-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 corer-------\n",
      "reward 0 done True action 0\n",
      "episode 97 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.891390891175042  steps 445  memory 0\n",
      "=========================episode 98 extol======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 extol-------\n",
      "reward 0 done True action 0\n",
      "episode 98 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.8930078701468855  steps 448  memory 6\n",
      "=========================episode 99 revel======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 grief-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 renew-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 rebel-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 repel-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 revel-------\n",
      "reward 0 done True action 0\n",
      "episode 99 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.896169965459203  steps 454  memory 9\n",
      "=========================episode 100 these======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 suite-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lynch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 these-------\n",
      "reward 0 done True action 0\n",
      "episode 100 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.8982259378937163  steps 458  memory 15\n",
      "=========================episode 101 teary======================\n",
      "------guess 0 0 wrong-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 telia-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cushy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 teary-------\n",
      "reward 0 done True action 0\n",
      "episode 101 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9002411993463814  steps 462  memory 19\n",
      "=========================episode 102 below======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 0 mouse-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 gecko-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 lindy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 below-------\n",
      "reward 0 done True action 0\n",
      "episode 102 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9031895174735398  steps 468  memory 23\n",
      "=========================episode 103 peril======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 hyper-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 linds-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 peril-------\n",
      "reward 0 done True action 0\n",
      "episode 103 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9051064934653769  steps 472  memory 29\n",
      "=========================episode 104 trail======================\n",
      "------guess 0 0 shine-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tolar-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 trail-------\n",
      "reward 0 done True action 0\n",
      "episode 104 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9065192737219415  steps 475  memory 33\n",
      "=========================episode 105 river======================\n",
      "------guess 0 0 trend-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 parse-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 oculi-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 fiber-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 giver-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 river-------\n",
      "reward 0 done True action 0\n",
      "episode 105 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9092820467105875  steps 481  memory 36\n",
      "=========================episode 106 llama======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 champ-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 swami-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 llama-------\n",
      "reward 0 done True action 0\n",
      "episode 106 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9110783825406137  steps 485  memory 42\n",
      "=========================episode 107 trade======================\n",
      "------guess 0 0 local-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 awake-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 grape-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 trade-------\n",
      "reward 0 done True action 0\n",
      "episode 107 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9128391485380187  steps 489  memory 46\n",
      "=========================episode 108 froth======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 forth-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 froth-------\n",
      "reward 0 done True action 0\n",
      "episode 108 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9149911576283004  steps 494  memory 50\n",
      "=========================episode 109 lilac======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 villa-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lilac-------\n",
      "reward 0 done True action 0\n",
      "episode 109 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9162567744078041  steps 497  memory 55\n",
      "=========================episode 110 roger======================\n",
      "------guess 0 0 onset-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 homer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wooer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 lover-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 joker-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 boxer-------\n",
      "reward -1 done True action 0\n",
      "episode 110 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9187317607591083  steps 503  memory 58\n",
      "=========================episode 111 rebar======================\n",
      "------guess 0 0 whirl-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toeas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gumps-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 rebar-------\n",
      "reward 0 done True action 0\n",
      "episode 111 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9207382807352684  steps 508  memory 64\n",
      "=========================episode 112 catch======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 adult-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 chins-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 catch-------\n",
      "reward 0 done True action 0\n",
      "episode 112 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9223077679326976  steps 512  memory 69\n",
      "optimize_model_batch -1 73\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.1287,  0.1569],\n",
      "        [ 0.3165,  0.0949],\n",
      "        [ 0.9474, -0.2819],\n",
      "        [ 1.1491,  0.0202],\n",
      "        [ 1.2282, -0.1518],\n",
      "        [ 0.8213,  0.0187]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.4929, 0.5071],\n",
      "        [0.5552, 0.4448],\n",
      "        [0.7737, 0.2263],\n",
      "        [0.7556, 0.2444],\n",
      "        [0.7990, 0.2010],\n",
      "        [0.6905, 0.3095]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 50, 'total': -184, 'avg': -3.68} {'count': 63, 'total': -223, 'avg': -3.5396825396825395}\n",
      "{'count': 56, 'total': -154, 'avg': -2.75} {'count': 57, 'total': -140, 'avg': -2.456140350877193}\n",
      "{'count': 69, 'total': -103, 'avg': -1.4927536231884058} {'count': 42, 'total': -80, 'avg': -1.9047619047619047}\n",
      "{'count': 49, 'total': -33, 'avg': -0.673469387755102} {'count': 38, 'total': -63, 'avg': -1.6578947368421053}\n",
      "{'count': 38, 'total': -11, 'avg': -0.2894736842105263} {'count': 20, 'total': -27, 'avg': -1.35}\n",
      "{'count': 24, 'total': -2, 'avg': -0.08333333333333333} {'count': 6, 'total': -6, 'avg': -1.0}\n",
      "done 512 optimizations, 512 transitions added to memory\n",
      "=========================episode 113 ovoid======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 swoop-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 ovoid-------\n",
      "reward 0 done True action 0\n",
      "episode 113 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9234644545760885  steps 515  memory 0\n",
      "=========================episode 114 elect======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 fetus-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 linch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 elect-------\n",
      "reward 0 done True action 0\n",
      "episode 114 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9249799599146731  steps 519  memory 3\n",
      "=========================episode 115 lowly======================\n",
      "------guess 0 0 leash-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 limit-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 cornu-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 lowly-------\n",
      "reward 0 done True action 0\n",
      "episode 115 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9264654562369429  steps 523  memory 7\n",
      "=========================episode 116 verse======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 surge-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chimp-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 bifid-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 1 kawed-------\n",
      "reward -1 done True action 1\n",
      "episode 116 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9286387304436139  steps 529  memory 11\n",
      "=========================episode 117 grape======================\n",
      "------guess 0 0 paint-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 soler-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 grape-------\n",
      "reward 0 done True action 0\n",
      "episode 117 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9297011613347715  steps 532  memory 17\n",
      "=========================episode 118 maybe======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 ladle-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 incus-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 payee-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 maybe-------\n",
      "reward 0 done True action 0\n",
      "episode 118 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9314368458457221  steps 537  memory 20\n",
      "=========================episode 119 mural======================\n",
      "------guess 0 0 youth-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 1 raile-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 scand-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 mural-------\n",
      "reward 0 done True action 0\n",
      "episode 119 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9327944872602503  steps 541  memory 25\n",
      "=========================episode 120 until======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 unlit-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 until-------\n",
      "reward 0 done True action 0\n",
      "episode 120 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9341252455735971  steps 545  memory 29\n",
      "=========================episode 121 waxen======================\n",
      "------guess 0 0 wispy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 wafer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 clout-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 bundh-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 waxen-------\n",
      "reward 0 done True action 0\n",
      "episode 121 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9357516990554969  steps 550  memory 33\n",
      "=========================episode 122 other======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 outer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 other-------\n",
      "reward 0 done True action 0\n",
      "episode 122 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9370239006519849  steps 554  memory 38\n",
      "=========================episode 123 birth======================\n",
      "------guess 0 0 again-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 drill-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 mirth-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 birth-------\n",
      "reward 0 done True action 0\n",
      "episode 123 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9382709109690412  steps 558  memory 42\n",
      "=========================episode 124 rayon======================\n",
      "------guess 0 0 medal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 roist-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 rayon-------\n",
      "reward 0 done True action 0\n",
      "episode 124 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9391899373747821  steps 561  memory 46\n",
      "=========================episode 125 inept======================\n",
      "------guess 0 0 usher-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tolan-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 inept-------\n",
      "reward 0 done True action 0\n",
      "episode 125 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9400952812598878  steps 564  memory 49\n",
      "=========================episode 126 inter======================\n",
      "------guess 0 0 pesky-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tolar-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 ether-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 cumin-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 inter-------\n",
      "reward 0 done True action 0\n",
      "episode 126 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9415743340354992  steps 569  memory 52\n",
      "=========================episode 127 shire======================\n",
      "------guess 0 0 pulpy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 snore-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 share-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 shire-------\n",
      "reward 0 done True action 0\n",
      "episode 127 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9427312397345327  steps 573  memory 57\n",
      "=========================episode 128 ovary======================\n",
      "------guess 0 0 logic-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 broom-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 tarot-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 ovary-------\n",
      "reward 0 done True action 0\n",
      "episode 128 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9438652371658662  steps 577  memory 61\n",
      "optimize_model_batch -1 65\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.1127,  0.1729],\n",
      "        [ 0.3437,  0.0676],\n",
      "        [ 1.0553, -0.3898],\n",
      "        [ 1.2564, -0.0871],\n",
      "        [ 1.3034, -0.2270],\n",
      "        [ 0.9000, -0.0601]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.4849, 0.5151],\n",
      "        [0.5686, 0.4314],\n",
      "        [0.8093, 0.1907],\n",
      "        [0.7931, 0.2069],\n",
      "        [0.8221, 0.1779],\n",
      "        [0.7232, 0.2768]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 60, 'total': -213, 'avg': -3.55} {'count': 69, 'total': -244, 'avg': -3.536231884057971}\n",
      "{'count': 64, 'total': -171, 'avg': -2.671875} {'count': 65, 'total': -157, 'avg': -2.4153846153846152}\n",
      "{'count': 80, 'total': -114, 'avg': -1.425} {'count': 47, 'total': -87, 'avg': -1.851063829787234}\n",
      "{'count': 58, 'total': -34, 'avg': -0.5862068965517241} {'count': 41, 'total': -68, 'avg': -1.6585365853658536}\n",
      "{'count': 41, 'total': -11, 'avg': -0.2682926829268293} {'count': 21, 'total': -29, 'avg': -1.380952380952381}\n",
      "{'count': 24, 'total': -2, 'avg': -0.08333333333333333} {'count': 7, 'total': -7, 'avg': -1.0}\n",
      "done 577 optimizations, 577 transitions added to memory\n",
      "=========================episode 129 treat======================\n",
      "------guess 0 0 olive-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 zesty-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 exert-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 treat-------\n",
      "reward 0 done True action 0\n",
      "episode 129 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9449767799435927  steps 581  memory 0\n",
      "=========================episode 130 brawn======================\n",
      "------guess 0 0 shrub-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 brace-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 braid-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 ymolt-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 brawn-------\n",
      "reward 0 done True action 0\n",
      "episode 130 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9463353080872698  steps 586  memory 4\n",
      "=========================episode 131 alloy======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 annoy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 alloy-------\n",
      "reward 0 done True action 0\n",
      "episode 131 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9471342712616496  steps 589  memory 9\n",
      "=========================episode 132 baron======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 apron-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 baron-------\n",
      "reward 0 done True action 0\n",
      "episode 132 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9481810828272742  steps 593  memory 12\n",
      "=========================episode 133 shave======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 shave-------\n",
      "reward 0 done True action 0\n",
      "episode 133 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9489525659958457  steps 596  memory 16\n",
      "=========================episode 134 swept======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 these-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 swept-------\n",
      "reward 0 done True action 0\n",
      "episode 134 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9499633729134137  steps 600  memory 19\n",
      "=========================episode 135 alarm======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 grand-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 quark-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 clips-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 alarm-------\n",
      "reward 0 done True action 0\n",
      "episode 135 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.951198781637987  steps 605  memory 23\n",
      "=========================episode 136 decal======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 decay-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 decal-------\n",
      "reward 0 done True action 0\n",
      "episode 136 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9519253371244049  steps 608  memory 28\n",
      "=========================episode 137 chaos======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 2 0 chaos-------\n",
      "reward 0 done True action 0\n",
      "episode 137 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.952641075608859  steps 611  memory 31\n",
      "=========================episode 138 brute======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 exert-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 brute-------\n",
      "reward 0 done True action 0\n",
      "episode 138 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9535788451425687  steps 615  memory 34\n",
      "=========================episode 139 suite======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 elect-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 nidus-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 suite-------\n",
      "reward 0 done True action 0\n",
      "episode 139 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9544980455953784  steps 619  memory 38\n",
      "=========================episode 140 funky======================\n",
      "------guess 0 0 coven-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 trail-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 spunk-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 hedgy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 bumfs-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 funky-------\n",
      "reward 0 done True action 0\n",
      "episode 140 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9558428315803071  steps 625  memory 42\n",
      "=========================episode 141 terra======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 tread-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 tamer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 terra-------\n",
      "reward 0 done True action 0\n",
      "episode 141 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9567172020980341  steps 629  memory 48\n",
      "=========================episode 142 patio======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 topaz-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 dutch-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 patio-------\n",
      "reward 0 done True action 0\n",
      "episode 142 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9577858581858936  steps 634  memory 52\n",
      "=========================episode 143 hippo======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 gloom-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bison-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 hippo-------\n",
      "reward 0 done True action 0\n",
      "episode 143 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9586217541990296  steps 638  memory 57\n",
      "=========================episode 144 buyer======================\n",
      "------guess 0 0 grunt-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 lemur-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 adios-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 queer-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 purer-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 choky-------\n",
      "reward -1 done True action 1\n",
      "episode 144 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.959844666176376  steps 644  memory 61\n",
      "optimize_model_batch -1 67\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.1739,  0.1117],\n",
      "        [ 0.3081,  0.1032],\n",
      "        [ 1.0629, -0.3973],\n",
      "        [ 1.3797, -0.2104],\n",
      "        [ 1.3414, -0.2649],\n",
      "        [ 0.9106, -0.0707]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.5156, 0.4844],\n",
      "        [0.5511, 0.4489],\n",
      "        [0.8116, 0.1884],\n",
      "        [0.8306, 0.1694],\n",
      "        [0.8329, 0.1671],\n",
      "        [0.7274, 0.2726]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 64, 'total': -231, 'avg': -3.609375} {'count': 81, 'total': -278, 'avg': -3.432098765432099}\n",
      "{'count': 74, 'total': -195, 'avg': -2.635135135135135} {'count': 71, 'total': -169, 'avg': -2.380281690140845}\n",
      "{'count': 93, 'total': -127, 'avg': -1.3655913978494623} {'count': 50, 'total': -94, 'avg': -1.88}\n",
      "{'count': 66, 'total': -37, 'avg': -0.5606060606060606} {'count': 45, 'total': -73, 'avg': -1.6222222222222222}\n",
      "{'count': 45, 'total': -13, 'avg': -0.28888888888888886} {'count': 22, 'total': -30, 'avg': -1.3636363636363635}\n",
      "{'count': 25, 'total': -2, 'avg': -0.08} {'count': 8, 'total': -8, 'avg': -1.0}\n",
      "done 644 optimizations, 644 transitions added to memory\n",
      "=========================episode 145 prank======================\n",
      "------guess 0 0 laugh-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 resto-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 briar-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 crazy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 drawn-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 frank-------\n",
      "reward -1 done True action 0\n",
      "episode 145 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9610314356427148  steps 650  memory 0\n",
      "=========================episode 146 exert======================\n",
      "------guess 0 0 would-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 retia-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 steer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 nymph-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 erect-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 exert-------\n",
      "reward 0 done True action 0\n",
      "episode 146 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.962183130770675  steps 656  memory 6\n",
      "=========================episode 147 acorn======================\n",
      "------guess 0 0 shard-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 agora-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 abort-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 acorn-------\n",
      "reward 0 done True action 0\n",
      "episode 147 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9629319549528005  steps 660  memory 12\n",
      "=========================episode 148 bobby======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 poppy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 moody-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 hobby-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 gucks-------\n",
      "reward -1 done True action 1\n",
      "episode 148 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9640274812465703  steps 666  memory 16\n",
      "=========================episode 149 mammy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 cabby-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 paddy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 humfs-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 mammy-------\n",
      "reward 0 done True action 0\n",
      "episode 149 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9650906298452442  steps 672  memory 22\n",
      "=========================episode 150 quail======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 flail-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 quail-------\n",
      "reward 0 done True action 0\n",
      "episode 150 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9659525452654006  steps 677  memory 28\n",
      "=========================episode 151 vapid======================\n",
      "------guess 0 0 haven-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 salvo-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 dirty-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 crump-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 vapid-------\n",
      "reward 0 done True action 0\n",
      "episode 151 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9667931799180093  steps 682  memory 33\n",
      "=========================episode 152 exert======================\n",
      "------guess 0 0 quiet-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 adept-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wrest-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 overt-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 exert-------\n",
      "reward 0 done True action 0\n",
      "episode 152 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.967613059227093  steps 687  memory 38\n",
      "=========================episode 153 white======================\n",
      "------guess 0 0 spank-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 fuzzy-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 2 0 troll-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 eject-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 humid-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 white-------\n",
      "reward 0 done True action 0\n",
      "episode 153 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9685702379816323  steps 693  memory 43\n",
      "=========================episode 154 harsh======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 viral-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 karma-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 synch-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 harsh-------\n",
      "reward 0 done True action 0\n",
      "episode 154 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9693462415707943  steps 698  memory 49\n",
      "=========================episode 155 barge======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 barge-------\n",
      "reward 0 done True action 0\n",
      "episode 155 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9698026165776815  steps 701  memory 54\n",
      "=========================episode 156 wrote======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 wrote-------\n",
      "reward 0 done True action 0\n",
      "episode 156 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.970400564832108  steps 705  memory 57\n",
      "=========================episode 157 leave======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 leave-------\n",
      "reward 0 done True action 0\n",
      "episode 157 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9708412430106028  steps 708  memory 61\n",
      "=========================episode 158 assay======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 handy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 assay-------\n",
      "reward 0 done True action 0\n",
      "episode 158 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9712753603457606  steps 711  memory 64\n",
      "=========================episode 159 shush======================\n",
      "------guess 0 0 spill-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 shush-------\n",
      "reward 0 done True action 0\n",
      "episode 159 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9717030145158132  steps 714  memory 67\n",
      "=========================episode 160 alter======================\n",
      "------guess 0 0 spoil-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 antre-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 alter-------\n",
      "reward 0 done True action 0\n",
      "episode 160 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.972124301744753  steps 717  memory 70\n",
      "optimize_model_batch -1 73\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.1535,  0.1322],\n",
      "        [ 0.4005,  0.0109],\n",
      "        [ 1.0680, -0.4025],\n",
      "        [ 1.4542, -0.2849],\n",
      "        [ 1.3725, -0.2960],\n",
      "        [ 1.0598, -0.2199]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.5053, 0.4947],\n",
      "        [0.5962, 0.4038],\n",
      "        [0.8131, 0.1869],\n",
      "        [0.8506, 0.1494],\n",
      "        [0.8414, 0.1586],\n",
      "        [0.7824, 0.2176]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 72, 'total': -262, 'avg': -3.638888888888889} {'count': 89, 'total': -306, 'avg': -3.438202247191011}\n",
      "{'count': 80, 'total': -211, 'avg': -2.6375} {'count': 81, 'total': -196, 'avg': -2.419753086419753}\n",
      "{'count': 107, 'total': -151, 'avg': -1.411214953271028} {'count': 52, 'total': -97, 'avg': -1.8653846153846154}\n",
      "{'count': 73, 'total': -48, 'avg': -0.6575342465753424} {'count': 49, 'total': -78, 'avg': -1.5918367346938775}\n",
      "{'count': 52, 'total': -18, 'avg': -0.34615384615384615} {'count': 24, 'total': -32, 'avg': -1.3333333333333333}\n",
      "{'count': 29, 'total': -3, 'avg': -0.10344827586206896} {'count': 9, 'total': -9, 'avg': -1.0}\n",
      "done 717 optimizations, 717 transitions added to memory\n",
      "=========================episode 161 often======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 tempo-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 extol-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 often-------\n",
      "reward 0 done True action 0\n",
      "episode 161 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9726762775527075  steps 721  memory 0\n",
      "=========================episode 162 foray======================\n",
      "------guess 0 0 young-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 coyly-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 poesy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 worry-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 foray-------\n",
      "reward 0 done True action 0\n",
      "episode 162 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9733509026636445  steps 726  memory 4\n",
      "=========================episode 163 refer======================\n",
      "------guess 0 0 spoon-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 fluff-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 dwarf-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 refit-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 refer-------\n",
      "reward 0 done True action 0\n",
      "episode 163 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9740088712212447  steps 731  memory 9\n",
      "=========================episode 164 dully======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 unzip-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 hwyls-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 gully-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 fully-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 dully-------\n",
      "reward 0 done True action 0\n",
      "episode 164 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9747770251647728  steps 737  memory 14\n",
      "=========================episode 165 munch======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 hunch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 punch-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 dogma-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 munch-------\n",
      "reward 0 done True action 0\n",
      "episode 165 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9755224767283474  steps 743  memory 20\n",
      "=========================episode 166 maxim======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 paddy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 basic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 maxim-------\n",
      "reward 0 done True action 0\n",
      "episode 166 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9760071641632908  steps 747  memory 26\n",
      "=========================episode 167 flame======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 spade-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 image-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 blame-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 chunk-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 flame-------\n",
      "reward 0 done True action 0\n",
      "episode 167 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.976716259625103  steps 753  memory 30\n",
      "=========================episode 168 welch======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 unfed-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 welsh-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 welch-------\n",
      "reward 0 done True action 0\n",
      "episode 168 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.977177308574907  steps 757  memory 36\n",
      "=========================episode 169 octal======================\n",
      "------guess 0 0 vigor-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tesla-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 octal-------\n",
      "reward 0 done True action 0\n",
      "episode 169 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9776292281438344  steps 761  memory 40\n",
      "=========================episode 170 fence======================\n",
      "------guess 0 0 decay-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 triol-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 wench-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 fence-------\n",
      "reward 0 done True action 0\n",
      "episode 170 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9780721991057384  steps 765  memory 44\n",
      "=========================episode 171 spiny======================\n",
      "------guess 0 0 fruit-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 1 aloes-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 missy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 spiky-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 spicy-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 spiny-------\n",
      "reward 0 done True action 0\n",
      "episode 171 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9787202635616228  steps 771  memory 48\n",
      "=========================episode 172 wrong======================\n",
      "------guess 0 0 piece-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 worry-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wrong-------\n",
      "reward 0 done True action 0\n",
      "episode 172 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9790370775629483  steps 774  memory 54\n",
      "=========================episode 173 riper======================\n",
      "------guess 0 0 moody-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 alter-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 giver-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 piper-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 riper-------\n",
      "reward 0 done True action 0\n",
      "episode 173 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9795546539620623  steps 779  memory 57\n",
      "=========================episode 174 manic======================\n",
      "------guess 0 0 clove-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 saucy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 magic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 manic-------\n",
      "reward 0 done True action 0\n",
      "episode 174 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.979959498938316  steps 783  memory 62\n",
      "=========================episode 175 trove======================\n",
      "------guess 0 0 quark-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toile-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 trope-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 trove-------\n",
      "reward 0 done True action 0\n",
      "episode 175 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9803563274469347  steps 787  memory 66\n",
      "=========================episode 176 crime======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 eerie-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 brine-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 grime-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 crime-------\n",
      "reward 0 done True action 0\n",
      "episode 176 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9808413314503566  steps 792  memory 70\n",
      "optimize_model_batch -1 75\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.1482,  0.1374],\n",
      "        [ 0.4027,  0.0087],\n",
      "        [ 1.0590, -0.3935],\n",
      "        [ 1.4008, -0.2316],\n",
      "        [ 1.4560, -0.3795],\n",
      "        [ 1.0602, -0.2203]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.5027, 0.4973],\n",
      "        [0.5973, 0.4027],\n",
      "        [0.8104, 0.1896],\n",
      "        [0.8365, 0.1635],\n",
      "        [0.8624, 0.1376],\n",
      "        [0.7825, 0.2175]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 81, 'total': -293, 'avg': -3.617283950617284} {'count': 96, 'total': -334, 'avg': -3.4791666666666665}\n",
      "{'count': 90, 'total': -237, 'avg': -2.6333333333333333} {'count': 87, 'total': -213, 'avg': -2.4482758620689653}\n",
      "{'count': 121, 'total': -174, 'avg': -1.43801652892562} {'count': 54, 'total': -101, 'avg': -1.8703703703703705}\n",
      "{'count': 88, 'total': -60, 'avg': -0.6818181818181818} {'count': 49, 'total': -78, 'avg': -1.5918367346938775}\n",
      "{'count': 58, 'total': -20, 'avg': -0.3448275862068966} {'count': 26, 'total': -34, 'avg': -1.3076923076923077}\n",
      "{'count': 33, 'total': -3, 'avg': -0.09090909090909091} {'count': 9, 'total': -9, 'avg': -1.0}\n",
      "done 792 optimizations, 792 transitions added to memory\n",
      "=========================episode 177 drunk======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 drunk-------\n",
      "reward 0 done True action 0\n",
      "episode 177 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9811265668648486  steps 795  memory 0\n",
      "=========================episode 178 blown======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 blown-------\n",
      "reward 0 done True action 0\n",
      "episode 178 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9814075556772622  steps 798  memory 3\n",
      "=========================episode 179 batty======================\n",
      "------guess 0 0 touch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 spent-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 blitz-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 batty-------\n",
      "reward 0 done True action 0\n",
      "episode 179 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9817757107413227  steps 802  memory 6\n",
      "=========================episode 180 hotly======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 hotly-------\n",
      "reward 0 done True action 0\n",
      "episode 180 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9820470350604972  steps 805  memory 10\n",
      "=========================episode 181 magic======================\n",
      "------guess 0 0 wring-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toeas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 magic-------\n",
      "reward 0 done True action 0\n",
      "episode 181 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9823143198868206  steps 808  memory 13\n",
      "=========================episode 182 goofy======================\n",
      "------guess 0 0 prose-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 cital-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dungy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 goofy-------\n",
      "reward 0 done True action 0\n",
      "episode 182 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9826645198165338  steps 812  memory 16\n",
      "=========================episode 183 trace======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 crate-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 trace-------\n",
      "reward 0 done True action 0\n",
      "episode 183 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9830077853230309  steps 816  memory 20\n",
      "=========================episode 184 allot======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 baton-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 ascot-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 afoot-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 allot-------\n",
      "reward 0 done True action 0\n",
      "episode 184 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9834273245982388  steps 821  memory 24\n",
      "=========================episode 185 chalk======================\n",
      "------guess 0 0 gaudy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 cleat-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 chalk-------\n",
      "reward 0 done True action 0\n",
      "episode 185 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.983674059590559  steps 824  memory 29\n",
      "=========================episode 186 shear======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 spear-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 swear-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 smear-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 shear-------\n",
      "reward 0 done True action 0\n",
      "episode 186 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9841565640486789  steps 830  memory 32\n",
      "=========================episode 187 arson======================\n",
      "------guess 0 0 split-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 chess-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 mason-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 arson-------\n",
      "reward 0 done True action 0\n",
      "episode 187 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9844702850998945  steps 834  memory 38\n",
      "=========================episode 188 ulcer======================\n",
      "------guess 0 0 glaze-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 riots-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 elder-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 ulcer-------\n",
      "reward 0 done True action 0\n",
      "episode 188 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9847777940580844  steps 838  memory 42\n",
      "=========================episode 189 stint======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 unlit-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 stint-------\n",
      "reward 0 done True action 0\n",
      "episode 189 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9850044231795223  steps 841  memory 46\n",
      "=========================episode 190 adore======================\n",
      "------guess 0 0 write-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 sloan-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 adore-------\n",
      "reward 0 done True action 0\n",
      "episode 190 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9852276782329125  steps 844  memory 49\n",
      "=========================episode 191 groin======================\n",
      "------guess 0 0 ether-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 broad-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 proof-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 groin-------\n",
      "reward 0 done True action 0\n",
      "episode 191 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9855924081568876  steps 849  memory 52\n",
      "=========================episode 192 cabal======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 awful-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 papal-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 cabal-------\n",
      "reward 0 done True action 0\n",
      "episode 192 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9859481328669539  steps 854  memory 57\n",
      "optimize_model_batch -1 62\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.1575,  0.1281],\n",
      "        [ 0.4846, -0.0733],\n",
      "        [ 1.0172, -0.3516],\n",
      "        [ 1.3913, -0.2220],\n",
      "        [ 1.4482, -0.3718],\n",
      "        [ 1.0602, -0.2203]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.5074, 0.4926],\n",
      "        [0.6360, 0.3640],\n",
      "        [0.7972, 0.2028],\n",
      "        [0.8339, 0.1661],\n",
      "        [0.8606, 0.1394],\n",
      "        [0.7825, 0.2175]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 89, 'total': -315, 'avg': -3.539325842696629} {'count': 104, 'total': -358, 'avg': -3.4423076923076925}\n",
      "{'count': 96, 'total': -249, 'avg': -2.59375} {'count': 97, 'total': -231, 'avg': -2.381443298969072}\n",
      "{'count': 136, 'total': -187, 'avg': -1.375} {'count': 55, 'total': -102, 'avg': -1.8545454545454545}\n",
      "{'count': 96, 'total': -64, 'avg': -0.6666666666666666} {'count': 50, 'total': -79, 'avg': -1.58}\n",
      "{'count': 62, 'total': -21, 'avg': -0.3387096774193548} {'count': 26, 'total': -34, 'avg': -1.3076923076923077}\n",
      "{'count': 34, 'total': -3, 'avg': -0.08823529411764706} {'count': 9, 'total': -9, 'avg': -1.0}\n",
      "done 854 optimizations, 854 transitions added to memory\n",
      "=========================episode 193 slosh======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 scowl-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 slosh-------\n",
      "reward 0 done True action 0\n",
      "episode 193 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9862263784787055  steps 858  memory 0\n",
      "=========================episode 194 mower======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 roger-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 power-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 mower-------\n",
      "reward 0 done True action 0\n",
      "episode 194 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9865664504057546  steps 863  memory 4\n",
      "=========================episode 195 allay======================\n",
      "------guess 0 0 rover-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 alist-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 album-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 allay-------\n",
      "reward 0 done True action 0\n",
      "episode 195 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9868324525099202  steps 867  memory 9\n",
      "=========================episode 196 minus======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 child-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 gipsy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 numbs-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 minus-------\n",
      "reward 0 done True action 0\n",
      "episode 196 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9871575604158215  steps 872  memory 13\n",
      "=========================episode 197 leafy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 spade-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 beach-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 mealy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 leafy-------\n",
      "reward 0 done True action 0\n",
      "episode 197 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9874746413789256  steps 877  memory 18\n",
      "=========================episode 198 chord======================\n",
      "------guess 0 0 scale-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 crook-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 chord-------\n",
      "reward 0 done True action 0\n",
      "episode 198 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9876611196745695  steps 880  memory 23\n",
      "=========================episode 199 stale======================\n",
      "------guess 0 0 tribe-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 state-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 nould-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 stale-------\n",
      "reward 0 done True action 0\n",
      "episode 199 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9879054458749221  steps 884  memory 26\n",
      "=========================episode 200 sissy======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 finch-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 slump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 gybed-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 sissy-------\n",
      "reward 0 done True action 0\n",
      "episode 200 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9882040614802484  steps 889  memory 30\n",
      "=========================episode 201 fresh======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 breed-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wreck-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 press-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 fresh-------\n",
      "reward 0 done True action 0\n",
      "episode 201 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9884953042400095  steps 894  memory 35\n",
      "=========================episode 202 visit======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 visit-------\n",
      "reward 0 done True action 0\n",
      "episode 202 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9886097778754867  steps 896  memory 40\n",
      "=========================episode 203 unmet======================\n",
      "------guess 0 0 stoke-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 urali-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 unmet-------\n",
      "reward 0 done True action 0\n",
      "episode 203 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9887793561904109  steps 899  memory 42\n",
      "=========================episode 204 plump======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 lumpy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 chins-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 plump-------\n",
      "reward 0 done True action 0\n",
      "episode 204 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9890015398241931  steps 903  memory 45\n",
      "=========================episode 205 aside======================\n",
      "------guess 0 0 spiel-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toran-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 aside-------\n",
      "reward 0 done True action 0\n",
      "episode 205 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9891652855635639  steps 906  memory 49\n",
      "=========================episode 206 treat======================\n",
      "------guess 0 0 elbow-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 stern-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 acidy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 treat-------\n",
      "reward 0 done True action 0\n",
      "episode 206 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9893798272837477  steps 910  memory 52\n",
      "=========================episode 207 spook======================\n",
      "------guess 0 0 broth-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 aisle-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 swoop-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 4 0 spook-------\n",
      "reward 0 done True action 0\n",
      "episode 207 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9896420402823863  steps 915  memory 56\n",
      "=========================episode 208 surge======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 sperm-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 surge-------\n",
      "reward 0 done True action 0\n",
      "episode 208 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9898471416266302  steps 919  memory 61\n",
      "optimize_model_batch -1 65\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.2426,  0.0430],\n",
      "        [ 0.4624, -0.0511],\n",
      "        [ 1.1138, -0.4483],\n",
      "        [ 1.4411, -0.2718],\n",
      "        [ 1.4476, -0.3712],\n",
      "        [ 1.0602, -0.2203]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.5497, 0.4503],\n",
      "        [0.6256, 0.3744],\n",
      "        [0.8266, 0.1734],\n",
      "        [0.8472, 0.1528],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.7825, 0.2175]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 96, 'total': -334, 'avg': -3.4791666666666665} {'count': 113, 'total': -388, 'avg': -3.433628318584071}\n",
      "{'count': 106, 'total': -271, 'avg': -2.556603773584906} {'count': 103, 'total': -242, 'avg': -2.349514563106796}\n",
      "{'count': 145, 'total': -196, 'avg': -1.3517241379310345} {'count': 61, 'total': -111, 'avg': -1.819672131147541}\n",
      "{'count': 106, 'total': -68, 'avg': -0.6415094339622641} {'count': 52, 'total': -81, 'avg': -1.5576923076923077}\n",
      "{'count': 68, 'total': -21, 'avg': -0.3088235294117647} {'count': 26, 'total': -34, 'avg': -1.3076923076923077}\n",
      "{'count': 34, 'total': -3, 'avg': -0.08823529411764706} {'count': 9, 'total': -9, 'avg': -1.0}\n",
      "done 919 optimizations, 919 transitions added to memory\n",
      "=========================episode 209 etude======================\n",
      "------guess 0 0 botch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 raile-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 tense-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 etude-------\n",
      "reward 0 done True action 0\n",
      "episode 209 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9900481816921516  steps 923  memory 0\n",
      "=========================episode 210 bongo======================\n",
      "------guess 0 0 moron-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 bongo-------\n",
      "reward 0 done True action 0\n",
      "episode 210 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9901472039388127  steps 925  memory 4\n",
      "=========================episode 211 seven======================\n",
      "------guess 0 0 suave-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lirot-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 seven-------\n",
      "reward 0 done True action 0\n",
      "episode 211 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9902938929616504  steps 928  memory 6\n",
      "=========================episode 212 siege======================\n",
      "------guess 0 0 glove-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 segue-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 siege-------\n",
      "reward 0 done True action 0\n",
      "episode 212 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9904383980694565  steps 931  memory 9\n",
      "=========================episode 213 tulip======================\n",
      "------guess 0 0 adore-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 sting-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 pitch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 tulip-------\n",
      "reward 0 done True action 0\n",
      "episode 213 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9906277304729939  steps 935  memory 12\n",
      "=========================episode 214 score======================\n",
      "------guess 0 0 tardy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 fibre-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 chore-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 score-------\n",
      "reward 0 done True action 0\n",
      "episode 214 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9908133138437554  steps 939  memory 16\n",
      "=========================episode 215 irate======================\n",
      "------guess 0 0 truer-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 wrest-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 irate-------\n",
      "reward 0 done True action 0\n",
      "episode 215 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9909500857820972  steps 942  memory 20\n",
      "=========================episode 216 wrath======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 tract-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 graft-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 wrath-------\n",
      "reward 0 done True action 0\n",
      "episode 216 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9911735289602733  steps 947  memory 23\n",
      "=========================episode 217 debut======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 sweet-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 filet-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 debut-------\n",
      "reward 0 done True action 0\n",
      "episode 217 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9913483047968794  steps 951  memory 28\n",
      "=========================episode 218 renal======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 relax-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 renal-------\n",
      "reward 0 done True action 0\n",
      "episode 218 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9914771117575993  steps 954  memory 32\n",
      "=========================episode 219 sprig======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 brush-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 swirl-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 sprig-------\n",
      "reward 0 done True action 0\n",
      "episode 219 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9916458762520571  steps 958  memory 35\n",
      "=========================episode 220 swirl======================\n",
      "------guess 0 0 offer-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 scram-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 shirt-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 swirl-------\n",
      "reward 0 done True action 0\n",
      "episode 220 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9918112989856259  steps 962  memory 39\n",
      "=========================episode 221 under======================\n",
      "------guess 0 0 lower-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tians-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 never-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 under-------\n",
      "reward 0 done True action 0\n",
      "episode 221 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9919734461296048  steps 966  memory 43\n",
      "=========================episode 222 happy======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 canny-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 gassy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 daily-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 mammy-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 jazzy-------\n",
      "reward -1 done True action 0\n",
      "episode 222 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9922106666466886  steps 972  memory 47\n",
      "=========================episode 223 order======================\n",
      "------guess 0 0 spent-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 dowel-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 cauri-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 order-------\n",
      "reward 0 done True action 0\n",
      "episode 223 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.99236490578114  steps 976  memory 53\n",
      "=========================episode 224 rabbi======================\n",
      "------guess 0 0 worth-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 aisle-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 cairn-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 rabid-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 rabbi-------\n",
      "reward 0 done True action 0\n",
      "episode 224 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9925534169290756  steps 981  memory 57\n",
      "optimize_model_batch -1 62\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.2116,  0.0740],\n",
      "        [ 0.4206, -0.0093],\n",
      "        [ 1.1504, -0.4849],\n",
      "        [ 1.4185, -0.2492],\n",
      "        [ 1.4344, -0.3580],\n",
      "        [ 1.0368, -0.1969]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.5344, 0.4656],\n",
      "        [0.6059, 0.3941],\n",
      "        [0.8369, 0.1631],\n",
      "        [0.8413, 0.1587],\n",
      "        [0.8572, 0.1428],\n",
      "        [0.7745, 0.2255]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 107, 'total': -363, 'avg': -3.392523364485981} {'count': 118, 'total': -406, 'avg': -3.440677966101695}\n",
      "{'count': 118, 'total': -294, 'avg': -2.4915254237288136} {'count': 107, 'total': -250, 'avg': -2.336448598130841}\n",
      "{'count': 158, 'total': -209, 'avg': -1.3227848101265822} {'count': 63, 'total': -114, 'avg': -1.8095238095238095}\n",
      "{'count': 117, 'total': -73, 'avg': -0.6239316239316239} {'count': 52, 'total': -81, 'avg': -1.5576923076923077}\n",
      "{'count': 71, 'total': -23, 'avg': -0.323943661971831} {'count': 26, 'total': -34, 'avg': -1.3076923076923077}\n",
      "{'count': 35, 'total': -4, 'avg': -0.11428571428571428} {'count': 9, 'total': -9, 'avg': -1.0}\n",
      "done 981 optimizations, 981 transitions added to memory\n",
      "=========================episode 225 arson======================\n",
      "------guess 0 0 alloy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 resit-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 arson-------\n",
      "reward 0 done True action 0\n",
      "episode 225 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9926642821075864  steps 984  memory 0\n",
      "=========================episode 226 synod======================\n",
      "------guess 0 0 plate-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 rosin-------\n",
      "reward -1 done False action 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 2 0 synod-------\n",
      "reward 0 done True action 0\n",
      "episode 226 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9927734967186236  steps 987  memory 3\n",
      "=========================episode 227 slick======================\n",
      "------guess 0 0 foyer-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 spunk-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 smack-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 slick-------\n",
      "reward 0 done True action 0\n",
      "episode 227 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9929165910709479  steps 991  memory 6\n",
      "=========================episode 228 condo======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 folly-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bound-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chips-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 condo-------\n",
      "reward 0 done True action 0\n",
      "episode 228 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9930914810605455  steps 996  memory 10\n",
      "=========================episode 229 furor======================\n",
      "------guess 0 0 hunky-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 turbo-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 aisle-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 furor-------\n",
      "reward 0 done True action 0\n",
      "episode 229 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.993228278901032  steps 1000  memory 15\n",
      "=========================episode 230 pilot======================\n",
      "------guess 0 0 depot-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 liars-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 pilot-------\n",
      "reward 0 done True action 0\n",
      "episode 230 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9933290966937447  steps 1003  memory 19\n",
      "=========================episode 231 caper======================\n",
      "------guess 0 0 timid-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 quark-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 rayon-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 parer-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 caper-------\n",
      "reward 0 done True action 0\n",
      "episode 231 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9934938018832267  steps 1008  memory 22\n",
      "=========================episode 232 tulip======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 stunt-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 guilt-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 tulip-------\n",
      "reward 0 done True action 0\n",
      "episode 232 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9936226332376679  steps 1012  memory 27\n",
      "=========================episode 233 timid======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 spilt-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 ditch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 bungy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 timid-------\n",
      "reward 0 done True action 0\n",
      "episode 233 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9937800909840574  steps 1017  memory 31\n",
      "=========================episode 234 medic======================\n",
      "------guess 0 0 pulpy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 sigma-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 comic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 medic-------\n",
      "reward 0 done True action 0\n",
      "episode 234 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9939032534344844  steps 1021  memory 36\n",
      "=========================episode 235 grill======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 brink-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 crimp-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 lushy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 drill-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 gowfs-------\n",
      "reward -1 done True action 1\n",
      "episode 235 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9940834395263182  steps 1027  memory 40\n",
      "=========================episode 236 meaty======================\n",
      "------guess 0 0 stall-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 irone-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 meaty-------\n",
      "reward 0 done True action 0\n",
      "episode 236 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9941715256359924  steps 1030  memory 46\n",
      "=========================episode 237 shiny======================\n",
      "------guess 0 0 lower-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 natis-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 sniff-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 suing-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 spiny-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 shiny-------\n",
      "reward 0 done True action 0\n",
      "episode 237 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9943437830860469  steps 1036  memory 49\n",
      "=========================episode 238 peach======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 leach-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 nidus-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 beach-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 peach-------\n",
      "reward 0 done True action 0\n",
      "episode 238 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9944834355792392  steps 1041  memory 55\n",
      "=========================episode 239 sight======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 stick-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 bumph-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 defog-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 sight-------\n",
      "reward 0 done True action 0\n",
      "episode 239 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9946464746973401  steps 1047  memory 60\n",
      "=========================episode 240 canoe======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 canoe-------\n",
      "reward 0 done True action 0\n",
      "episode 240 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9946997431641296  steps 1049  memory 66\n",
      "optimize_model_batch -1 68\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.1932,  0.0924],\n",
      "        [ 0.3592,  0.0521],\n",
      "        [ 1.1292, -0.4637],\n",
      "        [ 1.5725, -0.4032],\n",
      "        [ 1.4214, -0.3450],\n",
      "        [ 1.1317, -0.2918]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.5252, 0.4748],\n",
      "        [0.5762, 0.4238],\n",
      "        [0.8310, 0.1690],\n",
      "        [0.8782, 0.1218],\n",
      "        [0.8540, 0.1460],\n",
      "        [0.8059, 0.1941]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 116, 'total': -389, 'avg': -3.353448275862069} {'count': 125, 'total': -433, 'avg': -3.464}\n",
      "{'count': 128, 'total': -319, 'avg': -2.4921875} {'count': 113, 'total': -262, 'avg': -2.3185840707964602}\n",
      "{'count': 171, 'total': -228, 'avg': -1.3333333333333333} {'count': 65, 'total': -117, 'avg': -1.8}\n",
      "{'count': 124, 'total': -77, 'avg': -0.6209677419354839} {'count': 56, 'total': -88, 'avg': -1.5714285714285714}\n",
      "{'count': 77, 'total': -26, 'avg': -0.33766233766233766} {'count': 27, 'total': -35, 'avg': -1.2962962962962963}\n",
      "{'count': 37, 'total': -4, 'avg': -0.10810810810810811} {'count': 10, 'total': -10, 'avg': -1.0}\n",
      "done 1049 optimizations, 1049 transitions added to memory\n",
      "=========================episode 241 hairy======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 marsh-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 hairy-------\n",
      "reward 0 done True action 0\n",
      "episode 241 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9947786537080213  steps 1052  memory 0\n",
      "=========================episode 242 leaky======================\n",
      "------guess 0 0 creme-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 fetid-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 began-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 leash-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 leaky-------\n",
      "reward 0 done True action 0\n",
      "episode 242 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9949075692073008  steps 1057  memory 3\n",
      "=========================episode 243 snide======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 singe-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 snide-------\n",
      "reward 0 done True action 0\n",
      "episode 243 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9950084060930898  steps 1061  memory 8\n",
      "=========================episode 244 diode======================\n",
      "------guess 0 0 split-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 1 ocrea-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dungy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 diode-------\n",
      "reward 0 done True action 0\n",
      "episode 244 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9951072462747605  steps 1065  memory 12\n",
      "=========================episode 245 tight======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 might-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 tight-------\n",
      "reward 0 done True action 0\n",
      "episode 245 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9952041292897036  steps 1069  memory 16\n",
      "=========================episode 246 whoop======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 buxom-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 chowk-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 whoop-------\n",
      "reward 0 done True action 0\n",
      "episode 246 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9953225397594415  steps 1074  memory 20\n",
      "=========================episode 247 heady======================\n",
      "------guess 0 0 paint-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 chard-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 heady-------\n",
      "reward 0 done True action 0\n",
      "episode 247 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9953921780700072  steps 1077  memory 25\n",
      "=========================episode 248 torso======================\n",
      "------guess 0 0 tenth-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 tramp-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 turbo-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 idyls-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 torso-------\n",
      "reward 0 done True action 0\n",
      "episode 248 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9955059455988166  steps 1082  memory 28\n",
      "=========================episode 249 waist======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 waist-------\n",
      "reward 0 done True action 0\n",
      "episode 249 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9955728533521685  steps 1085  memory 33\n",
      "=========================episode 250 wrath======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 wrath-------\n",
      "reward 0 done True action 0\n",
      "episode 250 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9956387649788475  steps 1088  memory 36\n",
      "=========================episode 251 shank======================\n",
      "------guess 0 0 tithe-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 soral-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 shank-------\n",
      "reward 0 done True action 0\n",
      "episode 251 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9957251232182873  steps 1092  memory 39\n",
      "=========================episode 252 neigh======================\n",
      "------guess 0 0 beast-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 loric-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 feign-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 neigh-------\n",
      "reward 0 done True action 0\n",
      "episode 252 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9958097714500154  steps 1096  memory 43\n",
      "=========================episode 253 spurt======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 brunt-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 spurt-------\n",
      "reward 0 done True action 0\n",
      "episode 253 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9958721558257445  steps 1099  memory 47\n",
      "=========================episode 254 champ======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 chalk-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 chaff-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 champ-------\n",
      "reward 0 done True action 0\n",
      "episode 254 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9959538926167778  steps 1103  memory 50\n",
      "=========================episode 255 fibre======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 ridge-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 fibre-------\n",
      "reward 0 done True action 0\n",
      "episode 255 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9960537913640124  steps 1108  memory 54\n",
      "=========================episode 256 mangy======================\n",
      "------guess 0 0 wooly-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 retia-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dunsh-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 campy-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 mangy-------\n",
      "reward 0 done True action 0\n",
      "episode 256 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9961512236023895  steps 1113  memory 59\n",
      "optimize_model_batch -1 64\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.2474,  0.0382],\n",
      "        [ 0.4742, -0.0629],\n",
      "        [ 1.1690, -0.5035],\n",
      "        [ 1.6803, -0.5110],\n",
      "        [ 1.4573, -0.3809],\n",
      "        [ 1.1424, -0.3025]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.5521, 0.4479],\n",
      "        [0.6311, 0.3689],\n",
      "        [0.8419, 0.1581],\n",
      "        [0.8995, 0.1005],\n",
      "        [0.8627, 0.1373],\n",
      "        [0.8092, 0.1908]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 123, 'total': -412, 'avg': -3.3495934959349594} {'count': 134, 'total': -458, 'avg': -3.417910447761194}\n",
      "{'count': 134, 'total': -330, 'avg': -2.462686567164179} {'count': 123, 'total': -283, 'avg': -2.3008130081300813}\n",
      "{'count': 183, 'total': -238, 'avg': -1.3005464480874316} {'count': 69, 'total': -123, 'avg': -1.7826086956521738}\n",
      "{'count': 132, 'total': -79, 'avg': -0.5984848484848485} {'count': 59, 'total': -91, 'avg': -1.5423728813559323}\n",
      "{'count': 82, 'total': -26, 'avg': -0.3170731707317073} {'count': 27, 'total': -35, 'avg': -1.2962962962962963}\n",
      "{'count': 37, 'total': -4, 'avg': -0.10810810810810811} {'count': 10, 'total': -10, 'avg': -1.0}\n",
      "done 1113 optimizations, 1113 transitions added to memory\n",
      "=========================episode 257 tepid======================\n",
      "------guess 0 0 wider-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 edify-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 denim-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 lotas-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 tepid-------\n",
      "reward 0 done True action 0\n",
      "episode 257 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.996264972135312  steps 1119  memory 0\n",
      "=========================episode 258 arson======================\n",
      "------guess 0 0 share-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 arson-------\n",
      "reward 0 done True action 0\n",
      "episode 258 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.996302136283517  steps 1121  memory 6\n",
      "=========================episode 259 polar======================\n",
      "------guess 0 0 scout-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 lingo-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 vowel-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 folly-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 polar-------\n",
      "reward 0 done True action 0\n",
      "episode 259 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9963934368639843  steps 1126  memory 8\n",
      "=========================episode 260 stalk======================\n",
      "------guess 0 0 rally-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 adult-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 noise-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 stalk-------\n",
      "reward 0 done True action 0\n",
      "episode 260 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9964648515988803  steps 1130  memory 13\n",
      "=========================episode 261 where======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 where-------\n",
      "reward 0 done True action 0\n",
      "episode 261 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9965000269131928  steps 1132  memory 17\n",
      "=========================episode 262 sloth======================\n",
      "------guess 0 0 steak-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 split-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 2 0 sloth-------\n",
      "reward 0 done True action 0\n",
      "episode 262 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9965521347238969  steps 1135  memory 19\n",
      "=========================episode 263 title======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 utile-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 title-------\n",
      "reward 0 done True action 0\n",
      "episode 263 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9966204070306233  steps 1139  memory 22\n",
      "=========================episode 264 renew======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 riper-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 rebel-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 renew-------\n",
      "reward 0 done True action 0\n",
      "episode 264 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9966873274551001  steps 1143  memory 26\n",
      "=========================episode 265 drone======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 grove-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 froze-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 erode-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 drone-------\n",
      "reward 0 done True action 0\n",
      "episode 265 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.996769117631655  steps 1148  memory 30\n",
      "=========================episode 266 gravy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 array-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 crazy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 gravy-------\n",
      "reward 0 done True action 0\n",
      "episode 266 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9968488884015556  steps 1153  memory 35\n",
      "=========================episode 267 unite======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 lefty-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 quite-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 unite-------\n",
      "reward 0 done True action 0\n",
      "episode 267 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9969112845917633  steps 1157  memory 40\n",
      "=========================episode 268 decry======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 buyer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 perky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 leery-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 decry-------\n",
      "reward 0 done True action 0\n",
      "episode 268 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.996987545246912  steps 1162  memory 44\n",
      "=========================episode 269 derby======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 udder-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 decry-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 derby-------\n",
      "reward 0 done True action 0\n",
      "episode 269 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9970471958476266  steps 1166  memory 49\n",
      "=========================episode 270 great======================\n",
      "------guess 0 0 rigor-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 stale-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 great-------\n",
      "reward 0 done True action 0\n",
      "episode 270 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9970911573741874  steps 1169  memory 53\n",
      "=========================episode 271 riser======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 elder-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 wiser-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 miser-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 riser-------\n",
      "reward 0 done True action 0\n",
      "episode 271 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9971629769545145  steps 1174  memory 56\n",
      "=========================episode 272 stank======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 await-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 staff-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 lunch-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 stand-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 stank-------\n",
      "reward 0 done True action 0\n",
      "episode 272 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9972468236569344  steps 1180  memory 61\n",
      "optimize_model_batch -1 67\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 3.4626e-01, -6.0656e-02],\n",
      "        [ 4.1143e-01, -8.3207e-05],\n",
      "        [ 1.1754e+00, -5.0985e-01],\n",
      "        [ 1.7777e+00, -6.0841e-01],\n",
      "        [ 1.5184e+00, -4.4195e-01],\n",
      "        [ 1.1424e+00, -3.0249e-01]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.6003, 0.3997],\n",
      "        [0.6015, 0.3985],\n",
      "        [0.8436, 0.1564],\n",
      "        [0.9158, 0.0842],\n",
      "        [0.8766, 0.1234],\n",
      "        [0.8092, 0.1908]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 129, 'total': -429, 'avg': -3.3255813953488373} {'count': 144, 'total': -492, 'avg': -3.4166666666666665}\n",
      "{'count': 147, 'total': -359, 'avg': -2.442176870748299} {'count': 126, 'total': -289, 'avg': -2.2936507936507935}\n",
      "{'count': 196, 'total': -258, 'avg': -1.316326530612245} {'count': 70, 'total': -124, 'avg': -1.7714285714285714}\n",
      "{'count': 142, 'total': -84, 'avg': -0.5915492957746479} {'count': 61, 'total': -95, 'avg': -1.5573770491803278}\n",
      "{'count': 88, 'total': -27, 'avg': -0.3068181818181818} {'count': 28, 'total': -36, 'avg': -1.2857142857142858}\n",
      "{'count': 39, 'total': -4, 'avg': -0.10256410256410256} {'count': 10, 'total': -10, 'avg': -1.0}\n",
      "done 1180 optimizations, 1180 transitions added to memory\n",
      "=========================episode 273 cynic======================\n",
      "------guess 0 0 rebut-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 aloin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 minim-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 cynic-------\n",
      "reward 0 done True action 0\n",
      "episode 273 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9973013402011476  steps 1184  memory 0\n",
      "=========================episode 274 brute======================\n",
      "------guess 0 0 stamp-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 beget-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 brute-------\n",
      "reward 0 done True action 0\n",
      "episode 274 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9973415180112236  steps 1187  memory 4\n",
      "=========================episode 275 swore======================\n",
      "------guess 0 0 caper-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 borne-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 froze-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 store-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 swore-------\n",
      "reward 0 done True action 0\n",
      "episode 275 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9974071561653977  steps 1192  memory 7\n",
      "=========================episode 276 slush======================\n",
      "------guess 0 0 pixel-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 sully-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 slunk-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 slush-------\n",
      "reward 0 done True action 0\n",
      "episode 276 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9974584979132312  steps 1196  memory 12\n",
      "=========================episode 277 colon======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 goody-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 folio-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 colon-------\n",
      "reward 0 done True action 0\n",
      "episode 277 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9975088230263428  steps 1200  memory 16\n",
      "=========================episode 278 nanny======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 sandy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lanky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 canny-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 nanny-------\n",
      "reward 0 done True action 0\n",
      "episode 278 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9975703304049754  steps 1205  memory 20\n",
      "=========================episode 279 silky======================\n",
      "------guess 0 0 gaily-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 filmy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 silky-------\n",
      "reward 0 done True action 0\n",
      "episode 279 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9976065034726508  steps 1208  memory 25\n",
      "=========================episode 280 axial======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 fanny-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sigma-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 axial-------\n",
      "reward 0 done True action 0\n",
      "episode 280 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9976538978793279  steps 1212  memory 28\n",
      "=========================episode 281 shone======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 gouge-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 whose-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 shove-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 shone-------\n",
      "reward 0 done True action 0\n",
      "episode 281 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9977118233470779  steps 1217  memory 32\n",
      "=========================episode 282 ranch======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 ranch-------\n",
      "reward 0 done True action 0\n",
      "episode 282 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9977458898592854  steps 1220  memory 37\n",
      "=========================episode 283 fetus======================\n",
      "------guess 0 0 leery-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 fetid-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 fetch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 fetus-------\n",
      "reward 0 done True action 0\n",
      "episode 283 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9977905242305842  steps 1224  memory 40\n",
      "=========================episode 284 prove======================\n",
      "------guess 0 0 swine-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tolar-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 froze-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 grove-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 prove-------\n",
      "reward 0 done True action 0\n",
      "episode 284 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9978450763817024  steps 1229  memory 44\n",
      "=========================episode 285 swoop======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 swoop-------\n",
      "reward 0 done True action 0\n",
      "episode 285 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9978771590146824  steps 1232  memory 49\n",
      "=========================episode 286 poesy======================\n",
      "------guess 0 0 array-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 weedy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 poesy-------\n",
      "reward 0 done True action 0\n",
      "episode 286 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9979087639994849  steps 1235  memory 52\n",
      "=========================episode 287 gross======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 micro-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 proxy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 frown-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 brood-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 gross-------\n",
      "reward 0 done True action 0\n",
      "episode 287 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9979705693637043  steps 1241  memory 55\n",
      "=========================episode 288 stave======================\n",
      "------guess 0 0 bawdy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 among-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 creak-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 sluit-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 state-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 stave-------\n",
      "reward 0 done True action 0\n",
      "episode 288 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9980305481033603  steps 1247  memory 61\n",
      "optimize_model_batch -1 67\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.4194, -0.1338],\n",
      "        [ 0.2800,  0.1313],\n",
      "        [ 1.0868, -0.4213],\n",
      "        [ 1.8291, -0.6599],\n",
      "        [ 1.5033, -0.4269],\n",
      "        [ 1.1424, -0.3025]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.6349, 0.3651],\n",
      "        [0.5371, 0.4629],\n",
      "        [0.8188, 0.1812],\n",
      "        [0.9234, 0.0766],\n",
      "        [0.8733, 0.1267],\n",
      "        [0.8092, 0.1908]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 138, 'total': -457, 'avg': -3.3115942028985508} {'count': 151, 'total': -515, 'avg': -3.410596026490066}\n",
      "{'count': 159, 'total': -387, 'avg': -2.4339622641509435} {'count': 130, 'total': -296, 'avg': -2.276923076923077}\n",
      "{'count': 212, 'total': -277, 'avg': -1.3066037735849056} {'count': 70, 'total': -124, 'avg': -1.7714285714285714}\n",
      "{'count': 152, 'total': -90, 'avg': -0.5921052631578947} {'count': 62, 'total': -97, 'avg': -1.564516129032258}\n",
      "{'count': 94, 'total': -29, 'avg': -0.30851063829787234} {'count': 28, 'total': -36, 'avg': -1.2857142857142858}\n",
      "{'count': 41, 'total': -4, 'avg': -0.0975609756097561} {'count': 10, 'total': -10, 'avg': -1.0}\n",
      "done 1247 optimizations, 1247 transitions added to memory\n",
      "=========================episode 289 tryst======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 print-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 trust-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 yclad-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 tryst-------\n",
      "reward 0 done True action 0\n",
      "episode 289 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9980791740439443  steps 1252  memory 0\n",
      "=========================episode 290 loose======================\n",
      "------guess 0 0 riser-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 mouse-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 copse-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 noose-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 goose-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 loose-------\n",
      "reward 0 done True action 0\n",
      "episode 290 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9981359430302217  steps 1258  memory 5\n",
      "=========================episode 291 flush======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 skulk-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 pinch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 flush-------\n",
      "reward 0 done True action 0\n",
      "episode 291 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9981728538312551  steps 1262  memory 11\n",
      "=========================episode 292 briny======================\n",
      "------guess 0 0 leant-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 siroc-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 grind-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 brink-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 briny-------\n",
      "reward 0 done True action 0\n",
      "episode 292 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9982179662308985  steps 1267  memory 15\n",
      "=========================episode 293 coast======================\n",
      "------guess 0 0 moldy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 sonar-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 toast-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 coast-------\n",
      "reward 0 done True action 0\n",
      "episode 293 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9982532528637389  steps 1271  memory 20\n",
      "=========================episode 294 ester======================\n",
      "------guess 0 0 nadir-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 loser-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sheer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 ester-------\n",
      "reward 0 done True action 0\n",
      "episode 294 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9982878407744344  steps 1275  memory 24\n",
      "=========================episode 295 flume======================\n",
      "------guess 0 0 sieve-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 rotal-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 flume-------\n",
      "reward 0 done True action 0\n",
      "episode 295 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9983133315043938  steps 1278  memory 28\n",
      "=========================episode 296 qualm======================\n",
      "------guess 0 0 stank-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 realm-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 qualm-------\n",
      "reward 0 done True action 0\n",
      "episode 296 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.998338442726826  steps 1281  memory 31\n",
      "=========================episode 297 shone======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 coupe-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 evoke-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 shone-------\n",
      "reward 0 done True action 0\n",
      "episode 297 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9983713437652117  steps 1285  memory 34\n",
      "=========================episode 298 brook======================\n",
      "------guess 0 0 swami-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 0 perky-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 truck-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 brook-------\n",
      "reward 0 done True action 0\n",
      "episode 298 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9984035933193878  steps 1289  memory 38\n",
      "=========================episode 299 cheat======================\n",
      "------guess 0 0 coupe-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 liart-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 cadet-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 cheat-------\n",
      "reward 0 done True action 0\n",
      "episode 299 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9984352042896059  steps 1293  memory 42\n",
      "=========================episode 300 shrew======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 infer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 rebel-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 screw-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 dumpy-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 shrew-------\n",
      "reward 0 done True action 0\n",
      "episode 300 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9984814509919321  steps 1299  memory 46\n",
      "=========================episode 301 scram======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 scram-------\n",
      "reward 0 done True action 0\n",
      "episode 301 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9985115202769406  steps 1303  memory 52\n",
      "=========================episode 302 patio======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 aloft-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 baton-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 patio-------\n",
      "reward 0 done True action 0\n",
      "episode 302 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9985409941502131  steps 1307  memory 56\n",
      "=========================episode 303 saute======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 saute-------\n",
      "reward 0 done True action 0\n",
      "episode 303 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9985627159174243  steps 1310  memory 60\n",
      "=========================episode 304 decal======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 decal-------\n",
      "reward 0 done True action 0\n",
      "episode 304 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9985911760490943  steps 1314  memory 63\n",
      "optimize_model_batch -1 67\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.4696, -0.1840],\n",
      "        [ 0.1342,  0.2771],\n",
      "        [ 1.0313, -0.3658],\n",
      "        [ 1.8994, -0.7301],\n",
      "        [ 1.5383, -0.4618],\n",
      "        [ 1.1424, -0.3025]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.6578, 0.3422],\n",
      "        [0.4643, 0.5357],\n",
      "        [0.8017, 0.1983],\n",
      "        [0.9327, 0.0673],\n",
      "        [0.8808, 0.1192],\n",
      "        [0.8092, 0.1908]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 146, 'total': -482, 'avg': -3.3013698630136985} {'count': 159, 'total': -541, 'avg': -3.40251572327044}\n",
      "{'count': 169, 'total': -411, 'avg': -2.4319526627218937} {'count': 136, 'total': -307, 'avg': -2.2573529411764706}\n",
      "{'count': 225, 'total': -293, 'avg': -1.3022222222222222} {'count': 73, 'total': -127, 'avg': -1.7397260273972603}\n",
      "{'count': 164, 'total': -95, 'avg': -0.5792682926829268} {'count': 63, 'total': -98, 'avg': -1.5555555555555556}\n",
      "{'count': 97, 'total': -30, 'avg': -0.30927835051546393} {'count': 29, 'total': -37, 'avg': -1.2758620689655173}\n",
      "{'count': 43, 'total': -4, 'avg': -0.09302325581395349} {'count': 10, 'total': -10, 'avg': -1.0}\n",
      "done 1314 optimizations, 1314 transitions added to memory\n",
      "=========================episode 305 suing======================\n",
      "------guess 0 0 alert-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 opium-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 synch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 suing-------\n",
      "reward 0 done True action 0\n",
      "episode 305 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9986190726323995  steps 1318  memory 0\n",
      "=========================episode 306 finer======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 inner-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 diner-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 finer-------\n",
      "reward 0 done True action 0\n",
      "episode 306 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9986598852039572  steps 1324  memory 4\n",
      "=========================episode 307 sheen======================\n",
      "------guess 0 0 party-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 bleed-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 coins-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 humfs-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 sheen-------\n",
      "reward 0 done True action 0\n",
      "episode 307 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9986929727561636  steps 1329  memory 10\n",
      "=========================episode 308 tweed======================\n",
      "------guess 0 0 drier-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 altos-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 tweed-------\n",
      "reward 0 done True action 0\n",
      "episode 308 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9987124318567103  steps 1332  memory 15\n",
      "=========================episode 309 gaunt======================\n",
      "------guess 0 0 rouse-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 plumb-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 taunt-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 daunt-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 jaunt-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 vaunt-------\n",
      "reward -1 done True action 0\n",
      "episode 309 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9987504852462051  steps 1338  memory 18\n",
      "=========================episode 310 olive======================\n",
      "------guess 0 0 birth-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 alike-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 olive-------\n",
      "reward 0 done True action 0\n",
      "episode 310 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9987690880973266  steps 1341  memory 24\n",
      "=========================episode 311 pithy======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 itchy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 pithy-------\n",
      "reward 0 done True action 0\n",
      "episode 311 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.998793461786042  steps 1345  memory 27\n",
      "=========================episode 312 terse======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 truce-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 there-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 terse-------\n",
      "reward 0 done True action 0\n",
      "episode 312 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9988173528433845  steps 1349  memory 31\n",
      "=========================episode 313 mover======================\n",
      "------guess 0 0 queer-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 cater-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 noils-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 homer-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 mower-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 mover-------\n",
      "reward 0 done True action 0\n",
      "episode 313 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9988523053490985  steps 1355  memory 35\n",
      "=========================episode 314 sigma======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 sauna-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sigma-------\n",
      "reward 0 done True action 0\n",
      "episode 314 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9988693922963784  steps 1358  memory 41\n",
      "=========================episode 315 admit======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 tally-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 antic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 admit-------\n",
      "reward 0 done True action 0\n",
      "episode 315 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9988917798288798  steps 1362  memory 44\n",
      "=========================episode 316 soapy======================\n",
      "------guess 0 0 tweet-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 dryly-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 gassy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 soapy-------\n",
      "reward 0 done True action 0\n",
      "episode 316 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9989137240585362  steps 1366  memory 48\n",
      "=========================episode 317 valid======================\n",
      "------guess 0 0 nadir-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toles-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 valid-------\n",
      "reward 0 done True action 0\n",
      "episode 317 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9989298966003604  steps 1369  memory 52\n",
      "=========================episode 318 hunky======================\n",
      "------guess 0 0 fancy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 estro-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 pinky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 hunky-------\n",
      "reward 0 done True action 0\n",
      "episode 318 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9989510860673723  steps 1373  memory 55\n",
      "=========================episode 319 idler======================\n",
      "------guess 0 0 tramp-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 sewer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 fixer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 inner-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 idler-------\n",
      "reward 0 done True action 0\n",
      "episode 319 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9989769838446435  steps 1378  memory 59\n",
      "=========================episode 320 rearm======================\n",
      "------guess 0 0 round-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 remit-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 rearm-------\n",
      "reward 0 done True action 0\n",
      "episode 320 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9989922145709514  steps 1381  memory 64\n",
      "optimize_model_batch -1 67\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 5.0988e-01, -2.2427e-01],\n",
      "        [ 5.5075e-05,  4.1130e-01],\n",
      "        [ 1.2162e+00, -5.5067e-01],\n",
      "        [ 1.9163e+00, -7.4699e-01],\n",
      "        [ 1.5116e+00, -4.3517e-01],\n",
      "        [ 1.1064e+00, -2.6651e-01]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.6757, 0.3243],\n",
      "        [0.3986, 0.6014],\n",
      "        [0.8541, 0.1459],\n",
      "        [0.9348, 0.0652],\n",
      "        [0.8751, 0.1249],\n",
      "        [0.7979, 0.2021]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 157, 'total': -518, 'avg': -3.299363057324841} {'count': 164, 'total': -557, 'avg': -3.3963414634146343}\n",
      "{'count': 180, 'total': -437, 'avg': -2.4277777777777776} {'count': 141, 'total': -317, 'avg': -2.24822695035461}\n",
      "{'count': 237, 'total': -304, 'avg': -1.2827004219409284} {'count': 77, 'total': -136, 'avg': -1.7662337662337662}\n",
      "{'count': 174, 'total': -103, 'avg': -0.5919540229885057} {'count': 64, 'total': -99, 'avg': -1.546875}\n",
      "{'count': 102, 'total': -34, 'avg': -0.3333333333333333} {'count': 29, 'total': -37, 'avg': -1.2758620689655173}\n",
      "{'count': 46, 'total': -5, 'avg': -0.10869565217391304} {'count': 10, 'total': -10, 'avg': -1.0}\n",
      "done 1381 optimizations, 1381 transitions added to memory\n",
      "=========================episode 321 avail======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 plaid-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 quail-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 avail-------\n",
      "reward 0 done True action 0\n",
      "episode 321 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9990170968818513  steps 1386  memory 0\n",
      "=========================episode 322 civic======================\n",
      "------guess 0 0 clash-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toner-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 guimp-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 civic-------\n",
      "reward 0 done True action 0\n",
      "episode 322 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9990365596676015  steps 1390  memory 5\n",
      "=========================episode 323 datum======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 hatch-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 datum-------\n",
      "reward 0 done True action 0\n",
      "episode 323 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9990509034254591  steps 1393  memory 9\n",
      "=========================episode 324 panel======================\n",
      "------guess 0 0 maple-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 rosit-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 panel-------\n",
      "reward 0 done True action 0\n",
      "episode 324 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9990650336325834  steps 1396  memory 12\n",
      "=========================episode 325 sauce======================\n",
      "------guess 0 0 jerky-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 salto-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 mucin-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 sauce-------\n",
      "reward 0 done True action 0\n",
      "episode 325 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9990835472070718  steps 1400  memory 15\n",
      "=========================episode 326 check======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 unfed-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 bless-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 geeky-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 check-------\n",
      "reward 0 done True action 0\n",
      "episode 326 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9991061745071511  steps 1405  memory 19\n",
      "=========================episode 327 weedy======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 geeky-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 weedy-------\n",
      "reward 0 done True action 0\n",
      "episode 327 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9991282431372008  steps 1410  memory 24\n",
      "=========================episode 328 asset======================\n",
      "------guess 0 0 idler-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 santo-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 asset-------\n",
      "reward 0 done True action 0\n",
      "episode 328 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9991412219060256  steps 1413  memory 29\n",
      "=========================episode 329 award======================\n",
      "------guess 0 0 lanky-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 estro-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 dwarf-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 award-------\n",
      "reward 0 done True action 0\n",
      "episode 329 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9991582268516215  steps 1417  memory 32\n",
      "=========================episode 330 shyly======================\n",
      "------guess 0 0 serif-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 notal-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 sulky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 slyly-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 shyly-------\n",
      "reward 0 done True action 0\n",
      "episode 330 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9991790103047071  steps 1422  memory 36\n",
      "=========================episode 331 razor======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 carol-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 nidus-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 vapor-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 razor-------\n",
      "reward 0 done True action 0\n",
      "episode 331 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9991992806125077  steps 1427  memory 41\n",
      "=========================episode 332 dusty======================\n",
      "------guess 0 0 sheep-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tolar-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 musty-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 3 0 dusty-------\n",
      "reward 0 done True action 0\n",
      "episode 332 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999215135918689  steps 1431  memory 46\n",
      "=========================episode 333 peach======================\n",
      "------guess 0 0 rapid-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 stole-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 peach-------\n",
      "reward 0 done True action 0\n",
      "episode 333 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.999226821022535  steps 1434  memory 50\n",
      "=========================episode 334 ripen======================\n",
      "------guess 0 0 loose-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 udder-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 grief-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 rivet-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 ripen-------\n",
      "reward 0 done True action 0\n",
      "episode 334 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9992459108795064  steps 1439  memory 53\n",
      "=========================episode 335 cedar======================\n",
      "------guess 0 0 taker-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 linos-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 duchy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 cedar-------\n",
      "reward 0 done True action 0\n",
      "episode 335 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9992608428445372  steps 1443  memory 58\n",
      "=========================episode 336 deuce======================\n",
      "------guess 0 0 rhyme-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lotsa-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 genie-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 deuce-------\n",
      "reward 0 done True action 0\n",
      "episode 336 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9992754791368501  steps 1447  memory 62\n",
      "optimize_model_batch -1 66\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.5398, -0.2541],\n",
      "        [ 0.0283,  0.3831],\n",
      "        [ 1.3294, -0.6639],\n",
      "        [ 1.8995, -0.7302],\n",
      "        [ 1.5109, -0.4344],\n",
      "        [ 1.1061, -0.2661]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.6887, 0.3113],\n",
      "        [0.4122, 0.5878],\n",
      "        [0.8801, 0.1199],\n",
      "        [0.9328, 0.0672],\n",
      "        [0.8749, 0.1251],\n",
      "        [0.7977, 0.2023]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 168, 'total': -550, 'avg': -3.2738095238095237} {'count': 169, 'total': -575, 'avg': -3.4023668639053253}\n",
      "{'count': 184, 'total': -447, 'avg': -2.4293478260869565} {'count': 153, 'total': -341, 'avg': -2.2287581699346406}\n",
      "{'count': 248, 'total': -315, 'avg': -1.2701612903225807} {'count': 82, 'total': -143, 'avg': -1.7439024390243902}\n",
      "{'count': 186, 'total': -109, 'avg': -0.5860215053763441} {'count': 64, 'total': -99, 'avg': -1.546875}\n",
      "{'count': 108, 'total': -34, 'avg': -0.3148148148148148} {'count': 29, 'total': -37, 'avg': -1.2758620689655173}\n",
      "{'count': 46, 'total': -5, 'avg': -0.10869565217391304} {'count': 10, 'total': -10, 'avg': -1.0}\n",
      "done 1447 optimizations, 1447 transitions added to memory\n",
      "=========================episode 337 hyena======================\n",
      "------guess 0 0 beech-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 shell-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 ratio-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 hyena-------\n",
      "reward 0 done True action 0\n",
      "episode 337 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9992898256111574  steps 1451  memory 0\n",
      "=========================episode 338 syrup======================\n",
      "------guess 0 0 enema-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 triol-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 hurry-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 syrup-------\n",
      "reward 0 done True action 0\n",
      "episode 338 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9993038880062401  steps 1455  memory 4\n",
      "=========================episode 339 shrub======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 shrug-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 shrub-------\n",
      "reward 0 done True action 0\n",
      "episode 339 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9993176719472436  steps 1459  memory 8\n",
      "=========================episode 340 tenet======================\n",
      "------guess 0 0 serve-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 notal-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 tenet-------\n",
      "reward 0 done True action 0\n",
      "episode 340 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9993278304885036  steps 1462  memory 12\n",
      "=========================episode 341 urban======================\n",
      "------guess 0 0 piper-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 short-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 mural-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 urban-------\n",
      "reward 0 done True action 0\n",
      "episode 341 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9993411403365939  steps 1466  memory 15\n",
      "=========================episode 342 olden======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 olden-------\n",
      "reward 0 done True action 0\n",
      "episode 342 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9993509494790559  steps 1469  memory 19\n",
      "=========================episode 343 brisk======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 usurp-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 frisk-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 brisk-------\n",
      "reward 0 done True action 0\n",
      "episode 343 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9993638015404614  steps 1473  memory 22\n",
      "=========================episode 344 wring======================\n",
      "------guess 0 0 angle-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 dying-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 swing-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 wring-------\n",
      "reward 0 done True action 0\n",
      "episode 344 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9993763991140006  steps 1477  memory 26\n",
      "=========================episode 345 expel======================\n",
      "------guess 0 0 obese-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 expel-------\n",
      "reward 0 done True action 0\n",
      "episode 345 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9993826040464904  steps 1479  memory 30\n",
      "=========================episode 346 splat======================\n",
      "------guess 0 0 taper-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 loins-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 splat-------\n",
      "reward 0 done True action 0\n",
      "episode 346 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9993917958747351  steps 1482  memory 32\n",
      "=========================episode 347 elbow======================\n",
      "------guess 0 0 rowdy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 flown-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 elbow-------\n",
      "reward 0 done True action 0\n",
      "episode 347 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9994008508544857  steps 1485  memory 35\n",
      "=========================episode 348 lumpy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 lucky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 lumpy-------\n",
      "reward 0 done True action 0\n",
      "episode 348 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999412714802454  steps 1489  memory 38\n",
      "=========================episode 349 regal======================\n",
      "------guess 0 0 alive-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 snort-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 relay-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 regal-------\n",
      "reward 0 done True action 0\n",
      "episode 349 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9994243438285128  steps 1493  memory 42\n",
      "=========================episode 350 livid======================\n",
      "------guess 0 0 savoy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tiler-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 livid-------\n",
      "reward 0 done True action 0\n",
      "episode 350 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9994329142323617  steps 1496  memory 46\n",
      "=========================episode 351 solve======================\n",
      "------guess 0 0 heard-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toils-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 loose-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 solve-------\n",
      "reward 0 done True action 0\n",
      "episode 351 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9994441432829098  steps 1500  memory 49\n",
      "=========================episode 352 visit======================\n",
      "------guess 0 0 parka-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 ought-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 tweet-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 3 0 flint-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 midst-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 visit-------\n",
      "reward 0 done True action 0\n",
      "episode 352 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9994605713316068  steps 1506  memory 53\n",
      "optimize_model_batch -1 59\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.5075, -0.2218],\n",
      "        [ 0.0209,  0.3905],\n",
      "        [ 1.3395, -0.6740],\n",
      "        [ 1.8964, -0.7271],\n",
      "        [ 1.5087, -0.4323],\n",
      "        [ 1.1061, -0.2661]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.6747, 0.3253],\n",
      "        [0.4086, 0.5914],\n",
      "        [0.8822, 0.1178],\n",
      "        [0.9324, 0.0676],\n",
      "        [0.8745, 0.1255],\n",
      "        [0.7977, 0.2023]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 180, 'total': -582, 'avg': -3.2333333333333334} {'count': 173, 'total': -586, 'avg': -3.38728323699422}\n",
      "{'count': 191, 'total': -460, 'avg': -2.4083769633507854} {'count': 162, 'total': -355, 'avg': -2.191358024691358}\n",
      "{'count': 262, 'total': -326, 'avg': -1.2442748091603053} {'count': 83, 'total': -144, 'avg': -1.7349397590361446}\n",
      "{'count': 196, 'total': -111, 'avg': -0.5663265306122449} {'count': 64, 'total': -99, 'avg': -1.546875}\n",
      "{'count': 109, 'total': -35, 'avg': -0.3211009174311927} {'count': 29, 'total': -37, 'avg': -1.2758620689655173}\n",
      "{'count': 47, 'total': -5, 'avg': -0.10638297872340426} {'count': 10, 'total': -10, 'avg': -1.0}\n",
      "done 1506 optimizations, 1506 transitions added to memory\n",
      "=========================episode 353 giver======================\n",
      "------guess 0 0 short-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 liane-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 viper-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 giver-------\n",
      "reward 0 done True action 0\n",
      "episode 353 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9994712527348975  steps 1510  memory 0\n",
      "=========================episode 354 dingo======================\n",
      "------guess 0 0 brace-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 mount-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 dingo-------\n",
      "reward 0 done True action 0\n",
      "episode 354 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.999479124756115  steps 1513  memory 4\n",
      "=========================episode 355 lunge======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 lunge-------\n",
      "reward 0 done True action 0\n",
      "episode 355 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9994868795782053  steps 1516  memory 7\n",
      "=========================episode 356 train======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 train-------\n",
      "reward 0 done True action 0\n",
      "episode 356 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9994945189460358  steps 1519  memory 10\n",
      "=========================episode 357 wring======================\n",
      "------guess 0 0 awake-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lirot-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 wring-------\n",
      "reward 0 done True action 0\n",
      "episode 357 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9995020445784967  steps 1522  memory 13\n",
      "=========================episode 358 snide======================\n",
      "------guess 0 0 bravo-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 islet-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 spine-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 snide-------\n",
      "reward 0 done True action 0\n",
      "episode 358 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9995119047564766  steps 1526  memory 16\n",
      "=========================episode 359 charm======================\n",
      "------guess 0 0 paler-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 oints-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 guard-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 wharf-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 charm-------\n",
      "reward 0 done True action 0\n",
      "episode 359 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9995239558709778  steps 1531  memory 20\n",
      "=========================episode 360 whack======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 shady-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 chalk-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 whack-------\n",
      "reward 0 done True action 0\n",
      "episode 360 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999533382176297  steps 1535  memory 25\n",
      "=========================episode 361 swung======================\n",
      "------guess 0 0 inlet-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 oscar-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 spunk-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 swung-------\n",
      "reward 0 done True action 0\n",
      "episode 361 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9995426218282649  steps 1539  memory 29\n",
      "=========================episode 362 lumpy======================\n",
      "------guess 0 0 crier-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 loast-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 lumpy-------\n",
      "reward 0 done True action 0\n",
      "episode 362 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9995494313021099  steps 1542  memory 33\n",
      "=========================episode 363 bread======================\n",
      "------guess 0 0 shrug-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 telia-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 creak-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bread-------\n",
      "reward 0 done True action 0\n",
      "episode 363 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9995583531600947  steps 1546  memory 36\n",
      "=========================episode 364 jumbo======================\n",
      "------guess 0 0 boxer-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 alist-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 gumbo-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 jumbo-------\n",
      "reward 0 done True action 0\n",
      "episode 364 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9995670983534547  steps 1550  memory 40\n",
      "=========================episode 365 vying======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 minim-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 blind-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 vying-------\n",
      "reward 0 done True action 0\n",
      "episode 365 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999575670380384  steps 1554  memory 44\n",
      "=========================episode 366 heron======================\n",
      "------guess 0 0 corny-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 telia-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 heron-------\n",
      "reward 0 done True action 0\n",
      "episode 366 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.999581987825389  steps 1557  memory 48\n",
      "=========================episode 367 girth======================\n",
      "------guess 0 0 shank-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 epoch-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 truth-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 mirth-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 ledgy-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 girth-------\n",
      "reward 0 done True action 0\n",
      "episode 367 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9995943419521799  steps 1563  memory 51\n",
      "=========================episode 368 flume======================\n",
      "------guess 0 0 dimly-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 flume-------\n",
      "reward 0 done True action 0\n",
      "episode 368 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9996003814136963  steps 1566  memory 57\n",
      "optimize_model_batch -1 60\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.4468, -0.1612],\n",
      "        [ 0.0633,  0.3480],\n",
      "        [ 1.2934, -0.6279],\n",
      "        [ 1.8862, -0.7169],\n",
      "        [ 1.5318, -0.4553],\n",
      "        [ 1.1061, -0.2661]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.6475, 0.3525],\n",
      "        [0.4293, 0.5707],\n",
      "        [0.8723, 0.1277],\n",
      "        [0.9311, 0.0689],\n",
      "        [0.8794, 0.1206],\n",
      "        [0.7977, 0.2023]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 192, 'total': -616, 'avg': -3.2083333333333335} {'count': 177, 'total': -596, 'avg': -3.367231638418079}\n",
      "{'count': 195, 'total': -469, 'avg': -2.405128205128205} {'count': 174, 'total': -374, 'avg': -2.1494252873563218}\n",
      "{'count': 278, 'total': -338, 'avg': -1.2158273381294964} {'count': 83, 'total': -144, 'avg': -1.7349397590361446}\n",
      "{'count': 205, 'total': -114, 'avg': -0.5560975609756098} {'count': 64, 'total': -99, 'avg': -1.546875}\n",
      "{'count': 110, 'total': -35, 'avg': -0.3181818181818182} {'count': 30, 'total': -38, 'avg': -1.2666666666666666}\n",
      "{'count': 48, 'total': -5, 'avg': -0.10416666666666667} {'count': 10, 'total': -10, 'avg': -1.0}\n",
      "done 1566 optimizations, 1566 transitions added to memory\n",
      "=========================episode 369 rusty======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 rusty-------\n",
      "reward 0 done True action 0\n",
      "episode 369 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9996063309593449  steps 1569  memory 0\n",
      "=========================episode 370 trend======================\n",
      "------guess 0 0 lowly-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 retia-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dunsh-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 trend-------\n",
      "reward 0 done True action 0\n",
      "episode 370 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999614126128628  steps 1573  memory 3\n",
      "=========================episode 371 adult======================\n",
      "------guess 0 0 abbot-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 riels-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 adult-------\n",
      "reward 0 done True action 0\n",
      "episode 371 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9996198710421306  steps 1576  memory 7\n",
      "=========================episode 372 quash======================\n",
      "------guess 0 0 smirk-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 abyss-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 feast-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 quash-------\n",
      "reward 0 done True action 0\n",
      "episode 372 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9996273980998108  steps 1580  memory 10\n",
      "=========================episode 373 brood======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 brood-------\n",
      "reward 0 done True action 0\n",
      "episode 373 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999634776111763  steps 1584  memory 14\n",
      "=========================episode 374 pivot======================\n",
      "------guess 0 0 vodka-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 olive-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 ivory-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 pivot-------\n",
      "reward 0 done True action 0\n",
      "episode 374 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9996420080292902  steps 1588  memory 18\n",
      "=========================episode 375 timer======================\n",
      "------guess 0 0 shell-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 gecko-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 entry-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 truer-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 tamer-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 timer-------\n",
      "reward 0 done True action 0\n",
      "episode 375 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9996525882909785  steps 1594  memory 22\n",
      "=========================episode 376 spurn======================\n",
      "------guess 0 0 cliff-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 these-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 savvy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 sworn-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 umped-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 spurn-------\n",
      "reward 0 done True action 0\n",
      "episode 376 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9996628558586775  steps 1600  memory 28\n",
      "=========================episode 377 utter======================\n",
      "------guess 0 0 couch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 alert-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 pyins-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 utter-------\n",
      "reward 0 done True action 0\n",
      "episode 377 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9996695317599626  steps 1604  memory 34\n",
      "=========================episode 378 leach======================\n",
      "------guess 0 0 heist-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 loran-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 leach-------\n",
      "reward 0 done True action 0\n",
      "episode 378 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9996744517910796  steps 1607  memory 38\n",
      "=========================episode 379 plumb======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 plump-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 plumb-------\n",
      "reward 0 done True action 0\n",
      "episode 379 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9996808980775188  steps 1611  memory 41\n",
      "=========================episode 380 ahead======================\n",
      "------guess 0 0 phone-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 trial-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 ahead-------\n",
      "reward 0 done True action 0\n",
      "episode 380 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9996856488862135  steps 1614  memory 45\n",
      "=========================episode 381 coast======================\n",
      "------guess 0 0 large-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 avoid-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 cunts-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 coast-------\n",
      "reward 0 done True action 0\n",
      "episode 381 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999691873455314  steps 1618  memory 48\n",
      "=========================episode 382 lemur======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 ulcer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lemur-------\n",
      "reward 0 done True action 0\n",
      "episode 382 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9996964608619211  steps 1621  memory 52\n",
      "=========================episode 383 delta======================\n",
      "------guess 0 0 gripe-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 loast-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 metal-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 delta-------\n",
      "reward 0 done True action 0\n",
      "episode 383 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997024713395585  steps 1625  memory 55\n",
      "=========================episode 384 beset======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 upset-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 beset-------\n",
      "reward 0 done True action 0\n",
      "episode 384 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997083628017644  steps 1629  memory 59\n",
      "optimize_model_batch -1 63\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.3666, -0.0810],\n",
      "        [ 0.0107,  0.4007],\n",
      "        [ 1.3492, -0.6837],\n",
      "        [ 1.8701, -0.7008],\n",
      "        [ 1.6447, -0.5683],\n",
      "        [ 1.1061, -0.2661]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.6101, 0.3899],\n",
      "        [0.4037, 0.5963],\n",
      "        [0.8842, 0.1158],\n",
      "        [0.9290, 0.0710],\n",
      "        [0.9014, 0.0986],\n",
      "        [0.7977, 0.2023]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 203, 'total': -650, 'avg': -3.2019704433497536} {'count': 182, 'total': -609, 'avg': -3.3461538461538463}\n",
      "{'count': 201, 'total': -484, 'avg': -2.4079601990049753} {'count': 184, 'total': -390, 'avg': -2.119565217391304}\n",
      "{'count': 290, 'total': -349, 'avg': -1.203448275862069} {'count': 87, 'total': -148, 'avg': -1.7011494252873562}\n",
      "{'count': 216, 'total': -118, 'avg': -0.5462962962962963} {'count': 64, 'total': -99, 'avg': -1.546875}\n",
      "{'count': 111, 'total': -36, 'avg': -0.32432432432432434} {'count': 31, 'total': -39, 'avg': -1.2580645161290323}\n",
      "{'count': 50, 'total': -5, 'avg': -0.1} {'count': 10, 'total': -10, 'avg': -1.0}\n",
      "done 1629 optimizations, 1629 transitions added to memory\n",
      "=========================episode 385 shoal======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 shoal-------\n",
      "reward 0 done True action 0\n",
      "episode 385 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9997127047139858  steps 1632  memory 0\n",
      "=========================episode 386 blurb======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 blurb-------\n",
      "reward 0 done True action 0\n",
      "episode 386 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9997169819835557  steps 1635  memory 3\n",
      "=========================episode 387 lynch======================\n",
      "------guess 0 0 bring-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 month-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 hunch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 lynch-------\n",
      "reward 0 done True action 0\n",
      "episode 387 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997225861157594  steps 1639  memory 6\n",
      "=========================episode 388 lapel======================\n",
      "------guess 0 0 aging-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 raspy-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 2 0 lapel-------\n",
      "reward 0 done True action 0\n",
      "episode 388 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9997267162704229  steps 1642  memory 10\n",
      "=========================episode 389 doubt======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 point-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 moult-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 joust-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 doubt-------\n",
      "reward 0 done True action 0\n",
      "episode 389 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9997334636697474  steps 1647  memory 13\n",
      "=========================episode 390 musty======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 unity-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 musty-------\n",
      "reward 0 done True action 0\n",
      "episode 390 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9997374318787302  steps 1650  memory 18\n",
      "=========================episode 391 lusty======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 musty-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 dusty-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 lusty-------\n",
      "reward 0 done True action 0\n",
      "episode 391 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997426310758787  steps 1654  memory 21\n",
      "=========================episode 392 boost======================\n",
      "------guess 0 0 quash-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 oiler-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 canty-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 boost-------\n",
      "reward 0 done True action 0\n",
      "episode 392 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997477273220259  steps 1658  memory 25\n",
      "=========================episode 393 gummy======================\n",
      "------guess 0 0 rural-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 dumpy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 mummy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 gummy-------\n",
      "reward 0 done True action 0\n",
      "episode 393 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997527226557382  steps 1662  memory 29\n",
      "=========================episode 394 canny======================\n",
      "------guess 0 0 undue-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 manor-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 lanky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 nanny-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 canny-------\n",
      "reward 0 done True action 0\n",
      "episode 394 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9997588279551214  steps 1667  memory 33\n",
      "=========================episode 395 scour======================\n",
      "------guess 0 0 siren-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 shark-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 scour-------\n",
      "reward 0 done True action 0\n",
      "episode 395 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9997624185390916  steps 1670  memory 38\n",
      "=========================episode 396 teddy======================\n",
      "------guess 0 0 brass-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toile-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 1 whomp-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 teddy-------\n",
      "reward 0 done True action 0\n",
      "episode 396 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9997682844462619  steps 1675  memory 41\n",
      "=========================episode 397 skiff======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 ficus-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 sniff-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 skiff-------\n",
      "reward 0 done True action 0\n",
      "episode 397 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997728727216414  steps 1679  memory 46\n",
      "=========================episode 398 minim======================\n",
      "------guess 0 0 nerdy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 salto-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 pinch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 minim-------\n",
      "reward 0 done True action 0\n",
      "episode 398 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997773701430811  steps 1683  memory 50\n",
      "=========================episode 399 piper======================\n",
      "------guess 0 0 toast-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 cheer-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 riper-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 viper-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 1 flung-------\n",
      "reward -1 done False action 1\n",
      "------guess 5 0 piper-------\n",
      "reward 0 done True action 0\n",
      "episode 399 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9997839498497185  steps 1689  memory 54\n",
      "=========================episode 400 union======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 onion-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 union-------\n",
      "reward 0 done True action 0\n",
      "episode 400 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997882279293264  steps 1693  memory 60\n",
      "optimize_model_batch -1 64\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.3842, -0.0986],\n",
      "        [-0.1215,  0.5329],\n",
      "        [ 1.3920, -0.7265],\n",
      "        [ 1.8990, -0.7298],\n",
      "        [ 1.6857, -0.6092],\n",
      "        [ 1.1061, -0.2661]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.6184, 0.3816],\n",
      "        [0.3420, 0.6580],\n",
      "        [0.8927, 0.1073],\n",
      "        [0.9327, 0.0673],\n",
      "        [0.9085, 0.0915],\n",
      "        [0.7977, 0.2023]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 212, 'total': -679, 'avg': -3.202830188679245} {'count': 189, 'total': -628, 'avg': -3.322751322751323}\n",
      "{'count': 211, 'total': -505, 'avg': -2.3933649289099526} {'count': 190, 'total': -401, 'avg': -2.110526315789474}\n",
      "{'count': 304, 'total': -362, 'avg': -1.1907894736842106} {'count': 89, 'total': -151, 'avg': -1.696629213483146}\n",
      "{'count': 226, 'total': -122, 'avg': -0.5398230088495575} {'count': 65, 'total': -100, 'avg': -1.5384615384615385}\n",
      "{'count': 114, 'total': -36, 'avg': -0.3157894736842105} {'count': 32, 'total': -40, 'avg': -1.25}\n",
      "{'count': 51, 'total': -5, 'avg': -0.09803921568627451} {'count': 10, 'total': -10, 'avg': -1.0}\n",
      "done 1693 optimizations, 1693 transitions added to memory\n",
      "=========================episode 401 heavy======================\n",
      "------guess 0 0 twirl-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 hedge-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 heavy-------\n",
      "reward 0 done True action 0\n",
      "episode 401 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.999791380804705  steps 1696  memory 0\n",
      "=========================episode 402 lynch======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 lynch-------\n",
      "reward 0 done True action 0\n",
      "episode 402 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9997955117415455  steps 1700  memory 3\n",
      "=========================episode 403 audio======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 audio-------\n",
      "reward 0 done True action 0\n",
      "episode 403 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9997985561750878  steps 1703  memory 7\n",
      "=========================episode 404 filmy======================\n",
      "------guess 0 0 relic-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 santo-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 billy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 filmy-------\n",
      "reward 0 done True action 0\n",
      "episode 404 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998025450300753  steps 1707  memory 10\n",
      "=========================episode 405 bongo======================\n",
      "------guess 0 0 murky-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toeas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 logic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bongo-------\n",
      "reward 0 done True action 0\n",
      "episode 405 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999806454900442  steps 1711  memory 14\n",
      "=========================episode 406 vague======================\n",
      "------guess 0 0 whack-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 1 roset-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 angle-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 vague-------\n",
      "reward 0 done True action 0\n",
      "episode 406 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998102873501882  steps 1715  memory 18\n",
      "=========================episode 407 wider======================\n",
      "------guess 0 0 gamut-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 reoil-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 cider-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 wider-------\n",
      "reward 0 done True action 0\n",
      "episode 407 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998140439123449  steps 1719  memory 22\n",
      "=========================episode 408 segue======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 nudge-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 segue-------\n",
      "reward 0 done True action 0\n",
      "episode 408 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9998168124378091  steps 1722  memory 26\n",
      "=========================episode 409 punch======================\n",
      "------guess 0 0 tryst-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 anole-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 pinch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 punch-------\n",
      "reward 0 done True action 0\n",
      "episode 409 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998204397945741  steps 1726  memory 29\n",
      "=========================episode 410 gecko======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 ebony-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 sulci-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 gecko-------\n",
      "reward 0 done True action 0\n",
      "episode 410 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998239953248629  steps 1730  memory 33\n",
      "=========================episode 411 child======================\n",
      "------guess 0 0 curvy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 stoae-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 pling-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 chill-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 child-------\n",
      "reward 0 done True action 0\n",
      "episode 411 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9998283408957754  steps 1735  memory 37\n",
      "=========================episode 412 jelly======================\n",
      "------guess 0 0 known-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 artel-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 leggy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 belly-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 jelly-------\n",
      "reward 0 done True action 0\n",
      "episode 412 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9998325791741599  steps 1740  memory 42\n",
      "=========================episode 413 rainy======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 rapid-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 rainy-------\n",
      "reward 0 done True action 0\n",
      "episode 413 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9998350717455268  steps 1743  memory 47\n",
      "=========================episode 414 laugh======================\n",
      "------guess 0 0 prior-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 slate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 badly-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 laugh-------\n",
      "reward 0 done True action 0\n",
      "episode 414 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998383375437745  steps 1747  memory 50\n",
      "=========================episode 415 viola======================\n",
      "------guess 0 0 ghoul-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 terai-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 viola-------\n",
      "reward 0 done True action 0\n",
      "episode 415 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9998407443841867  steps 1750  memory 54\n",
      "=========================episode 416 cheat======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 exact-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 cleat-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 cheat-------\n",
      "reward 0 done True action 0\n",
      "episode 416 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998438978566632  steps 1754  memory 57\n",
      "optimize_model_batch -1 61\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.3538, -0.0682],\n",
      "        [-0.0691,  0.4805],\n",
      "        [ 1.4709, -0.8054],\n",
      "        [ 1.8955, -0.7262],\n",
      "        [ 1.7291, -0.6526],\n",
      "        [ 1.1061, -0.2661]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.6040, 0.3960],\n",
      "        [0.3660, 0.6340],\n",
      "        [0.9069, 0.0931],\n",
      "        [0.9322, 0.0678],\n",
      "        [0.9154, 0.0846],\n",
      "        [0.7977, 0.2023]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 222, 'total': -709, 'avg': -3.1936936936936937} {'count': 195, 'total': -643, 'avg': -3.2974358974358973}\n",
      "{'count': 216, 'total': -512, 'avg': -2.3703703703703702} {'count': 201, 'total': -423, 'avg': -2.1044776119402986}\n",
      "{'count': 317, 'total': -371, 'avg': -1.1703470031545742} {'count': 92, 'total': -155, 'avg': -1.684782608695652}\n",
      "{'count': 237, 'total': -124, 'avg': -0.5232067510548524} {'count': 65, 'total': -100, 'avg': -1.5384615384615385}\n",
      "{'count': 116, 'total': -36, 'avg': -0.3103448275862069} {'count': 32, 'total': -40, 'avg': -1.25}\n",
      "{'count': 51, 'total': -5, 'avg': -0.09803921568627451} {'count': 10, 'total': -10, 'avg': -1.0}\n",
      "done 1754 optimizations, 1754 transitions added to memory\n",
      "=========================episode 417 palsy======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 sadly-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 palsy-------\n",
      "reward 0 done True action 0\n",
      "episode 417 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998469888862008  steps 1758  memory 0\n",
      "=========================episode 418 sword======================\n",
      "------guess 0 0 showy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 artel-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 sworn-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 sword-------\n",
      "reward 0 done True action 0\n",
      "episode 418 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998500187092529  steps 1762  memory 4\n",
      "=========================episode 419 month======================\n",
      "------guess 0 0 enact-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 loris-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 month-------\n",
      "reward 0 done True action 0\n",
      "episode 419 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.999852251639768  steps 1765  memory 8\n",
      "=========================episode 420 ascot======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 total-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 about-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 ascot-------\n",
      "reward 0 done True action 0\n",
      "episode 420 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998551772533173  steps 1769  memory 11\n",
      "=========================episode 421 crypt======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 crypt-------\n",
      "reward 0 done True action 0\n",
      "episode 421 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9998573333831168  steps 1772  memory 15\n",
      "=========================episode 422 rarer======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 lager-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 maker-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 incus-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 parer-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 rarer-------\n",
      "reward 0 done True action 0\n",
      "episode 422 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9998615498188592  steps 1778  memory 18\n",
      "=========================episode 423 sonar======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 sonar-------\n",
      "reward 0 done True action 0\n",
      "episode 423 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.999863611073518  steps 1781  memory 24\n",
      "=========================episode 424 forth======================\n",
      "------guess 0 0 seedy-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 1 rotal-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 worth-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 forth-------\n",
      "reward 0 done True action 0\n",
      "episode 424 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998663117552086  steps 1785  memory 27\n",
      "=========================episode 425 quark======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 drama-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 wharf-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 quark-------\n",
      "reward 0 done True action 0\n",
      "episode 425 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9998696125297333  steps 1790  memory 31\n",
      "=========================episode 426 rowdy======================\n",
      "------guess 0 0 slink-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 poppy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 moody-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 wordy-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 rowdy-------\n",
      "reward 0 done True action 0\n",
      "episode 426 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9998728318078446  steps 1795  memory 36\n",
      "=========================episode 427 carat======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 tardy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 carat-------\n",
      "reward 0 done True action 0\n",
      "episode 427 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.99987472509557  steps 1798  memory 41\n",
      "=========================episode 428 lanky======================\n",
      "------guess 0 0 valor-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 nites-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 manly-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 lanky-------\n",
      "reward 0 done True action 0\n",
      "episode 428 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999877205704879  steps 1802  memory 44\n",
      "=========================episode 429 lapel======================\n",
      "------guess 0 0 clang-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 vital-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 awful-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 label-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 lapel-------\n",
      "reward 0 done True action 0\n",
      "episode 429 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.999880237506828  steps 1807  memory 48\n",
      "=========================episode 430 silly======================\n",
      "------guess 0 0 otter-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 nails-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 duchy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 silly-------\n",
      "reward 0 done True action 0\n",
      "episode 430 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998826089630809  steps 1811  memory 53\n",
      "=========================episode 431 death======================\n",
      "------guess 0 0 essay-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lirot-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 theta-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 death-------\n",
      "reward 0 done True action 0\n",
      "episode 431 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998849334613538  steps 1815  memory 57\n",
      "=========================episode 432 craft======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 draft-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 craft-------\n",
      "reward 0 done True action 0\n",
      "episode 432 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999887211931477  steps 1819  memory 61\n",
      "optimize_model_batch -1 65\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.4304, -0.1448],\n",
      "        [-0.1073,  0.5186],\n",
      "        [ 1.4499, -0.7844],\n",
      "        [ 1.9769, -0.8076],\n",
      "        [ 1.7212, -0.6447],\n",
      "        [ 1.1061, -0.2661]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.6399, 0.3601],\n",
      "        [0.3484, 0.6516],\n",
      "        [0.9033, 0.0967],\n",
      "        [0.9418, 0.0582],\n",
      "        [0.9142, 0.0858],\n",
      "        [0.7977, 0.2023]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 230, 'total': -734, 'avg': -3.1913043478260867} {'count': 203, 'total': -667, 'avg': -3.2857142857142856}\n",
      "{'count': 221, 'total': -525, 'avg': -2.3755656108597285} {'count': 212, 'total': -443, 'avg': -2.089622641509434}\n",
      "{'count': 332, 'total': -387, 'avg': -1.1656626506024097} {'count': 93, 'total': -156, 'avg': -1.6774193548387097}\n",
      "{'count': 248, 'total': -127, 'avg': -0.5120967741935484} {'count': 66, 'total': -102, 'avg': -1.5454545454545454}\n",
      "{'count': 120, 'total': -37, 'avg': -0.30833333333333335} {'count': 32, 'total': -40, 'avg': -1.25}\n",
      "{'count': 52, 'total': -5, 'avg': -0.09615384615384616} {'count': 10, 'total': -10, 'avg': -1.0}\n",
      "done 1819 optimizations, 1819 transitions added to memory\n",
      "=========================episode 433 shard======================\n",
      "------guess 0 0 biome-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 sassy-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 staff-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 shawl-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 shank-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 1 crude-------\n",
      "reward -1 done True action 1\n",
      "episode 433 finished.  reward -6  eps [0.9, 0.05, 200]  gamma 0.9998905453226643  steps 1825  memory 0\n",
      "=========================episode 434 imbue======================\n",
      "------guess 0 0 wince-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 raise-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 belie-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 imbue-------\n",
      "reward 0 done True action 0\n",
      "episode 434 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9998927126704883  steps 1829  memory 6\n",
      "=========================episode 435 fever======================\n",
      "------guess 0 0 wheel-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 ratio-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 scree-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 defer-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 fever-------\n",
      "reward 0 done True action 0\n",
      "episode 435 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9998953616040922  steps 1834  memory 10\n",
      "=========================episode 436 again======================\n",
      "------guess 0 0 manor-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 teils-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 again-------\n",
      "reward 0 done True action 0\n",
      "episode 436 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9998969194668503  steps 1837  memory 15\n",
      "=========================episode 437 budge======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 queue-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 judge-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 budge-------\n",
      "reward 0 done True action 0\n",
      "episode 437 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9998994645342819  steps 1842  memory 18\n",
      "=========================episode 438 grill======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 drill-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 frill-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 grill-------\n",
      "reward 0 done True action 0\n",
      "episode 438 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.9999024358063306  steps 1848  memory 23\n",
      "=========================episode 439 humus======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 mucus-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 humus-------\n",
      "reward 0 done True action 0\n",
      "episode 439 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999043677068031  steps 1852  memory 29\n",
      "=========================episode 440 vapid======================\n",
      "------guess 0 0 exert-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 plunk-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 swoop-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 hippy-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 4 0 vapid-------\n",
      "reward 0 done True action 0\n",
      "episode 440 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999067288765351  steps 1857  memory 33\n",
      "=========================episode 441 rodeo======================\n",
      "------guess 0 0 parry-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toile-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 homer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 rodeo-------\n",
      "reward 0 done True action 0\n",
      "episode 441 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999085757685219  steps 1861  memory 38\n",
      "=========================episode 442 teach======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 teach-------\n",
      "reward 0 done True action 0\n",
      "episode 442 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999099368980018  steps 1864  memory 42\n",
      "=========================episode 443 apnea======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 abbey-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 1 linds-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 annex-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 apnea-------\n",
      "reward 0 done True action 0\n",
      "episode 443 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999121605639132  steps 1869  memory 45\n",
      "=========================episode 444 chalk======================\n",
      "------guess 0 0 miner-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lotas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 awful-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 chalk-------\n",
      "reward 0 done True action 0\n",
      "episode 444 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999138999012837  steps 1873  memory 50\n",
      "=========================episode 445 freer======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 creek-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 green-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 freer-------\n",
      "reward 0 done True action 0\n",
      "episode 445 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999156047974667  steps 1877  memory 54\n",
      "=========================episode 446 naive======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 naive-------\n",
      "reward 0 done True action 0\n",
      "episode 446 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999168612783392  steps 1880  memory 58\n",
      "=========================episode 447 nosey======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 nosey-------\n",
      "reward 0 done True action 0\n",
      "episode 447 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999180990526486  steps 1883  memory 61\n",
      "=========================episode 448 today======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 atoll-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 today-------\n",
      "reward 0 done True action 0\n",
      "episode 448 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999193183988994  steps 1886  memory 64\n",
      "optimize_model_batch -1 67\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.5013, -0.2157],\n",
      "        [-0.1510,  0.5624],\n",
      "        [ 1.5450, -0.8795],\n",
      "        [ 1.9505, -0.7812],\n",
      "        [ 1.6957, -0.6193],\n",
      "        [ 1.2743, -0.4344]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.6719, 0.3281],\n",
      "        [0.3289, 0.6711],\n",
      "        [0.9187, 0.0813],\n",
      "        [0.9389, 0.0611],\n",
      "        [0.9101, 0.0899],\n",
      "        [0.8467, 0.1533]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 237, 'total': -759, 'avg': -3.2025316455696204} {'count': 212, 'total': -694, 'avg': -3.2735849056603774}\n",
      "{'count': 227, 'total': -541, 'avg': -2.383259911894273} {'count': 222, 'total': -463, 'avg': -2.0855855855855854}\n",
      "{'count': 346, 'total': -402, 'avg': -1.1618497109826589} {'count': 95, 'total': -161, 'avg': -1.694736842105263}\n",
      "{'count': 259, 'total': -136, 'avg': -0.525096525096525} {'count': 66, 'total': -102, 'avg': -1.5454545454545454}\n",
      "{'count': 126, 'total': -40, 'avg': -0.31746031746031744} {'count': 32, 'total': -40, 'avg': -1.25}\n",
      "{'count': 53, 'total': -5, 'avg': -0.09433962264150944} {'count': 11, 'total': -11, 'avg': -1.0}\n",
      "done 1886 optimizations, 1886 transitions added to memory\n",
      "=========================episode 449 onset======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 onset-------\n",
      "reward 0 done True action 0\n",
      "episode 449 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999205195914495  steps 1889  memory 0\n",
      "=========================episode 450 fetch======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 smelt-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 teddy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 fetch-------\n",
      "reward 0 done True action 0\n",
      "episode 450 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999220934089849  steps 1893  memory 3\n",
      "=========================episode 451 pulse======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 elude-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 uncle-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bulge-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 pulse-------\n",
      "reward 0 done True action 0\n",
      "episode 451 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999240169295706  steps 1898  memory 7\n",
      "=========================episode 452 youth======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 booty-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 youth-------\n",
      "reward 0 done True action 0\n",
      "episode 452 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999255214951713  steps 1902  memory 12\n",
      "=========================episode 453 carat======================\n",
      "------guess 0 0 lying-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 trout-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 smart-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 carat-------\n",
      "reward 0 done True action 0\n",
      "episode 453 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999269962683771  steps 1906  memory 16\n",
      "=========================episode 454 kneel======================\n",
      "------guess 0 0 broom-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 telia-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 synch-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 kneel-------\n",
      "reward 0 done True action 0\n",
      "episode 454 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999284418391168  steps 1910  memory 20\n",
      "=========================episode 455 muddy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 fluff-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 musky-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 muddy-------\n",
      "reward 0 done True action 0\n",
      "episode 455 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999929858785638  steps 1914  memory 24\n",
      "=========================episode 456 expel======================\n",
      "------guess 0 0 cinch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 seedy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 1 plumb-------\n",
      "reward -1 done False action 1\n",
      "------guess 4 0 expel-------\n",
      "reward 0 done True action 0\n",
      "episode 456 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.999931590578391  steps 1919  memory 28\n",
      "=========================episode 457 mower======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 homer-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 mower-------\n",
      "reward 0 done True action 0\n",
      "episode 457 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999329451756972  steps 1923  memory 33\n",
      "=========================episode 458 rotor======================\n",
      "------guess 0 0 toxin-------\n",
      "reward -1 done False action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 1 1 laers-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 rotor-------\n",
      "reward 0 done True action 0\n",
      "episode 458 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999339434919713  steps 1926  memory 37\n",
      "=========================episode 459 harsh======================\n",
      "------guess 0 0 serve-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 tonal-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 marsh-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 harsh-------\n",
      "reward 0 done True action 0\n",
      "episode 459 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999935251498467  steps 1930  memory 40\n",
      "=========================episode 460 crush======================\n",
      "------guess 0 0 idyll-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 gruff-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 crumb-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 crush-------\n",
      "reward 0 done True action 0\n",
      "episode 460 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999368501446659  steps 1935  memory 44\n",
      "=========================episode 461 flank======================\n",
      "------guess 0 0 rigor-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 stale-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 clack-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 blank-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 flank-------\n",
      "reward 0 done True action 0\n",
      "episode 461 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999384093201494  steps 1940  memory 49\n",
      "=========================episode 462 parer======================\n",
      "------guess 0 0 plied-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 puree-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 parer-------\n",
      "reward 0 done True action 0\n",
      "episode 462 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.999939326285911  steps 1943  memory 54\n",
      "=========================episode 463 queen======================\n",
      "------guess 0 0 thing-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 demon-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 raven-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 queen-------\n",
      "reward 0 done True action 0\n",
      "episode 463 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999405277059453  steps 1947  memory 57\n",
      "=========================episode 464 trout======================\n",
      "------guess 0 0 masse-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lirot-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 cundy-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 trout-------\n",
      "reward 0 done True action 0\n",
      "episode 464 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999417053362691  steps 1951  memory 61\n",
      "optimize_model_batch -1 65\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.6042, -0.3186],\n",
      "        [-0.1914,  0.6027],\n",
      "        [ 1.5511, -0.8856],\n",
      "        [ 1.9896, -0.8203],\n",
      "        [ 1.6955, -0.6191],\n",
      "        [ 1.2746, -0.4346]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.7156, 0.2844],\n",
      "        [0.3113, 0.6887],\n",
      "        [0.9196, 0.0804],\n",
      "        [0.9432, 0.0568],\n",
      "        [0.9101, 0.0899],\n",
      "        [0.8467, 0.1533]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 247, 'total': -790, 'avg': -3.1983805668016196} {'count': 218, 'total': -712, 'avg': -3.2660550458715596}\n",
      "{'count': 233, 'total': -553, 'avg': -2.3733905579399144} {'count': 232, 'total': -484, 'avg': -2.086206896551724}\n",
      "{'count': 360, 'total': -417, 'avg': -1.1583333333333334} {'count': 97, 'total': -163, 'avg': -1.6804123711340206}\n",
      "{'count': 271, 'total': -139, 'avg': -0.5129151291512916} {'count': 67, 'total': -103, 'avg': -1.537313432835821}\n",
      "{'count': 130, 'total': -40, 'avg': -0.3076923076923077} {'count': 32, 'total': -40, 'avg': -1.25}\n",
      "{'count': 53, 'total': -5, 'avg': -0.09433962264150944} {'count': 11, 'total': -11, 'avg': -1.0}\n",
      "done 1951 optimizations, 1951 transitions added to memory\n",
      "=========================episode 465 pleat======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 bleat-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 cleat-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 pleat-------\n",
      "reward 0 done True action 0\n",
      "episode 465 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999431446366449  steps 1956  memory 0\n",
      "=========================episode 466 fight======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 light-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 tight-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 wight-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 fight-------\n",
      "reward 0 done True action 0\n",
      "episode 466 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999445484005678  steps 1961  memory 5\n",
      "=========================episode 467 penne======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 while-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 fugue-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 pence-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 penne-------\n",
      "reward 0 done True action 0\n",
      "episode 467 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999459175054359  steps 1966  memory 10\n",
      "=========================episode 468 lefty======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 lefty-------\n",
      "reward 0 done True action 0\n",
      "episode 468 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999467226888814  steps 1969  memory 15\n",
      "=========================episode 469 dwell======================\n",
      "------guess 0 0 decal-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 dwell-------\n",
      "reward 0 done True action 0\n",
      "episode 469 finished.  reward -1  eps [0.9, 0.05, 200]  gamma 0.9999472528069845  steps 1971  memory 18\n",
      "=========================episode 470 flack======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 clamp-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 black-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 flack-------\n",
      "reward 0 done True action 0\n",
      "episode 470 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999485551398203  steps 1976  memory 20\n",
      "=========================episode 471 tulip======================\n",
      "------guess 0 0 stake-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 mount-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 dutch-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 tulip-------\n",
      "reward 0 done True action 0\n",
      "episode 471 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999495738163034  steps 1980  memory 25\n",
      "=========================episode 472 antic======================\n",
      "------guess 0 0 decor-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 alist-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 antic-------\n",
      "reward 0 done True action 0\n",
      "episode 472 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999503245643718  steps 1983  memory 29\n",
      "=========================episode 473 glare======================\n",
      "------guess 0 0 bagel-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 gleam-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 glaze-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 glade-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 glare-------\n",
      "reward 0 done True action 0\n",
      "episode 473 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999515510552476  steps 1988  memory 32\n",
      "=========================episode 474 frail======================\n",
      "------guess 0 0 clued-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 ariot-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 grail-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 frail-------\n",
      "reward 0 done True action 0\n",
      "episode 474 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999525104086305  steps 1992  memory 37\n",
      "=========================episode 475 radio======================\n",
      "------guess 0 0 grill-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 toeas-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 radio-------\n",
      "reward 0 done True action 0\n",
      "episode 475 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999532174365351  steps 1995  memory 41\n",
      "=========================episode 476 broke======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 0 froze-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 prone-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 erode-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 broke-------\n",
      "reward 0 done True action 0\n",
      "episode 476 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999543725021426  steps 2000  memory 44\n",
      "=========================episode 477 basal======================\n",
      "------guess 0 0 quirk-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 gnash-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 salve-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 basal-------\n",
      "reward 0 done True action 0\n",
      "episode 477 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999552759871339  steps 2004  memory 49\n",
      "=========================episode 478 quail======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 avail-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 flail-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 quail-------\n",
      "reward 0 done True action 0\n",
      "episode 478 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.999956380226946  steps 2009  memory 53\n",
      "=========================episode 479 flail======================\n",
      "------guess 0 0 pitch-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 realo-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 dungs-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 avail-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 flail-------\n",
      "reward 0 done True action 0\n",
      "episode 479 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999574572029799  steps 2014  memory 58\n",
      "=========================episode 480 wacky======================\n",
      "------guess 0 0 stake-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 loric-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 wacky-------\n",
      "reward 0 done True action 0\n",
      "episode 480 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999580905827115  steps 2017  memory 63\n",
      "optimize_model_batch -1 66\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.7531, -0.4675],\n",
      "        [-0.3038,  0.7152],\n",
      "        [ 1.5584, -0.8929],\n",
      "        [ 1.9683, -0.7990],\n",
      "        [ 1.6955, -0.6191],\n",
      "        [ 1.2746, -0.4346]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.7722, 0.2278],\n",
      "        [0.2652, 0.7348],\n",
      "        [0.9207, 0.0793],\n",
      "        [0.9409, 0.0591],\n",
      "        [0.9101, 0.0899],\n",
      "        [0.8467, 0.1533]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 256, 'total': -814, 'avg': -3.1796875} {'count': 225, 'total': -738, 'avg': -3.28}\n",
      "{'count': 240, 'total': -569, 'avg': -2.370833333333333} {'count': 241, 'total': -502, 'avg': -2.08298755186722}\n",
      "{'count': 374, 'total': -434, 'avg': -1.160427807486631} {'count': 98, 'total': -165, 'avg': -1.683673469387755}\n",
      "{'count': 282, 'total': -147, 'avg': -0.5212765957446809} {'count': 67, 'total': -103, 'avg': -1.537313432835821}\n",
      "{'count': 138, 'total': -40, 'avg': -0.2898550724637681} {'count': 32, 'total': -40, 'avg': -1.25}\n",
      "{'count': 53, 'total': -5, 'avg': -0.09433962264150944} {'count': 11, 'total': -11, 'avg': -1.0}\n",
      "done 2017 optimizations, 2017 transitions added to memory\n",
      "=========================episode 481 abase======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 shave-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 abase-------\n",
      "reward 0 done True action 0\n",
      "episode 481 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999589204447747  steps 2021  memory 0\n",
      "=========================episode 482 smith======================\n",
      "------guess 0 0 denim-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 skimp-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 smith-------\n",
      "reward 0 done True action 0\n",
      "episode 482 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.999959532039674  steps 2024  memory 4\n",
      "=========================episode 483 merit======================\n",
      "------guess 0 0 bulge-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 ariot-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 remit-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 merit-------\n",
      "reward 0 done True action 0\n",
      "episode 483 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.999960333358977  steps 2028  memory 7\n",
      "=========================episode 484 radii======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 rabid-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 radii-------\n",
      "reward 0 done True action 0\n",
      "episode 484 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999611188110947  steps 2032  memory 11\n",
      "=========================episode 485 duvet======================\n",
      "------guess 0 0 dance-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lirot-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 debut-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 duvet-------\n",
      "reward 0 done True action 0\n",
      "episode 485 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999618887102184  steps 2036  memory 15\n",
      "=========================episode 486 floss======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 gloss-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 floss-------\n",
      "reward 0 done True action 0\n",
      "episode 486 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999628296813159  steps 2041  memory 19\n",
      "=========================episode 487 bezel======================\n",
      "------guess 0 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 bezel-------\n",
      "reward 0 done True action 0\n",
      "episode 487 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999633830752654  steps 2044  memory 24\n",
      "=========================episode 488 poppy======================\n",
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 comfy-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bobby-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 howdy-------\n",
      "reward -1 done False action 0\n",
      "------guess 5 0 poppy-------\n",
      "reward 0 done True action 0\n",
      "episode 488 finished.  reward -5  eps [0.9, 0.05, 200]  gamma 0.999964465268939  steps 2050  memory 27\n",
      "=========================episode 489 lemon======================\n",
      "------guess 0 0 guilt-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 arose-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 hovel-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 melon-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 lemon-------\n",
      "reward 0 done True action 0\n",
      "episode 489 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.999965342624575  steps 2055  memory 33\n",
      "=========================episode 490 white======================\n",
      "------guess 0 0 bless-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 mince-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 guide-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 white-------\n",
      "reward 0 done True action 0\n",
      "episode 490 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999660288865881  steps 2059  memory 38\n",
      "=========================episode 491 fiend======================\n",
      "------guess 0 0 early-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 oints-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 widen-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 fiend-------\n",
      "reward 0 done True action 0\n",
      "episode 491 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999668676363668  steps 2064  memory 42\n",
      "=========================episode 492 sloth======================\n",
      "------guess 0 1 orate-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 1 chump-------\n",
      "reward -1 done False action 1\n",
      "------guess 3 0 sloth-------\n",
      "reward 0 done True action 0\n",
      "episode 492 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999675237011232  steps 2068  memory 47\n",
      "=========================episode 493 valor======================\n",
      "------guess 0 0 spear-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 lotic-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 valor-------\n",
      "reward 0 done True action 0\n",
      "episode 493 finished.  reward -2  eps [0.9, 0.05, 200]  gamma 0.9999680072102223  steps 2071  memory 51\n",
      "=========================episode 494 pence======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------guess 0 1 oater-------\n",
      "reward -1 done False action 1\n",
      "------guess 1 1 lysin-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 nudge-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 penne-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 pence-------\n",
      "reward 0 done True action 0\n",
      "episode 494 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999687971150164  steps 2076  memory 54\n",
      "=========================episode 495 sandy======================\n",
      "------guess 0 0 arson-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 telic-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 spank-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 sandy-------\n",
      "reward 0 done True action 0\n",
      "episode 495 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999694149735358  steps 2080  memory 59\n",
      "=========================episode 496 bride======================\n",
      "------guess 0 0 fizzy-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 roate-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 brine-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 bribe-------\n",
      "reward -1 done False action 0\n",
      "------guess 4 0 bride-------\n",
      "reward 0 done True action 0\n",
      "episode 496 finished.  reward -4  eps [0.9, 0.05, 200]  gamma 0.9999701701205297  steps 2085  memory 63\n",
      "optimize_model_batch -1 68\n",
      "monte weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.9182, -0.6326],\n",
      "        [-0.1942,  0.6056],\n",
      "        [ 1.7010, -1.0355],\n",
      "        [ 1.9452, -0.7759],\n",
      "        [ 1.6857, -0.6093],\n",
      "        [ 1.2746, -0.4346]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[0.8250, 0.1750],\n",
      "        [0.3101, 0.6899],\n",
      "        [0.9391, 0.0609],\n",
      "        [0.9383, 0.0617],\n",
      "        [0.9085, 0.0915],\n",
      "        [0.8467, 0.1533]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "{'count': 265, 'total': -842, 'avg': -3.177358490566038} {'count': 232, 'total': -762, 'avg': -3.2844827586206895}\n",
      "{'count': 242, 'total': -572, 'avg': -2.3636363636363638} {'count': 255, 'total': -535, 'avg': -2.0980392156862746}\n",
      "{'count': 387, 'total': -449, 'avg': -1.1602067183462532} {'count': 101, 'total': -170, 'avg': -1.683168316831683}\n",
      "{'count': 295, 'total': -154, 'avg': -0.5220338983050847} {'count': 67, 'total': -103, 'avg': -1.537313432835821}\n",
      "{'count': 144, 'total': -41, 'avg': -0.2847222222222222} {'count': 32, 'total': -40, 'avg': -1.25}\n",
      "{'count': 54, 'total': -5, 'avg': -0.09259259259259259} {'count': 11, 'total': -11, 'avg': -1.0}\n",
      "done 2085 optimizations, 2085 transitions added to memory\n",
      "=========================episode 497 swash======================\n",
      "------guess 0 0 belie-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 ratos-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 smash-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 swash-------\n",
      "reward 0 done True action 0\n",
      "episode 497 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999707607917183  steps 2089  memory 0\n",
      "=========================episode 498 antic======================\n",
      "------guess 0 0 spend-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 0 brawn-------\n",
      "reward -1 done False action 0\n",
      "------guess 2 0 manic-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 antic-------\n",
      "reward 0 done True action 0\n",
      "episode 498 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999713397668338  steps 2093  memory 4\n",
      "=========================episode 499 wryly======================\n",
      "------guess 0 0 midst-------\n",
      "reward -1 done False action 0\n",
      "------guess 1 1 realo-------\n",
      "reward -1 done False action 1\n",
      "------guess 2 0 curly-------\n",
      "reward -1 done False action 0\n",
      "------guess 3 0 wryly-------\n",
      "reward 0 done True action 0\n",
      "episode 499 finished.  reward -3  eps [0.9, 0.05, 200]  gamma 0.9999719072774738  steps 2097  memory 8\n",
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEWCAYAAABv+EDhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABW1UlEQVR4nO2dd5jcxPnHv6+2Xj+Xcy/nim1sY8wZMMYGY2NM7z10ML33mABJCDiUEPgBAVMSSKgJhBI6hJqEYnoHAwZsXA7cy22d3x8qK2klrbZotXf7fp7nntvVSjOj0Wjemfd95x0SQoBhGIapPiS/C8AwDMP4AwsAhmGYKoUFAMMwTJXCAoBhGKZKYQHAMAxTpbAAYBiGqVJYADCMA0T0NBEdVepzGaYSIF4HwHQ1iGi97mstgBiAlPL9RCHEveUvFcNUHiwAmC4NES0CcLwQ4gWL34JCiGT5S8UwlQGrgJiqgYh2JKLFRHQhES0D8Gci6kZE/yKidiJapXweoLvmZSI6Xvl8NBG9TkTXKud+S0S7FnjuECJ6lYjWEdELRHQzEf2tjNXBMCwAmKqjD4DuAAYDmAP5Hfiz8n0QgE0AbnK4fhsAXwDoCeBqAHcSERVw7n0A3gLQA8DlAI4o+I4YpkBYADDVRhrAZUKImBBikxDiZyHEw0KIjUKIdQB+B2AHh+u/E0LcLoRIAbgbQF8AvfM5l4gGAZgE4FIhRFwI8TqAx0t1gwzjFhYATLXRLoToUL8QUS0R3UZE3xHRWgCvAmgmooDN9cvUD0KIjcrH+jzP7Qdgpe4YAPyQ530wTNGwAGCqDbPXw7kANgOwjRCiEcA05bidWqcULAXQnYhqdccGepgfw1jCAoCpdhog6/1XE1F3AJd5naEQ4jsACwBcTkRhIpoMYE+v82UYMywAmGrnjwBqAPwE4A0Az5Qp38MBTAbwM4ArADwIeb0CAHktAxFNVT5P1a9tIKJfEtHTZSon04XhdQAMUwEQ0YMAPhdCeD4DYRgVngEwjA8Q0SQiGkZEEhHNBrA3gEd9LhZTZQT9LgDDVCl9ADwCeR3AYgAnCyHe87dITLXBKiCGYZgqhVVADMMwVUqnUgH17NlTtLa2+l0MhmGYTsU777zzkxCixXy8UwmA1tZWLFiwwO9iMAzDdCqI6Dur46wCYhiGqVJYADAMw1QpLAAYhmGqFBYADMMwVQoLAIZhmCrFVwFARLOJ6AsiWkhEF/lZFoZhmGrDNwGgbLhxM4BdAYwBcCgRjfGrPAzDMNWGn+sAtgawUAjxDQAQ0QOQA2J96mWmj72/BJ8uXYuV6+P4csV6TBnWA3uM74cH3v4eybTAzqN74+7/LUK/5hoEJcLCFevR2rMOzTUhBCTCqo1x1IWDCEiElBAISoSVG+IIShKaa0NIC4HXF/6M3cf1QVtrd9z5+rcQQmBQ9zp0qw1h8apN+H7lRkwY2IyXv2xH99oQ+jXXQADoVhvCpz+uxfpYEnWRIFZtTODH1Zvw273H4vuVG7CuI4mGaBDfr9yIZEognkpj+doO/Gfhz/jHSZPx3ver8dyny9DSEIEQwISBzfhu5UY01YRQHwni82Xr0FQTRFoA8WQa6bRAJBTAxngSASKcMn04rn32C2yIJ9E2uDuGttTh+U+XIygRiAifLl2LPo0R1EXkZtORSKF9fRz9m6NYsroDDZEgWnvWIihJWLspgZljemO3cX3x3CfL8MmPa7HfxP74xzuLsa4jicaaEDbGknj7u1VYunoT6qNBTBrcHS0NEdQr99i/uQbvfLcKvRoiiKfSCEkSft4QRyQo4fNlayEE0L9bDfo11SCZlp/F29+txNh+TWiuDSGWSCMlBOojQXy0ZA0mtXbHi58tR0Ai9KyPoG9TFF8sX4evlq/HVoO7gQiojwSxamMckWAAc6YNxSc/rsGTHy5Fn6YogpKEdbEkBnarwbqOJPbcoh+++3kDVm2MY2M8hVe+bMf4/k1YvSmB3g1RrNmUwFcr1qFfcw3WdiQxeWgPAMAnP66BRIRPflyLCQObMaRnLVasi6EhGsQ37RswbkAT2tfFsHZTEpGQhNpQAF+3r8fgHnXYEEti9cYE+jRFsXm/RqzrSEJAoH1dDKs3JrCwfT36N9egW20YA7rV4KMla5BMCQxpqUNjNIT2dTHsOrYP/vrGdxjXvwlvL1qJeCqNvk1RpNICAYnw+bJ1GN23ET3rwvhs2TpMGNiMH1ZuxMZ4Ct3rwlgfS6IjkcKaTQkQgHhKYPGqjdhiQDPWxZKYNaY3nv54KZas2oSx/ZvQsz6C9nVypGsBgZ71Efy4ehPiKYHGaBA1oQC2GtwNP2+I481vV0IIASJCfSSApWs60LMugtpIAKm0QO/GKFasi6GlPoK0EOjVEMEb3/wMEKFPYwQb4yms60hieK96REMSvli2DvFkGv2aa/Djmg5EgxKGttRh1YYEuteHsXDFeozp24hvf9qAgd1rsN/EAfjHO4uxZmMCm/dvxKc/rkUsmUZtOIA1mxJYuGI90mmBLQd1QyQkYfXGBOojQSRSaayPJTGspR4LV6xHNBTA0JY6rI8l8fLnK7DFwGas60iiPhJEMp1Gz/oIJInw1fJM+SJBCcm0QP9uNVi7KYHVGxNYH0siGgqgPhLE6TsNx9AWu83nCsO3WEBEdACA2UKI45XvR0Delek003lzIG/ejUGDBm313XeW6xlcsXDFOsz8w6uFF5rJm0XzdkfrRU/6XQyG6fTcd/w22G54z4KuJaJ3hBBt5uMVbwQWQswXQrQJIdpaWrJWMufFhliqRKViGIYpLz0bIiVP008BsATGfVAHKMc8I82RT8sOR5tlmNLQUt+1BMDbAEYQ0RAiCgM4BMDjXmbIXVH5SaS41hmmFDTVhEqepm9GYCFEkohOA/AsgACAu4QQn3icp5fJMxbEkqx2Y5hSIElU8jR9jQYqhHgKwFPly69cOTEqqTRXOsNUKhVvBC4l3BcxDMNkqCoBwCqg8jP7j6/5XQSGYWyoLgHgdwGqkGVrO/wuAsMwNlSVAGA3UIZhmAxVJQB4CsAwjFdMkz7AiYEn/C5GXnSqPYGLhY3ADMN4xT3h3wMA7kjthhQCPpfGHVU1A2AVEMMwXjNdet/vIrimqgQAd/8M4xUCISS1bxLSCKC6FgEuFnKgtkMC//a5JO6pGgGwYm0H1mxK+F0MpgKJII7N6Vu/i9GpuTZ0G14In6d9fyV8Nl6PnFnWMpwYeAKjqfBowcUSE3KohpmB90BIm34VeDR8CS4L3l3+gjlQNQJg6ytfxBn3v+d3MZgK5G/hK/FkZC4iiPtdFJ8QGEArikrhgMCrGCytwET6EgOoHQOldvSllYZzemANBtHyovKxI4QkLg7dj6cjF2N76SNP8nBGYJi0VPvWC6sNv/bGKkyQvsExwWfLXC5nqkYAMIwdk6QvAQD12ORzSYrjmMDT2E16I+/r5gbvxeuRs9AbK3OfbEErZTq+RyKXG0b+pwX+qX1+J3oyXo2cXVAeuWjCBu3zzaEbPMnDiQiM2oUJ0teG71GqzMEFCwCmU1KDDpTCqqPXU9dR5S9aiyCOWliVU+Cy0F9xS/hGLIoehlH0ves0dwu8CQBopvWO502VPsRY+sZwjJDGmcFHbK85L/R3NGI9Xo+c4bo8hdCkK/si0cf4G9bj6uBtqPNQwO9uErw3hG7SPgeRRKvtzEdgszyeValhAcB0OqKI4bPosfhV8G9FpzWBFmqf6yw7Vu8YR98YDKdueCVyNt6OnJx1vMHUue0fcLfz3RBaiv70MwA4liWAFP4anod/RS4x6LcPCLyKfQP/cczjw+gcDKCfTEdFTiElIY2DAi8hmLOOBE4NPqZ9+0b01T6PoMV4IjwXBwVfwXORCxCGN3bAP4RvNXz/UgzQPp8XfAh3Ky6iZmZLb+PZyEW4LvQnT8qVCxYAnZgoYngmfCHa6HO/i1IUEtJYFD0s5yKaAwMvoxHr8QflZTku+HTRee8beF37XIsOBJHEc+HzsY/0usNVxTOEluKJyCX4ZfBey98DSOHW0PW4NHgPdtS5FfahVaijWNb5zbTO8H2dqHVVjsfDl2ifww4dbQ0yef4yeB8WRQ/DVOlDXBOarx1PCLe+7wLHBZ7CM5GLsCV9ZXvWI+FLcXXodhwReN4xta3pc+yne46qOiiAFJ6PXIBBUjsAoD/9jCMCz2nnSUjjouB96IVV2rEwEngzcgpmSW+7vBcj+8UuBwC8kt5COzZJ+sL2/F4k571/wDpm1jnBh/BeZE5BZXEDC4AKphvWwknNMZyWYJT0A34d8tez4IXwebgjdE1B146lb/BN9BcAgItD99ueN5wW45rQfHwYnYPdAm9ZnjOMluCPoZscjbkRxHFn6BoMp8UAjLraeupAH1qFkdISXBB6oJDbcc0j4csAAIfauAx2x1rMDryNY4PP4C/hq3Omd3bwYcP3dahxVY4GyswcHolcjl8Enkc9NmadF9WNnE8IyhHc/xqeZzgnRO7cPiNIYDvpUwBAD1qb9fto+g6LoodhgiSrmwblMFCHKSO4PksPxGBF3RK1aAdhncpvAi3EScF/4a3oqZiiGI6H0FL0ptW4MJjf84+JEP6SnIV3xUisFbWG2WRcWG/k0oT1+E2Od7cG8bxnifnAAqBC2Yq+wHvRk3BcwH67hKGK8c1sgCoX3bAWA2gFhks/YmagMA8rs/5YynKfkwnYHNczL3Q79gn8F6MdVAvj6RvMCLyHeaE7AAAN2IjP0oMAAKcH/6kJjxpd5xFEEvtJr1q49hVON0VnHaUEhtESRBHDG5FTNVfKUdIPhvMPC7yIRdHDbNPTj4ABIFHgIv8rQn/GMYFnAAB98DMuC96NAFKIWsw67NgtdiXuS+6E8xPyyHWtqMHX6YxaZor0MfooHkJbS8bZ627SG3g6crHh2DHBZx3rXt/Rfy96Y5i0FCEkLdU9caVe+uEnPBK5XDt+b/gqDKMlWmebzGMlbwhJRCiBn0QTAKCRNuLY4DPKAM4KeVDX5jAz0Kdd6LN0gy8CgIgOJKJPiChNRFk71TOZUc9EyX6KfGP4ZgBGA5iXdMNa3B66DmPpG3TDWrwXPQmvR87Sfp9IX+ad5s6Bdw3f7dKw0893V16yHaQPNG+evR100gcouvHeyrS/gTZimegGAGiTvsSLkfMBACnl1diCFmJh9Ej8IXwr9pT+5+qezBwaeNFR331T6EZcG7oNfWgVhks/AgCu1qlWAODK0J2G73YGzVkxWdfspM7JxWBJbntXhe7AMcFnsa30qUEgWvF+eigeT03GWlGLT0Urfpk8Hu+kRwIArkkejEPil2BRujcA4K7wtdhckv315wSf1DrdemzELeEbLdM/WVEPnhJ4FLtKbxp+uyp0OwDgl4njsFZRfQ2kFWiTstuSKgD+G802SjdiI0LKDEEdcEyWPsHeijqwBauxv/QqzLPyBmXGtBZGtdtAklVP5jn8PtJ/EEUM4yTj2pP+aEcYCewivaU4OcjP0UsB4FcsoI8B7AfgNp/yrwh6YRWmSB/jn+mphuNhJDBAaTxpFzK6xWIabY0AUPi2cu9FTwIA7Bx4x/L3P4evxhaxOwpOHwCaaYOl1ks/WtPzrlImPcJwjwKN2Ii1qAMAHBx8GQDQm1YCEGjAJiwV3bPS6KnU6WORS7VjN4Zvxo2Qhe4liWPwt9TOhmu2lT7FQYGXcW7iJAjlue0gfYCrQnciLQhDY7K+3zylHy39gNHQj/gFgjlW0f43crpW14NpGQDgnfQIfCfkTraYWeEBgVdxXuIkrZwEa3WKdn7sUnwpBmIt6gwj9W9EP2zV8Sf8jEYAhKMSF+KVyDlZ198Y+j+cnDgbfwr90TaPC0IP4pbUXrgg9BAAoLXjPu03tf0/ldoaS6XuOBCvYiC144bQzVnpxGG/r26U4rg//DvlnuVGqH5/rGN7XBa6G3sE3sSaeB1eSG+lXdeq1L9qd1kratBIm7SOW5jeuStDd2J2+m3MDhjtDM20HgdIr+LskKzOmxG7BiEkNaHlBb7MAIQQnwkhcs9/uighJHF28O94IjIX14f/lOXW9+/IuTg39A8A9gLg3OBD2uf/pDbPmedO0rtYFD3cUY3ghBv1RxNl646dUNU960QNrk4cBMDKFVHgmuCtMLNLbF7WMRXSSZDDAv/Gh9ETcHDgJcM5YUohijhClMJS0cMynT0cRvxXhP6cdezK4B3YL/C6poMGoHl/SJQp0+kObpOA3NmuEbLAukapFzP6ur47JOfxYXooYkoHF3Hpdx5XDLfnJU60Pedv4avwREQ2Fh8W/yW27LgVh8bnar8vEKM0AStM7fVnNEEddHxncs9U2TXwNqZL72Fq4GPHsk6RjL/3xc+4XunkfxKNWI0Grd62lL5CraK2+mtypnaN2uashP5pgUezztOj1m0vWg1AnoWdFHhcG8m3oxkAcEbidAAZIbwK9YZ0aimW1fkDsqBo1D3XQbQCIUrmYVzPn4q3ARDRHCJaQEQL2tvbS5SqwImBJzDO5NNcLnaV3sSZwX+it9KQ9B4WAAwuc3Yjr9ODj2qfc/mvD6TluCt8bWGFVRhjscQ+KeTm82pqXEFpTpM+ACAbItXRdBOMAiCCBA4MGl0a/5GahoWiv226jZRZFDRTkmcrv1fUBK8rwvKV1Hht6r4SjTggdinM3BT+v7zuR1IEzxGBFwDANryEqhqwoxYxPK+MMG9L7ZEz3yblfn8QvaB2tqPoB4szhTIQOAyHK2X8QgzES6kt8I/UDngstZ125tnBf1jm1SHCWIVG/C+9Oe5I7opP04Nzlk/PjNg1uDm5F25I7mc4vqWFqvOG5L6G7/eGrwIATWV3VvBhzQX1puQ+2v0AwHpRg0+Ust2W2hPbx+TFYapqrMPCMDsl8In22WqevEHIhvVGxcvovOBDuCj0gOaE8XW6H4CMoFAFQAxhrBU1eCq1tUWqGQQIP4tG7ftE6SvsE/gvepg8vEqJZwKAiF4goo8t/vbOJx0hxHwhRJsQoq2lpaUkZRtA7bg4dL82qik3W0oLDd9rdAY2cwCtXItX1ooarUGqnB38u2HBzk0hY0dWiFfBk5G5Wccmxm7D/cnpODlxFu5M7oq1wp3niVqG3STZm+eKxOFYhxqkBWmdGQA0Yx3mh/5guO7yxJG4NHG0Y7jd/QOva8Zz/b0uih6GzSTZ+6eOOjBWWgRA1gsvEKMwruMOnBE/DVcnDs5Z/jfTo7KOqXrjYwLPgJA21JlqaAagzTjuSs62TLuJNuDkoKzzTuqm/1cnDtJ03Hr+kZoGALg7NUs7ZjXC3EH6UBsIXBr8KwDZu2cjIgCAMxOn4oXUlvLn4CNZqgsA6EBY+3xF8gjsFr/K8h7s+Fr0xzXJQ3B98gDcntxNO36GMqB5MbUlhnfcgx1if8D1yQPRrhhW9SwWcj+gX12rlkvf+UpI49lUGxaLFqwS9Uo+j4CQNngf6WczKtlOB0KbWapt1DxL2ICoXAZhnIWFkUC7aMZFiePtqgWAavDNtGv9IM8rPBMAQoiZQoixFn+P5b7aW4xxOkobI3RX6U0cEHjF8rcgkrghdFNWPBC9gc0cjqA+x+j+sdQUg9okgjjODP4TD4d/rRwR2EIyznRUobKX9F/cE7oK14du1oxO1mTq6OR4Zpn/WtTh4uQJ2IAaBJBCI21CT6xxLK/K4+FLcFDwFSxM98Mdqd0hICGBoOam1xc/4/3oidgh8KHhurfTm2Gj8qItsVDdLFRGYeoz0HdYANBCcvlG0ff4c/ga5e7kjm4davF4ejvckjKOUb5L98IliWMMxzaKSFbeAxV/85/RiJ0lo51E75Y5SfF8uS55oDaaBYCYkDv7IbrQCgAwM3Y15iUOwS2pfXB/arp2XFXL9aGVWC6as4RiD9Oz6G7wSpGfaR1twnpNqBBqldmo1QgZADYh+74L5ffJQ7KOJRFAEkFNXbRNzKjH3yAiqEEMcwJPYO/Af7XjHSKsXZ8ShPNDD2G09APWKYZZVfffg9ahFjE00ibcmtwDZ8VPwXLdM1BJm4TfAGrXZuOqz/4yU/tTn3FMaXPqDGBn6R30pZVYi3rsGLsuK68rEocDkAeGVrab+cnds46ViopXAXmBfsTttPqzG9ZiDC1ynW4ISfwpfAOuDVnbtifSV4ZGq5VHpwJqUHSAakdmVT51ZeQGEcEq1KMJG7TOQF0Rqs4k1O+/S2R0/6pQuTF8E6YFPsK+gf9gvEM0zAmU8ZX/QVjPwvYIyEvhz7JRHZgZLcleMarXCyCPxNUR+3bSJ1nXrBDN+Eq3wnLv2BV4OZVZcHNd4gDsEv89HkjuiN60CicGnsjyMlLRC1Z1BK3nweSO2ucaiuNvqZnYL3Y5Nuv4CzaICKYHPoDd4KGF1mB++HpjfrrnqHorbUAUh+lGn1ck5fUQZnXdQjEAt6b2ku8xeRCeSU0CAGxNshltPH2DtyxmJO9ET0YtOrSRqt6bJEJJ9MIq9KOV2sgVyKgT4wgZbCkqakdbCpIWxk3zrCMNCX9K7ql9/1H0xObSd/ilac1IRjARAjp7C2n3nhGOqnvoUtEDj6a3tzSymt1AX4+chcGSbNvpRasxJ/AELtStFZkTP1uzf3ToZiH90Y4oJTR7hFnYrBdRPJGaDAAYTMstYwZFojV44ZzsNloK/HID3ZeIFgOYDOBJIipriLxaXYfb3eRBM1t6C9Ml2af97+Hf4KnIL12ne0rAeXITIGtDqto4fhF4HqcqaVyTPBh/T05DHRlnBI3YgCGK18EfkgdijahDgITW0av6b7UBz5DkDjCBIE6Jy65vVrFkzg09hIG0HJ9HjsIIZZGUylY6d7oVohumx67LGsncldwVAPCjjUHVDUGkNFvDJmR3NNvEbjJ4cfyEJryTHgEAuCW5F/4vtR9SCGCxaEF3Wu+4sMxItqrj9fRY7fOPojsAwrtiJGIIaytx3bha/iu1Lf6ZmmITv4fwjeiHHWPXYWrsevxbUb84EUcIb6RHAwAejPwWAFBLHVirGD8B4MLECdrnT6PHagvtEqZO7a3oqQCMo11VhdKBMIIW7dU8Mi4Ws/rFyjj7++ShmgqtwcbRQD8b1K85GE7qACNTbvW5qR1/QmQLgGHSUownY0A39b0DkCWA9Lp7tQ53kD5AT2XG+bQitDchiisTh2rn3prcE8sh3/OxwWdQgzjWiyhuSmZmodFoDYb3arC872Lxywvon0KIAUKIiBCitxBil3Lmrx9xN5v057eG/4g/h6/Bh5HjtdGp9csrIyGNFqxGT6zRVAB65gb/hmfCFwKw171HEUMQSVwR+jMODcreKmtQh/WoMYwcATkWzPORCwDI3i7LlRdmpGL0a1QMm9qCFyXOy4L0SG063IQNWbaGraUvMEN6D1FK4EjdcnkA+FVIjrlzYvwsrEA3fCv6YpEu3gqQGUWvRuENtYbimBz4FN2wFhcHsztvs4cJALRK8kupV2+Y/bHN6I2dp8dPszxHP1o+IX6u5Tn6hUYS0kgLY+e4StTj7MQpaMFqtErL0aKoHn8WDYYOa5Hoix9Eb6wy1d1Vuo5Cj/nZNWKjpscHZDWZFXZd90OpHbXPZyr10YtWY1vpM+34jNg1SmeVrS7RM6pPfs//f+mMB9tfkrNwTdLa/nJQ/FJs13Ej+tCqrN/+mNwPH4sh2vdzEplYSfp7U4mQ/NzUFbqrdV46H6Vbtc+PR35luE5VH1rxteinfY4ps6QDg69qg7u7U5ku7lvdu3N7yqjeiSKOTYgYhFKC7F1Xi6UqVUCq8Q8A6pUR9hmBR7CD4pUCwOCOdWvIOJ3X837kBLwdPQULoicbYraonBB8SlvVqVfnHBLPGKDr0aEtTFJZJeqxAVFFX5+Z0nbT6fuDSOFTIXs63Bi+CRLSeFTxW1dnAMco8XK+EIPwvegFAPh75Df4OnpEVllVQ5l+gYreNvBs2t6LQVUjXBm6E83I7bWg7p6kV7Wo9KefDMI0Jcjg963ndcUD6T0xQjvmtGr4iPhFuENnfHwqvY3leWq76BAhtNt0eupIshEbcH3oFkgk8FhqO+3e3kqPQgJBbK94l+wRkN1KN4qoNorXs9GkX381Pd4yX70gfCD8W0QoqY06ARhmA3rsQmToA5ctRQ88m8pem/m16I95yUNRzDoSO25N7om5iWNxefJozb5jZh1q8SN6Zh1/MbUl/pg8wFCuD8RwtHbci9aOe3FvKuMC+nxK9qxS3XvVQVIMYRwYuxTvp4dijo2wd6K14z7DwKcdGcO1OtjU24z0g4uYaaYbpTg6RNgwW1snNcIrqlIAzAk+qX2uxyYQ0jgn9A/biH3TAsYNJnaT3sD+0quoRQcadSqaniZ1knkpun76+kZ6DNo65KBm3Whdlu5voeiPDaIGARKa8ckcFTGOEFaIZgBAP1ppsFeoOlF1kUwCQc17wo4bwrcAMMbHcRr16NmgM3JeEHzQ8VxCGt2xDn9O7oILk9mBrh4IX2H47rQY7p/pqRjW8Vc8qDOONpNxVqeO8v+U3BOvpcdrdZYSZOtNpLo3npbIXjF6aeIoAJnne1Xods22c2NyX1yRkFUuagdzWFxWI6oG/hqKYZOFERkgfJnOuLeaDdgq76eHaZ/VUfp/dCqr1bASAEIb+Vrlq0etn1Jz/i7WM5N5yUMNHbUTarA1FStVoQzBfF/q+6cuJtOrE98Wo7BP/AosReEqzGOmtGLioGYAhL8kZ2GVqNfUzXo7i5XN4Q+JAwDIbaQDYYOQ+DJoXW+loCoFgJ46dGSpWaxQ1Tc16MAt4RtxXfhWnBx83HCO6hcvI3B68J+G77Umf/+VaEBaEHrSWoP1v100IoUA1iuNRi3fYFNM8dfTY7Fe1/HqO+4NInsk5eQ6aWaqJHvfqLOiM+On5LzmJcUgm8vNdGv6ArUUw7emhUEnxuXNQlQDreommGs1tPm+jM9Btku0dtyH3ydllcpydMeEjtswLGYfTvpT0YpRHX82rPhUUf3BVf9sdWEQIMei/3d6S9yfnI7fJuRZ1n/TY7FW1KK7cn4tYrYj3euSBwIAToqfZVAV6HlXjMQ3aWPd6TvtJIJZHlIhpFyvDlYN9GbPJzcQ2c8Qhva0npnkw7tiJDbr+AuWK/frtLLXjN42AmTCfbjh+dTEnOeM6tOAR06ZAkC2A4SRQH9lTY9e4FvZHNQOf5fAAiQQ1O5rvYjip0Bp3N+tqDoBYHaNq6dNWX70AHBfcifD99tD1+Gi4H34LHqsdszsp6s3moWQMqh1wkhmCYA0JEgkcGbwEUM88BWKp4Daic9UQi+o+vwz46dgfMft+FIMBEBa49xFCWH7Smo8+tNPmgeE3qD0icuFO9MUAfDb0F/kMuXQ/QLA6coKyCWmqfqBgZe1eCqDaZlmvDRHgnwhbXzJVJXUhjxdD29P7Y77k9PxfnooXk2NwwdiWNY58pTdWZ3RYZOvKnSfVBwEYjqXyRQCiCOEi5MnGOpspWhAN1qHRmxALcVs3SmfTW+N1o778IyDug0AhkrLDN/N8WJ+nTjS8H2y9InrWPiqAP8oPSTHmflRKofrGMLaIsqRJocFJ74TffBDOtOZ2m1af3bcuN/C0fELNJfVF1JbYu/Yb/DbxC8wNXY99ohdYZUE4gihjmKaI4JevWflDKJX+YyRvtPUiC+lJ7i4s8KpOgGgRtA8IS7HJDk08G+Dvl/F7O2wY+ADnBT8FwB52XkuemINPhat2vf/RE7XIipO6cjesm60LvrjpYmjAWTUKvNCd6AFq7Twu++KEdrSeyCjK1a9Cd4Xw1CDOGYpvugtOqG3V/wK3KismgRk7wRzgwfkqegwWqJ9t5pRmFmPWqwVtdicFhkiIV4Tmo8bwrdgivQR7g1fqR1Pm0bq5pH8MtEd1yf2x8Hx7FW6TnQggouTJ2Cf+BU4MnGxpbthMahBzgDgufD5WXpcK1ql5dgn8F88GZaFhtU6gmIwjyqfS08yrDy9J/x7Q0hnlastQk2o6i85hk9+OIlUUcIlN6qbtJUPvxO7xzPtT7IRSf9MT8UZcdlD6vt0C15OT8BCMQCtHffh+MT5+EAMx52p3fCD6I2PxVDLNPSziy/SA7BG976qQujh1FTL8wHgpfSW+G3icFybPMgDq0uGqhMAqq59pZCNNptL32khAfQ00CYcEb8o6/gJ8XOwS8xoKzg6fkHWeY9FfqVFFgRkXXwN4tggIlgC+yndPrHf4B0h6/zUUQAAQwz8FaZGr8Y/USNdxkUIEgncpvii6418KQS08wHg5MTZykzCyKdisCE41wYblYWZ1aIOOwfexQtKVE0994avMoS5UMM5DO6R8drRqy7WoA43pPY3+P5XAit1Br+R0hJtAdBqG+OrHtW4HctDdeGGBILYb8v+6FmfESzmWUYjbcjyVHpXjISZy5NHYd/Yr7FY9MKlCflzpaGGyNB3rN1qc9fpWtThSUUw2gkAIOME8mx6UkHl0zt8HBS/1GC4X4IWtHbci3N13kr6dQeTOm5BGhLuTO2O70SfEi9VNVJ9AkAxqOoNbHND2bsyjaTFeC09HnvHfoMNutHaJ+nWrJHRy7rdf1R60eosnWsNsqf+9yenG77rO4bvlciOgHGEYB5xrjdt/tHdFDvkztSuhu+bTJ253vf66LjccUsQGCllZgBuQ9Kqq5LdxC950sIDZ0osEw54jYsO1Q/MNol9FAPwifHsSJd2FLuHw54m1UPGsJjpLsxhFEbSYsQQwispecZ4bvwkS5fRGMKaV9U9qV0MHlbFIErYlamRN/UhNs6Y4a6c76SzB1hm/pGahusSB+DapHUwvlzoo7laD56Mglid/b6WGqsFlSsHVScAtlG8JjoQ1qa65lAJADT3yg/EcC3AFADFFU228gOqYYkwtCPboGg22jbT+iwPgL+ndjB81wsmffgAJ8Oqefu/W3UrJ79N94bdxFxVZa3UCTTVL3tr6TOsVHTwb6dHai6kuTAvjrLb8nDv2G9sykXai1nKsAOl5qHkDlnH3hTZrp0q+sVJQLbQzpevTMHwtGicuj72huR+eC6VMWJPD3yAFCQcmzgfozvuwsPpaXk5BlQSz6Qn4YT4ObgzlXHpdasquSs1GzNjV+MDMdz2nA5E8H+p/Vyp9zL5Z0qgF/BuVJBJpSu2ir/kJVUhAITurThe8YtfJRpsDaK7xOZhbiJj7FXDu+q5PHk0Nuv4Cx5UFppYeaqosedV9gi8iX7KTkgq5il4zBCDhXCd4h5mdm3UY+5M9COIBtNKYiDjvvhkKnsErs5Adg+8hTfSYwAAB8Yvh9vX6y7dbKMXVhlcblUWi56OL99R8QvxTGqSY8RPv8m12MzMkSZ14oMWC5TyQW+gfiS1vfZZP8behKjmVaRSTx1IIZA1CywVDk5AJbUBAITn022u9suwunahx2pFdXHZgnS2is2KVYpK2iqyr5ciwa8NYcpK2tTw1okarERjlrS9KnEoHk5Nw08wTp3t/OfNo4PNOv6CVlqGZyPZtgMnHkjuiEMUYWHWDavugptZhveV0c8UblMCR50WPx03hf8va20CYAx+prJP7DdKjKRMnQyhZVjjcnNxrSy6828M32R5jtmIbm7gX4v+OClxdl75lhuzCkevirBC36ZeTm1RUsP0OYncLrrVgJMLarm5IbkfPkoPwdM5vLlU3kiPwWLR0zIulZdU3QxgmeiGf6W2BWBcng0A81O7Z3X++RBDGF+IQXjbQerPjGVv8H2RbjGUefGPOrofTEa3P8M5ujDM6r6kqo+93uNH5YHUdNyW3B236NxD3xfDNfWPGta5H/2U1xQYAO7QTcnNUS1VrjZFgfTSyOUVZlXXjabY9WZiCGkGWPvFS0VCxrYOyCvA9WGnf7SItVPSIjjNADzN2TnvchNDGE+nt4Hb8fs61GL72I24PzUj6zc2AheJfgZQg5jWyX4iWg3BqKxizahM6rgZM2LXuMrvLMWFTEU/Rbdb3alingGo7pfqGgAr9CqgzL0NwZiOu/AHCyNWDGFclTzcdjHS9Jgcgz/fHb4A2VisGhntvCz+q1u1CgABqYLeXJcs0/n4v5ke5WKkR9quYGPziDDrxJSOG7Bdh24PXZue4h7d1pU/uLTllIrJQwtfWZsvna8V+U+VqIAyb0YUCaOh1eUmJu3ohnaXPsdL0IIf0i2ay9/FieOxX0BeCJXKsb2bWTWgrgZ26oz114zWbT5u18HnQq8a0q9ydYu6hkJvuL4scZS2c5KZSLDzGSJvSu6Lz9KD8Ux6EvLtehod7Dn5YOVObCUD9J2+2/ZeKvSjcvPshHEHrwMoERLSiFDCsCx7rWXclOL5jy7KYQxhXJs4EItFT1sVk5VXCQCsFhmf8zfTozA1Zh+YDrDeyzRfit2E+kNl5W0zbdD8+u+1mNqqhIOdrxkmEFRW6+b/erpdU5Evdt1rCgFtS8TbdB5iKgO7eycUyqqWqSQdUCeh8715BaDOANQ1AHodrFv3xny5IvkLHB8/F+M67gAA3JTaF9vHbrT1p78gOcfSlVQvMN5Lj8APurUBetRY//9KTy626Ch2zKHXOfenn/Hf1BgkEcS36d5ot1hFHQlURTPUCJZASFuRFsLW02axaEFrx314W2RvHLPjyNK9A2RqO1IZO2Xu/vOnKt489aUYroQ2MOrhCU+ltrbc47UY1qMWL6S3MqhTnKEsl7anzphqWMzjtOfuU+lt0dpxH15PF7ZBux3/S43J+5o1uvjqALBd4FMAwE7x67B17Jas8yOhqmiGmpAudoZlR9Ls7uaSUvbRfg7CfZ8A+J1/AfhiAyCiawDsCSAO4GsAxwghVnuVnzoDUDd4MBtaT0mcZfg+pm8jPl2a7T5ZbnrWhw1eOCsLiM1SKPvGfo2lojuW5QiPWxMKYFPCOqiWGTsje8RnFdBeW/TD4x/8mPvEInkqvQ2uT+yPf6W39ST9dFoUpGf3cpSud8302gRgnn2UnU5o4vDrzXsewFghxHgAXwK42MvMzAOjXFv59Wv2RkebL+rLo3oRFbt4KB/eEyNydv4A8NlvZ1set4qjZIffNoD+3Wrw6KlTPEv/tQvUcB+EG1L742uPFrilCpwBlBJzF1zOLjkYIJyxk3GB4a5j+9iczQD+bQn5nBBC7YXfAODpsrxv2tcbvteYwjKbCUqVoZJQB08XJOZgfMftjm6qlcZrNrtZWRH22QbQqyGCYS2VGXcoH1LpUkbbKQ0GL6ACSnfiNOtom1bsu2V/nDNrM2w7NLPWYeZoa5uZJ3RCFVAl9CjHAnja7kcimkNEC4hoQXt79p67brjrP4sM33PFmKkUv3R1ap5E0DNvJS9RN+A4OX6m43mldANtiOav1TxycmvJ8veTlBAFqSG81J0XnXQeCYQsBhK7juMZgBOeCQAieoGIPrb421t3zlwASQDWEcMACCHmCyHahBBtLS2F7YyjtiE19s/9qZ3sT0YFGJMUKqQYGuP657dK+sHUdLR23KesiLTn6CmtRZQqw85jemOvLfrlPtFEQCJPwwgUqvs+a2Z+UTgrcwZQnA2gEL3+op8ya2Z8twtUOJ4JACHETCHEWIu/xwCAiI4GsAeAw0WZVojUogOPpbbLGQGxnK5rTlRIMTRyleehE/N3Qb3jyDaM7pu/cfvtuTPx0eWzso5XWgdYDGfNdBdITKVQG0BJO0lTI/GjCS9bm3uLV0bGFxUQEc0GcAGAvYQQ+ccbKJBG2qithKyPBHHxrtaunxWiAfJt9HL5ntaun16MkgtNsqUhgoZo9gYghQ4lvKzpco3Lr9x3XEFeQJ6qgAwrgTOfJQI+uDRbgDtdX2z+TDZ+2QBuAtAA4Hkiep+IbvUyMyLZy74RGzVdOhHQ1mod2qFSZgB+zV6H9aq3PO5FXBe1qk/eMXvfXjdMHNRcusJ4RLkiILSWYNP1XESCEv56nH3co+wmq1MB6Y72bapBk8MOXoW2h66Il92RX15Aw4UQA4UQE5S/k7zOsxdWI0Qp/KiEJnDs5Cul//egHMW4XG4zRPau2H649U5KhZRXneWUrpP0fzGUmXKqpbzOSwAY1N19iPDZBbph1kdkY74fr+Jx2w/xIVd7vBxAVIIXUFmIIYQrEofjzbS8a5P8wls3L71wOH+X7C3zOjPFvFCqKiMYKP1rWaiaxHxVpcUbO2vmCFu1jNrJdSqEO9Xkg3O2xYeXz8Ie4zM7oeWjnvIzcJzfCxPLSdXc6Wo04I7U7toG404zAL0NYEC38kZP1OPF6MfNSLdQ20NBV+W4KJcnjL6fIBRjA8gU5Lmzpxk2Vy+GRgs7hcrHv97F9rdCKczTpjiCFkazYEByvHe3FDIz0wvWStHmVipVIwDMOLULvXDw0x7ghdG1YuwbClppbDquncc4L+TxYpw4sndD7pMc6KbTbRNZ+6dXMk+esX3uk5BZwCfpBIC5eRkXguk+55BUxUwA/G7hpbaVdTkbQLmx3HqcyLZiqVIEgItzutflt7tUKe7HLoVikrZ73/OdjRSqSirlY9bryAnAwDx05sVSyP3nc+8CInO+43XFiWb16kJmo/qci70+H9Sc7p9T2lhPbAPwACdXT/1vrlQmHskIN7r2J053N1pTcVPUcsq8XLOcnGUxvR35viwHtw20Szi/hGxQ72+XzUsTkuDC2aPQv9k/taQeKzmgflafg6EDzqNKtesLaIvpSjMEVTBVIQCsOhmJ7McG+tPtBMVBbQN059i30lARBlM3IRLy7QwqTAOk6zCsX9pcM5YsI7CLPD/7TSaA3Qk2sWZK1YfsuJn16vXZmxfmHXPUdoNx8W72ocsLsgFkLd5y10isHk2p1ZaFpGawCxWQQDXJj6oQAGMsVpo6NQxjp5P5vNXgbrqjejWR8Xp9AKsbDtnSfUF1FBLTplTYVU1a2cfE/iXP/21Tk7J76XK9wObr3Ly8NeFAWQTho6dOweAe1r75fzh4i4LS9GJxYD4pGo3u8pVWdWn1GPTqqVyPqZjFc8XOACotoAbbAIqkV2O2R4fTyJIM52U+m417mc/GtCa1ZqIRRgvc7KQSRyFJRQJYzWry8Q23wu52vVqVrT5/9dGV8iWz7PxMBwv2tCLntlGOdQD6suSi6HotIAGjDaDz0VRTvPeUW6pCANiPLq2bx/+++dnyHONnXTqm691Gk/78t7Px/qU7W5fNXRJlJZ5S1wEYb/CJ07bHo6dOKWohmNMZTphHa25Hb4E8VUtuue9458B3Kl4YzHP/aIOD505W8rqXKWMDcHcz+vfQ0wGOh2mXY+ZozoONwEViNSV0epAbYpkdrvQjUONoNPMlljTu8er2hZDIPgql5NHQ15WO1uaUhHKf5vj94wY05e2NlCmP/L9UKiC3L7828le/l0DkRoIStivhKulC0imn+sKqLZmPFHrbxXR6+ve91DaJcngFlnPwVxUCwKoxuTXc2q0JcNsOnDoWIvt0vNqToJj2m0jZq4CAwhquZgS26bj0dd6zPreQcdtv5DQuV1hQNS0PT2wA7tNsa+2erc6ysgFYVJ9hHYDLJ1WQEbjI652KVo7OOcsozzaA4rB6nhLZP0y7eDlGYeCQobUNGQBw+DaD7H6yzauUFJNqQgk3XMqFTWpd284AdJ8XXJKtLjNfpw894IT6/NSXzW11Xzjb3gNH7UjVsMxOaqaiVEAOwqkU6gK7sj11xlTcdfSkzHkuri10BK6tAyjIi6c0axCsqDQvumKpDgFg0SCcOli9ADAae3WfC+xK9SHbnV4Oq+X15cLu3tQgcPtNLM0OngGJNM+qA9us08yt8jAyw+UWgIWq2JyiVKplVQWAFzuLetEBEQF/Oy637WJMv0bUR4KZ0btLW4H17zkyU04oeiFYieurq20wUx0CwOJYf4cYP7XhjAtmISoghwkANsaNG9LbJbP3hPx3tvKaIT3rsGje7gZ32GI4ZrtWTQhu3q8Jb1w8I+ucfFQ1+bzsmheQeq05XfdJZfJX/qs6aCc1ntuOZOoIo00h11WFjn23H2Ftu3DCru6szsmXYsbwnhqYy6LmKx9VIQCsWtNNh0607TD0Rk67RWGFPiS9gdkujQ8vn+WoaigGL7c+zBdzUfo0RXNeUxMyLo7bbZw7lY+ZXDYWtRM5fJtBuOdY+/j3VqgzAKdZnNvH0NdUJ+V4frmEU2aVbn5lyadjVttCn6bigvIREa45YDwOmWS34jsbp9mLo7Ar0bMp5ytaFQLAyuDktBmF/gEEJb0wIMvP2dfbn3fo1gN1v1lf3xgNeecF5EmqheHmhTGf8t+LdsJrF0zXvp82fTiuPmB83nlnbADOZTlph2GYNtK4mveGQybYpCmnoar59LOXUo1Kc84ACjFe53m+moPZjiKnVRoD5qGTBmH+EVvhINtQHfaM6mMM5ndg20DM2388HihBjJ7ydM7le0v92hLyt0T0obIb2HNE5Km+w97A6FzRg7rXol9zZgRmUO249gIyotdRk4MbqFdYVcUjp2xX1jKouLlzswqoW13YEFxNkgiNyqpp9Tm7sZ8UY2Tfe0J/RycAzQisO+m5T5cbznGbuxuPG8P5LtMtBU5tt9CVwKfsOAw3HzYRkkSYtXkf1+9HXTgzM7zvBOuOfluXUTqdZGhXswH4FW/gGiHErwCAiM4AcCkAz3YFK3CvbBy1XavxQAmMwJXI6D6ZUBmFxqgBCuh8XFRhIf10JCghGU85npOxAVhnUJAnidkI7HKW6IS5FERUch13tueO8/nmuiHbL/lzQQGqz8dPm4J+uphYha5JcYMfC8G8xK8tIdfqvtbB44FLwSGC4dBB6NLcwaQi8PL5PX7aFFsVhBtyle3WI7YqOG0vKETQRkK5g+iZR/B2I3r1ZTx9p+G47kDn+D35GIG9wpcQIha3aWUnKMVK4A8unYVhLcb4SuMHNJdsA59cVNp+GsXimw2AiH5HRD8AOBzyDMDuvDlEtICIFrS3txeUV6GrTLNGRjadkdPWfjnzcP45i/EDmrH3hP55XuW+PG5555KZeHvuzKLScNO5F9KHHmwy+B2wVbaLafZiG+N3YTp+7qzNsL9FOlZpWKmAss5V/utVF6XgoRMn52XwlMtSuk5NTclq0FWsbPr7SZPRVBvydIQP5FgH4GnO5ctDxTMBQEQvENHHFn97A4AQYq4QYiCAewGcZpeOEGK+EKJNCNHW0mIdWjcXhTY8OVRD5ns4aP1ozAbbXOsFnjxjex/3Gs4uTyFCoUd9BC0NZRh15VE29T7On7UZPv1NZrvFay1G7mrnnGt2aJe91VVq/uoMwFkFJP//70XZrq+5cCrz1kO6Y97++RnFswc6+VFYh5X/W6kPsugbXWsC4J0AEELMFEKMtfh7zHTqvQD296ocSmEKuswcefHU6cMtz8vX3W/zfk22aZWaq/Ybl/c15Yon4y4sUf5vnCSRYS0HIBsXDeeY9PWl5JydZeHuJqpjU20IEwY22/7upukevV0rbrNR3Z063X7hWqEUXGMWN3Plvvm3z1Kirsw3bl5vf35ZZgBd3QZARPqdvvcG8LmX+RXaYAmZznBg9xr0qLMe8fYyjYTz6bRyPexiVQSTh/bAdQdugcE9CgvX7EUHouLOC6g0eQ1tqQeQ2UBHnbXZxo7XdNju81BH/IdtMwiL5u1uG1JETjeT8KOnTrE9z40wPmHaUOxShPE+bzdQh4XAbutLTeMwXWgUP9hjvOyAeLTZ4cOGSlpHUwr8sgHMU9RBHwKYBeBMLzPLdwKgPWSdxwWBUBMO4M6j2lAfCWKnUb208yWJDHsF+I1hNANg/60GYO5uowHkP7o4fxf3XhleGCCLfeFGmzYD2maorEZQ4/TYTQA0G0A+wtzht5kuQ1S4IXtvAXuOmTLEn13jcgSDKyrpErazycN6YOHvdkWbS/XSDN173xXwywtof0UdNF4IsacQYonH+RV0nTwDUD4rL8WM0b3x8a93Mei/R/Sqx0W7WneUXo0XXrtgOl46b0fL327U7UKmjnC3H9ET2w3rgYttyukHbjqaYmYAT5y2PR5QfMLVtQLqc5NMBttiyuiGgsNnFNnZ9ayP4J7jcqxkzvsmTW6gDgvB9EzRhcr2w1nJDvP+Fnazri0GNudtX6l0qmIlsN077sYLSNgY9PQyZd8t++PgSYMM16k0RJ1nBoV6YAzsXoshPa23G5QkwlDlN7WcteEg7jthW8trctXDvcdvgz8dPrGgchaLm/qxk+/jBjRpK753HtMb1x24Bc7ZeaScrslgWwqc6jGXILv2wC0cNqgvPN9yYBkO2uK8YS31WHBJcZ5j5WaHkS3orewo+MEPqx3Vel7h5eP1b+PZMpLvK07af9KEh/khqP3GqD4NjmqKcQOa8sy9NKhFMs9+CunupthscpJNfqm7En4lav1EZHDjVAW6rQlAi0Zp97tlLg75O5fvgK0G4ICtBuDBBT8Y83GddylxLmy++R8yaSD23KLyghvaob+/qSN64qf1MSxfG/OvPB6mXRUzADsVUK4OSH5pc4e+zU5XRh1t/2Lbwg1dxbiwAtmzH1cvb4GZxpOlb6pejW4DuYzAWgHcp+k8AyjQWbIEvb3XE4Rc6c/bf7w2iGiuCaGlIYJf77W5x6UqHW4fQWc0D1eFACh0mk/IPPwsFZCLXlK9wslDw6sOThvhmsqpeizpo2qWaiFQLOkcfgEAjt9+CPbdUl7I5s4N1BtyuYEWYgT2i0LKWBvWP//8cFwolSOxYEDC23NnGmYE+5dofwkmf6pCACRd+HoP6p7tJkmk7wiM2AmGSkHTcRu3K8bA7rX497k74DwPFqJ1JOTMdh5j7/GyIZ5Caw9r24UVRIQzZozAMVNaiy2egW2HyYHB7Fx7M/m7T9O8V7KeUraTUsyz9F5she49EVS2Bh1o8e7kM+bKN5pruQ3IfhusvexhqkIApFI2KiBdzb56wXQ0KCEdNC9Q6NxAbZ6C5XEy/vcjPgtpKqDszIe21OcdLsAN6gwg4mAo23lML21W4qZhE4Bzdh6Jy/bMrTLIZyR8/qzN8OK5O2BQgesjrHAyEHoZF6gQ2aK2jxsOmaCtkcjg3GCHtdRj/4kDcPexW+PWX0w0bhNZQFn8iJnkFjn4nrE+Hjpxsk+lKT1VIQDMM4AzZowwfNcMpuYLKdOBmjsXp07dbGB02/8fuvVAx1Wh+SDlED51uvhFpRqczhzdG1NH9MQFNmsHJg5qxk6jemvrFNwYBr2aYAUDEoZldXwZnBY72eE0A3B7H+awFdZGYIdonJZ5l7YSAxLhuoO2wKg+jZg9ti961kfw9tyZ+N/FO2XKmOe4+W/HbeP7qmCVXHaXHvXexiLK6ms8zKsqvID0et635s5ArwbTLkvKf/XBd6uVH3BdOFjQDEDdND2eNOpfzNv7mblqv9L5GNvZANxQaIOriwTxVxd7yw7v1YBF83Z3laZfOnhtlpJH56mqRKxwm87wXkah5MfssZA81fUVqhDMV+VVyJaUXuG3yqdcoViAKpwB6IWBeTco9Zfzd9kMl+05BruO7WPbETg9JFUFkkjJAsBxiznPjMDyfw9C3eSNKvjy6kyVG8infor16TdvNwnkNwNw6vT6Nube7rKcZAY92b8VU4u/P2A8Tpw21PXmK52Rcg9JeB1AkaR0ltBYIp31u1ldUhsO4JgpQwzH7IzAViPULAGgHC9nHBEnG0DWuR6XZd8t++O1r37K65p8OiF1JWexgd3e+dXMogSm0+OdMbqwEAKWKqCsjPNP16um2KshiouVsCNdBV/2WCgTVTcDqLOI3Z9QjMQZ42Tm7ShEBaQaA80qoHKOHI6fKguwoTarhSudc2fJK3ZDDnp1FVX1kihSANSGg9reDrmeu56bD8u9SpqIXG3kY54tlsomZJufVdz+Cu/wSrE2Iq/8XA5HSiVUy2kDqAoBoB8Z6mP4mF0ktXalq3/14WevA7BHEwDKDMDpZK903HuM74dF83ZHc623Bis32K1KduLEacOwaN7urjxEQpJc38lU9uyuWNw8n/7d3AVbc7ORj7mGjp3SihfO2cHxmlxltKp3pyvKqYOuRHI1U/Vnu1AsnQlXAoCIziSiRpK5k4jeJaJZXheuVEwdYb2RjFlloH7T9znq7kPbDDFGC3QKFZBZZaqmq9oR8ih0GensIW7VGUDSxt23ELSUClgBXkqIKMswXMr+udJH+35gFoDmOirEQwwAzpo5AtNG5t7Uypx/JawDOFbZx3cWgG4AjgAwz7NSlRi7hUkp5UmOUUMGa9P+TJUP6CYvnDJH+8x0ENmPJ2Cjf+8s3axXnUI+giafugppKiAPZgAV8tDyDemcC6dnwUIhgxAO8yFTFeaqt7NmjsRBbZW16tmtEVi91d0A/FUI8Ql19mEjMsbhaEiWg3YLlLIXyjiPArTtBoXxXCty1WI5XkbvY8V4m0NQUwH503OVUidtl9S/Tt8e7evlgGRZI8QiqtfSC6jCBYD/xcuUoH9zDZas3uT+Sv8Lb8DtDOAdInoOsgB4logaAJR+uFVm1A7D3GHn48Nsdap5j2BhMbNgSseI3vVorg1phuOSUMg038Pn260ujJG9G4pOZ8fNWvCrPcboNm9nzOg7aauVwPrB37NnT9O5OZcm/3KufXErAI4DcBGASUKIjQBCAI4pNnMiOpeIBBF5vgpkUPfarJjsqgoos2hKLZebFO1fnYCNwZi7f/fk8zLVhoN4/9JZ2HGz0u3WlM9CsNJ2ovmnlk+7+ssxW+O47Yc4XlRpRuDrD97CladVqdCHDQeyn4jerbs+EsQpO8r7e29tshN2BtyqgCYDeF8IsYGIfgFgIoAbismYiAZCtil8X0w6bnnpvB2zJLmqMlaNiPlM5d2ogDLn2huB83l5D9zKG/2h1xOTzjzxqcSiZ20JmaOC8+3O9ekP6l6L71duzDOF0rLvluXVm08c1E37LITIqkDzuz95WA/XK9srS7S6nwH8CcBGItoCwLkAvgZwT5F5Xw/gApSpTgISZW39llQkgHkG4EYFpIaTmDwse8Wjvctocd1JS4Nz5Mqdx/TG5XuOKSoPoDTG1FxhL5jKINeg54p9xpapJJVL9gygcK++cq9hyIXbGUBSCCGIaG8ANwkh7iSi4wrNVElniRDiAz/14qqXTtBkA3BTpEE9avHq+dMtfcDtfNe9vtXbj2wrSTrmBWyFMGfaUG31b1ONvC1jPo3fb3tJPm1BpRQldlNFpehCVD1zrrScIrtWA1bt0CkKQGfDrQBYR0QXQ3b/nEpEEmQ7gC1E9AIAq51Q5gL4JWT1T06IaA6AOQAwaFDhO2tZkTECGxu528dqDiX82gXTkUqLLFuDsxeQ/43IXIZSCAD15dhuWA9NABQbqqGcZOw2LmwApfTLL+Caukh2DKNcODW7ChukZlHO8vkRx6ucuBUABwM4DPJ6gGVENAjANU4XCCEsd38monEAhgBQR/8DALxLRFsLIZZZpDMfwHwAaGtrK+mj32ZID/RpjOKMGcMNxwvdvMNqYww9haSqN8iVq8GVQgDoqQ3LzWxTIveOYZVGXjMAnzqESNBZADh2mDneqEoYoHjBbuP64ISpQ12da+cF1BVwNb9TOuZ7ATQR0R4AOoQQBdkAhBAfCSF6CSFahRCtABYDmGjV+XtNU20Ib/xyBsYPaDYcL32bL02L2axPY0nSUdlpVC/8bl9Zx9u3KYp5+8nx2Es9UlejbG6Mdz4B4AY1JMDh2wwuS36l6ICqPRTEflsOwJY6Y68TR23XCgBoiCpxooqon0oTHq5mAER0EOQR/8uQ287/EdH5Qoh/eFi2shOUCMm0KPmox0mf7DanPx8zCdNL6OYIwLCT0/8unqF93mtCP1zw8IdFpa2/16ZaWQU00eULVwnkY6/oXhd27QWSO9+SJOM+v04YDK7cqKFkWuplJ4xi1vVUmnB1qwKaC3kNwAoAIKIWAC8AKFoAKLOAiuDx07bHS1+sKElap00frsX9aFR04H2b7Jfz54p5tlkJFgG5JWoRF78YmmpCeO7saZb7Llc6XVQD0qnvS+1CHzpxMsYPaPI8P9tIwJ7n7D1uBYCkdv4KP6MLRhId068RY/qVRs2i33R9u2E9cMMhE7DL5tk2cUkinDp9GHYd27ck+VYqpVjFWk7yMQKXm/xHkfbnl3pDmHISDFDJBytOqPVSiIdYpeJWADxDRM8CuF/5fjCAp7wpUteDiBxDAZ9vs4eunzx+2pSCjeFdCbsqmDNtKOa/+o3lLmLFUC4/cSc30ErzVfcbLWyGObhjQesAii9PKXFrBD4fsifOeOVvvhDiQi8Lxhgpd188fkAzxvYvfnpdaQ2+VJyy4zAAzvsAVzJu21MljgEaFWNsSCqPEiKf7WDLkX8pcb0lpBDiYQAPe1YSpktRgf1GXhQa873ofN2c43H/U+ky+/qDJ+CRdxdjbP/SesXlIksFVEDrqLQBkaMAIKJ1sG4PBEAIIcr7BKqYStRFVwPl9oN3k1sxsX3c/FZpnZSZnvURzJk2rGz5ZVRAyn/1eJmahpcqOUcBIIToXJa7Lkilv4xdHbt33CuB3NZanoiS2jadFT/e9x9zR++0G2AuKq22u5wnT1elEnWx1UC5693NHsilwXkpGGOPVjslahzDWpz3FvZyFsoCgPGULj/C9OP2PNqBrG9TFEdv18qzThtKsVevlTpHXWnsB66NwAxTTcwY1Qsvfr7CfvTVyWdkVrelrgZfvrYjc165ClRiLt1jDD5YvLokaWkus6oNoAgBaXXpkZNb0ZFI4cqnPre+xi8bAFM5dNYXsbNy8+ET8ZOyB68jnfzBWHUtvRuj2HpId7z17cqs7U07C8duP6RkaWULy8L3A6g0WAAw3tDJX45oKIAB3UofuuKC2Zvh+U+XF5VGKdYB53o8Nx82EQ8t+AFbDmzOM7eui3kGUDZrTSWsA2B8ppN2qKxPNnLKjsO1PWQrApsH1NIQwanTK6icFcQWA5uxz4R+OH3GiPwvrrD3gQVAhVNh7YXpImTcQJlcmAfgoYCEPx6yZUFpuXGKKKdqiQVAhaOqYJ38zm8/sg3f/byhTCXKj66gJ600SrMfgNGw6cQlu4/G5v28j7pZ6ZTCGOtqy88ySmUWABVOc00YyxIdiCXtN1PZeUzvMpYoP7q8CqgT3F+xz+B4lztndVVUHXwneNR5w+sAKpyzd5b1jOq+up0FDl3BVCIzRuW/qVJ9RB4nTx3Rs9TF8R2eAVQ4B08ahIMnDfK7GIwdPsi5UqgiNBtAl5+iFcaAbjVYvGoTAHnw9doF09G7MVp0upVW277MAIjociJaQkTvK3+7+VEOhikaD97oZ8+ahodP3q6oNBoiQURD9q83z8+cmTXGuHnTwO61CAfLFX66LNkA8HcGcL0Q4lof82eYgvHyJd2sj3MMxv22GoDXvvoJL35uv33pu5furIte6bAjWEEl7Pp49XwrbcLFNgDGU/Jt77/cbRQaopWvmfTzRW6MhnDn0ZMczwkFpKwR68je9drncoe5ZqyZf8RWWcfK2bb8FACnEdGHRHQXEXWzO4mI5hDRAiJa0N7eXs7yMT4wZ9owfHT5Ln4Xwz2dvB+ttBFppVFo/Yzua71Vink2Nstin/By4pkAIKIXiOhji7+9AfwJwDAAEwAsBXCdXTpCiPlCiDYhRFtLS4tXxWWYwvC5Ax1j09FYwZ5Z5ePx06YUfG2XsAEIIWa6OY+IbgfwL6/KwfgDaxi85/1Ld0bUxab0jjuClbA8XZFC23EoIOHiXUfhqqeNET7tnoVfMzG/vID66r7uC+BjP8rBlIGu3sP4KOiaa8OuBIAV7AbqPT3qI34XISd+WduuJqIJkLuHRQBO9KkcjEdUzQSgk/afrA5yRzHysW1wtmnTLjn9TKPLG4GFEEcIIcYJIcYLIfYSQiz1oxyMd3TSftE1nVHF1RnL7BelqKrWnnVYNG/3EqTkHZXvb8cwFQhrTroeI3vXoyEqh1zx7PHaNBz9YbOg9lJuswBgPIEHm5VNxgbgbzkqiefO3iHrWKlnTW6re9rIFrz6ZXte1xQCLwRjPKWrbgrfmdQpVp18Jyq+r5RLQJrb011HteFvx23jeb4sABimiumqAtoONbT1hEHNjueVW0CaBU0wICHiEMupVLAKiPEU9jbxnyE969CrIYKLdxutHetMM5hSMnlYD1eGWa/EYiEzCrYBMJ2WahthViI14QDemmu9LpNtAN4TkAiptFzRhay78PIRsQBgPIGDjVU2M0b3xu2vfYvthnW9TU5KQSlb74eXzUI6R8fv1+vCAoBhCqCzj5y3HepOFcIUT10kdzfr1J68lA1sBGYYhikTlTZuYAHAeEpnHynbwRouphAq7X1gAcB4AneQDJNNz4bKChDHAoDxhEob6ZSacEB+dbYfwUZUxj17ju+LW38x0e9iaLARmGEKIBoK4OXzdkSfpqjfRWE8pNRuzESE2WP75j6xTLAAYDyhGlRArT3r/C4C00n53b5jMapPg9/FYAHAeEsX1wQxXRyvVrIfvs3gnOeUQ43KNgCGYZgqxTcBQESnE9HnRPQJEV3tVzkYhmHs8DOUSTnUqL6ogIhoOoC9AWwhhIgRUS8/ysF4RxWYAJgujJ82rHJm7dcM4GQA84QQMQAQQqzwqRwMwzBZVIIbc1e2AYwEMJWI3iSiV4hokt2JRDSHiBYQ0YL29vYyFpFhmGrHj3Dm5ZQ9nqmAiOgFAH0sfpqr5NsdwLYAJgF4iIiGCotYqUKI+QDmA0BbW1sFyGWGYaoFtgEUiBDCOgA5ACI6GcAjSof/FhGlAfQEwEP8LkYh8c8Zxm/KbQPwKyy3XyqgRwFMBwAiGgkgDOAnn8rCeEA1LARjmFIxbkAT/nPRTgAyRuByjJ38Wgh2F4C7iOhjAHEAR1mpf5jOCz9NhikNXg6mfBEAQog4gF/4kTfDMEwlYx47eTmY4pXAjCewCohhiqMc7xALAMZTWBPEMPlRThsACwCGYZgKxsuZAAsAhmGYCoZtAEwnhI0ADFMIan/PNgCGYRgf8dOdmW0ATKdleEs9AOCEqUN9LgnD5A/56MZmzrnLrQNguj5NtSEsmre738VgmIKolnWpPANgGIaxoRLWs7ARmGEYxge6+kSABQDDMIwJP20AZngdAMMwTBlhGwDDMAzjG5Iy8g8FvOum2QuIYRjGRCWogCYO6oaTdxyGoya3epYHCwCGYZgKRJIIF84e5W0enqbOMAzDVCy+zACI6EEAmylfmwGsFkJM8KMsDMMwZsb0bQQAjOhd73NJvMWvHcEOVj8T0XUA1vhRDoZhGCv2ntAPm/drxIjeDX4XxVN8tQGQbGk5CMBOfpaDYRhGDxGVvfP3w/XUbxvAVADLhRBf2Z1ARHOIaAERLWhvby9j0RiGYcpPOT2QPJsBENELAPpY/DRXCPGY8vlQAPc7pSOEmA9gPgC0tbVVx+oMhmGqlnLOBDwTAEKImU6/E1EQwH4AtvKqDAzDMJ0FP9Ye+KkCmgngcyHEYh/LwDAMU7X4KQAOQQ71D8MwTLXghxHYNy8gIcTRfuXNMAxTqZRTFeS3FxDDMAyjo5wzARYADMMwFUC1GYEZhmEYhWpcCMYwDMPoYBsAwzAM4zksABiGYSoINgIzDMNUGWwEZhiGqVLYCMwwDFPlsBGYYRiG8RwWAAzDMBUEG4EZhmEYz2EBwDAMU0GwDYBhGIbxHBYADMMwVQoLAIZhmApAUlQ/kVD5umVfNoQhogkAbgUQBZAEcIoQ4i0/ysIwDFMJ9G2K4rxZI7HXFv3LlqdfO4JdDeDXQoiniWg35fuOPpWFYRjGd4gIp+00oqx5+qUCEgAalc9NAH70qRwMwzBVi18zgLMAPEtE10IWQtvZnUhEcwDMAYBBgwaVpXAMwzDVgGcCgIheANDH4qe5AGYAOFsI8TARHQTgTgAzrdIRQswHMB8A2trayh8tiWEYpovimQAQQlh26ABARPcAOFP5+ncAd3hVDoZhGMYav2wAPwLYQfm8E4CvfCoHwzBM1eKXDeAEADcQURBABxQdP8MwDFM+fBEAQojXAWzlR94MwzCMDK8EZhiGqVLIj23ICoWI2gF8V+DlPQH8VMLidEW4jnLDdZQbrqPclLuOBgshWswHO5UAKAYiWiCEaPO7HJUM11FuuI5yw3WUm0qpI1YBMQzDVCksABiGYaqUahIA8/0uQCeA6yg3XEe54TrKTUXUUdXYABiGYRgj1TQDYBiGYXSwAGAYhqlSqkIAENFsIvqCiBYS0UV+l8dPiGgREX1ERO8T0QLlWHciep6IvlL+d1OOExHdqNTbh0Q00d/SewMR3UVEK4joY92xvOuEiI5Szv+KiI7y4168wqaOLieiJUpbel/Z3En97WKljr4gol10x7vku0hEA4noJSL6lIg+IaIzleOV3Y6EEF36D0AAwNcAhgIIA/gAwBi/y+VjfSwC0NN07GoAFymfLwLwe+XzbgCeBkAAtgXwpt/l96hOpgGYCODjQusEQHcA3yj/uymfu/l9bx7X0eUAzrM4d4zynkUADFHev0BXfhcB9AUwUfncAOBLpR4quh1VwwxgawALhRDfCCHiAB4AsLfPZao09gZwt/L5bgD76I7fI2TeANBMRH19KJ+nCCFeBbDSdDjfOtkFwPNCiJVCiFUAngcw2/PClwmbOrJjbwAPCCFiQohvASyE/B522XdRCLFUCPGu8nkdgM8A9EeFt6NqEAD9Afyg+75YOVatCADPEdE7ym5rANBbCLFU+bwMQG/lczXXXb51Uq11dZqiwrhLVW+gyuuIiFoBbAngTVR4O6oGAcAY2V4IMRHArgBOJaJp+h+FPA9l32AdXCe2/AnAMAATACwFcJ2vpakAiKgewMMAzhJCrNX/VontqBoEwBIAA3XfByjHqhIhxBLl/woA/4Q8LV+uqnaU/yuU06u57vKtk6qrKyHEciFESgiRBnA75LYEVGkdEVEIcud/rxDiEeVwRbejahAAbwMYQURDiCgM4BAAj/tcJl8gojoialA/A5gF4GPI9aF6GxwF4DHl8+MAjlQ8FrYFsEY3ne3q5FsnzwKYRUTdFFXILOVYl8VkD9oXclsC5Do6hIgiRDQEwAgAb6ELv4tERJD3Nv9MCPEH3U+V3Y78tp6X4w+yxf1LyB4Ic/0uj4/1MBSy58UHAD5R6wJADwAvQt6a8wUA3ZXjBOBmpd4+AtDm9z14VC/3Q1ZhJCDrXI8rpE4AHAvZ4LkQwDF+31cZ6uivSh18CLlD66s7f65SR18A2FV3vEu+iwC2h6ze+RDA+8rfbpXejjgUBMMwTJVSDSoghmEYxgIWAAzDMFUKCwCGYZgqhQUAwzBMlcICgGEYpkphAcAweUJEZxFRrd/lYJhiYTdQhskTIloE2W/7J7/LwjDFwDMAhnFAWT39JBF9QEQfE9FlAPoBeImIXlLOmUVE/yOid4no70o8GHXvhatJ3n/hLSIa7ue9MIwZFgAM48xsAD8KIbYQQowF8EcAPwKYLoSYTkQ9AVwCYKaQg+wtAHCO7vo1QohxAG5SrmWYioEFAMM48xGAnYno90Q0VQixxvT7tpA3/vgPEb0POd7LYN3v9+v+T/a6sAyTD0G/C8AwlYwQ4ktlu77dAFxBRC+aTiHIG3gcapeEzWeG8R2eATCMA0TUD8BGIcTfAFwDeVvEdZC3/QOANwBMUfX7is1gpC6Jg3X//1eeUjOMO3gGwDDOjANwDRGlIUfCPBmyKucZIvpRsQMcDeB+Iooo11wCOeIlAHQjog8BxADYzRIYxhfYDZRhPILdRZlKh1VADMMwVQrPABiGYaoUngEwDMNUKSwAGIZhqhQWAAzDMFUKCwCGYZgqhQUAwzBMlfL/xtkB2cHP8ZUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_all(*run_experiment(\n",
    "    model=ModelConfig(name='monte'),\n",
    "    num_episodes=500,\n",
    "    training=TrainConfig(optimizer='adam', lr=0.01, batch_size=-1, train_interval=16, clear_memory=True),\n",
    "    seed=1\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1b6a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(*run_experiment(\n",
    "    model=ModelConfig(name='nn'),\n",
    "    num_episodes=150,\n",
    "    training=TrainConfig(optimizer='adam', lr=0.009, batch_size=32, train_interval=32, clear_memory=True)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fcd1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(*run_experiment(\n",
    "    model=ModelConfig(name='nn'),\n",
    "    num_episodes=300,\n",
    "    training=TrainConfig(optimizer='adam', lr=0.03, batch_size=64, train_interval=64, clear_memory=True)\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
