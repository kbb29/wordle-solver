{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ebc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pathlib, random, time\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "\n",
    "from environment import Env, validate_against_hint, load_word_lists, construct_word_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae1b8e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = construct_word_df(*load_word_lists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895b599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def word_to_action(word, guesses, history):\n",
    "    return dfword_to_action((word, df.loc[word]), guesses, history)\n",
    "    \n",
    "def dfword_to_action(dfword, guesses, history):\n",
    "    #the action is going to be a word that we will submit next\n",
    "    #for the purposes of feeding into the model, we will represent the action word as:\n",
    "    #  how many of the entries in the hint history this word conforms to\n",
    "    #  how many untried letters it gives us\n",
    "    #  the number of uniq letters in the word\n",
    "    #  the frequency of the letters in the word\n",
    "    #  whether or not the word is in the guess list (as opposed to the target list)\n",
    "    word = dfword[0]\n",
    "    dfword = dfword[1]\n",
    "    \n",
    "    if guesses:\n",
    "        conforms_to_history = sum([int(validate_against_hint(word,g,history[i])) for i,g in enumerate(guesses)]) / len(guesses)\n",
    "    else: # we haven't made any guess yet, so this must conform\n",
    "        conforms_to_history = 1.0\n",
    "    num_untried_letters = len(set(word) - set(''.join(guesses))) / 5 #normalise to 1\n",
    "    action = np.array([conforms_to_history, num_untried_letters, dfword['freq_score'], dfword['uniq_score'], dfword['is_guess_word']])\n",
    "    \n",
    "    #if word == 'aargh':\n",
    "    #    print(f'recons', action, history, guesses)\n",
    "    return action   \n",
    "    \n",
    "\n",
    "def construct_action_vectors_global(arg): #guesses, history, start_idx, end_idx):\n",
    "    st = time.time()\n",
    "    guesses, history, start_idx, end_idx = arg\n",
    "    #print(guesses, history, start_idx, end_idx)\n",
    "    ret = np.array([dfword_to_action(dfword, guesses, history) for dfword in df.iloc[start_idx:end_idx].iterrows()])\n",
    "    #print(f'construct_actions_global took {time.time() - st}')\n",
    "    return ret\n",
    "           \n",
    "def construct_action_vectors(guesses, history, df):\n",
    "        return np.array([dfword_to_action(dfword, guesses, history) for dfword in df.iterrows()])\n",
    "    \n",
    "NUM_PROCESSES = mp.cpu_count() - 1\n",
    "def construct_action_vectors_mp(guesses, history, df):\n",
    "        grp_lst_args = []\n",
    "        grp_guesses = [guesses] * NUM_PROCESSES\n",
    "        grp_history = [history] * NUM_PROCESSES\n",
    "        \n",
    "        chunk_size = int(len(df) / NUM_PROCESSES) + 1\n",
    "        start_offsets = list(range(0, len(df), chunk_size))\n",
    "        end_offsets = start_offsets[1:] + [len(df)]\n",
    "        grp_lst_args = list(zip(grp_guesses, grp_history, start_offsets, end_offsets))\n",
    "        \n",
    "        #print(grp_lst_args)\n",
    "        pool = mp.Pool(processes=NUM_PROCESSES)\n",
    "        results = pool.map(construct_action_vectors_global, grp_lst_args)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        return np.concatenate(results)\n",
    "    \n",
    "    \n",
    "def construct_state_vector(guesses, history):\n",
    "        #print(history)\n",
    "        #so the state is going to be:\n",
    "            #  The number of green locations we know\n",
    "            #  The number of other letters we know to be in the word\n",
    "            #  The sequence number of the guess (1st guess, 2nd guess etc.)\n",
    "\n",
    "        #the number of locations which were green at some point in the history\n",
    "        num_green_locs = np.count_nonzero(history.max(axis=0) == 2)\n",
    "\n",
    "        green_chars = [guesses[x][y] for x,y in np.argwhere(history == 2) ]\n",
    "        orange_chars = [guesses[x][y] for x,y in np.argwhere(history == 1) ]\n",
    "        black_chars = [guesses[x][y] for x,y in np.argwhere(history == 0) ]\n",
    "        num_other_letters = len(set(orange_chars) - set(green_chars))\n",
    "        num_black_letters = len(set(black_chars))\n",
    "\n",
    "        sequence_number = int(history.size / 5)\n",
    "        #print(f'construct_state() with seqno {sequence_number}')\n",
    "\n",
    "        sequence_number_onehot = np.zeros(Env.num_guesses)\n",
    "        sequence_number_onehot[sequence_number] = 1.0\n",
    "        return np.concatenate((np.array([num_green_locs, num_other_letters, num_black_letters])/5, sequence_number_onehot))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0339f14",
   "metadata": {},
   "source": [
    "   \n",
    "so the state is going to be:\n",
    "* The number of green locations we know\n",
    "*  The number of other letters we know to be in the word\n",
    "*  The number of letters we know to not be in the word\n",
    "*  The sequence number of the guess (1st guess, 2nd guess etc.)\n",
    "\n",
    "the action is going to be a word that we will submit next\n",
    "for the purposes of feeding into the model, we will represent the action word as:\n",
    "*  whether or not it conforms to the hint history\n",
    "*  how many new letters it gives us\n",
    "*  the number of uniq letters in the word\n",
    "*  the frequency of the letters in the word\n",
    "\n",
    "the reward is going to be:\n",
    "*  the score improvement (if any) gained on the last guess\n",
    "*  the score will be calculated as 2 * num_green_letters + num_orange_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9dd99de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "#plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "832e7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def clear(self):\n",
    "        self.memory.clear()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb9ed4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of actions from gym action space\n",
    "#n_actions = env.action_space.n\n",
    "n_action_features = 5\n",
    "n_state_features = 9\n",
    "n_input_features = n_action_features + n_state_features\n",
    "\n",
    "\n",
    "def select_action(policy_net, state, actions, eps_threshold):\n",
    "    sample = random.random()\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            #now combine the state (shape 3,) and action (shape 5, n) into one input array (shape 8,n)\n",
    "            #first expand the state so that it is shape 3,1\n",
    "            #then repeat it to 3,n\n",
    "            states = np.repeat(np.expand_dims(state, 0), actions.shape[0], axis=0)\n",
    "            #print(f'states shape {states.shape} actions shape {actions.shape}')\n",
    "            #then concatenate to 8,n\n",
    "            state_actions = np.concatenate((states, actions), axis=1)\n",
    "            # policy_net(state_action) will return a single value estimate for each state/action row\n",
    "            # so, probably shape (1,n)\n",
    "            # Then return the index which has the max value\n",
    "            \n",
    "            estimate = policy_net(torch.tensor(state_actions, device=device, dtype=torch.float))\n",
    "            #print(f'ESTIMATE>>>{estimate.__class__} {estimate.shape} {estimate} {estimate.max(0).indices.item()}<<<')\n",
    "            return estimate.max(0).indices.item()\n",
    "    else:\n",
    "        randindex = random.randrange(len(actions))\n",
    "        print(f'returning random index {randindex}')\n",
    "        return randindex #torch.tensor([[randindex]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "def plot_values(vals, axes=['duration', 'episode']):\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel(axes[1])\n",
    "    plt.ylabel(axes[0])\n",
    "    plt.plot(np.array(vals))\n",
    "    # Take 20 episode averages and plot them too\n",
    "    window_width = 20\n",
    "    if len(vals) >= window_width:\n",
    "        cumsum_vec = np.cumsum(np.insert(vals, 0, 0)) \n",
    "        ma_vec = (cumsum_vec[window_width:] - cumsum_vec[:-window_width]) / window_width\n",
    "        plt.plot(np.insert(ma_vec, 0, [None]*int(window_width/2)))\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    #if is_ipython:\n",
    "    #    display.clear_output(wait=True)\n",
    "    #    display.display(plt.gcf())\n",
    "    \n",
    "def plot_all(episode_durations, episode_rewards, losses, epsilons, gammas):\n",
    "    plot_values(episode_durations, axes=['duration', 'episode'])\n",
    "    plot_values(episode_rewards, axes=['reward', 'episode'])\n",
    "    if losses: plot_values(losses, axes=['loss', 'step'])\n",
    "    if epsilons: plot_values(epsilons, axes=['epsilon', 'step'])\n",
    "    if gammas: plot_values(gammas, axes=['gamma', 'step'])\n",
    "    #plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae28e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, inputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(inputs, 20)\n",
    "        self.fc2 = nn.Linear(20, 16)\n",
    "        self.fc3 = nn.Linear(16, 20)\n",
    "        self.head = nn.Linear(20, 1)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c642286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearQ(nn.Module):\n",
    "\n",
    "    def __init__(self, inputs):\n",
    "        super(LinearQ, self).__init__()\n",
    "        self.head = nn.Linear(inputs, 1)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c1200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(model, optimizer, memory, batch_size=128):\n",
    "\n",
    "    transitions = memory.sample(batch_size)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    state_batch = np.stack([tr.state for tr in transitions])\n",
    "    action_batch = np.stack([tr.action for tr in transitions])\n",
    "      \n",
    "    reward_batch = np.stack([tr.reward for tr in transitions])\n",
    "    state_action_batch = np.concatenate((state_batch, action_batch), axis=1)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_value_estimates = model(torch.tensor(state_action_batch, device=device, dtype=torch.float))\n",
    "    #print(f'ESTIMATE>>>{estimate.__class__} {estimate.shape} {estimate} {estimate.max(0).indices.item()}<<<')\n",
    "       \n",
    "    expected_state_action_values = torch.tensor(reward_batch, device=device, dtype=torch.float)\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_value_estimates, expected_state_action_values)\n",
    "    \n",
    "    print(f'loss {loss}')\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    #for param in model.parameters():\n",
    "        #param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "class TrainConfig():\n",
    "    def __init__(self, train_interval=128, batch_size=128, clear_memory=False, lr=0.01):\n",
    "        self.train_interval = train_interval\n",
    "        self.batch_size = batch_size\n",
    "        self.clear_memory = clear_memory\n",
    "        self.lr = lr\n",
    "        \n",
    "class ValueConfig():\n",
    "    def __init__(self, name='reward', gamma=[0.9, 0.05, 200]):\n",
    "        self.name = name\n",
    "        self.gamma = gamma\n",
    "        \n",
    "class ModelConfig():\n",
    "    def __init__(self, name='naive', startword=None, target_list_only=None):\n",
    "        self.name = name\n",
    "        self.startword = startword\n",
    "        self.target_list_only = target_list_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71c62073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "def run_experiment(model=ModelConfig(name='naive', startword=None, target_list_only=False),\n",
    "                   num_episodes=128,\n",
    "                   eps=[0.9, 0.05, 200],\n",
    "                   value_function=ValueConfig(name='reward',gamma=[0.0, 1.0, 200]),\n",
    "                   training=TrainConfig(clear_memory=False, batch_size=128, train_interval=128)):\n",
    "    torch.manual_seed(0)\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "    EPS_START = eps[0]\n",
    "    EPS_END = eps[1]\n",
    "    EPS_DECAY = eps[2]\n",
    "    GAMMA_START, GAMMA_END, GAMMA_DECAY = value_function.gamma\n",
    "    env = Env(df)\n",
    "    memory = ReplayMemory(10000)\n",
    "    starting_actions = construct_action_vectors(env.guesses, env.history, env.df)\n",
    "    starting_state = construct_state_vector(env.guesses, env.history)\n",
    "\n",
    "    steps_done = 0\n",
    "    last_training = 0\n",
    "    losses = []\n",
    "    episode_rewards = []\n",
    "    episode_durations = []\n",
    "    epsilons = []\n",
    "    gammas = []\n",
    "    \n",
    "    if model.name == 'linear':\n",
    "        policy_net = LinearQ(n_input_features).to(device)\n",
    "        optimizer = optim.RMSprop(policy_net.parameters(), lr=training.lr)\n",
    "    else:\n",
    "        policy_net = DQN(n_input_features).to(device)\n",
    "        optimizer = optim.RMSprop(policy_net.parameters(), lr=training.lr)\n",
    "\n",
    "    print(f'pn params {list(policy_net.parameters())}')\n",
    "    for i_episode in range(num_episodes):\n",
    "        # Initialize the environment and state\n",
    "        env.reset()\n",
    "        print(f'=========================episode {i_episode} {env.target}======================')\n",
    "\n",
    "        episode_memory = []\n",
    "        state = starting_state\n",
    "        actions = starting_actions\n",
    "        guesses = []\n",
    "        for t in count():\n",
    "            eps = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "            GAMMA = GAMMA_END + (GAMMA_START - GAMMA_END) * math.exp(-1. * steps_done / GAMMA_DECAY)\n",
    "            \n",
    "            epsilons.append(eps)\n",
    "            #print(epsilons)\n",
    "            gammas.append(GAMMA)\n",
    "            steps_done += 1\n",
    "            # Select and perform an action\n",
    "            #print(state, actions)\n",
    "            action_idx = select_action(policy_net, state, actions, eps)\n",
    "            selected_action = actions[action_idx]\n",
    "            guesses.append(env.word_from_index(action_idx))\n",
    "            print(f'------guess {t} {action_idx} {guesses[-1]} {selected_action}-------')\n",
    "            history, reward, done = env.step_by_index(action_idx)\n",
    "            #here next_state == env.history\n",
    "            if not done:\n",
    "                next_state = construct_state_vector(guesses, history)\n",
    "                actions = construct_action_vectors_mp(guesses, history, env.df)\n",
    "            \n",
    "            print(f'reward {reward} done {done} ')\n",
    "            #reward = np.array([reward])\n",
    "\n",
    "            # Store the transition in memory\n",
    "            #memory.push(state, selected_action, reward)\n",
    "            episode_memory.append([state, selected_action, reward])\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                episode_durations.append(t + 1)\n",
    "                scores = history.sum(axis=1) # calc the score for each guess from the history\n",
    "                episode_reward = sum(tr[2] for tr in episode_memory)\n",
    "                print(f'episode {i_episode} finished.  reward {episode_reward}  eps {eps}  gamma {GAMMA}  steps {steps_done}  memory {len(memory)}')\n",
    "                episode_rewards.append(episode_reward)\n",
    "                # reward[i] = max(0, scores[i] - max(scores[0:i-1]))\n",
    "                \n",
    "                for i,tr in enumerate(episode_memory):\n",
    "                    if i == 0:\n",
    "                        score = scores[i]\n",
    "                    else:\n",
    "                        score = max(0, scores[i] - scores[0:i].max())\n",
    "                    print(f'{guesses[i]} {history[i]} {score}')    \n",
    "                \n",
    "                    memory.push(tr[0], tr[1], score)\n",
    "                    \n",
    "                # If we have gathered enough data, Perform one step of the optimization (on the policy network)\n",
    "                if len(memory) >= training.batch_size \\\n",
    "                    and steps_done - last_training > training.train_interval:\n",
    "                    loss = optimize_model(policy_net, optimizer, memory, batch_size=training.batch_size)\n",
    "                    losses.append(loss)\n",
    "                    if training.clear_memory: memory.clear()\n",
    "                    last_training = steps_done\n",
    "                #plot_durations()\n",
    "                break\n",
    "\n",
    "    print('Complete')\n",
    "    \n",
    "    return episode_durations, episode_rewards, losses, epsilons, gammas\n",
    "\n",
    "#env.render()\n",
    "#env.close()\n",
    "#plt.ioff()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f94916dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pn params [Parameter containing:\n",
      "tensor([[-0.0020,  0.1434, -0.2200, -0.1967, -0.1029,  0.0717, -0.0053,  0.2119,\n",
      "         -0.0237,  0.0707, -0.0808, -0.0525, -0.2553, -0.1770]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.1102], requires_grad=True)]\n",
      "=========================episode 0 lorry======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12189 whiny [1.        0.8       0.3476069 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12621 jumpy [0.5        0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12189 whiny [0.66666667 0.         0.3476069  0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12621 jumpy [0.5        0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12189 whiny [0.6       0.        0.3476069 0.        0.       ]-------\n",
      "reward -1.0 done True \n",
      "episode 0 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 6  memory 0\n",
      "jumpy [0. 0. 0. 0. 2.] 2.0\n",
      "whiny [0. 0. 0. 0. 2.] 0\n",
      "jumpy [0. 0. 0. 0. 2.] 0\n",
      "whiny [0. 0. 0. 0. 2.] 0\n",
      "jumpy [0. 0. 0. 0. 2.] 0\n",
      "whiny [0. 0. 0. 0. 2.] 0\n",
      "=========================episode 1 rebar======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 1 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 12  memory 6\n",
      "jumpy [0. 0. 0. 0. 0.] 0.0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "=========================episode 2 chain======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 2 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 18  memory 12\n",
      "jumpy [0. 0. 0. 0. 0.] 0.0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "=========================episode 3 sewer======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 3 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 24  memory 18\n",
      "jumpy [0. 0. 0. 0. 0.] 0.0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "=========================episode 4 issue======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 10960 chunk [1.         0.8        0.32276069 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12621 jumpy [0.5        0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 10960 chunk [0.66666667 0.         0.32276069 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12621 jumpy [0.5        0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 10960 chunk [0.6        0.         0.32276069 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 4 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 30  memory 24\n",
      "jumpy [0. 1. 0. 0. 0.] 1.0\n",
      "chunk [0. 0. 1. 0. 0.] 0\n",
      "jumpy [0. 1. 0. 0. 0.] 0\n",
      "chunk [0. 0. 1. 0. 0.] 0\n",
      "jumpy [0. 1. 0. 0. 0.] 0\n",
      "chunk [0. 0. 1. 0. 0.] 0\n",
      "=========================episode 5 money======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11290 filmy [1.         0.6        0.36894224 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12621 jumpy [0.5        0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11290 filmy [0.66666667 0.         0.36894224 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12621 jumpy [0.5        0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11290 filmy [0.6        0.         0.36894224 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 5 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 36  memory 30\n",
      "jumpy [0. 0. 1. 0. 2.] 3.0\n",
      "filmy [0. 0. 0. 1. 2.] 0\n",
      "jumpy [0. 0. 1. 0. 2.] 0\n",
      "filmy [0. 0. 0. 1. 2.] 0\n",
      "jumpy [0. 0. 1. 0. 2.] 0\n",
      "filmy [0. 0. 0. 1. 2.] 0\n",
      "=========================episode 6 detox======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 6 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 42  memory 36\n",
      "jumpy [0. 0. 0. 0. 0.] 0.0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "=========================episode 7 visit======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 7 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 48  memory 42\n",
      "jumpy [0. 0. 0. 0. 0.] 0.0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "=========================episode 8 filly======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12189 whiny [1.        0.8       0.3476069 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 2 12189 whiny [0.5       0.        0.3476069 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11618 imply [0.66666667 0.2        0.39606902 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12722 girly [1.         0.4        0.45029257 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12722 girly [0.8        0.         0.45029257 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 8 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 54  memory 48\n",
      "jumpy [0. 0. 0. 0. 2.] 2.0\n",
      "whiny [0. 0. 1. 0. 2.] 1.0\n",
      "whiny [0. 0. 1. 0. 2.] 0\n",
      "imply [1. 0. 0. 2. 2.] 2.0\n",
      "girly [0. 2. 0. 2. 2.] 1.0\n",
      "girly [0. 2. 0. 2. 2.] 0\n",
      "=========================episode 9 augur======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11260 quick [1.         0.8        0.29752438 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12621 jumpy [0.5        0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11260 quick [0.66666667 0.         0.29752438 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12621 jumpy [0.5        0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11260 quick [0.6        0.         0.29752438 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 9 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 60  memory 54\n",
      "jumpy [0. 2. 0. 0. 0.] 2.0\n",
      "quick [0. 2. 0. 0. 0.] 0\n",
      "jumpy [0. 2. 0. 0. 0.] 0\n",
      "quick [0. 2. 0. 0. 0.] 0\n",
      "jumpy [0. 2. 0. 0. 0.] 0\n",
      "quick [0. 2. 0. 0. 0.] 0\n",
      "=========================episode 10 heron======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 10 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 66  memory 60\n",
      "jumpy [0. 0. 0. 0. 0.] 0.0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "loss 0.24786612391471863\n",
      "=========================episode 11 using======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 11271 spilt [1.         0.8        0.57341335 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10837 using [1.         0.6        0.52606152 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 11 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 69  memory 66\n",
      "arose [0. 0. 0. 1. 0.] 1.0\n",
      "spilt [1. 0. 2. 0. 0.] 2.0\n",
      "using [2. 2. 2. 2. 2.] 7.0\n",
      "=========================episode 12 piece======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11753 utile [1.         0.8        0.58808702 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10961 mince [1.         0.6        0.52144036 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12920 piece [1.         0.2        0.63405851 0.33333333 0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 12 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 73  memory 69\n",
      "arose [0. 0. 0. 0. 2.] 2.0\n",
      "utile [0. 0. 1. 0. 2.] 1.0\n",
      "mince [0. 2. 0. 2. 2.] 3.0\n",
      "piece [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 13 recur======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12243 liner [1.        0.6       0.6272168 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11619 demur [1.         0.6        0.53293323 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12039 recur [1.         0.2        0.58565641 0.33333333 0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 13 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 77  memory 73\n",
      "arose [0. 1. 0. 0. 1.] 2.0\n",
      "liner [0. 0. 0. 1. 2.] 1.0\n",
      "demur [0. 2. 0. 2. 2.] 3.0\n",
      "recur [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 14 filly======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11101 unlit [1.         1.         0.47675919 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12715 milky [1.         0.6        0.38064516 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11724 dilly [1.         0.2        0.45095274 0.33333333 0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12346 hilly [1.         0.2        0.43015754 0.33333333 0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12235 billy [1.         0.2        0.42616654 0.33333333 0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 14 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 83  memory 77\n",
      "arose [0. 0. 0. 0. 0.] 0.0\n",
      "unlit [0. 0. 2. 1. 0.] 3.0\n",
      "milky [0. 2. 2. 0. 2.] 3.0\n",
      "dilly [0. 2. 2. 2. 2.] 2.0\n",
      "hilly [0. 2. 2. 2. 2.] 0\n",
      "billy [0. 2. 2. 2. 2.] 0\n",
      "loss 1.8411890268325806\n",
      "=========================episode 15 spiny======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 10846 picky [1.         0.6        0.34163541 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11425 spiny [1.         0.4        0.52420105 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 15 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 86  memory 83\n",
      "jumpy [0. 0. 0. 1. 2.] 3.0\n",
      "picky [1. 1. 0. 0. 2.] 1.0\n",
      "spiny [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 16 hydro======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12110 vying [1.         0.8        0.33377344 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11859 bylaw [1.         0.8        0.42313578 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11050 hydro [1.         0.8        0.44660165 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 16 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 90  memory 86\n",
      "jumpy [0. 0. 0. 0. 1.] 1.0\n",
      "vying [0. 2. 0. 0. 0.] 1.0\n",
      "bylaw [0. 2. 0. 0. 0.] 0\n",
      "hydro [2. 2. 2. 2. 2.] 8.0\n",
      "=========================episode 17 chase======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12097 wight [1.         1.         0.34499625 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12119 chalk [1.         0.8        0.43972993 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12368 chard [1.         0.4        0.49179295 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11993 chafe [1.        0.4       0.5267817 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11309 chase [1.         0.2        0.69332333 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 17 finished.  reward -5.0  eps 0.0  gamma 0.0  steps 96  memory 90\n",
      "jumpy [0. 0. 0. 0. 0.] 0.0\n",
      "wight [0. 0. 0. 1. 0.] 1.0\n",
      "chalk [2. 2. 2. 0. 0.] 5.0\n",
      "chard [2. 2. 2. 0. 0.] 0\n",
      "chafe [2. 2. 2. 0. 2.] 2.0\n",
      "chase [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 18 champ======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11995 blimp [1.         0.6        0.38265566 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10839 champ [1.         0.6        0.41329332 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 18 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 99  memory 96\n",
      "jumpy [0. 0. 1. 1. 0.] 2.0\n",
      "blimp [0. 0. 0. 2. 2.] 2.0\n",
      "champ [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 19 geese======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12097 wight [1.         1.         0.34499625 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12846 clang [1.         0.8        0.47966992 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11169 grove [1.       0.8      0.528012 0.       0.      ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11169 grove [0.75     0.       0.528012 0.       0.      ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12754 glaze [0.8        0.2        0.54316579 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 19 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 105  memory 99\n",
      "jumpy [0. 0. 0. 0. 0.] 0.0\n",
      "wight [0. 0. 1. 0. 0.] 1.0\n",
      "clang [0. 0. 0. 0. 1.] 0\n",
      "grove [2. 0. 0. 0. 2.] 3.0\n",
      "grove [2. 0. 0. 0. 2.] 0\n",
      "glaze [2. 0. 0. 0. 2.] 0\n",
      "loss 0.7349137663841248\n",
      "=========================episode 20 hippo======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 10777 pilot [1.         0.8        0.50658665 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11240 mound [0.5       0.8       0.4300075 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12918 bigot [0.66666667 0.4        0.44300075 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11721 viola [0.5        0.2        0.54769692 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11206 shock [0.2      0.6      0.492003 0.       0.      ]-------\n",
      "reward -1.0 done True \n",
      "episode 20 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 111  memory 105\n",
      "arose [0. 0. 1. 0. 0.] 1.0\n",
      "pilot [1. 2. 0. 1. 0.] 3.0\n",
      "mound [0. 1. 0. 0. 0.] 0\n",
      "bigot [0. 2. 0. 1. 0.] 0\n",
      "viola [0. 2. 1. 0. 0.] 0\n",
      "shock [0. 1. 1. 0. 0.] 0\n",
      "=========================episode 21 knock======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12237 clout [1.         0.8        0.46940735 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12087 phony [0.5        0.8        0.39738935 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11029 blown [0.66666667 0.4        0.40291073 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11422 gnome [0.5        0.4        0.53029257 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12049 snort [0.6        0.         0.64540135 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 21 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 117  memory 111\n",
      "arose [0. 0. 2. 0. 0.] 2.0\n",
      "clout [1. 0. 2. 0. 0.] 1.0\n",
      "phony [0. 0. 2. 1. 0.] 0\n",
      "blown [0. 0. 2. 0. 1.] 0\n",
      "gnome [0. 2. 2. 0. 0.] 1.0\n",
      "snort [0. 2. 2. 0. 0.] 0\n",
      "=========================episode 22 mogul======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 10777 pilot [1.         0.8        0.50658665 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10881 could [1.         0.6        0.44414104 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11943 mogul [1.         0.4        0.41830458 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 22 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 121  memory 117\n",
      "arose [0. 0. 1. 0. 0.] 1.0\n",
      "pilot [0. 0. 1. 1. 0.] 1.0\n",
      "could [0. 2. 1. 1. 0.] 2.0\n",
      "mogul [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 23 dingo======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 10777 pilot [1.         0.8        0.50658665 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11680 dingo [1.         0.6        0.45749437 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 23 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 124  memory 121\n",
      "arose [0. 0. 1. 0. 0.] 1.0\n",
      "pilot [0. 2. 0. 1. 0.] 2.0\n",
      "dingo [2. 2. 2. 2. 2.] 7.0\n",
      "loss 0.8214893937110901\n",
      "=========================episode 24 grace======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 24 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 130  memory 124\n",
      "jumpy [0. 0. 0. 0. 0.] 0.0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "jumpy [0. 0. 0. 0. 0.] 0\n",
      "=========================episode 25 briny======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 25 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 136  memory 130\n",
      "jumpy [0. 0. 0. 0. 2.] 2.0\n",
      "jumpy [0. 0. 0. 0. 2.] 0\n",
      "jumpy [0. 0. 0. 0. 2.] 0\n",
      "jumpy [0. 0. 0. 0. 2.] 0\n",
      "jumpy [0. 0. 0. 0. 2.] 0\n",
      "jumpy [0. 0. 0. 0. 2.] 0\n",
      "=========================episode 26 rupee======================\n",
      "------guess 0 12621 jumpy [1.         1.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12621 jumpy [0.         0.         0.26619655 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 26 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 142  memory 136\n",
      "jumpy [0. 2. 0. 1. 0.] 3.0\n",
      "jumpy [0. 2. 0. 1. 0.] 0\n",
      "jumpy [0. 2. 0. 1. 0.] 0\n",
      "jumpy [0. 2. 0. 1. 0.] 0\n",
      "jumpy [0. 2. 0. 1. 0.] 0\n",
      "jumpy [0. 2. 0. 1. 0.] 0\n",
      "loss 0.6088314056396484\n",
      "=========================episode 27 gouge======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 12375 opine [1.         0.6        0.59504876 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11398 boule [1.        0.6       0.5584096 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11824 lodge [0.66666667 0.4        0.55717929 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 10813 rouge [0.75       0.         0.58253563 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12013 mouse [0.4        0.2        0.66772693 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 27 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 148  memory 142\n",
      "arose [0. 0. 1. 0. 2.] 3.0\n",
      "opine [1. 0. 0. 0. 2.] 0\n",
      "boule [0. 2. 2. 0. 2.] 3.0\n",
      "lodge [0. 2. 0. 2. 2.] 0\n",
      "rouge [0. 2. 2. 2. 2.] 2.0\n",
      "mouse [0. 2. 2. 0. 2.] 0\n",
      "=========================episode 28 flier======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12243 liner [1.        0.6       0.6272168 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11845 idler [1.         0.2        0.61224306 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11375 plier [1.        0.2       0.5992198 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11415 flier [1.         0.2        0.57209302 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 28 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 153  memory 148\n",
      "arose [0. 1. 0. 0. 1.] 2.0\n",
      "liner [1. 1. 0. 2. 2.] 4.0\n",
      "idler [1. 0. 1. 2. 2.] 0\n",
      "plier [0. 2. 2. 2. 2.] 2.0\n",
      "flier [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 29 flesh======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 10974 heist [1.        0.6       0.6643961 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10710 flesh [1.         0.4        0.58733683 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 29 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 156  memory 153\n",
      "arose [0. 0. 0. 2. 1.] 3.0\n",
      "heist [1. 1. 0. 2. 0.] 1.0\n",
      "flesh [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 30 dryer======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12441 tried [1.         0.6        0.60996249 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12124 cruel [0.5        0.6        0.56204051 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11732 grief [0.66666667 0.4        0.52027007 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 10529 yrneh [0.75       0.6        0.52831208 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11389 pried [0.4        0.2        0.57167292 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 30 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 162  memory 156\n",
      "arose [0. 2. 0. 0. 1.] 3.0\n",
      "tried [0. 2. 0. 2. 1.] 2.0\n",
      "cruel [0. 2. 0. 2. 0.] 0\n",
      "grief [0. 2. 0. 2. 0.] 0\n",
      "yrneh [1. 2. 0. 2. 0.] 0\n",
      "pried [0. 2. 0. 2. 1.] 0\n",
      "loss 1.0004065036773682\n",
      "=========================episode 31 abode======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 10769 alone [1.         0.4        0.70256564 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10697 adobe [1.         0.4        0.63525881 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12289 abode [1.         0.         0.63525881 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 31 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 166  memory 162\n",
      "arose [2. 0. 2. 0. 2.] 6.0\n",
      "alone [2. 0. 2. 0. 2.] 0\n",
      "adobe [2. 1. 2. 1. 2.] 2.0\n",
      "abode [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 32 wound======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 10777 pilot [1.         0.8        0.50658665 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11240 mound [1.        0.8       0.4300075 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12915 hound [1.         0.2        0.42352588 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12358 bound [1.         0.2        0.41953488 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 10942 found [1.         0.2        0.40417104 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 32 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 172  memory 166\n",
      "arose [0. 0. 1. 0. 0.] 1.0\n",
      "pilot [0. 0. 0. 1. 0.] 0\n",
      "mound [0. 2. 2. 2. 2.] 7.0\n",
      "hound [0. 2. 2. 2. 2.] 0\n",
      "bound [0. 2. 2. 2. 2.] 0\n",
      "found [0. 2. 2. 2. 2.] 0\n",
      "=========================episode 33 lorry======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12925 intro [1.         0.6        0.55819955 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12879 gourd [1.         0.6        0.45623406 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12879 gourd [0.66666667 0.         0.45623406 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12492 cobra [0.75       0.4        0.54736684 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12492 cobra [0.6        0.         0.54736684 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 33 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 178  memory 172\n",
      "arose [0. 1. 1. 0. 0.] 2.0\n",
      "intro [0. 0. 0. 2. 1.] 1.0\n",
      "gourd [0. 2. 0. 2. 0.] 1.0\n",
      "gourd [0. 2. 0. 2. 0.] 0\n",
      "cobra [0. 2. 0. 2. 0.] 0\n",
      "cobra [0. 2. 0. 2. 0.] 0\n",
      "=========================episode 34 trait======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12093 trial [1.         0.6        0.61734434 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10984 train [1.         0.2        0.60477119 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12602 trail [0.66666667 0.         0.61734434 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 10984 train [0.75       0.         0.60477119 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12602 trail [0.6        0.         0.61734434 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 34 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 184  memory 178\n",
      "arose [1. 2. 0. 0. 0.] 3.0\n",
      "trial [2. 2. 1. 1. 0.] 3.0\n",
      "train [2. 2. 2. 2. 0.] 2.0\n",
      "trail [2. 2. 2. 2. 0.] 0\n",
      "train [2. 2. 2. 2. 0.] 0\n",
      "trail [2. 2. 2. 2. 0.] 0\n",
      "loss 0.8574913740158081\n",
      "=========================episode 35 cease======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 10923 lapse [1.         0.4        0.74139535 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11309 chase [1.         0.4        0.69332333 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11309 chase [0.66666667 0.         0.69332333 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11309 chase [0.5        0.         0.69332333 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11708 amuse [0.2        0.4        0.71429857 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 35 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 190  memory 184\n",
      "arose [1. 0. 0. 2. 2.] 5.0\n",
      "lapse [0. 1. 0. 2. 2.] 0\n",
      "chase [2. 0. 2. 2. 2.] 3.0\n",
      "chase [2. 0. 2. 2. 2.] 0\n",
      "chase [2. 0. 2. 2. 2.] 0\n",
      "amuse [1. 0. 0. 2. 2.] 0\n",
      "=========================episode 36 creep======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12441 tried [1.         0.6        0.60996249 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12124 cruel [1.         0.6        0.56204051 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11096 gruel [0.66666667 0.2        0.55051763 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12814 cried [0.75       0.         0.57194299 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12814 cried [0.6        0.         0.57194299 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 36 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 196  memory 190\n",
      "arose [0. 2. 0. 0. 1.] 3.0\n",
      "tried [0. 2. 0. 2. 0.] 1.0\n",
      "cruel [2. 2. 0. 2. 0.] 2.0\n",
      "gruel [0. 2. 0. 2. 0.] 0\n",
      "cried [2. 2. 0. 2. 0.] 0\n",
      "cried [2. 2. 0. 2. 0.] 0\n",
      "=========================episode 37 chard======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 10895 ultra [1.         0.6        0.57989497 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12343 cairn [1.         0.6        0.56675169 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12368 chard [1.         0.4        0.49179295 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 37 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 200  memory 196\n",
      "arose [1. 1. 0. 0. 0.] 2.0\n",
      "ultra [0. 0. 0. 2. 1.] 1.0\n",
      "cairn [2. 1. 0. 2. 0.] 2.0\n",
      "chard [2. 2. 2. 2. 2.] 5.0\n",
      "=========================episode 38 heart======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11530 later [1.         0.4        0.70445611 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12465 teary [1.         0.2        0.66553638 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11313 heart [1.         0.2        0.65611403 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 38 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 204  memory 200\n",
      "arose [1. 1. 0. 0. 1.] 3.0\n",
      "later [0. 1. 1. 1. 1.] 1.0\n",
      "teary [1. 2. 2. 2. 0.] 3.0\n",
      "heart [2. 2. 2. 2. 2.] 3.0\n",
      "loss 0.7614423036575317\n",
      "=========================episode 39 humus======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 11271 spilt [1.         0.8        0.57341335 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12392 dusky [1.         0.8        0.45635409 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11379 nurse [0.66666667 0.2        0.68861215 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12432 mushy [0.75       0.4        0.44969242 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11709 bushy [0.6       0.2       0.4392198 0.        0.       ]-------\n",
      "reward -1.0 done True \n",
      "episode 39 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 210  memory 204\n",
      "arose [0. 0. 0. 1. 0.] 1.0\n",
      "spilt [1. 0. 0. 0. 0.] 0\n",
      "dusky [0. 2. 1. 0. 0.] 2.0\n",
      "nurse [0. 2. 0. 1. 0.] 0\n",
      "mushy [1. 2. 1. 1. 0.] 2.0\n",
      "bushy [0. 2. 1. 1. 0.] 0\n",
      "=========================episode 40 mauve======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11898 plate [1.         0.6        0.64027007 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12238 dance [1.         0.6        0.60270068 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12199 maize [1.         0.6        0.56477119 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12505 maybe [1.        0.4       0.5500075 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12702 mauve [1.         0.4        0.53512378 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 40 finished.  reward -5.0  eps 0.0  gamma 0.0  steps 216  memory 210\n",
      "arose [1. 0. 0. 0. 2.] 3.0\n",
      "plate [0. 0. 1. 0. 2.] 0\n",
      "dance [0. 2. 0. 0. 2.] 1.0\n",
      "maize [2. 2. 0. 0. 2.] 2.0\n",
      "maybe [2. 2. 0. 0. 2.] 0\n",
      "mauve [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 41 rocky======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12925 intro [1.         0.6        0.55819955 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10789 world [1.         0.6        0.46388597 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12444 rough [1.         0.6        0.43543886 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11956 rocky [1.         0.6        0.42619655 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 41 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 221  memory 216\n",
      "arose [0. 1. 1. 0. 0.] 2.0\n",
      "intro [0. 0. 0. 1. 1.] 0\n",
      "world [0. 2. 1. 0. 0.] 1.0\n",
      "rough [2. 2. 0. 0. 0.] 1.0\n",
      "rocky [2. 2. 2. 2. 2.] 6.0\n",
      "loss 0.9323248863220215\n",
      "=========================episode 42 hater======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 7320 raile [1.         0.4        0.71837959 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 2112 dater [1.         0.4        0.67690923 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 6632 pater [1.         0.2        0.66388597 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 5544 mater [1.         0.2        0.66259565 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 3401 gater [1.         0.2        0.65263316 0.         1.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 42 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 227  memory 221\n",
      "aeros [1. 1. 1. 0. 0.] 3.0\n",
      "raile [1. 2. 0. 0. 1.] 1.0\n",
      "dater [0. 2. 2. 2. 2.] 4.0\n",
      "pater [0. 2. 2. 2. 2.] 0\n",
      "mater [0. 2. 2. 2. 2.] 0\n",
      "gater [0. 2. 2. 2. 2.] 0\n",
      "=========================episode 43 cigar======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 5138 liart [1.         0.6        0.61734434 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 2298 dinar [1.         0.4        0.57950488 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 1622 cimar [1.         0.4        0.53746437 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 1622 cimar [0.75       0.         0.53746437 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 8323 sizar [0.4        0.2        0.63033758 0.         1.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 43 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 233  memory 227\n",
      "aeros [1. 0. 1. 0. 0.] 2.0\n",
      "liart [0. 2. 1. 1. 0.] 2.0\n",
      "dinar [0. 2. 0. 2. 2.] 2.0\n",
      "cimar [2. 2. 0. 2. 2.] 2.0\n",
      "cimar [2. 2. 0. 2. 2.] 0\n",
      "sizar [0. 2. 0. 2. 2.] 0\n",
      "=========================episode 44 biddy======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 5200 linty [1.         1.         0.46364591 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 5685 midgy [1.         0.6        0.35726932 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 10235 wicky [0.66666667 0.6        0.31222806 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 4494 jimpy [0.75       0.4        0.30364591 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 9930 vibey [0.6        0.4        0.44459115 0.         1.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 44 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 239  memory 233\n",
      "aeros [0. 0. 0. 0. 0.] 0.0\n",
      "linty [0. 2. 0. 0. 2.] 4.0\n",
      "midgy [0. 2. 2. 0. 2.] 2.0\n",
      "wicky [0. 2. 0. 0. 2.] 0\n",
      "jimpy [0. 2. 0. 0. 2.] 0\n",
      "vibey [0. 2. 1. 0. 2.] 0\n",
      "loss 1.0079728364944458\n",
      "=========================episode 45 renew======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 12243 liner [1.        0.6       0.6272168 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11223 recut [0.5        0.6        0.55975994 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11310 reply [0.66666667 0.4        0.54865716 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11686 reign [0.75       0.2        0.57539385 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11686 reign [0.6        0.         0.57539385 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 45 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 245  memory 239\n",
      "arose [0. 1. 0. 0. 1.] 2.0\n",
      "liner [0. 0. 2. 2. 1.] 3.0\n",
      "recut [2. 2. 0. 0. 0.] 0\n",
      "reply [2. 2. 0. 0. 0.] 0\n",
      "reign [2. 2. 0. 0. 1.] 0\n",
      "reign [2. 2. 0. 0. 1.] 0\n",
      "=========================episode 46 table======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11898 plate [1.         0.6        0.64027007 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12691 lathe [1.         0.2        0.63249812 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12216 table [1.         0.2        0.62850713 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 46 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 249  memory 245\n",
      "arose [1. 0. 0. 0. 2.] 3.0\n",
      "plate [0. 1. 1. 1. 2.] 2.0\n",
      "lathe [1. 2. 1. 0. 2.] 1.0\n",
      "table [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 47 thump======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11101 unlit [1.         1.         0.47675919 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10776 dutch [1.         0.6        0.36150038 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11480 thump [1.         0.4        0.34691673 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 47 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 253  memory 249\n",
      "arose [0. 0. 0. 0. 0.] 0.0\n",
      "unlit [1. 0. 0. 0. 1.] 2.0\n",
      "dutch [0. 1. 1. 0. 1.] 1.0\n",
      "thump [2. 2. 2. 2. 2.] 7.0\n",
      "=========================episode 48 panic======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12126 tidal [1.         0.8        0.56618155 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10867 panic [1.         0.6        0.50256564 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 48 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 256  memory 253\n",
      "arose [1. 0. 0. 0. 0.] 1.0\n",
      "tidal [0. 1. 0. 1. 0.] 1.0\n",
      "panic [2. 2. 2. 2. 2.] 8.0\n",
      "loss 0.7553609013557434\n",
      "=========================episode 49 bloat======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 6246 notal [1.         0.6        0.60153038 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 6901 ploat [1.         0.2        0.57353338 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11033 gloat [1.         0.2        0.56228057 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11880 bloat [1.         0.2        0.56177044 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 49 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 261  memory 256\n",
      "aeros [1. 0. 0. 1. 0.] 2.0\n",
      "notal [0. 1. 1. 2. 1.] 3.0\n",
      "ploat [0. 2. 2. 2. 2.] 3.0\n",
      "gloat [0. 2. 2. 2. 2.] 0\n",
      "bloat [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 50 elegy======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 2695 elint [1.         0.8        0.60132033 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 9710 umped [0.5        0.8        0.46874719 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 1548 chewy [0.66666667 0.8        0.40699175 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 3551 gleby [0.75       0.4        0.46145536 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 4813 knive [0.4        0.4        0.46727682 0.         1.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 50 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 267  memory 261\n",
      "aeros [0. 1. 0. 0. 0.] 1.0\n",
      "elint [2. 2. 0. 0. 0.] 3.0\n",
      "umped [0. 0. 0. 1. 0.] 0\n",
      "chewy [0. 0. 2. 0. 2.] 0\n",
      "gleby [1. 2. 2. 0. 2.] 3.0\n",
      "knive [0. 0. 0. 0. 1.] 0\n",
      "=========================episode 51 baggy======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 2325 dital [1.         0.8        0.56618155 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10398 yamun [1.        0.8       0.4652063 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 3417 gawcy [1.         0.6        0.38334584 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 6655 pawky [0.75       0.4        0.37890473 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 7943 savey [0.6        0.2        0.66271568 0.         1.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 51 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 273  memory 267\n",
      "aeros [1. 0. 0. 0. 0.] 1.0\n",
      "dital [0. 0. 0. 1. 0.] 0\n",
      "yamun [1. 2. 0. 0. 0.] 2.0\n",
      "gawcy [1. 2. 0. 0. 2.] 2.0\n",
      "pawky [0. 2. 0. 0. 2.] 0\n",
      "savey [0. 2. 0. 0. 2.] 0\n",
      "loss 0.7776903510093689\n",
      "=========================episode 52 ivory======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 10907 thorn [1.         0.6        0.49821455 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11140 glory [1.         0.6        0.47066767 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 10716 ivory [1.         0.4        0.45380345 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 52 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 277  memory 273\n",
      "arose [0. 1. 2. 0. 0.] 3.0\n",
      "thorn [0. 0. 2. 2. 0.] 1.0\n",
      "glory [0. 0. 2. 2. 2.] 2.0\n",
      "ivory [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 53 buxom======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 10777 pilot [1.         0.8        0.50658665 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11664 buxom [1.         0.8        0.32528132 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 53 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 280  memory 277\n",
      "arose [0. 0. 1. 0. 0.] 1.0\n",
      "pilot [0. 0. 0. 2. 0.] 1.0\n",
      "buxom [2. 2. 2. 2. 2.] 8.0\n",
      "=========================episode 54 singe======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11354 slide [1.         0.6        0.68747187 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11558 since [1.         0.4        0.66214554 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11285 singe [1.         0.2        0.65062266 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 54 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 284  memory 280\n",
      "arose [0. 0. 0. 1. 2.] 3.0\n",
      "slide [2. 0. 1. 0. 2.] 2.0\n",
      "since [2. 2. 2. 0. 2.] 3.0\n",
      "singe [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 55 madly======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12126 tidal [1.         0.8        0.56618155 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12832 madly [1.         0.4        0.47603901 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 55 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 287  memory 284\n",
      "arose [1. 0. 0. 0. 0.] 1.0\n",
      "tidal [0. 0. 2. 1. 1.] 3.0\n",
      "madly [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 56 beach======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12370 leant [1.         0.6        0.66826707 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11811 heady [1.         0.6        0.56831208 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 10838 peach [1.         0.4        0.55390848 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11736 beach [1.         0.2        0.54214554 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 56 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 292  memory 287\n",
      "arose [1. 0. 0. 0. 1.] 2.0\n",
      "leant [0. 2. 2. 0. 0.] 2.0\n",
      "heady [1. 2. 2. 0. 0.] 1.0\n",
      "peach [0. 2. 2. 2. 2.] 3.0\n",
      "beach [2. 2. 2. 2. 2.] 2.0\n",
      "loss 1.063012719154358\n",
      "=========================episode 57 light======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 5200 linty [1.         1.         0.46364591 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 5143 licht [1.         0.4        0.42649662 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 10883 light [1.         0.2        0.41497374 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 57 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 296  memory 292\n",
      "aeros [0. 0. 0. 0. 0.] 0.0\n",
      "linty [2. 2. 0. 1. 0.] 5.0\n",
      "licht [2. 2. 0. 2. 2.] 3.0\n",
      "light [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 58 rinse======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 8273 siler [1.         0.4        0.73863466 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12711 rinse [1.         0.2        0.72606152 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 58 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 299  memory 296\n",
      "aeros [0. 1. 1. 0. 1.] 3.0\n",
      "siler [1. 2. 0. 1. 1.] 2.0\n",
      "rinse [2. 2. 2. 2. 2.] 5.0\n",
      "=========================episode 59 denim======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 5103 lenti [1.         0.8        0.60132033 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 3454 genic [1.         0.4        0.51147787 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11168 denim [1.         0.4        0.53419355 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 59 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 303  memory 299\n",
      "aeros [0. 2. 0. 0. 0.] 2.0\n",
      "lenti [0. 2. 2. 0. 1.] 3.0\n",
      "genic [0. 2. 2. 2. 0.] 1.0\n",
      "denim [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 60 boney======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 9384 toile [1.         0.6        0.64591148 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 2481 doyen [1.         0.6        0.55750938 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 1792 coney [1.         0.2        0.54475619 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 6969 poney [1.         0.2        0.54448612 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11002 money [1.        0.2       0.5431958 0.        0.       ]-------\n",
      "reward -1.0 done True \n",
      "episode 60 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 309  memory 303\n",
      "aeros [0. 1. 0. 1. 0.] 2.0\n",
      "toile [0. 2. 0. 0. 1.] 1.0\n",
      "doyen [0. 2. 1. 2. 1.] 3.0\n",
      "coney [0. 2. 2. 2. 2.] 2.0\n",
      "poney [0. 2. 2. 2. 2.] 0\n",
      "money [0. 2. 2. 2. 2.] 0\n",
      "loss 0.7246494293212891\n",
      "=========================episode 61 bluer======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 12243 liner [1.        0.6       0.6272168 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10894 ulcer [1.         0.4        0.56204051 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11508 bluer [1.        0.2       0.5500075 0.        0.       ]-------\n",
      "reward 0.0 done True \n",
      "episode 61 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 313  memory 309\n",
      "arose [0. 1. 0. 0. 1.] 2.0\n",
      "liner [1. 0. 0. 2. 2.] 3.0\n",
      "ulcer [1. 2. 0. 2. 2.] 2.0\n",
      "bluer [2. 2. 2. 2. 2.] 3.0\n",
      "=========================episode 62 funky======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11101 unlit [1.         1.         0.47675919 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12840 punch [1.         0.6        0.33818455 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12475 funky [1.        0.6       0.3047862 0.        0.       ]-------\n",
      "reward 0.0 done True \n",
      "episode 62 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 317  memory 313\n",
      "arose [0. 0. 0. 0. 0.] 0.0\n",
      "unlit [1. 1. 0. 0. 0.] 2.0\n",
      "punch [0. 2. 2. 0. 0.] 2.0\n",
      "funky [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 63 humus======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11271 spilt [1.         0.8        0.57341335 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12392 dusky [1.         0.8        0.45635409 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11379 nurse [0.66666667 0.2        0.68861215 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12432 mushy [0.75       0.4        0.44969242 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11709 bushy [0.6       0.2       0.4392198 0.        0.       ]-------\n",
      "reward -1.0 done True \n",
      "episode 63 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 323  memory 317\n",
      "arose [0. 0. 0. 1. 0.] 1.0\n",
      "spilt [1. 0. 0. 0. 0.] 0\n",
      "dusky [0. 2. 1. 0. 0.] 2.0\n",
      "nurse [0. 2. 0. 1. 0.] 0\n",
      "mushy [1. 2. 1. 1. 0.] 2.0\n",
      "bushy [0. 2. 1. 1. 0.] 0\n",
      "=========================episode 64 altar======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11810 acrid [1.         0.6        0.55177794 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11067 angry [1.         0.6        0.50466617 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12165 alter [0.66666667 0.4        0.70445611 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12690 amber [0.5        0.4        0.61254314 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11909 arose [0.4       0.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done True \n",
      "episode 64 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 329  memory 323\n",
      "arose [2. 1. 0. 0. 0.] 3.0\n",
      "acrid [2. 0. 1. 0. 0.] 0\n",
      "angry [2. 0. 0. 1. 0.] 0\n",
      "alter [2. 2. 2. 0. 2.] 5.0\n",
      "amber [2. 0. 0. 0. 2.] 0\n",
      "arose [2. 1. 0. 0. 0.] 0\n",
      "loss 1.0091931819915771\n",
      "=========================episode 65 kneed======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 2695 elint [1.         0.8        0.60132033 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 1263 bunde [1.         0.6        0.48627157 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 7182 punce [0.66666667 0.4        0.48528132 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 92 admen [0.75       0.2        0.60114029 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 6268 noyed [0.8        0.2        0.55750938 0.         1.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 65 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 335  memory 329\n",
      "aeros [0. 1. 0. 0. 0.] 1.0\n",
      "elint [1. 0. 0. 1. 0.] 1.0\n",
      "bunde [0. 0. 1. 1. 1.] 1.0\n",
      "punce [0. 0. 1. 0. 1.] 0\n",
      "admen [0. 1. 0. 2. 1.] 1.0\n",
      "noyed [1. 0. 0. 2. 2.] 1.0\n",
      "=========================episode 66 nudge======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 2695 elint [1.         0.8        0.60132033 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 1263 bunde [1.         0.6        0.48627157 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 7182 punce [0.66666667 0.4        0.48528132 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 4256 hynde [0.5        0.4        0.47714929 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 6276 nudie [0.8        0.         0.55024756 0.         1.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 66 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 341  memory 335\n",
      "aeros [0. 1. 0. 0. 0.] 1.0\n",
      "elint [1. 0. 0. 1. 0.] 1.0\n",
      "bunde [0. 2. 1. 1. 2.] 4.0\n",
      "punce [0. 2. 1. 0. 2.] 0\n",
      "hynde [0. 0. 1. 1. 2.] 0\n",
      "nudie [2. 2. 2. 0. 2.] 2.0\n",
      "=========================episode 67 friar======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 5138 liart [1.         0.6        0.61734434 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 7354 ranid [1.         0.4        0.57950488 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 7089 prima [1.        0.4       0.5371943 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 1926 crias [0.75       0.2        0.67816954 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 9815 urial [0.8        0.2        0.59381845 0.         1.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 67 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 347  memory 341\n",
      "aeros [1. 0. 1. 0. 0.] 2.0\n",
      "liart [0. 1. 1. 1. 0.] 1.0\n",
      "ranid [1. 1. 0. 1. 0.] 0\n",
      "prima [0. 2. 2. 0. 1.] 2.0\n",
      "crias [0. 2. 2. 2. 0.] 1.0\n",
      "urial [0. 2. 2. 2. 0.] 0\n",
      "loss 1.0569204092025757\n",
      "=========================episode 68 drain======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 12093 trial [1.         0.6        0.61734434 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10720 drain [1.         0.4        0.57950488 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 68 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 350  memory 347\n",
      "arose [1. 2. 0. 0. 0.] 3.0\n",
      "trial [0. 2. 1. 1. 0.] 1.0\n",
      "drain [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 69 album======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12799 antic [1.         0.8        0.54085521 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11004 album [1.         0.8        0.46436609 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 69 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 353  memory 350\n",
      "arose [2. 0. 0. 0. 0.] 2.0\n",
      "antic [2. 0. 0. 0. 0.] 0\n",
      "album [2. 2. 2. 2. 2.] 8.0\n",
      "=========================episode 70 agree======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12151 afire [1.         0.4        0.65068267 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10730 argue [0.5        0.4        0.62910728 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 10931 lynch [0.         1.         0.36564141 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11873 adept [0.25       0.6        0.61272318 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 10973 askew [0.4      0.4      0.655994 0.       0.      ]-------\n",
      "reward -1.0 done True \n",
      "episode 70 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 359  memory 353\n",
      "arose [2. 1. 0. 0. 2.] 5.0\n",
      "afire [2. 0. 0. 1. 2.] 0\n",
      "argue [2. 1. 1. 0. 2.] 1.0\n",
      "lynch [0. 0. 0. 0. 0.] 0\n",
      "adept [2. 0. 1. 0. 0.] 0\n",
      "askew [2. 0. 0. 2. 0.] 0\n",
      "=========================episode 71 alley======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11086 alien [1.         0.6        0.68219055 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 251 almeh [1.         0.4        0.59291823 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12165 alter [0.66666667 0.2        0.70445611 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11086 alien [0.75       0.         0.68219055 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 256 aloed [0.8       0.2       0.6875919 0.        1.       ]-------\n",
      "reward -1.0 done True \n",
      "episode 71 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 365  memory 359\n",
      "arose [2. 0. 0. 0. 1.] 3.0\n",
      "alien [2. 2. 0. 2. 0.] 3.0\n",
      "almeh [2. 2. 0. 2. 0.] 0\n",
      "alter [2. 2. 0. 2. 0.] 0\n",
      "alien [2. 2. 0. 2. 0.] 0\n",
      "aloed [2. 2. 0. 2. 0.] 0\n",
      "loss 0.6943779587745667\n",
      "=========================episode 72 ninja======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 12126 tidal [1.         0.8        0.56618155 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11252 human [0.5        0.8        0.45578395 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11675 fancy [0.66666667 0.6        0.42487622 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12318 plank [0.5        0.4        0.47522881 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12653 tonga [0.6        0.2        0.54970743 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 72 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 371  memory 365\n",
      "arose [1. 0. 0. 0. 0.] 1.0\n",
      "tidal [0. 2. 0. 1. 0.] 2.0\n",
      "human [0. 0. 0. 1. 1.] 0\n",
      "fancy [0. 1. 2. 0. 0.] 0\n",
      "plank [0. 0. 1. 1. 0.] 0\n",
      "tonga [0. 0. 2. 0. 2.] 1.0\n",
      "=========================episode 73 knife======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11753 utile [1.         0.8        0.58808702 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12421 chide [1.       0.6      0.499985 0.       0.      ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11712 knife [1.         0.6        0.47990998 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 73 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 375  memory 371\n",
      "arose [0. 0. 0. 0. 2.] 2.0\n",
      "utile [0. 0. 2. 0. 2.] 2.0\n",
      "chide [0. 0. 2. 0. 2.] 0\n",
      "knife [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 74 fauna======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12126 tidal [1.         0.8        0.56618155 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12897 mangy [1.        0.8       0.4391898 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 10878 whack [0.66666667 0.8        0.36975244 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12937 vaunt [0.75       0.4        0.46337584 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12525 baron [0.6        0.2        0.57509377 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 74 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 381  memory 375\n",
      "arose [1. 0. 0. 0. 0.] 1.0\n",
      "tidal [0. 0. 0. 1. 0.] 0\n",
      "mangy [0. 2. 1. 0. 0.] 2.0\n",
      "whack [0. 0. 1. 0. 0.] 0\n",
      "vaunt [0. 2. 2. 2. 0.] 3.0\n",
      "baron [0. 2. 0. 0. 1.] 0\n",
      "=========================episode 75 dairy======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 10895 ultra [1.         0.6        0.57989497 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12343 cairn [1.         0.6        0.56675169 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11687 dairy [1.         0.4        0.55315829 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 75 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 385  memory 381\n",
      "arose [1. 1. 0. 0. 0.] 2.0\n",
      "ultra [0. 0. 0. 2. 1.] 1.0\n",
      "cairn [0. 2. 2. 2. 0.] 3.0\n",
      "dairy [2. 2. 2. 2. 2.] 4.0\n",
      "loss 1.0233256816864014\n",
      "=========================episode 76 gusty======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 11271 spilt [1.         0.8        0.57341335 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12130 dusty [1.         0.6        0.51006752 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11213 musty [1.         0.2        0.49575394 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11246 gusty [1.         0.2        0.48579145 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 76 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 390  memory 385\n",
      "arose [0. 0. 0. 1. 0.] 1.0\n",
      "spilt [1. 0. 0. 0. 1.] 1.0\n",
      "dusty [0. 2. 2. 2. 2.] 6.0\n",
      "musty [0. 2. 2. 2. 2.] 0\n",
      "gusty [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 77 cache======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11898 plate [1.         0.6        0.64027007 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12238 dance [1.         0.6        0.60270068 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12199 maize [0.66666667 0.6        0.56477119 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12563 vague [0.75       0.6        0.52516129 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12583 cable [0.8        0.2        0.59048762 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 77 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 396  memory 390\n",
      "arose [1. 0. 0. 0. 2.] 3.0\n",
      "plate [0. 0. 1. 0. 2.] 0\n",
      "dance [0. 2. 0. 1. 2.] 2.0\n",
      "maize [0. 2. 0. 0. 2.] 0\n",
      "vague [0. 2. 0. 0. 2.] 0\n",
      "cable [2. 2. 0. 0. 2.] 1.0\n",
      "=========================episode 78 serif======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11264 risen [1.         0.4        0.72606152 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12750 serif [1.         0.2        0.67093773 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 78 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 399  memory 396\n",
      "arose [0. 1. 0. 1. 1.] 3.0\n",
      "risen [1. 1. 1. 1. 0.] 1.0\n",
      "serif [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 79 guide======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11753 utile [1.         0.8        0.58808702 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12327 guide [1.         0.4        0.51099775 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 79 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 402  memory 399\n",
      "arose [0. 0. 0. 0. 2.] 2.0\n",
      "utile [1. 0. 2. 0. 2.] 3.0\n",
      "guide [2. 2. 2. 2. 2.] 5.0\n",
      "loss 0.8162769079208374\n",
      "=========================episode 80 couch======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 10777 pilot [1.         0.8        0.50658665 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11240 mound [1.        0.8       0.4300075 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11604 cough [1.         0.6        0.37152288 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11151 bough [0.75       0.2        0.35948987 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11005 vouch [0.8        0.2        0.34301575 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 80 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 408  memory 402\n",
      "arose [0. 0. 1. 0. 0.] 1.0\n",
      "pilot [0. 0. 0. 1. 0.] 0\n",
      "mound [0. 2. 2. 0. 0.] 3.0\n",
      "cough [2. 2. 2. 0. 2.] 4.0\n",
      "bough [0. 2. 2. 0. 2.] 0\n",
      "vouch [0. 2. 2. 2. 2.] 0\n",
      "=========================episode 81 digit======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11101 unlit [1.         1.         0.47675919 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10846 picky [0.5        0.8        0.34163541 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11343 might [0.66666667 0.6        0.37311328 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12522 width [0.5        0.4        0.36927232 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 10701 digit [1.         0.         0.44741185 0.33333333 0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 81 finished.  reward -5.0  eps 0.0  gamma 0.0  steps 414  memory 408\n",
      "arose [0. 0. 0. 0. 0.] 0.0\n",
      "unlit [0. 0. 0. 2. 2.] 4.0\n",
      "picky [0. 2. 0. 0. 0.] 0\n",
      "might [0. 2. 2. 0. 2.] 2.0\n",
      "width [0. 2. 1. 1. 0.] 0\n",
      "digit [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 82 flare======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11705 large [1.         0.4        0.65491373 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12270 blare [1.        0.2       0.6544036 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12654 flare [1.         0.2        0.63903976 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 82 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 418  memory 414\n",
      "arose [1. 1. 0. 0. 2.] 4.0\n",
      "large [1. 1. 1. 0. 2.] 1.0\n",
      "blare [0. 2. 2. 2. 2.] 3.0\n",
      "flare [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 83 tilde======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11753 utile [1.         0.8        0.58808702 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10818 tilde [1.         0.2        0.58634659 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 83 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 421  memory 418\n",
      "arose [0. 0. 0. 0. 2.] 2.0\n",
      "utile [0. 1. 1. 1. 2.] 3.0\n",
      "tilde [2. 2. 2. 2. 2.] 5.0\n",
      "loss 0.9422379732131958\n",
      "=========================episode 84 brown======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 12740 droit [1.         0.6        0.54322581 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12816 crony [1.        0.6       0.4696174 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11981 grown [1.         0.4        0.42703676 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12880 brown [1.         0.2        0.42652663 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 84 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 426  memory 421\n",
      "arose [0. 2. 2. 0. 0.] 4.0\n",
      "droit [0. 2. 2. 0. 0.] 0\n",
      "crony [0. 2. 2. 1. 0.] 1.0\n",
      "grown [0. 2. 2. 2. 2.] 3.0\n",
      "brown [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 85 batty======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12126 tidal [1.         0.8        0.56618155 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12052 haunt [1.         0.6        0.49536384 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12300 tacky [0.66666667 0.6        0.44687172 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11962 patsy [0.75       0.2        0.60144036 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11507 matey [0.8        0.2        0.60006002 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 85 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 432  memory 426\n",
      "arose [1. 0. 0. 0. 0.] 1.0\n",
      "tidal [1. 0. 0. 1. 0.] 1.0\n",
      "haunt [0. 2. 0. 0. 1.] 1.0\n",
      "tacky [1. 2. 0. 0. 2.] 2.0\n",
      "patsy [0. 2. 2. 0. 2.] 1.0\n",
      "matey [0. 2. 2. 0. 2.] 0\n",
      "=========================episode 86 boost======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11374 ghost [1.         0.6        0.53419355 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12159 blind [0.         1.         0.42496624 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11664 buxom [0.33333333 0.6        0.32528132 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12464 broke [0.5        0.2        0.55183796 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11493 bravo [0.4        0.2        0.50733683 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 86 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 438  memory 432\n",
      "arose [0. 0. 2. 2. 0.] 4.0\n",
      "ghost [0. 0. 2. 2. 2.] 2.0\n",
      "blind [2. 0. 0. 0. 0.] 0\n",
      "buxom [2. 0. 0. 1. 0.] 0\n",
      "broke [2. 0. 2. 0. 0.] 0\n",
      "bravo [2. 0. 0. 0. 1.] 0\n",
      "loss 0.6845471858978271\n",
      "=========================episode 87 steal======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 11656 steal [1.         0.4        0.77968492 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 87 finished.  reward -1.0  eps 0.0  gamma 0.0  steps 440  memory 438\n",
      "arose [1. 0. 0. 1. 1.] 3.0\n",
      "steal [2. 2. 2. 2. 2.] 7.0\n",
      "=========================episode 88 eight======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12899 inlet [1.         0.8        0.60132033 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11462 edict [1.         0.4        0.54604651 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11556 eight [1.         0.4        0.51372843 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 88 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 444  memory 440\n",
      "arose [0. 0. 0. 0. 1.] 1.0\n",
      "inlet [1. 0. 0. 1. 2.] 3.0\n",
      "edict [2. 0. 1. 0. 2.] 1.0\n",
      "eight [2. 2. 2. 2. 2.] 5.0\n",
      "=========================episode 89 shack======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11427 snail [1.         0.6        0.68228057 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11357 stamp [1.         0.6        0.59849962 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11683 shady [1.        0.6       0.5684021 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12103 shack [1.         0.4        0.53857464 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 89 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 449  memory 444\n",
      "arose [1. 0. 0. 1. 0.] 2.0\n",
      "snail [2. 0. 2. 0. 0.] 2.0\n",
      "stamp [2. 0. 2. 0. 0.] 0\n",
      "shady [2. 2. 2. 0. 0.] 2.0\n",
      "shack [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 90 offal======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12550 talon [1.         0.6        0.60153038 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12429 voila [1.         0.4        0.54769692 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11182 aloud [0.66666667 0.4        0.56303076 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12932 loamy [0.75      0.4       0.5356039 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11105 octal [0.8        0.2        0.57380345 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 90 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 455  memory 449\n",
      "arose [1. 0. 1. 0. 0.] 2.0\n",
      "talon [0. 1. 1. 1. 0.] 1.0\n",
      "voila [0. 1. 0. 1. 1.] 0\n",
      "aloud [1. 1. 1. 0. 0.] 0\n",
      "loamy [1. 1. 1. 0. 0.] 0\n",
      "octal [2. 0. 0. 2. 2.] 3.0\n",
      "loss 0.7925578951835632\n",
      "=========================episode 91 slosh======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 11374 ghost [1.         0.6        0.53419355 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 3137 flosh [1.         0.4        0.52060015 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11986 cumin [0.         1.         0.39687922 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12084 bawdy [0.25      0.8       0.3955889 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11577 spoke [0.4        0.4        0.63882971 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 91 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 461  memory 455\n",
      "arose [0. 0. 2. 2. 0.] 4.0\n",
      "ghost [0. 1. 2. 2. 0.] 1.0\n",
      "flosh [0. 2. 2. 2. 2.] 3.0\n",
      "cumin [0. 0. 0. 0. 0.] 0\n",
      "bawdy [0. 0. 0. 0. 0.] 0\n",
      "spoke [2. 0. 2. 0. 0.] 0\n",
      "=========================episode 92 novel======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12338 olden [1.         0.6        0.59642911 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12061 novel [1.         0.2        0.54364591 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 92 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 464  memory 461\n",
      "arose [0. 0. 1. 0. 1.] 2.0\n",
      "olden [1. 1. 0. 2. 1.] 3.0\n",
      "novel [2. 2. 2. 2. 2.] 5.0\n",
      "=========================episode 93 fjord======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 10907 thorn [1.         0.6        0.49821455 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11140 glory [1.         0.6        0.47066767 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 10763 fjord [1.         0.6        0.37374344 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 93 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 468  memory 464\n",
      "arose [0. 1. 2. 0. 0.] 3.0\n",
      "thorn [0. 0. 2. 2. 0.] 1.0\n",
      "glory [0. 0. 2. 2. 0.] 0\n",
      "fjord [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 94 would======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 10777 pilot [1.         0.8        0.50658665 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10881 could [1.         0.6        0.44414104 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11703 would [1.         0.2        0.41446362 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 94 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 472  memory 468\n",
      "arose [0. 0. 1. 0. 0.] 1.0\n",
      "pilot [0. 0. 1. 1. 0.] 1.0\n",
      "could [0. 2. 2. 2. 2.] 6.0\n",
      "would [2. 2. 2. 2. 2.] 2.0\n",
      "loss 1.0584099292755127\n",
      "=========================episode 95 bylaw======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 2325 dital [1.         0.8        0.56618155 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 9753 unlay [1.         0.6        0.50706677 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11859 bylaw [1.         0.4        0.42313578 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 95 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 476  memory 472\n",
      "aeros [1. 0. 0. 0. 0.] 1.0\n",
      "dital [0. 0. 0. 2. 1.] 2.0\n",
      "unlay [0. 0. 2. 2. 1.] 2.0\n",
      "bylaw [2. 2. 2. 2. 2.] 5.0\n",
      "=========================episode 96 hyena======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 2687 elain [1.         0.6        0.68219055 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 5494 manet [1.        0.4       0.6264066 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 6279 nugae [1.         0.4        0.59291823 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12489 hyena [1.         0.4        0.58328582 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 96 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 481  memory 476\n",
      "aeros [1. 1. 0. 0. 0.] 2.0\n",
      "elain [1. 0. 1. 0. 1.] 1.0\n",
      "manet [0. 1. 1. 1. 0.] 0\n",
      "nugae [1. 0. 0. 1. 1.] 0\n",
      "hyena [2. 2. 2. 2. 2.] 7.0\n",
      "=========================episode 97 apply======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 75 actin [1.         0.8        0.54085521 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 253 almud [1.         0.8        0.48915229 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 574 ayelp [0.66666667 0.4        0.60363091 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 25 ables [0.5        0.2        0.72963241 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 418 argol [0.6        0.2        0.58817704 0.         1.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 97 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 487  memory 481\n",
      "aeros [2. 0. 0. 0. 0.] 2.0\n",
      "actin [2. 0. 0. 0. 0.] 0\n",
      "almud [2. 1. 0. 0. 0.] 1.0\n",
      "ayelp [2. 1. 0. 2. 1.] 3.0\n",
      "ables [2. 0. 1. 0. 0.] 0\n",
      "argol [2. 0. 0. 0. 1.] 0\n",
      "=========================episode 98 after======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 424 ariel [1.         0.4        0.71837959 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 384 apter [1.         0.4        0.66388597 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12031 after [1.         0.2        0.63675919 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 98 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 491  memory 487\n",
      "aeros [2. 1. 1. 0. 0.] 4.0\n",
      "ariel [2. 1. 0. 2. 0.] 1.0\n",
      "apter [2. 0. 2. 2. 2.] 3.0\n",
      "after [2. 2. 2. 2. 2.] 2.0\n",
      "loss 0.954348623752594\n",
      "=========================episode 99 donut======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 2374 doilt [1.        0.8       0.5196099 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 2356 docht [1.         0.4        0.41932483 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11670 donut [1.        0.4       0.4695874 0.        0.       ]-------\n",
      "reward 0.0 done True \n",
      "episode 99 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 495  memory 491\n",
      "aeros [0. 0. 0. 1. 0.] 1.0\n",
      "doilt [2. 2. 0. 0. 2.] 5.0\n",
      "docht [2. 2. 0. 0. 2.] 0\n",
      "donut [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 100 bulge======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 2695 elint [1.         0.8        0.60132033 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 2565 dulce [1.         0.6        0.51087772 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 6782 phyle [0.66666667 0.6        0.47669917 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 5939 mulse [0.75       0.2        0.63570893 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12472 bulge [1.         0.4        0.47456864 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 100 finished.  reward -5.0  eps 0.0  gamma 0.0  steps 501  memory 495\n",
      "aeros [0. 1. 0. 0. 0.] 1.0\n",
      "elint [1. 1. 0. 0. 0.] 1.0\n",
      "dulce [0. 2. 2. 0. 2.] 4.0\n",
      "phyle [0. 0. 0. 1. 2.] 0\n",
      "mulse [0. 2. 2. 0. 2.] 0\n",
      "bulge [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 101 harem======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 2638 earnt [1.         0.4        0.69188297 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 1427 carle [1.         0.4        0.66643661 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 6603 pareu [1.         0.4        0.64036009 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 3925 hared [1.         0.4        0.63084771 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 10101 warez [0.8        0.4        0.54862716 0.         1.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 101 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 507  memory 501\n",
      "aeros [1. 1. 2. 0. 0.] 4.0\n",
      "earnt [1. 2. 2. 0. 0.] 1.0\n",
      "carle [0. 2. 2. 0. 1.] 0\n",
      "pareu [0. 2. 2. 2. 0.] 1.0\n",
      "hared [2. 2. 2. 2. 0.] 2.0\n",
      "warez [0. 2. 2. 2. 0.] 0\n",
      "=========================episode 102 bilge======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 2695 elint [1.         0.8        0.60132033 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 5936 mulie [1.         0.4        0.54850713 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 9941 vilde [1.         0.4        0.50829707 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 6810 pilae [0.75       0.2        0.65419355 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11580 bilge [1.       0.4      0.512018 0.       0.      ]-------\n",
      "reward 0.0 done True \n",
      "episode 102 finished.  reward -5.0  eps 0.0  gamma 0.0  steps 513  memory 507\n",
      "aeros [0. 1. 0. 0. 0.] 1.0\n",
      "elint [1. 1. 1. 0. 0.] 2.0\n",
      "mulie [0. 0. 2. 1. 2.] 2.0\n",
      "vilde [0. 2. 2. 0. 2.] 1.0\n",
      "pilae [0. 2. 2. 0. 2.] 0\n",
      "bilge [2. 2. 2. 2. 2.] 4.0\n",
      "loss 1.0347527265548706\n",
      "=========================episode 103 musty======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 11271 spilt [1.         0.8        0.57341335 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12130 dusty [1.         0.6        0.51006752 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11213 musty [1.         0.2        0.49575394 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 103 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 517  memory 513\n",
      "arose [0. 0. 0. 1. 0.] 1.0\n",
      "spilt [1. 0. 0. 0. 1.] 1.0\n",
      "dusty [0. 2. 2. 2. 2.] 6.0\n",
      "musty [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 104 prime======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12091 urine [1.         0.6        0.60141035 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11134 trice [1.        0.4       0.5972093 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 10687 pride [1.         0.4        0.57167292 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11611 prime [1.         0.2        0.55735934 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 104 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 522  memory 517\n",
      "arose [0. 2. 0. 0. 2.] 4.0\n",
      "urine [0. 2. 2. 0. 2.] 2.0\n",
      "trice [0. 2. 2. 0. 2.] 0\n",
      "pride [2. 2. 2. 0. 2.] 2.0\n",
      "prime [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 105 abhor======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12331 actor [1.         0.4        0.59741935 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12727 abhor [1.         0.4        0.53932483 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 105 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 525  memory 522\n",
      "arose [2. 1. 1. 0. 0.] 4.0\n",
      "actor [2. 0. 0. 2. 2.] 2.0\n",
      "abhor [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 106 drier======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12441 tried [1.         0.6        0.60996249 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12124 cruel [0.5        0.6        0.56204051 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11732 grief [0.66666667 0.4        0.52027007 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11389 pried [0.75       0.2        0.57167292 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 2512 dries [0.8        0.         0.71108777 0.         1.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 106 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 531  memory 525\n",
      "arose [0. 2. 0. 0. 1.] 3.0\n",
      "tried [0. 2. 2. 2. 1.] 4.0\n",
      "cruel [0. 2. 0. 2. 0.] 0\n",
      "grief [0. 2. 2. 2. 0.] 0\n",
      "pried [0. 2. 2. 2. 1.] 0\n",
      "dries [2. 2. 2. 2. 0.] 1.0\n",
      "loss 0.652814507484436\n",
      "=========================episode 107 punch======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 11101 unlit [1.         1.         0.47675919 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12840 punch [1.         0.6        0.33818455 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 107 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 534  memory 531\n",
      "arose [0. 0. 0. 0. 0.] 0.0\n",
      "unlit [1. 1. 0. 0. 0.] 2.0\n",
      "punch [2. 2. 2. 2. 2.] 8.0\n",
      "=========================episode 108 thong======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12237 clout [1.         0.8        0.46940735 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12839 thong [1.         0.6        0.42277569 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 108 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 537  memory 534\n",
      "arose [0. 0. 2. 0. 0.] 2.0\n",
      "clout [0. 0. 2. 0. 1.] 1.0\n",
      "thong [2. 2. 2. 2. 2.] 7.0\n",
      "=========================episode 109 edict======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12899 inlet [1.         0.8        0.60132033 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11462 edict [1.         0.4        0.54604651 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 109 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 540  memory 537\n",
      "arose [0. 0. 0. 0. 1.] 1.0\n",
      "inlet [1. 0. 0. 1. 2.] 3.0\n",
      "edict [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 110 afoul======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11182 aloud [1.         0.6        0.56303076 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11901 afoul [1.         0.2        0.52288072 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 110 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 543  memory 540\n",
      "arose [2. 0. 2. 0. 0.] 4.0\n",
      "aloud [2. 1. 2. 2. 0.] 3.0\n",
      "afoul [2. 2. 2. 2. 2.] 3.0\n",
      "=========================episode 111 quote======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12742 clone [1.         0.6        0.58367592 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 10739 biome [1.        0.6       0.5539985 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12640 quote [1.         0.6        0.51066767 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 111 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 547  memory 543\n",
      "arose [0. 0. 2. 0. 2.] 4.0\n",
      "clone [0. 0. 2. 0. 2.] 0\n",
      "biome [0. 0. 2. 0. 2.] 0\n",
      "quote [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 112 krill======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 10718 print [1.        0.8       0.4856114 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12708 grimy [1.         0.6        0.40843211 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12098 brick [1.        0.6       0.3924081 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12705 fried [0.5        0.4        0.54454614 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12098 brick [0.8       0.        0.3924081 0.        0.       ]-------\n",
      "reward -1.0 done True \n",
      "episode 112 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 553  memory 547\n",
      "arose [0. 2. 0. 0. 0.] 2.0\n",
      "print [0. 2. 2. 0. 0.] 2.0\n",
      "grimy [0. 2. 2. 0. 0.] 0\n",
      "brick [0. 2. 2. 0. 1.] 1.0\n",
      "fried [0. 2. 2. 0. 0.] 0\n",
      "brick [0. 2. 2. 0. 1.] 0\n",
      "loss 1.1429558992385864\n",
      "=========================episode 113 ocean======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 6305 oaten [1.         0.4        0.70028507 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11527 ocean [1.         0.2        0.66226557 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 113 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 556  memory 553\n",
      "aeros [1. 1. 0. 1. 0.] 3.0\n",
      "oaten [2. 1. 0. 1. 2.] 3.0\n",
      "ocean [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 114 color======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 9533 triol [1.         0.6        0.57077269 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 3147 fluor [1.         0.4        0.46790698 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 10751 labor [0.66666667 0.2        0.58766692 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 5709 milor [0.75      0.2       0.5311928 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11305 valor [0.6        0.2        0.55966992 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 114 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 562  memory 556\n",
      "aeros [0. 0. 1. 2. 0.] 3.0\n",
      "triol [0. 1. 0. 2. 1.] 1.0\n",
      "fluor [0. 1. 0. 2. 2.] 1.0\n",
      "labor [1. 0. 0. 2. 2.] 0\n",
      "milor [0. 0. 2. 2. 2.] 1.0\n",
      "valor [0. 0. 2. 2. 2.] 0\n",
      "=========================episode 115 flirt======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 9528 trild [1.        0.8       0.5112078 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11893 flirt [1.         0.2        0.47105776 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 115 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 565  memory 562\n",
      "aeros [0. 0. 1. 0. 0.] 1.0\n",
      "trild [1. 1. 2. 1. 0.] 4.0\n",
      "flirt [2. 2. 2. 2. 2.] 5.0\n",
      "=========================episode 116 touch======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 2374 doilt [1.        0.8       0.5196099 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 6250 notum [1.         0.6        0.45527382 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12503 pouty [1.         0.4        0.43021755 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11774 touch [1.         0.4        0.42106527 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 116 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 570  memory 565\n",
      "aeros [0. 0. 0. 1. 0.] 1.0\n",
      "doilt [0. 2. 0. 0. 1.] 2.0\n",
      "notum [0. 2. 1. 1. 0.] 1.0\n",
      "pouty [0. 2. 2. 1. 0.] 1.0\n",
      "touch [2. 2. 2. 2. 2.] 5.0\n",
      "loss 0.9248390197753906\n",
      "=========================episode 117 husky======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 8447 sluit [1.         0.8        0.58817704 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 2584 dunsh [1.         0.6        0.49035259 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 2022 cushy [1.         0.4        0.45125281 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11650 husky [1.         0.2        0.43555889 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 117 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 575  memory 570\n",
      "aeros [0. 0. 0. 0. 1.] 1.0\n",
      "sluit [1. 0. 1. 0. 0.] 1.0\n",
      "dunsh [0. 2. 0. 1. 1.] 2.0\n",
      "cushy [0. 2. 2. 1. 2.] 3.0\n",
      "husky [2. 2. 2. 2. 2.] 3.0\n",
      "=========================episode 118 reach======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 7549 retia [1.         0.4        0.71609902 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 7444 redan [1.         0.4        0.66661665 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 7420 reamy [1.         0.4        0.62595649 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12034 reach [1.         0.4        0.61809452 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 118 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 580  memory 575\n",
      "aeros [1. 2. 1. 0. 0.] 4.0\n",
      "retia [2. 2. 0. 0. 1.] 1.0\n",
      "redan [2. 2. 0. 1. 0.] 0\n",
      "reamy [2. 2. 2. 0. 0.] 1.0\n",
      "reach [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 119 speck======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 4385 istle [1.         0.6        0.71273818 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 9002 syned [1.         0.6        0.62433608 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 8692 speug [1.         0.6        0.58517629 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11768 speck [1.         0.4        0.56651163 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 119 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 585  memory 580\n",
      "aeros [0. 1. 0. 0. 1.] 2.0\n",
      "istle [0. 1. 0. 0. 1.] 0\n",
      "syned [2. 0. 0. 1. 0.] 1.0\n",
      "speug [2. 2. 2. 0. 0.] 3.0\n",
      "speck [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 120 chest======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 4385 istle [1.         0.6        0.71273818 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 8884 suent [1.         0.4        0.66271568 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 3488 ghest [1.         0.4        0.60093023 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 10938 chest [1.         0.2        0.61245311 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 120 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 590  memory 585\n",
      "aeros [0. 1. 0. 0. 1.] 2.0\n",
      "istle [0. 1. 1. 0. 1.] 1.0\n",
      "suent [1. 0. 2. 0. 2.] 2.0\n",
      "ghest [0. 2. 2. 2. 2.] 3.0\n",
      "chest [2. 2. 2. 2. 2.] 2.0\n",
      "loss 0.9349714517593384\n",
      "=========================episode 121 whiny======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 11101 unlit [1.         1.         0.47675919 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11476 dying [1.         0.6        0.38655664 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12189 whiny [1.        0.4       0.3476069 0.        0.       ]-------\n",
      "reward 0.0 done True \n",
      "episode 121 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 594  memory 590\n",
      "arose [0. 0. 0. 0. 0.] 0.0\n",
      "unlit [0. 1. 0. 1. 0.] 2.0\n",
      "dying [0. 1. 2. 2. 0.] 3.0\n",
      "whiny [2. 2. 2. 2. 2.] 5.0\n",
      "=========================episode 122 urine======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12091 urine [1.         0.6        0.60141035 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 122 finished.  reward -1.0  eps 0.0  gamma 0.0  steps 596  memory 594\n",
      "arose [0. 2. 0. 0. 2.] 4.0\n",
      "urine [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 123 bland======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12126 tidal [1.         0.8        0.56618155 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12647 gland [1.         0.4        0.49242311 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11060 bland [1.         0.2        0.49191298 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 123 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 600  memory 596\n",
      "arose [1. 0. 0. 0. 0.] 1.0\n",
      "tidal [0. 0. 1. 1. 1.] 2.0\n",
      "gland [0. 2. 2. 2. 2.] 5.0\n",
      "bland [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 124 erupt======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12441 tried [1.         0.6        0.60996249 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11284 erupt [1.         0.4        0.55948987 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 124 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 603  memory 600\n",
      "arose [0. 2. 0. 0. 1.] 3.0\n",
      "tried [1. 2. 0. 1. 0.] 1.0\n",
      "erupt [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 125 group======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12740 droit [1.         0.6        0.54322581 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12816 crony [1.        0.6       0.4696174 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11952 prowl [1.         0.6        0.45086272 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 10801 group [1.        0.4       0.4432108 0.        0.       ]-------\n",
      "reward 0.0 done True \n",
      "episode 125 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 608  memory 603\n",
      "arose [0. 2. 2. 0. 0.] 4.0\n",
      "droit [0. 2. 2. 0. 0.] 0\n",
      "crony [0. 2. 2. 0. 0.] 0\n",
      "prowl [1. 2. 2. 0. 0.] 1.0\n",
      "group [2. 2. 2. 2. 2.] 5.0\n",
      "loss 1.1297274827957153\n",
      "=========================episode 126 float======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 6246 notal [1.         0.6        0.60153038 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 6901 ploat [1.         0.2        0.57353338 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11033 gloat [1.         0.2        0.56228057 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11880 bloat [1.         0.2        0.56177044 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11024 float [1.        0.2       0.5464066 0.        0.       ]-------\n",
      "reward 0.0 done True \n",
      "episode 126 finished.  reward -5.0  eps 0.0  gamma 0.0  steps 614  memory 608\n",
      "aeros [1. 0. 0. 1. 0.] 2.0\n",
      "notal [0. 1. 1. 2. 1.] 3.0\n",
      "ploat [0. 2. 2. 2. 2.] 3.0\n",
      "gloat [0. 2. 2. 2. 2.] 0\n",
      "bloat [0. 2. 2. 2. 2.] 0\n",
      "float [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 127 shale======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 4383 isnae [1.         0.4        0.78103526 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 7880 salue [1.         0.4        0.75615904 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 8397 slade [1.        0.2       0.7544186 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 8659 spale [1.         0.2        0.74139535 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 8941 swale [1.       0.2      0.711988 0.       1.      ]-------\n",
      "reward -1.0 done True \n",
      "episode 127 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 620  memory 614\n",
      "aeros [1. 1. 0. 0. 1.] 3.0\n",
      "isnae [0. 1. 0. 1. 2.] 1.0\n",
      "salue [2. 1. 1. 0. 2.] 2.0\n",
      "slade [2. 1. 2. 0. 2.] 1.0\n",
      "spale [2. 0. 2. 2. 2.] 1.0\n",
      "swale [2. 0. 2. 2. 2.] 0\n",
      "=========================episode 128 denim======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 5103 lenti [1.         0.8        0.60132033 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 3454 genic [1.         0.4        0.51147787 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11168 denim [1.         0.4        0.53419355 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 128 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 624  memory 620\n",
      "aeros [0. 2. 0. 0. 0.] 2.0\n",
      "lenti [0. 2. 2. 0. 1.] 3.0\n",
      "genic [0. 2. 2. 2. 0.] 1.0\n",
      "denim [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 129 prowl======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 6190 nitro [1.         0.6        0.55819955 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 1699 clour [1.         0.6        0.49530383 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 7569 rhody [0.66666667 0.6        0.44660165 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 7106 prole [0.75      0.2       0.6195949 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11952 prowl [1.         0.2        0.45086272 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 129 finished.  reward -5.0  eps 0.0  gamma 0.0  steps 630  memory 624\n",
      "aeros [0. 0. 1. 1. 0.] 2.0\n",
      "nitro [0. 0. 0. 1. 1.] 0\n",
      "clour [0. 1. 2. 0. 1.] 2.0\n",
      "rhody [1. 0. 2. 0. 0.] 0\n",
      "prole [2. 2. 2. 1. 0.] 3.0\n",
      "prowl [2. 2. 2. 2. 2.] 3.0\n",
      "loss 1.2629314661026\n",
      "=========================episode 130 clock======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 2374 doilt [1.        0.8       0.5196099 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 6903 plong [1.         0.6        0.43282821 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 1690 clomb [1.         0.6        0.40330083 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 1700 clous [0.75       0.2        0.57053263 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 1702 cloye [0.8        0.2        0.55732933 0.         1.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 130 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 636  memory 630\n",
      "aeros [0. 0. 0. 1. 0.] 1.0\n",
      "doilt [0. 1. 0. 1. 0.] 1.0\n",
      "plong [0. 2. 2. 0. 0.] 2.0\n",
      "clomb [2. 2. 2. 0. 0.] 2.0\n",
      "clous [2. 2. 2. 0. 0.] 0\n",
      "cloye [2. 2. 2. 0. 0.] 0\n",
      "=========================episode 131 wrist======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 8509 snirt [1.         0.6        0.62502626 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 3736 grist [1.         0.2        0.58577644 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 3245 frist [1.         0.2        0.56990248 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11540 wrist [1.         0.2        0.56762191 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 131 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 641  memory 636\n",
      "aeros [0. 0. 1. 0. 1.] 2.0\n",
      "snirt [1. 0. 2. 1. 2.] 4.0\n",
      "grist [0. 2. 2. 2. 2.] 2.0\n",
      "frist [0. 2. 2. 2. 2.] 0\n",
      "wrist [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 132 timid======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 5200 linty [1.         1.         0.46364591 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 2269 dicht [1.         0.6        0.39894974 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 9333 timed [0.66666667 0.2        0.54448612 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 6799 pight [0.5       0.4       0.3744036 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 4785 kited [0.6        0.2        0.53035259 0.         1.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 132 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 647  memory 641\n",
      "aeros [0. 0. 0. 0. 0.] 0.0\n",
      "linty [0. 2. 0. 1. 0.] 3.0\n",
      "dicht [1. 2. 0. 0. 1.] 1.0\n",
      "timed [2. 2. 2. 0. 2.] 4.0\n",
      "pight [0. 2. 0. 0. 1.] 0\n",
      "kited [0. 2. 1. 0. 2.] 0\n",
      "loss 0.9869213700294495\n",
      "=========================episode 133 vegan======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 12370 leant [1.         0.6        0.66826707 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12739 pecan [1.         0.4        0.58967742 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12404 began [1.        0.4       0.5663916 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 12801 vegan [1.        0.2       0.5383946 0.        0.       ]-------\n",
      "reward 0.0 done True \n",
      "episode 133 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 652  memory 647\n",
      "arose [1. 0. 0. 0. 1.] 2.0\n",
      "leant [0. 2. 1. 1. 0.] 2.0\n",
      "pecan [0. 2. 0. 2. 2.] 2.0\n",
      "began [0. 2. 2. 2. 2.] 2.0\n",
      "vegan [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 134 nasal======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11427 snail [1.         0.6        0.68228057 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12841 pasty [0.5        0.6        0.60144036 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 10757 basic [0.66666667 0.4        0.60222056 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11449 mason [0.5       0.2       0.6607952 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12771 nasal [1.         0.         0.74922731 0.33333333 0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 134 finished.  reward -5.0  eps 0.0  gamma 0.0  steps 658  memory 652\n",
      "arose [1. 0. 0. 1. 0.] 2.0\n",
      "snail [1. 1. 1. 0. 2.] 3.0\n",
      "pasty [0. 2. 2. 0. 0.] 0\n",
      "basic [0. 2. 2. 0. 0.] 0\n",
      "mason [0. 2. 2. 0. 1.] 0\n",
      "nasal [2. 2. 2. 2. 2.] 5.0\n",
      "=========================episode 135 stick======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11271 spilt [1.         0.8        0.57341335 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11150 sting [1.        0.4       0.5495874 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11133 stick [1.         0.4        0.51768942 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 135 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 662  memory 658\n",
      "arose [0. 0. 0. 1. 0.] 1.0\n",
      "spilt [2. 0. 2. 0. 1.] 4.0\n",
      "sting [2. 2. 2. 0. 0.] 1.0\n",
      "stick [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 136 super======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11264 risen [1.         0.4        0.72606152 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12029 super [1.         0.4        0.66061515 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 136 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 665  memory 662\n",
      "arose [0. 1. 0. 1. 1.] 3.0\n",
      "risen [1. 0. 1. 2. 0.] 1.0\n",
      "super [2. 2. 2. 2. 2.] 6.0\n",
      "loss 1.0460608005523682\n",
      "=========================episode 137 prize======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 12091 urine [1.         0.6        0.60141035 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11134 trice [1.        0.4       0.5972093 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 10687 pride [1.         0.4        0.57167292 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11611 prime [1.         0.2        0.55735934 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11114 prize [1.         0.2        0.51108777 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 137 finished.  reward -5.0  eps 0.0  gamma 0.0  steps 671  memory 665\n",
      "arose [0. 2. 0. 0. 2.] 4.0\n",
      "urine [0. 2. 2. 0. 2.] 2.0\n",
      "trice [0. 2. 2. 0. 2.] 0\n",
      "pride [2. 2. 2. 0. 2.] 2.0\n",
      "prime [2. 2. 2. 0. 2.] 0\n",
      "prize [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 138 staff======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11427 snail [1.         0.6        0.68228057 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11357 stamp [1.         0.6        0.59849962 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11291 stack [1.         0.4        0.58463616 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 8756 stagy [1.         0.4        0.59018755 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 12562 stave [0.8        0.2        0.69935484 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 138 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 677  memory 671\n",
      "arose [1. 0. 0. 1. 0.] 2.0\n",
      "snail [2. 0. 2. 0. 0.] 2.0\n",
      "stamp [2. 2. 2. 0. 0.] 2.0\n",
      "stack [2. 2. 2. 0. 0.] 0\n",
      "stagy [2. 2. 2. 0. 0.] 0\n",
      "stave [2. 2. 2. 0. 0.] 0\n",
      "=========================episode 139 unzip======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11101 unlit [1.         1.         0.47675919 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11637 unzip [1.         0.4        0.35033758 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 139 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 680  memory 677\n",
      "arose [0. 0. 0. 0. 0.] 0.0\n",
      "unlit [2. 2. 0. 2. 0.] 6.0\n",
      "unzip [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 140 cheer======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12243 liner [1.        0.6       0.6272168 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11691 tuber [1.         0.6        0.54772693 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 10771 hyper [1.         0.6        0.50031508 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 2045 cyder [0.75       0.4        0.52138035 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11000 gamer [0.4        0.4        0.61305326 0.         0.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 140 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 686  memory 680\n",
      "arose [0. 1. 0. 0. 1.] 2.0\n",
      "liner [0. 0. 0. 2. 2.] 2.0\n",
      "tuber [0. 0. 0. 2. 2.] 0\n",
      "hyper [1. 0. 0. 2. 2.] 1.0\n",
      "cyder [2. 0. 0. 2. 2.] 1.0\n",
      "gamer [0. 0. 0. 2. 2.] 0\n",
      "loss 1.0515519380569458\n",
      "=========================episode 141 enemy======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 2695 elint [1.         0.8        0.60132033 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 2760 enzym [1.         0.6        0.42304576 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 7143 pudge [0.33333333 0.8        0.4587847  0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 951 blech [0.5        0.6        0.46355589 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 9936 viewy [0.6        0.4        0.42694674 0.         1.        ]-------\n",
      "reward -1.0 done True \n",
      "episode 141 finished.  reward -6.0  eps 0.0  gamma 0.0  steps 692  memory 686\n",
      "aeros [0. 1. 0. 0. 0.] 1.0\n",
      "elint [2. 0. 0. 1. 0.] 2.0\n",
      "enzym [2. 2. 0. 1. 1.] 3.0\n",
      "pudge [0. 0. 0. 0. 1.] 0\n",
      "blech [0. 0. 2. 0. 0.] 0\n",
      "viewy [0. 0. 2. 0. 2.] 0\n",
      "=========================episode 142 gloom======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 4337 indol [1.         0.8        0.50931733 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 6918 pluot [1.         0.6        0.46913728 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 217 alcos [0.66666667 0.2        0.67492873 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 971 blook [1.         0.4        0.46148537 0.33333333 1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 5 11017 gloom [1.         0.4        0.47612903 0.33333333 0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 142 finished.  reward -5.0  eps 0.0  gamma 0.0  steps 698  memory 692\n",
      "aeros [0. 0. 0. 2. 0.] 2.0\n",
      "indol [0. 0. 0. 2. 1.] 1.0\n",
      "pluot [0. 2. 0. 2. 0.] 1.0\n",
      "alcos [0. 2. 0. 2. 0.] 0\n",
      "blook [0. 2. 2. 2. 0.] 2.0\n",
      "gloom [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 143 girly======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 6181 nirly [1.         0.8        0.48954239 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 5743 mirly [1.         0.2        0.46025506 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12722 girly [1.         0.2        0.45029257 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 143 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 702  memory 698\n",
      "aeros [0. 0. 2. 0. 0.] 2.0\n",
      "nirly [0. 2. 2. 2. 2.] 6.0\n",
      "mirly [0. 2. 2. 2. 2.] 0\n",
      "girly [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 144 fungi======================\n",
      "------guess 0 112 aeros [1.        1.        0.8375994 0.        1.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 5200 linty [1.         1.         0.46364591 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 3289 fundi [1.         0.6        0.38379595 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 7185 punji [0.66666667 0.4        0.34604651 0.         1.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11115 fungi [1.         0.2        0.35951988 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 144 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 707  memory 702\n",
      "aeros [0. 0. 0. 0. 0.] 0.0\n",
      "linty [0. 1. 2. 0. 0.] 3.0\n",
      "fundi [2. 2. 2. 0. 2.] 5.0\n",
      "punji [0. 2. 2. 0. 2.] 0\n",
      "fungi [2. 2. 2. 2. 2.] 2.0\n",
      "loss 1.0230014324188232\n",
      "=========================episode 145 fiber======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1.0 done False \n",
      "------guess 1 12243 liner [1.        0.6       0.6272168 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11858 timer [1.         0.4        0.59564891 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 12024 cider [1.         0.4        0.57194299 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 4 11434 fiber [1.         0.4        0.51975994 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 145 finished.  reward -4.0  eps 0.0  gamma 0.0  steps 712  memory 707\n",
      "arose [0. 1. 0. 0. 1.] 2.0\n",
      "liner [0. 2. 0. 2. 2.] 4.0\n",
      "timer [0. 2. 0. 2. 2.] 0\n",
      "cider [0. 2. 0. 2. 2.] 0\n",
      "fiber [2. 2. 2. 2. 2.] 4.0\n",
      "=========================episode 146 urban======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12093 trial [1.         0.6        0.61734434 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11717 urban [1.         0.6        0.51726932 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 146 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 715  memory 712\n",
      "arose [1. 2. 0. 0. 0.] 3.0\n",
      "trial [0. 2. 0. 2. 0.] 1.0\n",
      "urban [2. 2. 2. 2. 2.] 6.0\n",
      "=========================episode 147 thrum======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11748 lurid [1.         0.8        0.48768192 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12881 thrum [1.         0.6        0.41110278 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 147 finished.  reward -2.0  eps 0.0  gamma 0.0  steps 718  memory 715\n",
      "arose [0. 1. 0. 0. 0.] 1.0\n",
      "lurid [0. 1. 2. 0. 0.] 2.0\n",
      "thrum [2. 2. 2. 2. 2.] 7.0\n",
      "=========================episode 148 handy======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 12126 tidal [1.         0.8        0.56618155 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 11482 candy [1.         0.6        0.46502626 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 11298 handy [1.         0.2        0.45698425 0.         0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 148 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 722  memory 718\n",
      "arose [1. 0. 0. 0. 0.] 1.0\n",
      "tidal [0. 0. 1. 1. 0.] 1.0\n",
      "candy [0. 2. 2. 2. 2.] 6.0\n",
      "handy [2. 2. 2. 2. 2.] 2.0\n",
      "=========================episode 149 truss======================\n",
      "------guess 0 11909 arose [1.        1.        0.8375994 0.        0.       ]-------\n",
      "reward -1.0 done False \n",
      "------guess 1 11540 wrist [1.         0.6        0.56762191 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 2 12670 crush [0.5        0.6        0.51378845 0.         0.        ]-------\n",
      "reward -1.0 done False \n",
      "------guess 3 10855 truss [1.         0.         0.69899475 0.33333333 0.        ]-------\n",
      "reward 0.0 done True \n",
      "episode 149 finished.  reward -3.0  eps 0.0  gamma 0.0  steps 726  memory 722\n",
      "arose [0. 2. 0. 2. 0.] 4.0\n",
      "wrist [0. 2. 0. 2. 1.] 1.0\n",
      "crush [0. 2. 2. 2. 0.] 1.0\n",
      "truss [2. 2. 2. 2. 2.] 4.0\n",
      "loss 0.7905142307281494\n",
      "Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAACW/UlEQVR4nO29d5wkR3n//366Z2bDRZ1OF3S645QQyukkBEKAAkIkCdsi5/CVwdiAwcbGNtg4/GzAxoCJMsEkG5FFEkkBESRQQDnnjE6X7zbMTHf9/uiu7urq6p6e3Z3bPV1/Xq99zc5Mh+qaqnrqSZ9HlFLUqFGjRo3dF95sN6BGjRo1aswuakFQo0aNGrs5akFQo0aNGrs5akFQo0aNGrs5akFQo0aNGrs5akFQo0aNGrs5akFQo0YPiMgFIvKamT62Ro25AqnzCGo8HiEi2423o8AkEMTv/1gp9ZWd36oaNeYmakFQ43EPEbkHeKNS6meO7xpKqe7Ob1WNGnMHtWmoxm4FEXmmiDwgIn8lIo8AnxeRPUTk+yKyXkQ2xf/vY5xziYi8Mf7/tSLySxH59/jYu0XkOVM8dl8RuVREtonIz0Tk4yLy5Z3YHTVqALUgqLF7YgWwBHgCcA7RPPh8/H4NMA58rOT8JwO3AkuBDwCfFRGZwrH/C/wW2BP4B+BVU36iGjWmgVoQ1NgdEQJ/r5SaVEqNK6U2KKW+qZQaU0ptA/4FeEbJ+fcqpf5bKRUAXwBWAsv7OVZE1gDHAe9VSrWVUr8EvjtTD1ijRj+oBUGN3RHrlVIT+o2IjIrIp0XkXhHZClwKLBYRv+D8R/Q/Sqmx+N/5fR67N7DR+Azg/j6fo0aNGUEtCGrsjrAjJN4JHAQ8WSm1EHh6/HmRuWcm8DCwRERGjc9WD/B+NWoUohYENWrAAiK/wGYRWQL8/aBvqJS6F7gS+AcRaYnIU4AXDPq+NWq4UAuCGjXgw8AI8BhwOfCjnXTfVwBPATYA/wycR5TvAES5ECJyUvz/SWZuhIj8jYhcsJPaWeNxjjqPoEaNOQIROQ+4RSk1cI2kRg0TtUZQo8YsQUSOE5H9RcQTkTOAs4DvzHKzauyGaMx2A2rU2I2xAvgWUR7BA8CblVK/m90m1dgdUZuGatSoUWM3R20aqlGjRo3dHLucaWjp0qVq7dq1s92MGjVq1NilcNVVVz2mlNrL9d0uJwjWrl3LlVdeOdvNqFGjRo1dCiJyb9F3tWmoRo0aNXZz1IKgRo0aNXZz1IKgRo0aNXZz1IKgRo0aNXZz1IKgRo0aNXZzDFQQiMhiEfmGiNwiIjfHDIvm9yIiHxWRO0TkOhE5ZpDtqVGjRo0aeQw6fPQjwI+UUmeLSAsYtb5/DnBg/Pdk4JPxa40aNWrU2EkYmCAQkUVEBT5eC6CUagNt67CzgC+qiOfi8liDWKmUenim23PrI9v4wXUPzexFRTjzyL05YJm7ONX1D2whUIqjVi/OfH73Yzt4aPM4Jx6wFID7N47xjasewKT72HvxCC89fk3mvB2TXb5w2T1MtIPcvYaaPq956lrmD2V/0h9e/zBP3ncJe84fAuB71z7E7b/fVvpYpx68nCOtNt/w4BZ+cmNUbOuoNYs55UlRZcb7NozxzauzbddYvmiYVzz5CaX3CkLF5391N1vHOww1fV71lCewcLhZek4vXHP/ZhqecNiqRZnPb3lkKz+8rnxordlzHmcfu0/ms60THb502b1MdtJ+nzfU4LUnrmWo4aOU4htXPcALjtyb4Wa2qNkF1z/M8Ub/a/z4xke48cEtADzviL05aMUCZ3uuvX8zF978ewDWrV3C05/ozAfioc3jfO3K+wlDxT57jPLi46rVuFFK8fWrHuCso/ZmqJFt+1d/ex8PbR5P3osIZx+7D6uX2Pu5CFfdu4nRls/BKxdWuvcDm8a4/dHtnHzQMgAe2z7Jlfds4ozDVlQ6fyr4wXUPc+sjW3Nz9xe3r+eKuzcCcPKTlnH0mj0AuPnhrYy1uxz7hCUA3LV+Ow9vmUjmrsbDW8Y574qo/1ftMcJLjovm7pbxDl++PD92XnfivrQac8cyP0iNYF9gPfB5ETkSuAp4m1Jqh3HMKrLl+R6IP8vMVhE5h6jIOGvWZBfHqrjj0e3818V3TOncIigFG3dM8s8vPNz5/ft/dAvtIORrf5yxiHHupXfy81vX8+t3nwrAeVfcz8cuvgNd0lyvqc85fCWLRtJF8dd3buADP7oVALNUuj5+v6XzeM7hK5PPd0x2+ZOvXM3fPe9g3njSfgD8xdevZbIbUlRqXSm44aGtfO61x2U+/+Qld/KD66OfZdXiEU7560gQfOnye/jvX9ydu55u07MPXcFSaxE0ceNDW/jnH9ycvF+9ZJQzj9y78Pgq+Ofv38RIy+dLb8gql5+65E6+c81Dpc8O8PwjVmYW9J/fup4P/jjtd33c0Wv24Ph9l3D7o9v5y29cx4LhBmcclvb/9skub7b6X+Nvv309j22P9kUPbp7gP158pLNNH/7ZbVx863oADlw2n5++w11K+WtX3s+Hf3Z78v65R6zMbQpcuPGhrbzrG9exx2iLZx2Sll3eMt7hr791ffLMED13Nwz5y2c/yXmtf/jujaxcNMy5r17X874AX7zsXv7vN/dx/fueDcA3r3qAf/vRLdz8j2fkBOpM4S++fi3j8aK8Yfsk//IH0dz9lx/czC2PRBuk392/ORk7//7jW3lk6wQ/eOtJAHzq53fyy9sfS+auxreufjDT/885fCULh5tccuujzrFz7BP2YN3aJQN5xqlgkIKgARwD/JlS6jci8hHgr4H39HshpdS5wLkA69atmxJL3vOOWMnzjnjeVE4txAn/34V0usXNmegEdMP89xOdkHYQJu87Qchw0+OWf3oOAF+6/F7e850bmOwGQDNzHMCP3n4ST1qR7rru3zjGSR+4mB2WpqCPn+xGr0opJrshbz3lAN5x+kHONv/RJ38d3zeLyW7AISsXctzaPTj/2lSz2tEOWDp/iCv/7rTM8eddcR9/9c3rk3sXYcdkdK8PnH0E7/rGdZmd01Qx0Q3wHKv9ZDcsXUw//fM7+dcLbiGwfjPdj5f8xTNZu3QeV9yzkRd96rKknyY6+jX7rGOT3eS+NtrdkNc+dS2X3rbe2d8aO9oBJ+y3hGULhrk+1iBcGGsHjDR93nXGQbzvezfRDcr7Pbl+3MYJq991m/7phYfxqhMire6Q9/6IyU7xddvd7LjuhYlOwKRxfLsbxsJmMESYYagY7wS8/bQD+doV92d+l8luyAuO3JtNO9qMGfNo+2Q36SOIxutEwe8J8L4zD+Xvv3sj3SB6hk78+ot3nczqJaP85q4NvOTcy3vOi52NQeomDwAPKKV+E7//BpFgMPEg2Tqt+8Sf7RLwPSkdtJ1Q5RYViBYW87xuqGh46U/R9KJFTA8m8ziAhpdd5PTuabzddR6vFzLdloZf/LM3PEkGb7bNiqYvDLf8zEQZbweMtPLX08/Ta0Ea70Rt1uagmVgEuoGiE+bv2wlU6bP7ut9Dd7/r7xvW79MJsv2sofvJNQaCUNHwhIYvud/ZxHi8wHvivk56ry4jLT9tW8V+HIsFQNfqL92mpjHWGj3GezcMS9tooxNk54e+dlDSH9OB1gRGmj4N38uMzU4Q0vSE4aY1vjtB5v1Yu5v7nSH6bXxPjDGk51z0moydePy5rjGbGJggUEo9AtwvInrreSpwk3XYd4FXx9FDJwBbBuEfGBR8TwhLaLy7gXtidK0JEIQKc23Xg8VeIML4HHu3O9qKBMGYpRHo4/V1EkHiF9dkb1oTJGlzGNLwPUabDdrd9LnG2l1Gm3nFUt/DJVRM6DYvHG7EbZ3+BOkEoXNx7YYhzZJn15M1DN39rr9vWpNZt9leJEsFgYoWjobn5Rbh7DW6jLYaeD3GmtYIvIJnKMJ43Eb7d9L9ZwrOpu+VLmChKhdWNvT80P4l/XzBgKjx9e8x2vJp+ELHFEKBouELoy0/s6EaawdJH+n3rrEVKIUvYoyh+PP4NR077k3ebGPQUUN/Bnwljhi6C3idiLwJQCn1KeCHwHOBO4Ax4HUDbs+MoucOqeDHtndOQaisCRcvovYuLdEIsvI70Qgs9T7RCOLr6EncKtkVN333M3W6kUagd//jnYD5Qw3GOyHDrbw9V9+jbJGDdCFaGPtCegmOKuiGyrlgdQOVLOIuFO2mbU2smTxbVsDaQkz/HkUage8JzYZX+swTnZDhpo9I+eI+0QmmpBHo/rfHqh4zpuCMNgnlGkE/Gp0+NlTgi9mfg9kta/PXcNOnZW14ok2ChyCZeTTeDjLvI3Pv1DWCZsV5sbMxUEGglLoGsD1HnzK+V8BbBtmGQcLzpHRydoIw2aGZaNsagVKZXb6949RINAJrLfM9YajhZXYukC5A2o+hFxzbtGSi4XuJvTPzLGHI/GaDkVY0ZMba3UgQtLuMOhx7iQpc4kOBdLHUpqGZUJk73dD5jO3A/blGspu2dqT6vZeo91rbCZPrRq/Z8/Tv4drhJoLAk9JnjjQCP9LCemgEoy0/GUdVd+baNGS3Qb83BWfDL29rGFbXRCDtN90X+txBrZGpRtCInyVta7sbCYKmT8401A0V7W5Iq+Ex1g7oBJEWI8acTQSB2BpBrE1KViOwx8psY+7EL+2CiDSC4lHbKbCZ2iajIFCZBcq2QSfnFWgEACMtP6cRBNYOS++AyuzkRRpBN27jSLzoT7Sja43HO1EbjQKtxkaqEcSmoRnwEXRCVfAM4dQ0AkuANj0tqC3TW0WNQCkV7YKr+Ag68QLvCWVdM94OGG76Sb9XFQQTbbcgsJ8ZYtNQDx9BXxqB5bsatEaQ+AhaHg0va+bqxj6b0ZafcZzr8anPHU98Ktnn1IJA938y57Qg8LV/qZrvbGejFgTTgCdC2e9p+wIynxu7O20v1mg23BpBkOxM8/catZxc5vGJMzNuS7lpyO0j6MSLaOKPiJ28Y223IGgV+Dls6DYvmEGNoFvoI1ClPgIv2c2VawTNhhbUvXwEUR/ZY8DcJUaLq/uZw1AlpiGvh2koERhaI6hoZ9f9b7c90QgaWZNl2QIWhHltqgz6N9Jt1f0yOI0g+j1Gmo3YNJT1ETQbHiNNn04QmRZ1lBEYAqHAlKYFQTKGLL9HohE0qs2LnY1aEEwDDV8SG6ALnQJncTuIwuT0xNaDSMPecWoEekdfpBEUmYbi8zpdrRGUmIY8t81aCwK96Ot7TbQDt2nIy5pPijDeCRhueol9dUZMQ4FyhjG2u2F5xJRfoBFYPoKGlxXUiWnIMqlNFGgE5i6xzAGrF6HRlo/vSSXTkG5bVY1A36NjtV2PgaYx1uxdtI0gdAvgIiSmoSArCAamEdjO4iANq27HUUPJ+O4EmRBPWyOwx1dXawSWVmlHnOkorH7CbHcGakEwDXgilI17OzxOI3EkKbcgSBaknEYQvfqOGPlS01CyY61mGnI6WsMoqmKkmRUEY4WmoWphcjo8EmJT2wzslKKoIfczVNEIinbwnmXnzZmGrAWsKGrI3CWWPXNqyoh2+qUaQWwa0j9tZUEQ75Jtk09qRjRNQ+7QYo0gVNPTCKxd9EzD7M+GYeYyw6rNjc5YJnqoi1KphmCPrzCMooa01phqN1lBkEYEzi1BsMuVqpxLaHjlGkE3COk6Ft2usQNq+g6NILGv2wtSHIHgWMxGm43MwNXXN6+T7vLKnMXFPoKMaUgLggLTUNUwuWgn24jPKY+gqYpuqNymoSB0alMaRbvpZKGwJ3OYFbD2PYvMLuYusVQjaKdx75708BHEpiG/T40gaaPtLI7PNwVnwy8PdQ0KfDNFsPsvSATqYATBmNGfTU9yJj0dPqqPNf0j4+2AiU6YZAa7flNTI7D9HnrzVqR1zjZqjWAa8DwpnXCdgh2SGS2hX31X1JClricxyQ6NYLjlM96xj1eZ67giQWwULUztIIrBHzFCVYM4mmLEYRqqGiY3EZuGonOmbxoKw0gLK0ooK3v2ot10EGZ3dbZG0E5e3aYheyevF7xIEBTvslPTUAPfK1/ctWbVt0ZQ4PzsOsZK05fSKLBAqT6jhrI+Aa0RDMp+PmFoBOY4179by/cYiXNiooU/Gz1katy2GTCM/XwujUAk9S9p31ltGnocodFLEBSZKKydj95NpNd1L6J2TLKJ0aZfmFmcZhinO58iFAkCvZs2VWfThp2/TrUwOZ0wFbWrfMdZBWnORJGfoyyhrFgj8IQkXLBp+QhSp3E1jUAveFFmsds5b54/0vJKE8q0U3Ok1Uieod88Anth08+WyXgvcWzDFDQCy2SZLJ47KaGsa5n2GhkfQdfKKM6ailwaQaNAI6gSETjbqAXBNFBGMRFlTLp3ZnbYXBCGbtNQLjIhva+NUYePIEyihrILVq8QSrdZxfIRdIKM6SJ/naoUE6lpqVlAb9EPTLObzYiq/RxFSHbTKr9wm33ueYIn5BYSW4jp38Ne2BKfg9YICsZQ2r+N2DTkPk47NUdbfqIt9q8RFDiL/ewiVraABaHbJ1YE87cyXwdlNtH9OdzwM0LNDKseTTY6YS6RzNQQcv67MMoZ0v3fNZ7JzBFKEs5qjeDxAzMJxkbC7+OYvLaTKlBYgqBcI3CZ+IcdUUP5hUpP7h7ho45FtB2EtHwv2b2bqfc6ySxznYphcqazuNko3h1XhXk/W6joyKcipBpB3sRmC19zISnSQsaLNALD51AUrgspD9NIvMAXLbJpWKSftLN/H4EtNF2moWJ/RhiqvikmOqG9Ico6WGcaOkJNC+CEKyq+X2Qa0j6Cbo5awtQQ8pu0aOdv05TozzVEhFaPfIzZQC0IpgFfijUCm+it7DtbI0iSsSx7rN6ZisNH4MwjsMJH28nOp8w05NZG9G5a2/PH290kl8BpGqoYJqfDHqGY8K4f2KyuJnoJgsJEvkDlnMxN30sztrvZftZI8wjcvhtPpDBcNzo/NWWUJZSlJqT+BUFiGrL7qps3I5YJgsS+348gcPjK+r1GP7DNkK6wajN8NG8aMgVB/jf1xKSYSJ/FZhdo+JLz/802akEwDfglPgJb7XV+VxA+mjiLHVxDLrMQpOGj5k4+SShLwkhjjaAscsahjSil4p2Nh0hkHuppGqoYJjfeMTSCHqRmVWC2272gVwgfdVBM2KdF0VXlUUPaeV8YheRLqYM8GzUUt8UxnhInqKkRVLSzp+GQlvbk0AiKIsrMZ5pO+GjCPTQw01Aa2GCaIc2w6lGHDwyiPjbf57X1aKNk93+o8mOuF0fZbKAWBNNAmSDQEylU5MwsyU7IEBZmJFDRzjQIlDNiCCJBoFSW+z6wbKCu2HAbaSJY3sSiKyqNxlTU48ZONHedimFy40b4adlCUxUZ05AlzCKtpndCWT4BLJ+IZu7ki2ioxwsyi/UzeiKlz2zGvfslGcOm5pBqBNUEaurQtjYdDoqJhldMOmfnrFSBnYcRTkGr6Afjna4x1lKTnBlWnZqGAouFNGsqcmnMpkZghsI6zYq1j+Dxg7JsT3OgFBU6MTWCjApeQjFRtKO1E72i62bvp9X/MvNIy3HvNIIkuvew1gg6xRpB1TC5mdYIikxDiTCbUkJZnvq7Zezk7VeNIq4hveA1PI+m70WJWI7Fb9wyDZnnuu4z0vSNqJXCx8xAaxPtrnuMmhQTrYYU/p7pDrjafc172AJgUDTUGX+U7+UEeCZz3hjfnsTO4xLTkN755zSCWhA8/lEWPpqluE2P0U41SHdtlSkmQuVMJgOjJkHHFARZk0ViGupBMWEea/6vd8WjsWPa3Inmr9M7TE5nao4mUUMzYBpytBuqZVXboX8aQZhnLTV3lL3qERSR2OmEMnCT8+nzhxu+wYOUb/e400fQux+VUokfozBqyKKYKNrxB5aZpQrsfkvmw4BCK83kxyhaK6sRNPzIkRst/On43mO0FYWTZqKG8r+pri8RPUsq3Gz/Ui+iwdlALQimgbKEMnMRN3dx5oTXc0oXtdAopJgIy0xDaSKMff2OZcuuYh7J7KZDnXATfadDVU3ThY0qYXKTcWnCkcSBN/0J4tJkov/zpo6iNrs0AntXZxY2STO3s8+qmT2LaK0z3DSO554wolz0T1amEUSJZ9U1gnYQJpuS/MKWNyOW/T7pDrj3fTV0v5kRNua1ZhoTHTMwwUvCu82wahFhtNVIxner4TFvqBElmPXQCHzjdzIjoGyXXC8W19lALQimgVKNwHRaGse4dql6N2FeF1wUEyXOYodpyHZiumLDbaQFZUwfQVaA6HJ+Zc7iKmFyacq/ziye/gSxS4Am/+vs0UbxkC8WBGGu31sujcBOKCtwxJokdkmosGOBNek3ylhFTeoEuzBKGcpMHR2jjRqtkoSyqRDG5TWC7OtMY8w0DTXSDY8dVm2O79GWn/jExjJzK/+bRoKgt0bQi8V1NjBQQSAi94jI9SJyjYhc6fj+mSKyJf7+GhF57yDbM9ModRYbNtfQsahGn8evVsKSiDuapEwQpBwpqYPLTihLbKGlUUN5jcB2HOZNQ27Kql5hcrqtKdfQ9MPqzHab2bKpRlBBEOQSygo0gh7O4rECjcBOKAO3L8VcuIoosiF1SptO5SrRO2XhkDoLWyxNtSjUNY0aygdHFB2vHyWnEQxSEBhmSIie0w6r1uUqx2JmXR2Rp8Ol9XkmtC/ATugLXBFnM2ACnWnsDNK5k5VSj5V8/wul1PN3QjtmHFWihsDeXTs0AscC77LHlgkCV7lKWxPoGrbQItgUy+b/esc0YpmGhgp22b3C5JLSgYa6Pm2KiQLfTMdh6rDRj0ZgTub0NRsgoAVRWUKZK1xXQ5efNNvm6k7TRDdRoIW4kA2HzJuGcrZtz0sytu1cFrPP7OAHF1y/06AFwYQRmJCaX1OCQi0ctOmzESqGW34ULp0zDeU1goYniQ8veRZnDsr082VmGrVpaBrwpThqyJyI5i7OnPBhaWRBfrDYVAcmzPhn+/pJmJwjNtxGq5FOEI3UpBQLgmZkMx1vdzMF0/PXKt/5JBpFJrN4mqahjLM4v9iUFeUpomdw+WbMwiYuiglzkc2Rzhnho+Wmoa6hEWTPzR6XNw1V0Qj0WBFxZWHnKbvTiLL8tTOCoMK9u47j7QI1Mw0zedF00ic+gkYaFVdkGtLDwLVJ80RyYb6ByieUNWeAU2umMWhBoICfiMhVInJOwTFPEZFrReQCETnUdYCInCMiV4rIlevXrx9ca/uE73mFEQ6FO9OuuVCldsQqIWalCWUujSBxYqrMvcuza0vCR+OFYaTlJRqBy1FsXqtMENh5CE2vODyxKjKmoZJncMHOCtVwaWJmYROXRjBeYk+2E8rstibXMPq3V/joUMNzFkYpgx4r84calbKwy4oNdS2NoBdME2BgCdRBCAIdoZaGj6b5MolpyNAIJuKEyZGmz3DTTxLK5g814vPygsBMKDO1nHzEWTmL62xg0KahpymlHhSRZcBPReQWpdSlxvdXA09QSm0XkecC3wEOtC+ilDoXOBdg3bp1c6YHfa9492MOFHNgZ6KGTI1A8oPF3iW6jtOw6wTo4817dsMQEcve/ejNsP7W5O3y329jJcoyYWWdzKOtqPaBacN2oVcU0JgVdTQzUUN5QRt9np3sLtg8MRpuQeCxQ9f7dUQNZaO38podpBQTdlvNa+wxrxW1rcT2bybleQXP4IIeKwuHm7kdriYZNNEo0V7MdlUSBK55MMCEsok4yzuJUDNIEe2w6pGmz5bxDg1fsWikmUmgXDjcZNtE16mtmwllpt/DpRFs72aZgmcbAxUESqkH49dHReTbwPHApcb3W43/fyginxCRpT18CnMGvucVDlpzspgTw/W5ixWz4eUjNHpRTIB7J6rD5DqByjqKwwD+5/kwlnb3QcCnW/uyJTjDaLPlI2j6THRCxiYDZw6BRq8oIDNhCmaGhjobrZV3eJfnULh3006NzTMKmziihkzHosvnoO/ncs4n12gH7L046ywuMg1p81pfGoEWBCNNto53Mt91wryPIC2Y5NAIShIoXSiaBzCY8NE0MCHrI+gEKhdWrX1gzUCxYuFQSqnSCVg40uTBzeNuigmvokbg7UZ5BCIyT0QW6P+B04EbrGNWSOx1EpHj4/ZsGFSbZhq+V7zz6jp2PODWFEKl8pmrDnu5y5eg4TINZTSRILKFZhbCh6+JhMDp/wJvvgzefBkPH/NOjvDuZmT9tclhtuqshc6msXapaahXmJwdftqagQplReyjLjZNG0XmFzuqS1+n1EfQTs0u9sJmJpS5wnWTa7hMQ66Esk6QONztwihl0OymC4cbTooJO9S2zJ/Rr0bgEgTJLnoAETV2FnzLcNLbYdVJVFwnIqkbaTWSKLmFw9o0lNcavQL2UVuL390yi5cDvxSRa4HfAj9QSv1IRN4kIm+KjzkbuCE+5qPAS1WV2LM5Aq0RuJrcLtghuQSBXbwCNBNnXiMoSohq+B4t38uYhuz7dgKLM+fOi6LXI18Kyw+B5Yew6fDXs10Ns/K2r6T3dUwUgA072uWmoR4+gpxpyPHM/aKIYqLtYNPMt9ed3GXneejrlBWvzwiCMC9YIE4oK9EITEqE0oQyi8EVqi3GY4ZG4KLsdo3Jorb26yNoF8wDoLQO+FRh+6OSmtpdlQurHjGcxSOxs7gdhGyb6LBwpBmd5/IROHw0hRTmc0wQDMw0pJS6CzjS8fmnjP8/BnxsUG0YNFK7LdjrSyZixWFvN/8PAhdVbX53HDoiEEwMN71M8QxzJ9oNFJ3QigS54yJYeSTMW5o+08givh08jZff/0MY2wijS3K7aR2qunFHm332GClsT68wuQlLI2j4Mx01NHMagZOG2mYfNX7bxBE73Mj8JuZxJiWBUxAYmbBlCWWmwNDH9WUaGm46nMV5gr4k0sbR1v6jhvLBFOkuevAaQcMwc9lh1SNxZnE3iEjo9DmbxjrMa/mZokTmM/ieGCa8dGy0GtlldibIFWcadfjoNFDEVglW+GiBaSgZ+A4yuZZBc2xes4wiQTtxNcyIJh0mlyyEE1vhgd/C/qdmrtH0hS8Hp+GHk3BNpBXYu+lRwzS0zNsG91/hbE+vMLmxnGko4n+ZjlJo3s+VFFepHoHDR2BrEmZhE/sV0mdzaQSBIQhc4bpgRLlYmcUuU+SYcVzDKz7OhhYEC4YbzsI0NkFfs8SMVeQHK4IrvDrdRfc8vW/YvFgtw8xlh1WPNH3a3ZCxWBBnTaGNaJNmjWtttrVJ/1zJiM0Z2PDMNGpBMA2UOfBM1bc4oSydAG6NwFI/Hb4EEyNWAfusb0LFu7z4/Ht+AWEX9j8lc42m73GrWsP6JcfAFZ+FMMztpvXCrRS8bMPH4PNnwNaHc+3pFSY33glo+V6y82z4XmF5z6pwZROD6efoP6HM5Zsxf5+28aqFmN6BLhguEQRSrBEkPEyJaag4oWzCcBYXhcC6MN4JaHjCaMt3ho/mqLd1qKsj+9t8xio5DK75oc8bpEYwbJnQOkGYC6vWwkKpSPs1x/tI0498Wda47sa+gNRHEyavrhyhunj94wiJ9HcM/K7DBmp/biaUuX0E+QWkzMY9YhWwt+/bCcI0auiOC6E1H1Y/OXvf+Pq3r3kJbLob7rooRzGhd0h7sZkjtv48EihXfzHXnl7Fzsfb3YyzuWoNgzJkTW/9aQRFCWV6kpvIFDZx+IPM3XaZRmBGr5iwd7ClCWUGz75IVE+5KsXESMuPo7Wyvq6OQ/tslvw+mbHWr7PYpqEewBrpilADzTWUDas2x6ROKDPfNxzaerRZiDc0nhjJcQ56khIW19lCLQimgUT6O9S8IueZK87dudA4atnq7MUctj4En3oah8ldJc5ilcaGKwV3/AzWngSNVuZSeod6916nwLy94IrP5uoYaG6gl/gX4xPAskPhqs9D0LGu1SOPoJ0NP22W2MurwuwzV9TQzCWU5UnnzHNN01BRQplJQ20vLGYdYjBMQz3yCPR1q/oIRlt+UlbUJunLJ5QVV50zN0PVoobMhDK9ex6cRpBmsae8VlE78mHVZgCEaRqCSEi4yotGPoLof8/o/yAMK+UIzTZqQTANlGkERYVpMlFDKi1I4lfgI3HFJAORCeeR6/nD8W8Who92YxNP0/fg7p/D5nvh0BfmLqVtp5OqCce8Gm77Ea3tD8VtSk1DPgEvb1zIPYufDKf8LWx7GG69wHqGHpnFnWxCWlG95H7QDrKLmUZamKZ4yCe76QqCwMyRMHMltNA0qaFz10sK00ihA3bCiqjqKQiaWUFQyUcQ978uPmMHNdg5F7qtLrOGuXj3HTWksucNIo8gNQ2lTLcQzwsrrNrcnJimIdCmIQchpMpqBJnwUZuqw/fmnGloZ5DOPW5x0APf4A3+3TSvuB2GorAy9jsZlh9SmFnctSZMGkGSvbbTR+DKI+i24eovgPgcN/5LhptviHb8N36LYx+6hjf4GwFYeM1tjLQPpuEvgCs+DSNL4JAX5p4pE8547Gvhl//Jfvd9HTg5+u6xO1h24/f4u8Zl7C0b+dE+L2btgc+GhfvAFZ+BQ85MrtVTEFg72ap1jsuQXfzz//ciQ2s4kgTdgiBPMRHdX5uGIp6gpiNCxGQfdZUGhbwjvch/oZRKnJoavlTTCCLTUCNpQzsIGSG6Trub9xGYu2gb00soy2oEg4ioGXcw3UK0cbD9IcMZU1Ajw647qk1pzrkZ/W/2vyuPYC5GDdWCYBo48o5PcEJzA1xifLjsEHjzr7Oqr2V7TT4PlRFT7uAsr7AgcfN3Ycd6eM4H8C94F6eO/wh+cRtc9M+cDpweyycuh79srOXfF/0N3PJDeOqfQnM490wZO/3iNfDEMzjw7m/S5KRoF3X+W9jj/st5XQPuDFfy6Ipngt+AY14Fl/wrbH8U5i9LrlU24As1gmn6CIYaHpPd0DLDZZPiiuB5DtpoR0JZtrCJikN3UwIznQzme16e1jrMawS5wve2j6DAWaydysOWRlBlMY7YOD2jDVkTl60RlDGl9p1Q5irQZIWRziTG29FNkvBRw8xlh1WPWhrASMswG8U+AnOMKqXiuRkd5/tSGhFYxuI6W6hNQ9PABc/8AYdPfIYH33Qr/PV98Nx/h0dvgvsuzwyUwOG0jD4v1gicPgIX++gVn4U91sJx/4/b5x/HSzrfgYv+GQ5/Ef9y2I84fOIzHD7xGW499fOs6t7H/7fxHaBCOPZ1zmfK2enXvYGR9kbO8H5L67Eb4f7LaT/zPRw+8RlOb3+A4eGh6LgnPjt6vfNi6xnKfQSmRuBakPpFJwhpNbyYArs/0xBoR55l/3UklJmFTTpBmOwa9e+ueZh8z0UxkWoEqQPW8hHkTEPR57aQsgUGVBcEY+0oc9blpHf5CMpMd0UFgYrQcWkEA+QaGut0acXEfEDGHGY/q6kBjLT8JDQXIsHQtJy9url655/RCBw5QmUsrrOFWhBMA2poAdsYJWguhOFFcNTLYWgRXPGZLLuiMcdtk1HqOMw75pw1i83j1t8G9/0a1r0BPI+rl/0hCxiDVcfCmf/FDn8+2xhlG6M8tvLpfHb+HzNfbYcDToMl+zqfSafJJ+3c/xS2DK/ilY2f0frd56ExjH/c66PnxrCfrjgSRveEOy9MrtUrTG7cchY3Cuzl/UCzZtpFVKqahlwRN6FyRQ2lbe0EYdIP+nefMDUCKyLHVY/ADsm0M2GLIprGOi5BkNdCXBjvhAw3/dT2b4XeupLo9DPb6Dd8NDsPIi1AnzYYjcAOTEjNYZmwashqALaPoOXTbAgnb/w6/NMy+Ke9kE8/DSFMruF7kobCOjWC4gzt2UItCKaBhr2ba82LhMFN5zM0mVImBQVJTqYgcIXqFaWxJ7jtR9HrYX8EwP3LnsG7um9Cveyr0BzJJpQFId9tPZdPL/0beP6Hyp/LjPbxPK5d8Uc82bsF79r/g8POxp+3JClGk0wuz4v8I3denBDi9AqTy5mGCuzl/UAn3TUteoukPGQvH4EjCc5JCmjE1IcqXbD1uToiysw+t9viZzSCgp1+HOVSlPWsjzNNQw1PKhWAH293o6ghRxt0hbLMMxdQcMD0EsqCMMxmwQ9IEJhjzfRHZcKqIaMBuMJHhyXgjC3nwV4HwZOeh/f7GzhM7km0DXP+FEWcRfeuNYLHBZyRHOteD2GHo9afn3xkroV2QQ7TTGDCZV/PhY/eeRHs9SRYtAqAkaEhvtZ9Ou3hPZPrJ/cNFN0Qrlp4amT7L0HTore4Zs/nM6maSDAJx70BSAVAhnTugFNhx6Pw+xvSZ+hpGkon3UxMkKigipe7d5UynRD9prbsCh1hu7qtNnWB7jdtGnJlnyeRYhkaardpSEe5pJnF2balpqG0H32vuGBS5h6xsHK1wZ1NPYMagUXKaFc4m2mMdezAhFT42ZTbdvjoUMNLCtKMNBuc2LmMxeEmOPXv4TkfBOAk77pE6HuZPAJ3oAG4WVxnC7UgmAaclAR7PRHWPJXDNqUmkoytultVI/By9XszGkF7DO79dYYiQu8KJ9rZKAxIa7M2S4q3p/fO2te3+wv5X3U6HPAsWHUMkE6WDOmczlKOyezKip1DtnSgvi+4wxOrQu9kbXoLbecv42qCeDft0ggcFCCQN+HoRVKbhlzZ5y6NoG0JvwlrgdcmbHuBtwWRvm419tEgYxqyTWl5H0GxbbvfhDJzbHfDwQuCCUsj0L6ittYIMj4CI3y05SMi6Xhv+Zwx/gMe8VdE433+XgTLDucZ/nUZjcCMgHKFHkNtGnrcoJDy94mns3LyLvZiE2BxDVkDXk9sJ1WtY0FKFrL7fg3BJByQUkQkxWlieuFsQZxo59PssRBCPnS1E4R8SF4Dr/xG8ple+DKF6xesiJLLYj9BWbFzpVTsrJxZZ3E3jEIBm76XcCTpZyijl9CIFtHsZ2HooADxshrBaCuvEUS77XyuSaTZRXkLIhKbEuyEsuwCX5RHMGYUrs8+QxXTUJAxDdm/eS6hrMCxbT9fFRu/KSxCI2gCBqQR2P4ow8zVCbMEe1kNQI9znyHaLNx8Ewe3r+dHw8+NzKFAe9+TOUZuZygcA2KNwIiAyoWPlpjYZgu1IJgGCil/4136yY3rAStRx1iQuqFKbLn58MS8WSUIjcXsjovAH4I1T02+T2oSxItIYITFRZWY8rHhLpj0CRAvCpYmoReeHA31AafAfZfD+OZMmJyNdpC1retnhunZiDU1gk0DoE1GveBX1AgatkYQ90MSPtqOdtuu7PPAYjN1mQHHO0EmyqWIdG7C6SzuLQgiagUVm6/yYaEugsPUQT4DGoFBbd4NVea5BpVQZofYQjovzA2S1gC0Zgnw53yZW4dfy55fPo0OTX7cTDXxiTXPoCkBqzZH5Is5jaAPE9tsoRYE00ChRrD8MLb4e/AMP7KVh5YjTNc2DU2NwMVQ6Ig2SY678yJ4wlOhNZp8rxfVMUMQDDf0AqVpqCsIgkbWyetaFLQTM1eY5rCzIWjDtV8tDZOzF1B93+j46SWUtRpeLnQ1yqquqBFYzXUVINemBTvMUy+CmkK6UCMwfgZX4t24pS0VJZTZmgNE2mUvQTBmmLTssFClVJxHYJmGGuniaaNf046+xnDDz2kEg3IWm/0pIrHpMtaUrWcdbWWjhU4Mr+LmcA3BKe/lUyv+kY1qYfLd5Irj2KGG2HvDZYD2M8UagSvirITFdbZQC4JpoFAj8DxuGj6Wp8p1CGHmB293owgFzQejd5+FDiVjVZoXbuNZD30SfviXsP7mHHOoHujaXNENFUNN2xZawTSU0wjyE2XY5SwG2PsoWLUOrvgM8brhXNhtUjUo33FWRaIReJIrUlNFG3JpBLlorcntHHTTh3lP40usvvqDzGcseQ59Tx2j7yVaTmhdL22LSxDY9aA9R/SRPg7yGkGvRWbCoMCwd6h2xS6NstoJ/QqCxHnfiDY8YZ+mpX6hq42ZiNhxI9+Z7RgfbhocQ5PbWBM+wE/C4/Cf/k5uXXhCNiLNa3J5eAgr1/86uW5p0akSFtfZwkAFgYjcIyLXi8g1InKl43sRkY+KyB0icp2IHDPI9sw0imK7Aa4bPpY92Mohcm9mYHfDyMziSxRrrMdTYYiZsYC8nAs48ZEvwbVfhfkr4ODnZ86xTUOhUgw1UpNF1xEb7oK9MLl206MuZ7HGcW+EDbezeutV8b0dGoG1k46euXjHWRV6wbcT8jpV/SOWWcXOGgXgqv9hv5s/xYv9Szjg1nN5gX+ZYRqKzBwTcYx+Wh8gPV37CMx75jKLrSgXfXvbRzBh0StDNo69CKlG4OVs1nYNX42yhLJ+C9N0QkXL95K2Dl4jCDOmIYj7PVQpB5eBKGw0FhwPX4uH4tbGgUDefxeGcGl4BAvG7oONd0caWcwjplQ+IrCMxXW2sDMoJk4uKUb/HODA+O/JwCfj110CReo6wDWtowE43b+SxvgJsD0y4QxPbGCZbGHCCxia2EDQ2TNzLY0cB03Q4UVyIXcufgr7v/1HzvbYpqFuGFEf6P8rawSWzdq1m9Zhdc4ayof+Afz43Rz64NeA1zsjh5ymoRmimBhuenSsZ6jqH0nU+rGNEHYJG9Hvlqj3YQhXfpYte63jyPv/nBsXv5OTguu5xfARTHTTXbo+L6cR+LZGYAmCdp4/SJ9rwmkaqqARpOymxRqBvZMVkfja+d8z6+ztLci78S5cC0HTh2JunDaPtUs1xFbDY9FIs/B7DdvUBumGx2X6HGk1aOgd+4NXA3Bn84lAXnB3w5BLwyOiN3dehO89KRMI4qKY0H0AsH2yy3g7qs2xaLT3swwCs801dBbwxbhO8eUislhEViql8lVO5iDKioBsUIu5w9+ft/FtuPTbcGn0+d/pAwS4Dtp3rGBv/iZnR2zZ9vJbf8gK2cS3lp/N/gXt0YuB3iWGoUp2Qa4wuSLYGoGLm37hSLN4AjaH4ehXsvqyT7CEs52mhIQNMiMI4mfuoTKf8eFLOfvYfXjjSfvlvusEIQuGGzR9lcuUrSoET9zyA/jAfwLgNedxrPwFDf+g6IC7LoaNd7H+aX8G9wv373ECTxv/CffFM6kdhBkh5zs0gq6Vl+BKHhzvBIl/B0oSyjpBxqkJbvOWDZPd1A4L1W2xi9enbY2O+6NP/ppnPHEv3nrqgVlnbwWFTo8pLXhdCWWX3Poor/28u/qdhgic/5YTOWKfxaXHRc7ifDhsUVj1opFmOg4fupqNzRWo0aika7ORnR9BqLhbrWBsdG9G77wI3zs4Em7xc+Q1gtRc+8iWCU76wEVJn37ljU/mxAOWsrMxaEGggJ+IiAI+rZQ61/p+FXC/8f6B+LOMIBCRc4BzANasKU+G2plINAIXDXUY8rHFf8n8R37Dsw9dwUkHRj/u1654gAc2jzHZCTl871Ge8+jn+EzrP3gsfHrm/HTXEDvwrvgMD6ql3LfniYXtsWmCu2GqDusM2F6ZtUA+Kzd2wJr4k5P35w+PWVV8kUP+AO/X/8XTvBvoBmflvtaTzLxuGamZiXs27OCux3Y4v9PUCE0/ZKJjCoJqQtADTt/6zYg88Lg3oC77BJ9q/yc/mjwOOCDidhpdytb9ngtcxZ2LTuBJD3+HNRO3AFHJR9MR6wq5tAsRubKZO1afF4WP2hmzUC1qyPQt2G1MCxE5BIExNu54dDtr95wXn9ufRpBwQvkSJ5SZ3D3RtR7aPAHAu844iAXD+U3H+q0TfPSiO3hg03ipIIjIHaHlW6ahOOnQFVb9vjMPTfv6wasZWbuOj5xydNwHWR9aNP+Fx5Y/jTV3/4jWkjfRUelvUFjgJ1A8tGWcTqA466i9Of+ah3ho83jhcwwSgxYET1NKPSgiy4CfisgtSqlL+71ILEDOBVi3bt2cMawlgqCAlnf9yL58J1jIypUHcdJxBwBwyW1XcdvEdraoDlv3XMYTDz6Kg376evb67bvhsK8m52fooNffitx9Kf/bfQnDfvFPZmsRYZhGt+hFscpi2PDFwTuTHczLFgyzbEGevTTB3kfRbi7i6cF1To3ALnYD1SkmOoFKdt02NLd8J/DoBmm1NlemrAtHBjewqnsfPPWTcNTLGV/1VIY+fSovuO4tMPE0uO0COPHtNFrRs98+7xgCJTxh02XASXTDMN1tGwu0HTlmmtRc1ejagWLU4LzxCzKLtVPaRER6Vr4Ym1qL7aQv42UyM7bH20E61lR/GoH2V2mCtkz2vdWOl6xbzZ7zh3LXuG/DGB+96I5MMSYXUse0K1dHOc2G+y6NBBw7NsDmexlZ93oOXhlFCtk01Lq9G1c8jTV3f40ndm/lOu+QRDgWZaV3w1R7POVJyzj/modmjYhuoM5ipdSD8eujwLeB461DHgRWG+/3iT/bJVCqEQRh4qgNM/b2NKolCBWb9n4GnwjOYq/7LoAtDyTHJcW1QwVXfg7lNTkveKbbJh/D5fRr+FH2quZjr2IeMYuu6GepYl/PwPN5bNlTOcm7zun8TUtHmiaS3gll2nlbKAjisEfb7l5VIzhj/Ptsl/mRnwPoLj6QN3feBgjc9XNY+kQ47o3JtTaF87hO7c/KOHSwY2gEZvhoJoHKYpFtNfKcTHaxFL2W5DOLw1zklhm1UgTTWW+Hheq2uphadcZ2NzapJFpEvxpBPDZ1GHXGh6JsgeT+3TT9hlmMyXmvAnqRpi8GDXXB2Hj4d9HrqmOM87LzQwvBLSueCuJx5OTVkRbSQyMwNzQLYzNrLwE+KAxMEIjIPBFZoP8HTgdusA77LvDqOHroBGDLruIfgHJncScIM45a8/NWw8NLdkKK7wVPib40KJwTdX1iO1zzvwQHn8UGFpULAsvpF6hoN9L0vWRxqhY1JDkKgCoCxMbGlU9juWxG1t+c+y6JTLESq6L2Fy9iSeZuweSPCqpIzu5uE4tloBRsvBsevIrjJn7NRSOnQ3MkaeevwsM5/2nnwztuhLf8BhatSvpjrB1waXg4e2y6joVspxOEGdOQZwnn6Jq9NQI7wiv1NdimoW7ONOT1kUdgcg3ZhXZcGoHO2NaLr253NjKuSvhotPhqx7YdVWVep2jsaU3IrNPtQmLqcoTDavbYwvH94O8AgZVHJR/ZY0u3MxxeBKvWcdTEb1nWeYBg+6OAO0cIon7W43hhbPp6PGoEy4Ffisi1wG+BHyilfiQibxKRN8XH/BC4C7gD+G/gTwbYnhlHYR4B6c7UE8ssYGS+6oSy29Q+tEeXZyic9eQcve3bMLmVyaNfl7mnCy0/q+LrTOSGJ8nErZZHkLVZV91N29iy90nRM9z/89x3mlunZajryQQp2RUlXD6FGkG04OuC7MnnQYFpSCn41jnw0aPgv0/BI+SC4ecmX+vdaRnFxM+DIxEV8ir/Z3QDlTENJeGjVpx8RhA48gjsbO5EEFhDzQ4zjdrWm3QuYxqyBHAiCByCU2dsp4LApRH0Xsy0xuPUCLQgcJgPTaTh0uW76E7BdbTjuzSs+t5fwtIDYThNIDOLEgHZnf+Bz2Jt+3bO3XwOe376KFbL7x0U8+nmQI/jRSONTFt3NgbmI1BK3QUc6fj8U8b/CnjLoNowaLgIxTT04LJLH2ozi94JRd8J21adxJ53XQhhAJ6enIolN3wBlh9GZ+VxwM/cxetj2HH4QZgWSNcTv3pmsW3O6l8QhAv25rZwFcsf+Dnwrsx3rophVThYuolG4N4F6gW/GVgaQaiY53r2X/w7XP81ePKbYNWx/NuvtvJgsDL5utDhFy/S4+2Aq9WBbNz3Bbzzrq9zwaNPYWzxc4Box7p5vBO1y8ol8a2oIdOxHbXXpj2I25PjGgqYP5Sdxp4jL8GGaRrqGKZESPu41ciPNZ2xrceTSbesF9ZqCWV6fkgmoaxpmLX0ZqFo8+N7QqvhFY6F5F4FmoU2c0VC13GPjXfBXZfAM9+d+dj03/men5IIisAJf8J/3yRs3bqVd0x8nFf4F+F7p+Xuq8/XYbxaI5hODs10UGcWTwN6EXMN/Ha84/E820cQ74TihDL93Y59ng7jm+Cha4BosBwntzKy8SZY93o0f1qZwzPJPQhTjcCPtY/ENFSRa8jMyrXt1VXR8Lwo0eaR38LElsx3LnXd9wSR8l2R1haKfATtWHvJhcB2Hc9w20/iam4vhjP+DY54MXeOHOnMks0XpklNQyCsP/U/uF7ty7Nu/luO/PWf8snmf7L6p+dw2K/eykFyXy680tQIXJnFtgaTOovzUUOuRKleCWXj7QBPIi2yL40gHhu2RhDECWJQMaEsmR9xQpkWPoYmp3m5yso5jrb8Qu1QI9l0CPDzD8ADUaJjlFkc5dcc9+i34LYfZ0+88nMgPhzzmszHLcsEm9CKewJD87lm4alc0DyN8f2ezYv9i2mqTuZ8M1x3PN4ALHgcm4Ye99DzxK0RxJWyLI1Am4z8eNfWNQUBklA4j7Q38OHWx5kcXQlHvDgZbGUagUjWNq5t0U3f68805NsJM9U4imw0feH84EREBZH5JUwnrF7QTYekiC4o01sjKI4ainam+WcIswubUnDxP8OeB8KZ/5Vsue3Qy8Cc5AbsegSt4fn8cecdPDz/UOZtv4d95RFaW+5mz/t/ykv8S3LO1KyPIP/MNq1HahqyncVBLlHKq5RQFjDaaiR9Ht3TSigr8BF0DT9IsmiHKolaq1IUR7PEJgllSmshXjLWq4y7kaZfIWoout4Rt30ULv4XuOAvk2eZDEJe6l3IaXd/AL77VgjiRbszDr/7cpS9v3Bl5nqp5p31ZSQEgfEY2nLYa1gi21nzyI/d54ch4+0uIjDczJdX3ZmoBcE0kGgEjh2Q3tF5YtcFiMPmvKxGIPP2hJVHwq0/hAev4uCfv5klbOPGZ3wKhhYkg60XlbJZFSw0BIG2W1cx8dhx7doB2y8avsf1aj9uO+bvompqP/7bKEtzw52JM9rWUBp+npLZhF6sipzFJg11NhfC8hE8eDU8fC08+Y+jBLgY1QVB9D7tV2Gjt5T/e9LH+NpxX+OM9vuZ/H+/ZMfSIzncuyvnTF2qNkVtePBq9u/cxn7tW2Fye+Y5m5aQNNujYdMr67bk+HqUgvW3Rvdcf1vGt+B50Ti1KSZci7DOOteC2NwVN/vSCCKB7YlkCtO0GunYqzLuRlp+4VgAYPN9+I/8jlf7P+bA2/4bluwHD14FD/2OhiccNHYN72v8D5tHVsP2R+CWH0Tn3fidSENf9wZHH2R9WTZxpI4I3LH3idwZrmS/u7+aOd8M19WcUiJSSts+aMx2ZvEujbLM4k6oa+d6uQIxTZ1aH6rsAn/g6XDpB+C/T2E+8Cedt3L2ooOB4gXJhjmYtEbQ8FLTUBWNoGWFXmoHbL/Q97pnv5dzkDwAv/lk9AcccNDfAIc5q2CVmoaCYtOQUirZSXf9LNlfJwyz4ZBXfAZa8+GIl2SuUVUQJOyjcTsixtNIiJlZ04/tdSSHPfplruim5gE/nODDm94C/x2ZyxIL9Pm/gBd/AUjNIma7wME15DANOSkmLvlX+Pn7k7fLnvBxRpppQqDJn5OG9rrDRztG9rQ51pp+xONflXRu/lCDUEW8TKYg0Ke7OIBsjDRLTENbH4b/Wse+wST/2ISNez2ZJa/9P/jwYXDFZ1kZns5f7fhX7lXL+dW6L/Ka614DV34W9n161FdLnxj9b6FlmdK0BqQ3WXoMBQq+GpzG32/6UrTpWBm5TM1wXVOjsxM5dyZqjWAaKArpg/yOR0ObjLT6qCe2JwJP+3N4xTfgZedxxx9ewA/DE4wIoGqCwKzMpYtimOGjlRLKPMntpp3OtB7IcNg894Pwmu/By86D/U/lKbd9gBO8m5yx3WVcQ3qBm+yGuQUnCTf0JF9cp2toBGMb4cZvwREvzkSDQL7MYxFNuF6k07Dc9J7j7SDhYRrf60hGpM3w5tuTc4/ffgmL1JbIL/Gy8/jM6n/lF95xcMeFiWnCLpbiqn2slGLMYRryxdIIbvhWtLAd/iJ4yZdBfJ645de5okCdrnbSah+ByzQUbTT0LjzRPlW66agWNWRRTBi5C6bTutfGZbRVYhq6+gsQTHL3Mz7Ma9vv4vpnfgbm7Rn1w/Xf4M9+/3eA4o2ddxIM7QHrXgt3Xwpf+gPY+iCc+bHUS2/A5gpKI8ui733jmb4ZPJ2rn/LxqGCTdb4eK1qQ20EaOxO1IJgGijQCnfSkoyKyReRVQrYVhKmTrOF5UW2BA58FB51BsOzw6NpaEBQsSDaasQNMt0vH1CcmjEo+guyAbAdhJZNS7jpmFJDnR7urg86AF32eLcOr+WTzwzR3PGydU17w3sx4nrBMAqkD2ktoAHQ9B20yAqJdX3fCqfZr3419Tbvf9fu0X71EiJlml4llRwAw/7HrknNPH/s+DzTWRJFKB53B7Yuexg+8Z0B7GzwQcet0gjDZeYIRNWSZGYNQ5fIIMqSBj94M3/kTWH0CnPVxOPgFsM86Dt5xRbbgvVHIp0wj0L/PhGUa0tpnlRwGfV4z9hFkBEHDT3IKqkSrjbQa7oSyoANX/Q8ccBqPPuFMLgmPojEU1+447o3QHWdZ+37eof6ce9TKSOAc/WrwmvDwNfCCj8AaN/+lne+SRpbFGoGf5ghtZR4bVz8LDEaATEKZIcjtDdjORC0IpoEijcDkc7d3mNrMYpNt2eM9papNozLMexah4aUqfqgicrOG7yVhalU0gpYvdMIwXUQrErbZKKzENLyI85/0ARayA/+qz2XPaZSHPppC194JdhLbdkrCpvutE8RRLXf/Ai75NzjoubDisNz17Ygb/b+LibNl9GvLT6mvx9pBQtMdLN6XrWqUBRtjQfDg1RzQuY0L578gWd2bDeGy8HAQD+68KK7qlvWfuMZaWi/ZCh8V4xl+9dFICL/ky9CIaRr2P5W1ndtZ7qc+CTMTu2v0ow19nH5uM6GsL43ACJrICoJUI6jCljvS9NyBA7f+ELY9DMe9Me9fW3kEnPRO/m+f93Bx++DkuZi/F5z+T3DG++GolxfeMy0sY8/N6PuEYr5g85aUJw3DTN0JFwvtzkItCKaBotKKZgKLbXPuxGYWTQNg7yY0EgK5bnaw9XIWN41oGV0Uo+lLYlKoFjWUTZjJ7Kb7QFmx80eH1nCxOgb53RehO5me43mlxetNbSFZADbfB3ddgrrzEvZga+KbMe/dCUKWdh6Cr706chj+wady14a8fT3hi3H0e8Po14afOvvGO0FSH8D3fa4L92XhxqhsKVd+lnGGuXzBs9LreB4bw5GooM8dFzoze12mIR0/73IWd0MVmcBu+GbkB5m/V3rAAafioTime23yUdMTFo3dC2GYjDm3jyDateqwx5RiIsqNqBKxBDqfRgx7enTOkO8lvENVxt1oq5HNI/j9TVHs/2WfgEWr4cDT3VQVp76XG5ecZvx+8XcnvBlOeBNlSFlybbNt6iPoBmFh0anofulY0dqjXV51Z6IWBNNAESOkaaLIC4LIzGJHS9gaQRpilh1sZeGjkHW2RiURsxTF1aKG0nubDth+UVbsvBuEnMfpsGM93Py9zDllGoEpVMY7AXTb8NnT4YtnsejrZ/PJ1kcScxiQcYCecf+HQAXwsq/C8CLn9XWmq0YRX4z9WcOTxNln1hJoeMJ1an8WbLktsj9f9zUuHnombX9+cm4ivA84FR76Hd3tGwA7tDZ6NbVLV00HMIqnX/MVCCbhOMsEtvfRbGU+R7SvSj46S13IX9/xCvjhO9MdtJN0zoujhrIagc6NqJLDAAbpnJePGgoSjaD3uBtu+mlm8bXnwSefAl88C+6/PHpuz8/kKGSeJVMlrrrG27DGlp1rEkUEpuR7LkFgjhVTI6h9BLsgijJhTROFLQiSOHevXCPIOaRKJmfmPEO91CUWs5THvQe8GVduOmD7RVnpyU6g+K13JOyxbxTBo9vn5SmZs+el3421u3DL9yMTwHM+yLaj/5gTvJvZc8edud9mZfgw+2++DJ78ZtizqKIDCRumRtea5JnnixcWnfSkhdhYu5vUdPZEuDbcD0914SsvhoWr+NzQq3MUE90wjEuPqqjmAVlBIxKFeJpCyuQ0MhGFjwYRZfaap8LyQzPf4/lc4R3BIWNXRmGl9/6ad7Q/zVZ/D7jyc+x39//F13FoBLEde8zyEejciCpFcfR5rYbge17ONJSa83qbhkZbfiSU7r8CvvtnsPYkeN0F8IafwlP+NNPGHNeQbwry6kthM5mblkbgp+Gj3TAl5CvSCJKxEpv27PKqOxO1IJgG0uL1+axQwKDZzfL2JBQTRkJZrjCNNg1ZSSu9NQLJ2C69OJrFvm6va+jnMLWbflFW7Dzqhwasez3cdxl8+hnwuedwiLo9eWYXzL4c78SL3eInwHFvYOMxf8qkavLE+85LKCAiFV3xMv9CFB4c+5rSNvue59QInLu6uE/MV202GU40Ao/rwljw+E14+XlsYb4js1ih9j4ahhcxctF7OL/1dxx57+cz98vY/iFLd33rBfCZ0+DcZ/L6m17PN+WvYNPdeW0gxi/CI1jUfQw+fRL870v4vbecf1j9WXjiGRx3y/s5Wm4vZB/tGCGyaTADiSCoUnNYa8a+EC+a6a495RrK05/bGGn6NDpbUee9Ikr8evEX4QlPhdXHR/1NMcWE+Xz9aASpszfLs6TnsGdt8orGTieIamZoQW6XV92ZqAXBNOEi+Ep9BFojiD5XcW1W7TswE8r8gt2KGZ4X3a/8JzPL6GmNwBzwVRZ0k8W0U+I47HmdkmLnSYLXMa+Gw/4I5i+DTXfzt1v/kYWTjxRe09QuvPW3RKRg614Pnk+7tQffD09g9QPfYySMCny0g5DO5Bgv9i/h7qXPhIV7l7bZ92xeoOLJrH+j9DWiJx5vdxNnsefBwyzhlv1eCy/9Cux1EIFFQ621rS4+nPIeOnsdxiiTHHHHJyM7v35ea6zpXfnSrTfC118bHTtvL8aae/CwWgJHvQIOPtP5nN/vrOPmJafBgpWw/yn848L3spmF8If/zWRjAX/c+H5pPYKEayi0NAKpphHo3z8SvKnAbTW8DA11zzyCls/T5Vpk++/hrE/A6BLHvdyUGebz9WP6zLP8ZseIre0XC4JII0hNQ9X6bhCoBcE04XKO5Z3F2Z1D01ChizQC20egF/deGmzTT52tgYryCLIqcAXTUGIDVUkG8FQpJqDINBRP8pHFcPbn4BVfh1d9hyE1yTs2/AO0iyqQpUJlxW1fAX8Ijn5Vcp8vdZ9Fs7uDw2//OM/2fkvrth8gl36AJbKdW/Z5cc82+55XKY8gej5LI/DShLIRQyMA4XdPemeSnBSEefZRiH/j4/8fv3/Bl/jTzp/hh+2I5kC3TQRzzzHeCVjGJg686ByYtwxe/2N4xdc5/5AP87r2u+CFn4BGK9fubhDyWDDKTw75t6jfX/wFHm2ujvp2eCE3rTiLZ3lX0tjxkPOZTY1Ah+jqZ/L9ihpBnOCXmlHypqEqFBOjLZ+ne9cRDu8Ba05w30vPR6vKnosCvQpMjRkgCLImoEhzM0KPXbkIfsrimviTfC8THr0zUQuCacKVzm862yJnWPx5xokcmSDCgoXG5n8p8iXY0OplGIcg+jEDqoarDq3rGlF7Q8och71ghsnZcBYDWfYkPrHn37Bf9064/JPOa+o+HGWCVfedHxWQmbdn9F0Yco3any1LjuDAu77Ip1sfZtkFb2Tosg9za7gP65fadZHy8L1srL7OAXELArFeU2ZOLQhcuSa2ILAd251Acataw4Y9j41yHuLPPcm2bXJ8B+e2PoTf3gYv+78kMkhHrxQtyHoRN6ONWoaj8trlf4AArd990fnM3VBlQnd1zHzkj/L60gi8WGPW88D2EfSkmGh4nORfz+Tqk6IwWQeScG7rNzTnQj8bnVz4aPy4pkag229+bl+j3Y1MQ8O1RrDrw6UKm+F3pkbQNk1GEk2gooQlL9Ya8upneXt0MpF5vEknXEUjyJiGgqlrBLo9Lo3AplDQuGn+CVzTPBKu/HyGpE5Dt+eF/q9odndkbODRd8L1p36BX552PmdM/ht3/tFP2PCqi3hR++9pNNwLhQntvNQ5FGUagRawyasvSfF6re674v+DUFk01DocMRuSef/+L4dN9yREhEk0EIBSHH71ezjKu5Mtz/l4JidC/1RFi0pCgWEIgoZBVrihuZJL1FFxaG87+8wWxQREi7oWbp705hrSJtIk4TIMM5E9oYr6q0pC2bLJu1khm9i6Kk8FkbbPET5Kdi5MxUfQTkywlkbg6e9LnMWesG0iG/7bK5lykBi4IBARX0R+JyLfd3z3WhFZLyLXxH9vHHR7ZhouVdisrGRGDXUzJiMvm1DmGIdZe78eVL01grZBv2BrBFVpqCHaSZnJcVNBEX9Kkf234Qnfaz4Xtj6QpwVG7+4Ur/J/ymPzD4J9jrO+A29oIRNLDuYWtYYdexzExJ6HsJV5lZ7Bjtcvt/M6NIIwzNA+FGkEGXOdZQbU8ekbVj8b5u0F33wDfPQYvs/b+NMbXwIfPQY+cgT7PvQDPth5Md7BL8g+g9YIChZkvYiPZjKL0/KL3UDxVfUs2P77KDHLfGZPU0yksfvt2CHvxxpBL/bRXMKloRkPaQZTFdUSdtVEMLEqLhG6eeXTKt3PhDkX+okaykf06c+zGsGkJlYs0Ai2TkR0IqOGs/jxnFD2NiBfqzDFeUqpo+K/z5QcNyfh0ghM55TmHQHbZETsUApjHv5ihxIYMcmVooZMR5XtFKuuEURRQ25HW1UU5QVoLqZ8+z0u9Y6LnJhX5IdDNww5Vm7jYO8+frf8jzJcMKbpzaQB6OcZ9Hm6/8oS+XQ/Ja+esH2ii1LkTEO2RmBGf+VooLXQbw3B8z4EB5wGex/NTbI/D44cBHsfDfscz6/X/ikfD87KhY/20gjMMpVpG1LW106guNw7BkaWRNFIjmfePpEKgm4QJv4o26HtgsluqgWB6SPQfaQji8qw7NFfcXu4ii2t5YXHdEK3Vtt0COMqsGmog8R0l+YRQGoZKEpG3BoXLTJNQ4+7CmUAIrIP8DzgX4B3DPJeswUd/WOibez8G74wqcm8upZGoFSuSIkJc2CUZSma0Opl19AIsmFy1cNH20HKmz9ljcB3awRFWaNNX5gMPTj+dXDJ/we/OTfiYIqx9v71vL3xTbaqEa5Z/CyeZZxrRmuZxUOKnIUu2FXnyhL5TE1AX39rvEBq05Ar+zxQ2bBIHWabUDyYXD8HnQmHRJE/77nlZzxrzXKO/MOIh+pXP74F/7a7cr+N1giKqB5cpiHzd+oEIb7vw/4nR2YppVI6jPhZtxqCQK2/lYWdx/C91eUUE1sfgh2P0YkZdZOES5UlndNt17xcheiMs+jR3/Kt8BQOKKGiTsO5LT9cn2HV9rHtAo3AFgTFGoE2DcV5BH41/8ogMGga6g8T1ShcUHLMH4nI04HbgD9XSt1vHyAi5wDnAKxZs2YAzZw6bJIyMCdyloQrazIyNIKCXb5ZF6AsSzF7TqS6J2GpYifOVIkaSlXfjpddAPpFkbrbKYgRb+hY6mNfA7/6cFJEROPpAD58NnweW4Kmdc1U0Hb8dFEtcha6kC7cIZCWIXQmVyVRQ5Jcf5ul7qeCJRWGQaAyu0Tb1JBqMPYCT+K7ABJOI1ub1D93oSBwmoZMapJYSO9/SkRR8fsbYMXhmWfdNtGJzDjdCfY470w+Munz70s+xe+9Ufditv1R+MyzYMejqBd/K7mWi2sIYtOQTR1u495f4wWT/CI8nFUlBex1fxYxyEbP33/4aNfapHm2IAiymoKJpp+OlZFWOo4ed6RzIvJ84FGl1FUlh30PWKuUOgL4KfAF10FKqXOVUuuUUuv22msv1yGzBptUDlLVV1dg0t+bJopGklFZvDhre6x5zV6CoBXv7BKNwE99BL3K/mmYu1jzWaaCIv6UKLPUrRF0QgULVsA7boK3X5/5+8Lx3+OpEx/l063X5kjnTNObSQPQT1Kcnsy6yUllOMeptk3YzOoetjQCc35rDijzmaM+iTXHAg3GZvaccBSuh+g3j+5ZLghGbI3ApHbwJM50JnFWm8/TCRQLR5q8wL8Mf2ITe6hNvOmR9zIinXy0UncSznsljG2ABStYcP5r2ZvHIs3YoqFOyALjZMZSjeDOi1Bei8vDg0urlLVjwkF77GepV6ZgGtJao6Xh5TQCVz6GUZVuJM5Cf7zWIzgROFNE7gG+CpwiIl82D1BKbVBKacaxzwDHDrA9A4FNIQFGqT+dL5AQn+WdZEEYOm2IQMxPnk0oq6IRmMXANelcdN9qP7degCKzSvXdtPNaBfwpRVmjmezKkT1g8ZrM38bmCh5iKQtGWjkaalMjaCW7NtVXUlxWI6CiRpB9hVTdd2WfByqrEdjhiIlG6TkEgaUROAVBQTWz5DxH+GiGrDAIozGwcG9YdkhUJ8E47rPND/Im/7ssGmnySv+nTO7xRN439BfsO3ETn1n/Cj720Evge2+LpKlS8P13wP2/gT/4JLziG0h3kk+0PkJDUl6erlFfW/dRT/rzOy+ivc+TmWDITUUdo1sQhpoxDVUwGybHJmbHVNM3f0/d/1oQlNGTgBE11INna5AYmGlIKfVu4uJLIvJM4C+UUq80jxGRlUopTUh/JuVO5TkJtyCIBkCr4WV8CC5WUns3YaJhagQFds78OZZGICnpXFWHmMkR1PDiRamPiZJtj5s/RVNtuNtfPBn0gjFvqJGnoTYW0I6f2rv7SYpLFm4rfNS1HuUFQdq/5iJrZ58HlkZgZ6qmWphtGsomlJkUxiYa1jPYmHDQV5uFfDJmu/1Pgd+eC+0xaI2yx8QDnOr/jlP93/HEbsBR3l08fPA/cfHvDuOLq/6evTddwYJgC0++6n9g/nIYWgjXfBme8ddRzgew4anv4ahL3sW2zb/jYe8QIFo0NUWF7qNS+vOtD8GjN6FO/nu4rbiGNeQ1sPSZ+zOZ2seaZTqdGkFpHkH62UgmaujxpxE4ISL/KCJnxm/fKiI3isi1wFuB1+7s9kwXvuQFQdfWCBIfQWpmMW2jhRqBMTCSSma9TEON6BwzEarh2LGWwaS3SAi7pqURFJiGCpzF5aUqo8UhYp20C9OkC6hJb1G13rN5TOIsLok4ylFMGMeYRV/M7PMkCzcTNWSbhrJmkuQ6QiXTUCLMCgSqriVgChHTDJkJ7d3/FAjacO+vANh7Q/R6S7iaPxz7OjvUEI/t/0KCUHH94lP5nyVv5/0L/waOemVUFe0nfxfRXDzjr5J7bT7gD9iiRtnv3q9mzCi+SEabKS1VeefFAPgHnAqUC4J2iRlSox/TZxISbHANmb+nbRpy05Ok9xvJRA09fsNHUUpdopR6fvz/e5VS343/f7dS6lCl1JFKqZOVUrfsjPbMJMo0goRTKMmUTM0svkFDXagR+KYQqaoRROqlmQjVTBaqihqBSTExAwllLuehrp5W9XiNThAV9hlt+TlzgI6DN2moI2dxdT+HbwsClf0801YroaxMI9BjIEyul8/tME0z9vXAzTVk1yLQ94vaXt001DAEdua3ecJTo9rON34bgBXrL+OecDmvaP8ND7eewBeCZ9NuzE9yI3xPCBB4/odg32fAqmOj2g/G87a9Ib4RPIOVD/6U+Z2IcrsdJxia/R9FDRUJggth/nKaex9B05fSAvbdAhPTVGmoRST1ZREX5fHzgmCyRBCYptYRg2Kirkewi0IXmDHRMXZ0pkZghjGa8dPF4aNeRv2EKj4CL85YTgehy4ZdBjPTNY10mnrUkIs/RfPRu44PQlVIj6AdiCMOjUCbgHS1MMj6OaqECNr29bKwXZ3spF+bjl2evqZdV8KV25GYhgqc2xHXUNov4wWmoXQxdS8qE+0AkTR5S7fdqRE0R6Lazjd8E7b9nqWP/YZfhIezgUV8/Elf4gPdl6BLZnqifV8hNIbg1edHdNCteZn7dwLFV4JT8VSHQx85H4gWTc8QBJPduMa2a7yHYaQR7H8KiFs7NFHkdDZ/r37Hd1Tj2RCcjiiwNHy02L8ERkKZly2vujNR+elFZJWIPFVEnq7/BtmwXQW+lEUNSaaQuG0ygmhSFAoCI4qgjBffhK5za+5G9CCtuutJdqihYRqach6Be4ev+ejzx8cLeMEips0FI46i5ZloLUOr6fbxDPmEsvjzChpBo0AjMLPPXXkJdknPIue2HTUUkdvl3XypIHA/o/YtiGSFURo1FGYd1eveAN0J+P7baXTHuDQ8AoAFo0NAZMrTvi6TbRcRp3OlG4TcpfZm04oTedJD3wIU7W5WI5jolOR+3PFTGN+YRDVFNQmKBUEnVIVmSI1+TZ8NY4OnS8Jq6Fsl4aOuiDPj3sON1EcAxU7+QaKSs1hE3g+8BLgJ0D2ugEsH1K5dBmVRQ03Py5g6bJMRQLsbFAqChi+5UpU2XXX+nGgw6R2VqRFUtYM2M0LKHcFSFVGCWz7Guyhr1CwoM+QYne1uRFbnNA0ZgjYtHhIW8tG7kE8oK44Ft30E5i7PTNbKaASOGsh5iol4nNhRQ55kS1UadNcmUloLtyQY7+Q1iYaXliftBiprU19xGKw+AW79IaE0uCyMHLwLh6M8jm6gktyIyGdWbt7Qv9Om1aex3yPvY2820O6ucGoEuQV6w53wrXNgr4PhSc8DdLnKEkHQdUcNmRnhVcKqTZjauh0B5ycagX6GYo1guOklPh2zvGoFWqwZRdWooRcCBxmhnjViuARBYuNtSKaYSLJQ+WIIguKEsqbvsWMyWkTtcnhFaFg7KjNqqF/TUDcI6XrZxa5fFCWU9VLXixzGUbJTgWnIELTdRqqFmRxPvWDb18s0Ar3LbCX9a2gEpmnIiBzTDlxX+Kit/dn940m+eH1Z+GjReuw6L81ujgTnPLuvjnsj3H852/Y6mu33RZneC0cayTmJRuAwldrQzzm57EgAjvDuYiI4GLOaXqIRmO2Y3Ab/91IQL2JbjU1OPU1DoXvT0W9YdfZcoySsFQ6caASaYsIxdfS9Rw2NzmShHWHnSoKqPXAX0Ox51G4IV2m+NNLGy6iQJseKSUxVTjGR3Un28hHoQa1j7H0juaq6aSjVCKbrLC6KAuoURISU1TCAdPc10mow3gkyC2M3UHiSNYe1zcinPsJHczwyJeGHdtRQy/cy9zJzSVwagV3S0/QxmbCTF8cLE8p6awS2k9nkO+p0HSUiDzkTlh3Kxv1fmHy0INYIOoFKYuldUXQ2dLvaSw8llAZHenfS7oZ4IonmpcdvRhje8C147DY4+7OwZN/k40g7LM4sLuO1yt2jIsyYfzvgQ2sEem67tA09PkzNrKj07c5AVY1gDLhGRC4EEq1AKfXWgbRqF4LvCZ1OdsKZiWOeJ8ku0DQZ6QHfLhEEZv3eMl58E6kgMDWCfqOGUju9H/QnRGwU8acUTU7TP+FCO3Zk6gk02U1L/XUM/qJUq5kaxURo5BEU53m4o4aGm8ULeNchWOxqdEXCVxc80cd0AuV2FvdKKHM4mU0iNecOujEEf/JrNt23CS7+NQALhxvJM+lYelfFPhv69/BbI2xZ+EQO33gXF8bmG90Op0Zw54WwYG/Y7+TM9UaafhIS675fMdNt7h4VEWVipxF9RQllhdp+fHwmu9tI5NzZqCoIvhv/1bAQ0UnnnZZ6J+CkmDAGvA6bcyGz69AaQS/TUOIsNm2sUzUNKbre9CgmXBqBSsJmy30ELnTjSa13tGPtbjKZupoaARJu/G4Y9mUaSjSCgkluQtvR9au+/qjlwDWJ2EKHqcl0bOtnFHHUqDBMQ67iMub9oJxiImcaMoR/N1CFCYSm03XhSFYj8L04Gq7HjjapPdDw2LT4MI7Y/H063W6UR+BlNdpksxAGcNclcPALMoyzEC2mj20vtlr3MkNOrQxrytZallBWFhEINgPsHBcESqkviEgLeGL80a1Kqc7gmrXrwJf8hDN3u2YykbnTMzUCl3oP0aRLGQ5VHITRSyPI7qg8T2hazJE9n8kTRGIWyj4jjnLtcfCnlNU40IuqKxsZ0hh3vaMdawfsmVw3zCxgjbj/TN9MLyQagREjXpb5nXnV6r71e5oFZRLOKGMxSygLujpqSDmd86Y/SmcHDzs0Aq+XIOgELJ2fLWFpmuTaQVioPZl9qJ3FJpWCi3vLhpmkuGWPw9nv3q+xtP0gY97eSb9M2I7WB6+GiS0p/5GB0ZafoxvJ3C8Mmd/ML3WJaWgKgRAZZ3FoRw1V0PYTZ3GW+A9mxzRUqQdiiojbgY8DnwBuq8NHI+gCMybM8DszmchcABvGYKmkEZQsSCZsH4HJNdRXXdaY6iERXjNYj8D0leSO91JtxAWt5uvF1lwA7IpWzdg2X8RH74JeiEyNoIwd1nzV/ZyPyMlrBM6axQnXkMNGD5nAA1dNAfN+UJJQ1u46tBYjQKCE7M3sX20aMu35ruAJG+aGaOueEavpfu1bMxQTk7Zp6M6LAMmZhUCbhsrzCJxjrU/fmQnTfxdayZFVBEHqLM4S/0GxWXSQqDq7/wM4XSn1DKXU04FnA/85uGbtOvC9/M7LnEhm6KAZ5653bZOxk8yFLA21Kjwuc45WreMdleelFBN9VWHyJVkUvAqaSBFc/Cm6ApeTa8hKrrKhta3UNGSWTMwuoDpbtipPE+QLydhZo9lnixeSRDPIq/uARUWeT1AzGT31q6tvqgoC27xlY6KT10IzhXwKakVA1g+itbdkrEk1QWBGRU0sOoBx1eLA7u0ZQaCvmfyed14YFeQZXZK73kivPIIC82uyWZuC2dOcm0UUE2WBILo9GZoPbS7uzlGNAGgqpW7Vb5RSt1FHEQHR5HcllGnpbhYSd2oEBcyIEJuGjDyCahpB1jRkagS9yv5lrxM5eYuie6pfxxFVVcIGahaUcUHTBegJNJ7RCLJt1Q69Ipu7C3ZpyTKNwCxIYz6Pa5G1C91ki9dnn7lToBGYi2xSXKaEdK4oO3us3c1pLS1jN9oJ3AlYZltHmn6ygJpjzRVFZ8PUCMRvcoNay8HhrezBVhrhZOaaw8G2qG7zA1dCzCtkY6SZzymx7+eMUHNkhFdF05dkQxMq5RTspT6CRt6MmGhls6ARVHUWXykinwE0jfQrgCsH06RdC55jB6STniBbNtA0s5jqY6FG4Eklp2XmHJ1Q1kl3aVOxhTb9iDXUPH8qaDg0gnSHXqwRFC0mWiPQE8jcCXYsFT2arCHtILK5V0kaSrJylXuSZ9pq+QjMRTJzTSP73BUGnDi2DaZZV9+YCWVJcRlHZrEn5X3o4ihKkpm6qnAHHR2nTRqNNAS6k2qfZiZ9EeyEy2vCA/h/3g/58saX0z1vIYv4dyY7AS/wfs2J33h5euL+bkEw2ooKCLW7bnK5Ql4rB0dUVTR9j+3dKFKpa7EDZPx/DkENqTYy6owamrvho28G3kLEEArwCyJfwW4PV2k+nfQE2ULippnFFATFky7l8g9LwhhN6EGdFM42tI++6rLqkpee9HVerj1eyp+iF2KzpKTrvuYxNmwfgbkT7FrUCDqru4iP3oVEEBiLcq/IDzsePV9D2DANFYQBR8XjDY3Aob15koa16ud20lD7xRpBGComu2FOk7AL+RSahjzt5Ez5nMwi7b5DA7RhRs95Inyq+wIe8lZy4MIuL9/+Bc72L2WyexhvaFzAxIInMHzSn8HwYlhzgvN6w4Z26BIEUV5Ecc7KVJh1NbkjRMI96/NJ5/Z8V3q8cYzNAAtzO2poEvhQ/FfDgM3/AlnnVEYjMGyvSaxxifrYivlflConpzORSygzdvT91GVtNmJHq+fenVa+TnzPwNiVlSWpafNVYfhoGC1So3EUSNZHoDILqPZPdEO3s9AF2zQU9CAFdL3au20zoSwsCANuGUK/MGrIGGsJlXRJZrFrQS4KOzUjlzphmHBW2dC71tFWI9FkJiyNoKqPIEqs9NjAIr7YPY11C/bghfNu5BUP/4wfbnk6R3l3cv+h/8Dq4/9f6fW0VjTeDlg0krdYd0J3zooO7552ZnGoaBq5I16FuZ1oj1ZNCJiDUUMi8rX49XoRuc7+2zlNnNtwaQRmboBZSLzTTW2vJt1uWYiZ5n8JSnamdnvAEARe/4VpINr56azcokWhCkz+FI0iCgWoqBF4pmkoTSSyK1rp0NV2gc3d2V5Dg4MeCWU5riHtSHVoBElCWSwIrPY0jHyLIg3GbRoq5hoKHVFDiSZhm4YMB6dSxQ5U28nZ8L1MhFqVhDLt94oSLqPP9DzYctir2c97hD+6//9jTA2x7aCzS68FZHJKXCiioY7aPzOCIEMrbsztwjK0Do3A1Mp2NnppBG+LX58/6IbsqjDzBDS6hnNKz2ddaCM1GeWjDGyY9vJAFTstTeQyiw3TTv9RQ1FC2VSTyaL2pINb86ekC0FZ1FAxxUSxaSi780ueoWQhsGFqcPq1uHBQVgAURQ2Z2ecJnbj1W5qV2Yqcm57kE8rKaKhdO8ukXnHONORlrlu0aUh3stH5Ld/LZLF7XlRFLSzpt2zCZfqcvifsOOD5bPjZ37KyfQ//G5zCsSOLndcwMewIHDDRKQgfhdRP0S9MMsmo0FD6XcZfUOhfyo+V1lzVCIwykn+ilLrX/AP+pMoNRMQXkd+JyPcd3w2JyHkicoeI/EZE1vb9BLOMhie5nZfpnDILiZtx7llBUG6P7QRhNNgqDNhEEJjso1Nwiml6C9sB2y9cmcKpaSB/3V6x1J0gJZ0DyzRkUSM0kqih6s9gRnnp16oUE6Yj1b5mEGY1AvuaTT/NVC0KHzU1C/3cTtNQSR5BahrKtjGNNtN1ANxjUicbmnV2zbHWK4cBsmyd5mP6ntBoDnNecDIAXw5Oq/S7jToCB0wURWHp9k/F9Bn50EzzYVagpceVb/IyUUM9QqcHiao98CzHZ8+peO7bKK5F/AZgk1LqAKK8hPdXvOacQWT/tTNn0x2dqSaaZpbMTqhgrJvZnnZ5wyI0rAnd8Lwphck1G9EOtRu4S0r2cx0g00eJs7CEnreXs9j3hFbDy+wC2xY1QiteXIv46F1wJZQVRXXZvgF9j5xpSNKwUS1g7J1iNlPVndkrRh7BRCdfXCa5nzHmbKQCJHuefgb9fdmmweR6anhexgzZK6sZ4tKRVnh1dK0oiOIj3T/kvXv+BzeptZUSGV3aoYmiqCH9LP2EVWu0GpLJ+rcFmkbR2NHPnyWdKx/7g0SpaUhE3ky089/P8gksAH7V6+Iisg/wPOBfgHc4DjkL+If4/28AHxMRUbNRomeK8A277Vd/ex8/v209tz6yjUP2Xhh9L+kOKbL9Rj+2lxk4RfbLdBEt8yWY0BMnpZgwd6x9CAJPuOHBLXiesHzhUOXzitrzrm9ex4qFw7zvrENLKR/s5CqAj198B88+dAUHLJufqQZlFyTpWtQIDc/j5oe3MtTwE8rkXtBaV0Yj6JVQlvgKikxDvTWChp+WPuwUaDBmaOZYO2DUKi6T3i9djB/aPM77f3RLYo7buKMNwEjTrRF88bJ7M8/ifG7DR9P0JWuGrCAITA2tYS2avidM0uJ6/2BgszN6yoatHSql+PDPbudF6/Zh70UjhbxWUfu9aWgEKQ21beJKjivURKqbhj7441u4a/0OAE4/dDl/cPQ+fbe3F3rNjv8FLgD+Ffhr4/NtSqmNFa7/YeBdRILDhVXA/QBKqa6IbAH2BB4zDxKRc4BzANasWVPhtjsPUax/NCDO/cVdrN86ycrFw5x80DIgG45oFtFuWDshF/Sxk92wdDCb0BMnDenzaPrCi47dhxP337Ps1AxOO2Q537r6gej/g5dXPs/GkasXc9iqhdz+++1ccut6XnnCE5Idj2uXPmQ8M8COyS4f/PGtdAPF2047MMMnZNcksOPITz14GRt2RAlKpx+yolJ7+6GYOHD5Ak550jIOX7UIgL0XD3P6Ics5bu2S7DU9swayO3y05XsJrUIncIcdmpuOyW7AUEGMuh4nQaj45e2Pcf41D7Hf0nnJonT0msU8cfn8zDmrFo/y5H2XsGmszaF7L+So1Yud1wZ40brVnHTgUiBaSM1qeL1yGCD7O5k7ZrNOR5qk1nvMa7ZX3Y7Htrf5yIW3s2C4waue8gQAZ1gpwB8es4oDlxctT8VoNdLntjdpLgI6GwctX8DJB+3F4fssSs9zmIYmOgEfv/hOls4fYsm8Jhu279F3W6ugVBAopbYAW4CXAYjIMmAYmC8i85VS9xWdKyLPBx5VSl0VcxVNGUqpc4FzAdatWzentAXPk4Q/ZqId8OzDVvDvLzoy+d6015qJPOYaWORQGjVU3soJZZoL3QgfFRE+aLSpCt70jP150zP27+scFw5asYDv/9lJ/OL29bzqs7+Nn6WY0TThEIoXeK3uj3cClIr8LCaFr1mZasxi1XzjSfvxxpP266u9/SSULRpp8rnXHpe8H2r4nPvqdbnjzOzzIjpxkzitiBtHDBOT7RjPPINBQ6377+tvegp7zi/W7EZaPuf98VMKvzfxD2cemj6bL+lYMzSCsqSysU6Q+CjMHbPWCCAdv1X8WmYhJUj9SxOdoCe9yDtPP6jn9V3QFfI0k26Rg7hoE7FotMnnX3d85jObhRZSv8dbTt6f152475TaWgWVdCIReYGI3A7cDfwcuIdIUyjDicCZInIP8FXgFBH5snXMg8Dq+B4NYBGwoWrj5wJMjWDMUfAjVdPDDA+8K9zMhsmn029CmVmYZi7AfJZOyeS01fzx5LVrFH5P1WpTI3AVXOkXqQanQzmrmeTKYGafF2kEo61GEv5YlNnrGz4CO1Q2c5yfCoKxkgzkmUDT9BEYC3mZRjBuUFxkNII4DwFMIrveS1TD8itp6oextiEIpuHncmGk5aNUqq33qxG4YJZX1RhLnPuDrVhWtXf+GTgBuE0ptS9wKnB52QlKqXcrpfZRSq0FXgpcpJR6pXXYd4HXxP+fHR8zp3b8vaCLhSilIp53Rww5RBNjwqgo5SKpspGExbWrawRp1FCe7ng2YT5LYhpyqOsN36PlexlNQL/albts05Cr//tFqhEQv05fEJi5Ji6uIYjLLRqmIVc9ALPkZRWNoGtoBC6n8kyg2ZB0rPlpPQFXDoOGWVmtYe2ktRCbMHINerbB8ivpOPzxTpA4dKeTC+PCSGZuZgvQuCipqyANrMhrBC5OqZlE1dHRUUptADwR8ZRSFwN5HbgCROQfReTM+O1ngT1F5A4iZ/JfF585N2ESTJnVsjRMx13WNNR7sCQZk51uaRhjpj2aYsJQ1+cCzGfppa5HbJLR7ljvaMfaQY6sbsQoWh7Gi97INHe+pgYXvc6ARiB5QWA/+6jxzN1QFUYN6c1iGUOomVCmd99TZY/thYbnZcyQdh6GC0XzwKURVIkaatimoXh86UXaPGamkGi4nYAgzGreU9UIzLVEo4xTaiZR9eqbRWQ+cCnwFRF5FNhR9SZKqUuAS+L/32t8PgG8qOp15iL0BNsx6VbhMvbadpBI9iqCIN11hLldRxGSqCHDgTcXkMZ6h0a0jXtymmySeiK47L0jTY/fb4m+14676WoEadQL8Ws2Rnyq17QFgR1WaD5zEdeP76U7bZPYMH+cJNeZCXNZGZp+qhFE4Z/ZPAwXxtsBS2N/hT0PUmdxUJn+3K5zrTXO8Qo+gqnC1HADa25WmdsuNB1RQ2WV6GYSVUf4WUR1i/8c+BFwJ/CCQTVqV4IeYNsnYu4X2zRk2GvNSVlNI0hT58Ow2qDShHbpgtPP0wwOw830WUyuGRdGW2mhEV2UPLL3xhqBwXczlnzfTc6dDrxEcBsawTT70CRiS8NHs88+YjxzUWax6SOIqM7dDdO/uQ5QGKRZoel7GXNXkkBYJghK5kFaM7p63otZZhNSQTDWwww5HZj8RrbWKCLJb9CPAEpYaI1kSj2uB20a6qkRiIgPfF8pdTIQAl8YaIt2MegBsG0yqtxpmyZMjcDkgc9MgIKdvpk63w1DWo1qCpzegeo0/rkAM/szCaEtWMiGDdu/aRrSKrPWesyCJEmi1BzUCMwFPE0oyx5jPktRJqxIlsW0aJGRpEBMyLiDcnomYWouVRPKTF9O1jTkZd5XFQR29roWQuOZwIQZdhYbGxuX+dD3hDCoVkzKhC6vqlHGKTWT6Nk7SqkACEVkUa9jd0f4PTQCM0EqqgzVyHxuXsOGuXgGqrqamTKfzg0hADpxR7JO34LJqUPzoMA0ZBB2md+Dm3KhH6QLmTtrdCows8+LNILRpp/UrCiqR+B7aUJZu0BrMI8NwqxjdhBoeu4dfU9B4Aia8OJQ52Q33Qd1uK6xDVnTUFIfeaadxUZot4uYUM+9fu+ry6tqlHFKzSSq+gi2A9eLyE8xfANKqbcWn7J7IBEEk27ThF5YbNOFV0EQmKGUQVhMaWvDLJM5l6DNH4t6TM6Rls+2WLDqiTDmcPyNxnkESplhktOfMCaDpp01OhWYiWD6ui6NAFKneFGFMn2dbhCWOhAjOuhsyPIgYNfq9aRcECilMmHWGSerQcgYFghDF0QkqbENqa9gLI62g6kVnylDZpPmiOjTc28qGkEmfHQnaQRVBcG34r8aFmxBkCv4YX2fcrT0FgSeJww1ojjtoKKPAIxCKXNII4Do2SeMXVqZs3j9tigjOMkj6ARJLVcdCjjcTGO5Z3LnZDLKuiZ5vzBzTXR+gstHAMT9U5JQZtBZl+02G7FGMNEJWDKvNa32l6FpmYZ6aQSaNysxDTnCLn1P4nKZfUTcGKR9+rXKWJsqzFKpLrrpRCPoc+w0fY+2oRFoTXd4LggCpVTtFyiAHsh6B1ukEejv9YSvGmusHad2ZEIZtLo+qJDBqUI/i1m7uew4yCaWJRqBReE73g5SeuUZ0ghCQxBMV6Ca2ed6jtu/pX6WHZPdTBEfEybXUKfHjtnzUo1gnz0G6yxO2mdE/RSxj6a/UyM5RyNhJBVtVqm+eJtlXVONoJuahmbYR5D8Xu2AUOV3/v4U56DJQguGRjAXTEMicjeQ+2WVUv3l7z8O0cs0VEUjKFtodFhhVRpqSCfQnNMIWo3E8V3myB4xfAR6R2T6Fuwyf+OdoLDgylTgWxrBTCSUJRpBmCZfmdDPojcMzqghL3U6d4KwlDVTm7cix+zgYtDtcWznYdiwNTcXNcNU7OutRupkTXwERmbxTJuGhg3BDfm5pgMM+p2DZp0DiMtv+t6M50Hk7lvxODN5bJgo9n9JwbG7FWxnsW0a0juF7RPFPoIyO6KOJqlKQw3poJ9rGsFI00smZ9nEHGk2ctFAOuoKDApfw66e7pymv+iZTtl++r0IZva53uzZ19Q75K0TUfRZUdSQvk6vYjua1iJyFg9uETEzoE2uoCImZdtXZvZDwxIE/dCfm2ygXSOzuBsOxjSkd+h6Xud8BJ5+7d801LGihoabgxUCUDGPQCm1wfh7UCn1YSJ66d0eSfhoPIFzGoGf/d6VWl+289EcNGUlE23MVR+Bfpa2VWQ+f5zPWLubcQIDbB2Pd1+JsziN5R4vqeHbL0wzQ7cPTazsehCXHNUagfXb6HGTPGNBzWKIYuyLqKrNe2rhOcisVJv2O6VUcUsCu6CO56VRQn4iCMrDi13Q1eiAjNNY32+mo4Y0FYqe1zlacUcBqirQ5VU1Bv37aVQ1DR1jvPWINITBt24XQJpH4F6IEh+CZRqqUrxCHz/eCQiC6k5LPej7jVgYNIabPht2tHtWDBtp+YQqCpHUpiFId8uDNg1lKSGq+2YKr5csjoZGYP2W+lnKNAJ9Sqh0kaMSjUCihXGiEw40Gck0WXhellLFhQmHU19HCaWCIL52H3b9lp83DUG5qW26GG56yby2f0/d9H7HjinQAMY7edqaQaDqYv4fpD6CLhH76C5NDTFTsDOLhxturqHUNFTsJHNhpOWzeazdl0Zgl06cK9B8OmU8OZAl9DILkm8djxdJzzYNdWcsoQzylBAz4SOAaAHXGoF9yZFEI9DCLt8/ZrJWz6ghXwr9VjMJsw2mRlAkCFzhkDpKKHEST6W0qrGAmgtp0p8D0I5HW41kXttjJNUI+hNAuryqhsnUOkj0qlD2jvjf7xMJAv20iqig/YcG17RdA4kPYNJN7mU7k51hcz2cxQ933LHKRUjKAM4xjUAnirW75aUjzWSdcYdGoIvv6L6ciI9rNbxpL9pg0UbPgCAwGWg1m6ntKM9rBG5nMYBSmqq6JKFMdo4gaNkaQY88Av17mlqKPieNtIk+72cXr2tsQ1YjKOvP6WKk5Sd9nNMIEnNXf9ds+UKna/gIBswVpdFLI9Clew4CjgPOJxIGLwB+O8B27TLQO6Ltk93SQuLbLdOR50XZkEqV71bS8NE+NAI/O7HmCoabfpIYVu4XSZ3A4+2Aph/tGLWab4eP6uNmasLkE8pmRhCE8U7e9bvotqemjGLTUFT2VJXy5/ieFOa2zCSylfZ6awQuyoTUJJTVCPoqrdpIE8rMqJtBmoZGmsWCYMoagSHQIBrbrmp1M41eFcreByAilwLHKKW2xe//AfjBwFu3C8CMCnKpcHpAbJ/I+xAaWiUuWWiG48pVZUXUc/ecgxQTkBaSKePJgSyz41g7Soj6/dbJ1DSU0FBno4ZmSoWe6YQyUyMIC6KQ9DOnpgyHacjYbRcVrzHvaUeqDQKZzOJM1FC5RjBSIgj0Y7mouIvQ9MQoTGNoBONZv9JMYqTlsymuAW3/pmkobH/XbPjCeCdbj2CvkspyM4WqzVwOtI337fiz3R56wm4r0Aj0fLadxZDNpCzCaLN/jaA1RzWCkZhPZ7wTlO7QRi3T0JJ50UTYau3uzGzcmeTUmemEMlsjcF1vqOHhifmM+WNy1+nBNeQaczMN0zTk+0ZmcUFCmSvM17cibFIfQR+mITNqyBBC9piZSYy2/EJncRoK2999W35WIxg0V5RGVZ3ji8BvReTb8fsXAv8ziAbtajDDR1cuGs59nwiKiQ5Dlg274QmT9DYN6YWzckLZFJNZBg3TIVpFEGiTz9o95yXnQT5qaKZNQ55EGoFSypk12i/MimFhQTiqiDDaahhaT7FGkLKwloeP2iHLg4CtEfRiH3WF+dox9/oa/ezim77H9m5c2CfIawQznVAG0fjbNuHWOKZKMdHwJSm1CdkiPoNE1TyCfwFeB2yK/16nlPrXsnNEZFhEfisi14rIjSLyPscxrxWR9SJyTfz3xqk8xGwiLaThDtNLKy7lw8C8RBUuNw0pBe1u9TDGJHx0rgqCiU7pJDdNQ+MGV07i+DN2jE0/YjSdiTKVGg0/0giKqon1C9Nc0i1JUBtu+rkQWRP695zsZOsyuOB5wkRnZor1lMGmoe7FNTTeCfA9ySzMiT1dsotnP7t4MxHL5SyeaYoJiMaz7uMiiol+tfIoaiht/8SA60kk9616oFLqauDqPq49CZyilNouIk3glyJygVLKrnV8nlLqT/u47pyC+UO7JLe5+7P5QhoVdj7mObt+QlmaNLV4pJgITYfYjrW7WUGQJJSlz6WpqMc6AYtGmjPSTj/WCLSfYNqkc0ZxorIopNGWXymhbLIbJ0n10AjS6+6shLLexevH2gGjTT8TNaUf1Q5y6Ct81MsnlEE6ZgahEYxm/H3Z32uqgqDle8lz2Eytg8TAcpdVhO3x22b8t0sVpq+CnoLAGPA2g6BfQSMwtYiqC1JCMTHHwkc1583WiU4SAuo+LnrmzWMdlII9bY3A2ClqCo6JdsDIDKXia04fzeszbdI57eRV5YJgxNAIXDxC+rTJbm/aBPO3H2ypSjN8VDJ+DBcmOkFuHuhF1PaZ9RU1ZGgE3TBM+mrrRIeGI1x3JpAJgbWamoTE9ptQZjq9Y6bWnZFZPFASCxHxReQa4FHgp0qp3zgO+yMRuU5EviEiqwuuc46IXCkiV65fv36QTe4b5iLhNA2VCArbOeaCWfGsevjo3EwoM6N8yp85Om5jHJGxcKRJw5PE0WguPqNxAfuxzsyl4vvx7lLvaqefUBa1t5dGYJardEYNadNQN98PuXv65eNypqDvY/MElWoEtok0bqp9jb6ihsxyoIFiYawdjrWDgc2DbAhs9reYagh3w0/DYHWo7c4wDQ1UECilAqXUUcA+wPEicph1yPeAtUqpI4CfUlAGUyl1rlJqnVJq3V577TXIJveNXjuvjCCwCNGS4hUlv4JpGqqsEVTQNGYDZv+Uqer6uA07opoEIy0/EQ4i2T6NTEPdTNWr6cKP8wjCGRIEer0OjIQyFzKmhgIaakh9BGUL3M7WCJJwyYQPqTiPIF/Fz32NvmiofS8JG20HIfNaDSMMdTDLnLnxsJtaJSLQhUigpaR50X12cUGgoZTaDFwMnGF9vkEpNRm//Qxw7M5oz0zCtlfbMMdBzjSU7KZ6746j43ZtH4HZP2W7WV3WcsP2dnKePtc+T1NWz6iz2PMSx270frqCINUIihLKINs/rsxrPUwmk2Ir1XwEgy5eb95Pj2WT5sGEKxzSjrDRc6o/Z7EkYaOa3TYZMzNcuF4jaxqyNIIp+giaho9A06vsDIqJgQkCEdlLRBbH/48AzwJusY5Zabw9E7h5UO0ZFMydl124HtJC4pB3Fqep9cXXz/gIdvGEsoxQ6zHJR1p+YhoabfnJrsg2F+jM65l0qmmKiXCGnMWmRlCUUAa9+8dLNIJi81F6z+hYO2R5pmGXRdVNKtIIXKYhO2xUP2d/zuIsDXXD95z1wWcSGdNQYUJZv6YhScKDbabWQWKQXoiVwBdExCcSOF9TSn1fRP4RuFIp9V3grSJyJhGR3UbgtQNsz0DQsMwULvjxwlK0EypLOhmZUtTQ1AbhoJHRCHq0baSZCoKRpp9OamuBHG76PLhpHKVmbuerSedmWiPo9qERuO6pz6viLNbHDnoR0WYXW7st8hGMtwP2GM1Gd+U0ggq+s1w7DNt6uxuV+tR1GAaRTAZ5BlUTU9YIDIHmYmodFAYmCJRS1wFHOz5/r/H/u4F3D6oNOwO9ooYg3S0UCoKSnb6Lk6UXmnNUI8j6CMon52groqyG2EfQdE9q87iZTCjTjl39fjow7eZhj/BRDRePUKIRdHubhoq00JlGs0AjKMsjsDVnex7o3XRZZJmrHWbUUNOXxCc3iNBRcNNkaNj+jqpo+h6h0oWYdp6PoK4pME1kHJcFP5jeHdiS3U6td2GkxA5ZhDRiYae4gCpjpIcz1MRw02fL+BgQOeW0Y86e1CNNny1x9ujM+QiygmC6USdJJE1QTDEBWR+S6xhbEJRTTGRpOAYF2wxpRki5MO4I882TzumooT4pJgwfQcMTPF0EahY1gn7Hjj6+E4QzWmOj530HfofHOewIFhf07iBvG81fw4YrFb8XEnV9bikEtPyITydU1TQCjcg0pCe1JQjM42Y4akjz5UxbI9Cx9XFuQpHPwYwqc/sIolftIyjVCOKvBm4assyQuo3F9QjyYb55Gur+F9Gm7yU+mE4Q0vS95HfbKT4C6x6JdtO3RhBvGkKVhI/u0s7i3QVVTEOJRpATBLuXRqD5dKD35DQXi8g0pJ3FedOQ65zpwLc1gmn2oxlbX8a82iu8tj8fQfTdTNRwLoNdklEHRxRXKMtTrdgx9+luuj8fAUAnDBNBkAQYDEojKNHgpsw1lERdhYZpaBdPKNsdYNoAe2kEOdNQfGqZINC1UaPjqrWp2efxOxPDFUP6TMfviBk1ZIePNn3n/9OB70Wx3DqMb7r9mHINhQSqmE58uIcPxbMEQTkNdf6ag4DOgDbHsKbosNENQtpBmPud7Jh7PadafUUNWeY3X5JnH5iPwMEkrGFrN1Wh50UnUKlpqNYI5j5MLqFePoJcYfuKLKH6ulV3+M05qhEAhWGgRcdBNBG0YMibhrKaw0zA94QwTEMgp9uPKRFbTGtdsDD14pVKfQS9M4tTjWDAPgKHVqspOmyMFSRI2RE2VTLuc+3w0/yFTqBoeF7y7IPyEZg79ZliH9XzohOETqbWQWHurRS7GDIaQcEPpiewHd6ox3mvXYOrvGUZ0slZ6fCdipGKk1Mfp8tPjhY4/gaiEUisEYQzoxGkBWXCqNBNjzyCIm4cO7O4XBBkrzko2HkE0b3FmVA2UUCZ4FkLf8o1VH0R1dpDO4hMQ62GJM++K2kEpkBzMbUOCnNwqdi1UEYhoaEHtG3rq6oRjCYaQbUBodXLQVDvThcjFe22+rhR69U2F2R9BDMkCHxJdu8wAxpBwj5aXuimV98kmcXd3hQTjZ0UNZSaLStoBAXhkKlGkJ5vXrsKkgU0DOnG9ZyrjrWpYhA+Ar3od8LQydQ6KMy9lWIXQ5XwUb1bypFtWZmURRjpVxBUvO5sYLTiLi0RAPGuKzENWYvyyCAEgUiye9fvpwP9O2gtozCPoMD8ZV8nMQ2VCCh97MBNQwWCwKyypVHEnZNm4doaQR+CwPARdILI/KY3ZoPaELUaXmHi2FTZRxOndxAysZOqk0EtCKaNKqYhPUhsldjOpCxCYk6pKAjmKvsoVH8WfdxwohHozGJxHmceO13YUUPTZx+Nzu+VUNZrB5uLGipJuEqquO0k01DDEgRBXg4kGkHRPLDDSPsyDcVacGIaymQWD24eJGZbWxBMlX3UEGhjM0ik2Au1IJgmPE+S2OkyigkopqHuVYKyX41gqhS4OwNpPkB/pqEiugDbqTwTmGlBkE0oCwt3qIkfpOB+nuUjqMI1tLMoJkxbuNaobIwXhEMmAsDyN/SVUGaQ3emooSJakpnESMFvNtWEMlMjGJtBIsVeqBPKZgC+JzQMcjnX9+AKH62mPhbtOoqQ2G3noGkocQJXFAT6+JECuoAkHNWXGbMFN6yEspkSBKGugVxwvfRZCnwE8WntCuyjCa3JTqKYqKIRFIVD2mGjWiD0RTpnZOR2tI/AGBuDgh6n9m869YSyNHx0Z5qGakEwA/A9KSU8Kwofrao+9ussnirh1c5AGv1T7Zn1rq4oamjUEhgzgVQj6B2vXwWJuh9qjaDAR1BAo2G2C1Iysiqkc4PmqbFDPiH6bV0awVhBOORMJJS1EmdxlLTXahgJZQMMmigydfpJIEh/99Z9oRPKdgbPENSmoRmBL1K6EOndQq4eQcXiFf2bhuYm6RykfVA1fFTz0iT2c+uZEs1hBidMKgjS99OB/v3DUBGGxbvEXqG1ea6hEo2gwC810xCJwhvthDJXOYKJAu6cooSy6WkEYvTnLGgESWh4f9dLo4bUjNbY6IVaEMwAfE9KF6JEI+jhJCuCNov0bRqag4JAR3L0yhpNNYHotagwjb7eTKbhR+GPJHTAM+Us7qURDDc9RMpMQ9F5be0sruAj2Bn0BE3fy4TYRoLUpRHEPoKieWBFD/Vj6tM7704Qxj6CwYePQrFfZ6oagW5rNyadc9U4GQRqQTADMBOeXPBEaPlebqfneYJI76STxDRUuTDNLmAa6jFBRq2dfpGT2fYlzAR0P7dnSBDo31drGUW/t8SaZS/T0GQnwOsxbnaWaQiiRdBschHXUBGbpl3ERf/E/WgE+tjEbGbMycFGDUULdT6hLPtaFaZAG4/zCHYGBiYIRGRYRH4rIteKyI0i8j7HMUMicp6I3CEivxGRtYNqzyDhG44pFxq+MNzMd3XDk0r2577zCBwOvLmC4Yo+gtQ0lI0esie1NkvMqGlIZ6l2Z1Yj0H6Hst9lpOmXRA1Fr5PdsOcuV19jZxQ+d2sEDkHQDhCJqqaZsMOop7Kb1v2htY5mw+tpapsJFEUNpTkR/WoE2sSlGGt3Hxfho5PAKUqpI4GjgDNE5ATrmDcAm5RSBwD/Cbx/gO0ZGHzPXaZSwzNYNzOfe1IpqqDfqKGkGPgcjBoa7REZo5HLLC5IDhIRRpv+jO58cxrBDCWUBSoKSe1FO17oIzDyCHr1X5JQtjM0Al8yO98iQVCUKWsnVupr9WPb18fqENWGsTnoxWs1HYwWzM2EULLPsWNmSLvqOw8Kg6xQpoDt8dtm/GePjrOAf4j//wbwMRGR+NxdBlGoWvHEbBTsWPvVCCqXqtQUE3MxoawqxYSVUTys8wgcSVTDLX9Gd756Ut/2yLbM+6lC/273PLaDdhCWC4KmXxham3ANdYOev22SULaTNIKGpRFs2NHmsjs3ZI67d8NY4TwwX/Uuuh+KCT2ezIiqIr/STGKk5eMJOeHmaz9d33kE0fE3P7yNTqAeH3kEcb3iq4ADgI8rpX5jHbIKuB9AKdUVkS3AnsBj1nXOAc4BWLNmzSCbPCUsmddixcLhku+HEvuofd6S+a2e11+xcBjfExaONHseCzB/qEGr4bHHaO9r72wsj/tpybzyti0aaTLc9JJ+bfkee4w2WTpvKHfsioXDpf3fL3Q/f+GyexGJ+nM68D1hXsvna1c+EF1/uPh3XLFouLBvzKihRT3GwpJ5rZ02BpbOH2KPeWl7Fg43+flt63nZf1+eO/ag5Qtyny2ZN8Ti0WaiGew5r8VQw2O0j37PmYZ8j/nDDea1fPacnx8zM4Wi32vPeS1avsf8Pp29C4aaeALnXnpXdJ0K68NMQHbG5ltEFgPfBv5MKXWD8fkNwBlKqQfi93cCT1ZKPea8ELBu3Tp15ZVXDrjF/WHjjjZDDY95BQN320SHbqDYwxowE52AbRNd9lpQPlCVUjywaZzVS0Yrt+nBzeOJAJlruH/jWKVneWjzOMsWDCXq8u+3TrB4tMlQI7tL2rB9kuGmX9j//aIbhFxz/2Y6gWLP+S2e6Fi8+sU9j+3g4S0TeAJHrl5cqMFsHmvjeeIUFg9sGuNp778YgL0XDfPrd59aeL8gVDyydYJVi0em3fZe2LijTavhJQJz4442t8balI19l85jxaKs0J7sBmwe6ySbhG4Q8ui2Sfbuo+33bxzjpA9czNtOPZCPXHg7Hzj7CF68bjUPbxlnz3lDzhrQM4GJTsDW8Q7LrI3IdPr/9t9v47HtbRq+cNTqxTOm0YjIVUqpda7vdkpsklJqs4hcDJwB3GB89SCwGnhARBrAImCD4xJzGr12twsKdoDDzWomDRHpSwgAO2UBmCqqPou9ECwv2PXP9I6v4XusW7tkRq+5duk81i6d1/O4xSU7+GzSVvni4Huy08aAPf6XzGvxlP33rHz+UMNn+cJ0HjR8ry8hAC7TUNRXKxcNtg+K5vB0+v/A5Qs4cPl0W9YfBhk1tFesCSAiI8CzgFusw74LvCb+/2zgol3NP1Cjxs6C6fyfi/6f2YTuj7HEWVxHxveDQWoEK4EvxH4CD/iaUur7IvKPwJVKqe8CnwW+JCJ3ABuBlw6wPTVq7NIwBUE/jtTdAS4fQY3qGGTU0HXA0Y7P32v8PwG8aFBtqFHj8QSbz6dGilxCWd0/faEWmzVq7CIw/f616SML3R86Om+QSWSPR9S9VaPGLgKTUqI2DWXRTHwE3cz7GtVQj6YaNXYR+LWzuBAiUXLmeO0jmBLq3qpRYxdBNmqonro2Gr6kpqE5mD8zl1GPpho1dhGYboFB8ufsqmh6Xh01NEXUvVWjxi4C0zRUL3R5NBtebRqaIureqlFjF0GdUFaOhmeYhur+6Qu1IKhRYxeBGTVU73jzaPpeIggGWaf48Yi6t2rU2IWgZUEdHplH0xc0QY2LrrxGMWpBUKPGLgSdXVxHDeVh9kmdcNcf6t6qUWMXgvYT1FFDeTQyprO6f/pBLQhq1NiFkAiCWiPIwaw5UPdPf6h7q0aNXQi1aagYjZqUb8qoR1ONGrsQamdxMUzhWEcN9Ye6t2rU2IXgJYXe66lrQwtHT7KhtjV6ox5NNWrsQtDZxXV4ZB7aL1D7B/rHIEtVrhaRi0XkJhG5UUTe5jjmmSKyRUSuif/e67pWjRo1Iuidbm36yENrSbUg6B+DLFXZBd6plLpaRBYAV4nIT5VSN1nH/UIp9fwBtqNGjccNtMWjdobmoU1Ddd/0j4GJTqXUw0qpq+P/twE3A6sGdb8aNXYH+HX4aCFq09DUsVN6TETWEtUv/o3j66eIyLUicoGIHFpw/jkicqWIXLl+/fpBNrVGjTmNxDRU73pz0JpAnWzXPwYuCERkPvBN4O1Kqa3W11cDT1BKHQn8F/Ad1zWUUucqpdYppdbttddeA21vjRpzGTqhrI4aykP7Teoci/4x0B4TkSaREPiKUupb9vdKqa1Kqe3x/z8EmiKydJBtqlFjV0aaUFbvem00ah/BlDHIqCEBPgvcrJT6UMExK+LjEJHj4/ZsGFSbatTY1aFLEtTF6/PQvoG6b/rHIKOGTgReBVwvItfEn/0NsAZAKfUp4GzgzSLSBcaBlyqliWRr1KhhQzuLa/NHHnXU0NQxMEGglPolUPqLKKU+BnxsUG2oUePxhto0VAwtHGv/Sf+oe6xGjV0IsSW1Nn84UJuGpo66x2rU2IWg17hGHSKZQ7PWlqaMWhDUqLELofYRFCMxDdV90zfqHqtRYxeCSJ1QVoRmnVA2ZdSCoEaNXQi+V1NMFKGmmJg66h6rUWMXgl9rBIWoE8qmjloQ1KixC0EnlNUhknk0axrqKaPusRo1diEkpqFGPXVt6GI9tbbUP+rRVKPGLoREENQO0RwaNenclFH3WI0auxCkDh8tRB01NHXUo6lGjV0I2upRmz/yqKOGpo66x2rU2IVQh48Wo04omzrqHqtRYxdCYhqqzR85NOvqbVNGLQhq1NiFoPMI/FoQ5FCzj04ddY/VqLELwfMidk2tGdRIkTiLG3Xf9ItaENSosQvBE6kzZwuQOItrjaBvDLJU5WoRuVhEbhKRG0XkbY5jREQ+KiJ3iMh1InLMoNpTo8bjAb4ntX+gADXFxNQxyFKVXeCdSqmrRWQBcJWI/FQpdZNxzHOAA+O/JwOfjF9r1KjhgCdCq84qdqIOH506BtZjSqmHlVJXx/9vA24GVlmHnQV8UUW4HFgsIisH1aYaNXZ1RBpBvdC5kHIN1RpBvxikRpBARNYCRwO/sb5aBdxvvH8g/uxh6/xzgHMA1qxZM7B21qgx1/GS41Zz/Nols92MOYl99hjhT08+gJMPWjbbTdnlMHBBICLzgW8Cb1dKbZ3KNZRS5wLnAqxbt07NYPNq1NilcNzaJRxXCwInPE/4i2cfNNvN2CUxUB1TRJpEQuArSqlvOQ55EFhtvN8n/qxGjRo1auwkDDJqSIDPAjcrpT5UcNh3gVfH0UMnAFuUUg8XHFujRo0aNQaAQZqGTgReBVwvItfEn/0NsAZAKfUp4IfAc4E7gDHgdQNsT40aNWrUcGBggkAp9Uug1H2vlFLAWwbVhho1atSo0Rt1HFqNGjVq7OaoBUGNGjVq7OaoBUGNGjVq7OaoBUGNGjVq7OaQyF+760BE1gP3TvH0pcBjM9icQaBu48ygbuPMoG7j9DFX2vcEpdReri92OUEwHYjIlUqpdbPdjjLUbZwZ1G2cGdRtnD7mevugNg3VqFGjxm6PWhDUqFGjxm6O3U0QnDvbDaiAuo0zg7qNM4O6jdPHXG/f7uUjqFGjRo0aeexuGkGNGjVq1LBQC4IaNWrU2M2x2wgCETlDRG4VkTtE5K9nuz0AIrJaRC4WkZtE5EYReVv8+RIR+amI3B6/7jHL7fRF5Hci8v34/b4i8pu4L88TkdYst2+xiHxDRG4RkZtF5ClzsA//PP6NbxCR/xOR4dnuRxH5nIg8KiI3GJ85+y2miv9o3NbrROSYWWzjB+Pf+joR+baILDa+e3fcxltF5Nmz1Ubju3eKiBKRpfH7WenHXtgtBIGI+MDHgecAhwAvE5FDZrdVAHSBdyqlDgFOAN4St+uvgQuVUgcCF8bvZxNvI6o5rfF+4D+VUgcAm4A3zEqrUnwE+JFS6knAkURtnTN9KCKrgLcC65RShwE+8FJmvx//BzjD+qyo354DHBj/nQN8chbb+FPgMKXUEcBtwLsB4rnzUuDQ+JxPxHN/NtqIiKwGTgfuMz6erX4sxW4hCIDjgTuUUncppdrAV4GzZrlNKKUeVkpdHf+/jWgBW0XUti/Eh30BeOGsNBAQkX2A5wGfid8LcArwjfiQ2W7fIuDpREWQUEq1lVKbmUN9GKMBjIhIAxglqss9q/2olLoU2Gh9XNRvZwFfVBEuBxaLyMrZaKNS6idKqW789nKiyoa6jV9VSk0qpe4mqnNy/Gy0McZ/Au8CzIicWenHXthdBMEq4H7j/QPxZ3MGIrIWOBr4DbDcqNT2CLB8ttoFfJhoMIfx+z2BzcZEnO2+3BdYD3w+Nl99RkTmMYf6UCn1IPDvRDvDh4EtwFXMrX7UKOq3uTqHXg9cEP8/Z9ooImcBDyqlrrW+mjNtNLG7CII5DRGZT1Tb+e1Kqa3md3HxnlmJ8RWR5wOPKqWumo37V0QDOAb4pFLqaGAHlhloNvsQILazn0UktPYG5uEwJcw1zHa/9YKI/C2RefUrs90WEyIySlSN8b2z3Zaq2F0EwYPAauP9PvFnsw4RaRIJga8opb4Vf/x7rS7Gr4/OUvNOBM4UkXuIzGmnENnjF8cmDpj9vnwAeEAp9Zv4/TeIBMNc6UOA04C7lVLrlVId4FtEfTuX+lGjqN/m1BwSkdcCzwdeodJkqLnSxv2JhP618dzZB7haRFYwd9qYwe4iCK4ADoyjNFpEDqXvznKbtL39s8DNSqkPGV99F3hN/P9rgPN3dtsAlFLvVkrto5RaS9RnFymlXgFcDJw92+0DUEo9AtwvIgfFH50K3MQc6cMY9wEniMho/JvrNs6ZfjRQ1G/fBV4dR72cAGwxTEg7FSJyBpG58kyl1Jjx1XeBl4rIkIjsS+SQ/e3Obp9S6nql1DKl1Np47jwAHBOP1TnTjxkopXaLP+C5RBEGdwJ/O9vtidv0NCLV+zrgmvjvuUR2+AuB24GfAUvmQFufCXw//n8/ogl2B/B1YGiW23YUcGXcj98B9phrfQi8D7gFuAH4EjA02/0I/B+Rz6JDtFi9oajfiOqPfzyeP9cTRUDNVhvvILKz6znzKeP4v43beCvwnNlqo/X9PcDS2ezHXn81xUSNGjVq7ObYXUxDNWrUqFGjALUgqFGjRo3dHLUgqFGjRo3dHLUgqFGjRo3dHLUgqFGjRo3dHLUgqFGjT4jIP4rIaTNwne0z0Z4aNaaLOny0Ro1ZgohsV0rNn+121KhRawQ1agAi8koR+a2IXCMin5aoBsN2EfnPuI7AhSKyV3zs/4jI2fH//yZRPYnrROTf48/WishF8WcXisia+PN9ReQyEbleRP7Zuv9fisgV8Tnv29nPX2P3Ri0Iauz2EJGDgZcAJyqljgIC4BVE5HBXKqUOBX4O/L113p7AHwCHqogbXy/u/wV8If7sK8BH488/QkSOdzhRJqq+zulEdAjHE2VJHysiT5/5J61Rw41aENSoEXH/HAtcISLXxO/3I6LePi8+5stElCAmtgATwGdF5A8BzXvzFOB/4/+/ZJx3IhEdgf5c4/T473fA1cCTiARDjRo7BY3eh9So8biHEO3g3535UOQ91nEZh5pSqisixxMJjrOBPyViaC2DyyknwL8qpT7dV6tr1Jgh1BpBjRoRydrZIrIMkrq9TyCaH5od9OXAL82T4joSi5RSPwT+nKhMJsCvidhaITIx/SL+/1fW5xo/Bl4fXw8RWaXbUqPGzkCtEdTY7aGUuklE/g74iYh4RCySbyEqcnN8/N2jRH4EEwuA80VkmGhX/4748z8jqpj2l0TV014Xf/424H9F5K8wKKeVUj+J/RSXRSzVbAdeyezWUKixG6EOH61RowB1eGeN3QW1aahGjRo1dnPUGkGNGjVq7OaoNYIaNWrU2M1RC4IaNWrU2M1RC4IaNWrU2M1RC4IaNWrU2M1RC4IaNWrU2M3x/wMm7I1qn7mtOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEWCAYAAABv+EDhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAACTsUlEQVR4nO19d5jkxJn+W5K6e9LmZQMsy+6SFlgwYYkmBxuwAWOwz/F8Tti+853vfg5nG+dw5/PhfD6nczY+4zPYBJMx2YBZMCzLkjewC2yOk7pbUv3+KFWpVKqS1D3T0z1Mvc8zz8x0q6WSWqqvvvd7v+8jlFJYWFhYWEw8OO0egIWFhYVFe2ANgIWFhcUEhTUAFhYWFhMU1gBYWFhYTFBYA2BhYWExQWENgIWFhcUEhTUAFhYZIITcQAh5x2hva2HRCSA2D8Di5QZCSL/0bw+AKoAg+v99lNLLx35UFhadB2sALF7WIISsAfAeSumtmvc8Sqk/9qOysOgMWArIYsKAEHIqIWQ9IeRfCSEbAPyUEDKNEHIdIWQzIWR79Pc86TN3EELeE/39d4SQewghl0XbriaEnNPktgsJIXcRQnYTQm4lhHyXEPKrMbwcFhbWAFhMOMwBMB3APgAuAXsGfhr9Px/AEID/yvj8sQCeAjATwFcB/JgQQprY9tcA/gJgBoDPAXh702dkYdEkrAGwmGgIAXyWUlqllA5RSrdSSq+klA5SSncD+DKAUzI+v5ZS+iNKaQDg5wDmApjdyLaEkPkAjgbwGUppjVJ6D4BrRusELSyKwhoAi4mGzZTSYf4PIaSHEPIDQshaQsguAHcBmEoIcQ2f38D/oJQORn/2NbjtngC2Sa8BwLoGz8PCYsSwBsBiokFVPXwYwIEAjqWUTgZwcvS6idYZDbwEYDohpEd6be8WHs/CQgtrACwmOiaB8f47CCHTAXy21QeklK4FsAzA5wghZULI8QDOa/VxLSxUWANgMdHxTQDdALYAuB/AjWN03LcCOB7AVgBfAnAFWL4CAJbLQAg5Kfr7JDm3gRDySULIDWM0TouXMWwegIVFB4AQcgWAJymlLfdALCw4rAdgYdEGEEKOJoTsSwhxCCFnA7gAwB/aPCyLCQav3QOwsJigmAPgKrA8gPUAPkAp/Wt7h2Qx0WApIAsLC4sJCksBWVhYWExQjCsKaObMmXTBggXtHoaFhYXFuMJDDz20hVK6h/r6uDIACxYswLJly9o9DAsLC4txBULIWt3rlgKysLCwmKCwBsDCwsJigsIaAAsLC4sJCmsALCwsLCYorAGwsLCwmKBoiwEghLyBEPI4ISQkhCxtxxgsLCwsJjra5QGsAPB6sOYbFhYWFhZtQFsMAKX0CUrpU+04toXFeMV9z23Fs5v68zecgOiv+vj9X9e3exjjDh0fAyCEXEIIWUYIWbZ58+Z2D8fCom34+FXL8d93PNvuYXQkblqxAf9yxaNYt20wf2MLgZZlAhNCbgWreKjiUkrp1UX3Qyn9IYAfAsDSpUtt5TqLCYu6H6JaD9s9jI7EUD0AAFT9oM0jGV9omQGglJ7Zqn1bWExEBJSi6lsDoEMtui72+jSGjqeALCwsGEIK1AM7wenAr0s9sCRBI2iXDPRCQsh6sJ6ofySE3NSOcVhYjCeEIRUrXYsk+HWx16cxtKUaKKX09wB+345jW1iMVwSUomY9AC34dbEGoDFYCsjCYpwgDKmlgAyoCQrIXp9GYA2AhcU4QUjtCtcEGwRuDtYAWFiMEwQ2BmCEiAFYD6AhWANgYTFOENoYgBFCBWQNZEOwBsDCYpwgpNYDMMF6AM3BGgALi3GCwAaBjeD6f3t9GoM1ABYW4wQ2CGxG1eYBNAVrACwsxgHCkK1wLcWhB78uVgXUGKwBsLAYBwgopzgoKLXlDlTw4K+lgBqDNQAWFuMAoTTpWy8gDZsJ3BysAbCwGAcIpXnNFjxLo24zgZuCNQAWFuMAgewB2FVuCrYYXHOwBsDCYhwgtAYgEzYPoDlYA2BhMQ7AVUCApTl0iGMAlh5rBNYAWFiMA0jzv5U6amA9gOZgDYCFxThAEFoKKAuxB2B7AjcCawAsLMYB5BiApYDSiPMALAXUCKwBsLAYB7B5ANmweQDNwRoAC4txAJkCsiWPk6CUipW/NY6NwRoAC4txADkRrGonuQTkSd96AI3BGgALi3EAmwdghnw97LVpDNYAWFiMAwQ2CGyEHPi116YxWANgYTEOEFoZqBEJD8AagIZgDYCFxTiAnAhmV7lJ8OvhEBsgbxTWAFhYjAPYRDAzeGZ0b8WzHkCDsAbAwmIcQA4C21IQSXCD2Ffx7LVpENYAWFiMAyQzgW22qwxOAfVWPEuPNQhrACwsxgEsBWQGp336Kp69Ng3CGgALi3EAOQhcC2zBMxkyBRRSwLdeQGFYA2BhMQ5gKSAzaoICcgHY69MIrAGwsBgHsBSQGbEHUEr8b5GPthgAQsh/EkKeJIQsJ4T8nhAytR3jsLAYL7DVQM2oixgA8wDs9SmOdnkAtwBYQik9DMDTAD7RpnFYWIwLyMXg7Ao3iZqUBwBYA9AI2mIAKKU3U0r96N/7AcxrxzhGiqFagLO/eRceWrvduM07f/oX/N+ydanXP/n7x/Bff3om9xi/vH8t/v7yhwqPaeWLu3DW1+/EruF64c+MFa5+5AW87X8eyN3u6Y27cfrX7sC2gRoAYMPOYZx+2R1Yt20wsR2//svWbBu1MX7z1qdxwKU34IBLb8D7f1n8upvw/NZBHPGFm3HApTfgsM/dhGc27tZu5wchXvfde3H7k5u07wcNFIP70V2r8P9++0jTYy6K4XqAc791t7j+lFKc/c27xPVTf/7n7lWpffz79U/gKzc8Kf7/7zuexcevXN7QOFIGwA+xessATr/sDmzaPdzs6eXi89c+jv+86cnU6/9z9yp8+LePNry/R9btwKGfvQkHXHoDln7pFmza1bqxc3RCDOBdAG4wvUkIuYQQsowQsmzz5s1jOKx8bOmv4skNu/HY+h3GbR5YvQ0PP59+f9mabXhknflzHA+t2Ya/rC4+wT3x0i48s6kfG3e2/uZpFA+v3Y4/P7cld7vHX9yJVZsHsGbrAABmEFZtGcCzm/sT2720cwhPbtiN5et3jtoYH39xFyZ3e1g4sxcrXhz5ftdtH8T2wTqOXjgNu4Z9rN06qN1u17CPR9btwOOGYzbSEeyRdTtw33Nbmx90QWzpr2LlS7vwxIbd0bgontywG4fPn4p3n7Qw8dNTcfGo5nt6aO12PPx8vIB65PkdDd3v7LixCoj//8RLu7Bqy4Dxeo8G7ntuK/6qebYfWbcDDzaxKHl2Uz92V328cr8Z2NJfw9ptrRs7h9eqHRNCbgUwR/PWpZTSq6NtLgXgA7jctB9K6Q8B/BAAli5d2lHhfR6YG6iZZXl+SDFQ9bWv+2H+6fRXg0LbcfCHoZHPjBX6qwFCyq6b65DM7QCI68Z/q3VeBpTtRgNBSDFnShcOmjMZ9zybb6zywL+Hsw+Zg3uf3Wr8Xvg51AwKlkaKwflhiP5RvCYmcLVNEN1z/Hk47cBZ+MCp+ya2vfuZzcbnwJX+D0LaMIVT9ZMGoObH59/K2kADNR+Tu0up14OQJoL2RcGf3Tcu3Ru3P7V5TL7DlhkASumZWe8TQv4OwGsBnEEp7bzZqgC4W571RYUmAxAUu0kGqn5DN1NNeRg7CWKS80N0l93c7fjvfjE5Jh9m/np/bXQNgOs48FwyKteQT9xljznboeFW75eujWlcAFB2ndwJMgjZtaOUghCzoR0p+Fi5zeLPg6cx7r1lT/uchJQC0ukElDYc4+CGSI4B8Hunlc1zBqqBNuegWQPAz3tabznaf+sNQLtUQGcD+BiA8ymlrfdzWgT+cPcPm7+ogFLs1nyRQUiNk4GM/qqfWP3lgd9ERfY91sib5MR20fXcPawYAN9gADKuf6MIKYVLAIeQUbmGgWIATBND3rXhH+sqObnXL6QUIQWG6q1NGBP3WjQ4fm6OxgD0VTzt96Q+B814AHEMwBX/82O1MmDeP6xfnIWUJmI2RSEMQE9Z7L/VaFcM4L8ATAJwCyHkEULI99s0jhGBf8kmSx2GFJTq368HYXEPoIGbqZM9ANNK3rRdigIKVAoo+f5owA8YPeU6ZFRoNP7dldxiHoCJ3+ef6yq5udePj7vVFIK416KxcUPgapyOvi4PAxpPTV0th5Q2TNvUggCuQ9BdkgxALft6jhQ1P0QtCLVJZ0FIG1q0iX0G3ANgtNK4poCyQCndrx3HHW34QfaDlmUgirqJ/Y1SQH7nGoCBggZATOxRbIXHBIweQHX0VroBjQ3AaFxDmboB4ntGxUBBCqir5OZOanzyGagGbJnVIqj3Gjc8rpteV/ZWPONzIMMPGvcA6gFFySXCyNYlCqhVHgDfv+4eKRrfU6F6AAOjeF+b0AkqoHELvirTrWyA+ObQTVB+QQPQaAyg3sEegCmYm9qulqR++qtM0qoGSFvhAYRRgNolpKlVnIoUBWTwAExejhiX8ADyKSAhTmjxClK91/gYXU3coa+ijwEEVOMBBBSNhAVrfoiy64hrXPNDMXm2ygPg5+KH6f2HtDkPoB6EwpB1lRzjvDKasAZgBBATvIGr4w8En8Bk+EGIvJIlYUgxUGPKmaIPRByY6zwDUJQC4tx/PMHneQCjGASmFA6JPIBRuIb8HuAegGli4OdsClomKKA8A1BAnDAaUD0A/lvjAKC37GG4HqaCpmGY5Mv5PhrxAqp+iLLnxgYgCAvHm5pFbAD0FFCzMQDuxfRVPHFPtBLWAIwA8Qpf/0Xxm0N34zMPoNhKWD5WHjqVAqKUFn4ohfqnYBB4tGWgrkPgjBIFxCmfUjQ5mWWgeiMXj4v97vLc3GJneQuT0YIabxJBYJ0H0MXYZpXWUD1hYQAamLjrQYiyS4SRlYPArWoQw+85HaUXNEsBBaEwYibKbLRhDcAIELvaeq5OXu2puQLsxs/ev7zfoisKTpN0mgEYrodCyZIfA+Dcf7Eg8Kh6ACGF5xB4oxUDUD0AEwWUE7Tkn6uUnNxJLc5PGSMKiCbvOU8TBeZ1elTJbqgagGhfjVT0rPls4pQ9gPh6tuY5yKKAmg0CM0MWewDWAHQ48lRA8o0tb0Mj3jPvJpEnthxnQaBTZaDyueTKQEUQODsPoFWJYA4hkQy0OPVmgpoH0LQMNPpcd5Eg8BhRQNwQCRkoNXsAXKOvfleBwpfzU2vUAyi5jpg8637rKSB+7+m+z4A2R8FWJQqo1xAzGW1YAzACCFe75msnCpMBiFUTxaiQIttyiEzgDquJLp9L3gQWT/xJT8BIAdWCUQnYAjEFxDOVR+oFcCqAP9im/eWpVuI8gPwYAP/uxyoIzM8xjgGYDYDKa6t0CadFGwnecg+gJHsAOUH1kUJQQNoYQAhKzfEeE+oBRcWLPQBrADoc/IanFBjUlIOQVwG7E5M5V01k738iegCU0pj7jwrameSj8j5Hi+6QZaD8/5FAUDd5HsBw9oQViCBwfiaw8ABaHQMwBIF1mcCTTB6AJhEMaIy759y5LgbQqsqg/HnWxwCi3w3eOzU/SHgAlgLqcMg3bp7GeUBjAPJWl/IEVzwGwB/KQpuPGYoagKofiusTUzz6AKl8TUdLMx0qHkBRw2tCURkovz6miY+vJrtKbm4OSZb8eDShLjaygsBGCiiVCJbcd9FxlFwHpSj2UPVDEXNrdR6AVgZa8PlWwT0ZgHsANg+goyFbf63G2WQACmr1R0QBjXTmGmXI55K1KuPblVyCgagMhilLtr/qi4d+tNxlP6RwCRFa9pFeR/4dCwrIlAhWMAjMs12zqI2xzgMoQgHxQm3q96QaAL8ZCigIUfEcEMKUQDuH6on3WoEsFRA/h0YNQD2gkgFwrQfQ6ZA9gDwDIFvzoh7AQBMUUHWcU0B8JT9rUhcGan6C2tF5ALMmdYm/RwPt8gCEl2OigEKuAsrveiXyAFqsAkrVAqJmA9BrMgBqIhgPAjcwccvqmbLniD4S8hhHG3IegBr/46fTOAUUigVNb8XDUF1fbG40YQ3ACCB/N8ZKh/x9qUFLoDwwJuxuhgISvGyhzccMMkWT9XDvjpLmZk+uIKTAln7zw9xf9TF7ckX8PRoY7RiAWiEzLxHMHASOYwBZ2wFj5wFUFU82zPAAeKE2dUxhCH0iWBMUEMA8x+2DY2cAgPRCTr0eRVENWEIbEHtMWaXmRwPWAIwAQSIGoAkCS/ee/EVy9zbvBkl6AMVupqL7HmvI2dBZpSD4dZw9ma3sN0iNbWTDUfUD1AMqths1AxBSOFEiGDByCkieFLOyi2PViv59/nXKBc9MGKtEsLqfXMgICkgTA6h4Lsquk+K1/TBMeFl8X414ADJ3zjwA6V5rMQUEpJVAalC8KOo+S2gDzDGT0YY1ACOAnMmrb3YRv69bMeRlCw5oaKM88Imh0xrC9Bf0APh15BO73NJPnvRUQzFaD4qcCAaMnALypUnRVGE0CKko3VykGBxQLAbQ+mqgSS18VgwAYF6Amg8T0uRz0lwmMJU8AAfbx5ACAsweQMNB4CAZBAasAehoyM+grua/PHkkdfDFXMSsm8wENTuzUzBQ9eNEnYwchX7FAGyM+qKWXScx6amGYjQNgCMFgUcsAw0pCGE18k0F5nicI6vZS6wCyqeA8ooUjhaEB1AgBgCkk5v4pZAT7vi+Glm5V1UPIKKAijTPaRaJxZlyPwuPqMF7R80EBvTzymjCGoARIFHqwVDpkEM3mefdIAkKqMEYQKdRQANVH1N6WJ3zLI03P+c5Uxi3v2FnFQCrkS4/zP3KdqMlmQspRC0gYOTXMaBUGBNWYjq9DT/nab0l1PxQm1SoUkBZ1zCvRMlogX8fKRmowQCoyU3yyl8Yg6ZiAIHIsyi7cbVUfj1bgSyF3khkoHIegHqcVsAagBHAzzMAMgU0nL5h8miaxMNSMLOXP5SdRwH5mFTxEg+oaTsAmD0p6QFM6yknPse3m9FbgUP0FVebgR+GEV/P/x/ZdfSjmALADUD63Pm9wevAa5uMiISyfApozBrCcLpRqT+liwEA6fo28qVQn4nGKSB2TO4JANE90+JEMCB9jxRV+amQYxmmoPlowxqAEcC0whfvJ4LA6cm8oVpA49wD6K/66K14KLkkc/Li5zwrUvfIBqCuybvorXhR1uRoJYLxgG125m7x/VERTzAFgfm5xAZAn1xECBI177OOybdpZUtEkweQRQElSqJI14Ibg7gYXOOZwEBcdA/g90zrPIBJUYVT1QA07QEEyXLQQOuT+awBGAHkQl9ZmcCq+kGsEApQQOWcGjIq1DZ9nYKBqo++ioeyl+0BDFR9dJdcTO5mdNHGKAg8vbesBIHZ9Z7U5WHSKNZN4ZQNX8WONJ8iCOMVsUNMFBC7N6b3MQOguz5hNC4+0WXFUQJKxX3TyhWkWgoizIkB9FW8pLRZuqfVtpJFS0HwRDI5CAwADgEmd3stMYBhSDFYCzA1ojTV5D5xLk3kAVRsEHj8gE/kU7pLmYlgk7tL2kzgvIJRA9VATIRFqYh6h5aD7q8G6I0MQLYHwLbjD8DGXdX4YdYEgWMPYOQPCq/S6sgU0AiL6gVhKCggz0QBCQ+Afdc62iKgbFx8guMKHP0xqbhvWkkDqZnAfo4HoFJAuj4AfB9FyzjzMchBYIDdF5UCvROaAffmp3ZHHpvynarXoyjqSj8AoPU0njUAIwCfvCd36et28JXAlG4vEQPQrXx02D1cx5RudiMUWU3IafWdZgCYB+CiVCAG0Fdx0V1y4RC2KurVxA544lRf2Ru10rn8knkSBTRiD4AqFJDm1PnYp/eYPQBK2apWLnhmPGZIxX3TSiWQqRZQNgUk9bhQDIC8GCq6cueegpwJDDBjk3evNQv+fU2JjKz6rDVDAfkB65fBDXzFc+A5xBqATgafvNUVPkdo8gA0Kx8VlLJ2kJMNN5kO8s3eaQaAxwDKnmNsewgwQ9Fb8UAIQW+ZTWI66ohPJL0Vd9RK58oTGPcARnodgzBWxTiO3qDEKqDIAOg8gDBJAan9kTm4tl54AC1MBlM7gmX1BAai+jY1XzwXahVQeTGU5eHISHkAkoqm7OU3z2kGA4oBUD3amM4qvs+ach6EkDGpCGoNwAjAb/wpBgOQeF/qGZCUv+kf5KofRis5dpMVCerKE0cn1gLqi1byWZnAfDsgdoN7o9VcIg+g5qOr5MBznVHrniRXs3REMbiRU0BCBkr0iWDCA+g1B4F5fkKeByDfc/K+WwE1BsDpsiwPgFJgMEp6k69FqNQEKkrd1AweAPMaswUHzYJ7+1zWnKxlRMEfvUbicDynQg5ij0VPAGsARgD5YdM1cOY3+OSuEkIKke0p88qmCYZ/8ZO7iscA5Emhk2Sg9YCpUcRKPscD4AaA95Hln/MlmkA1FKOhApLr9nijRQGF8YToOoZEsKoPzyHifPQUEIsBxEFggwGg8T3H9t06FYnRAzDFALqSgU35Wqi9gYtSNyYPYFIBwUGz4OOfqonPJesaNZDMFnk8JU8xAC0u52ENwAgQSBO8jmsNqX415isrBh34TTY54nKLrCYSHkAHGQA5YJuXB8ApIL49EBsAID5Hebu+ijuqFBCrBZR8rVmEUXE5gMcA9Aagr8vLlHjyInVc725uHcl+83tuTFRAfMUbHTsrCAzEz4G6ck5SQMUmTz4GoQLyeC0dN3ex0Sz4+LkKSF7QJeMaxffJPZ6K5AH0RpRZK2ENwAgQUgqHsJVNHgUExHxskRgA9ygaoYDqHRoD4A9Mn4bK0W0rT+xA9DC7SQPQP+yLGAEPAo+0f2+cyBTz2COPAcQGwCH6PIDdVXYuJeUck/uJgsA5eQCcXhwLCkgtPJjVExiA+L507RRHHAQWHgC/Z9j1zGue0wz6lWfTROk2clxhyLz42vWOQVMYawBGAD96uPsqHuoBRdVPflmxDJTf+Lx4Vv5ErQaaClFA0sTRSRSQnLSV55ZzFRCAxASvTnwqBRSEdMQBv2QQePQMAF8Qe26GB6A5RxmURjEAz2wkgNgD4ElKYxEDEHkt0ZiyYgBAPIEmJkua7A3cMAWkeADy9RztOABflU+JZKAmSrcZA8ANGJCWzbYC1gCMAGEUmOstsy9N5etkigiIH0Y5wGUsD1xLxgAKBYF9/Uqk3eA3Mac5TAoWPwgxXA/RVymJ7QGIEhJA/DAP1Pz4/VGa7GIO2xm9fgAhFfEEl5gMQJD0cnQUULTYKDk5QWCpB7EpQXG0oBY15F+ryQCo31OWDLTopF1TPABOofRJ98xo00AqBaRSWRwNBYGVWAZgYwAdD146OC7cpHgASgxgwHDj68BdPyEDbTAG0FkUEDuXvmiSq/l6t5b3TOB1UOQVfkmZHAeihDEgTS00i9gDiCex0SgGF8tAidYw91d99HWVMrN8g8gDcKI4QF7nMNd1RjVDWoc4BpA0BHkeAF/cqM9BIgZQ0ANQ5ZMJFVCBshnNYKDqw3VimbJp1d/IvVMVsYwkBWQ9gA4GL/RlWoGaJHl+gYla5RnHcx7AgEoBGSYvOVbAt5c/B8TnuHtYoop46dwRrpZaIwOlIqfAc4g2s5jTXvGKNW0gKYUITJcypLRyQbZWTiCU0pQKSO59oAM37P3VZB8B/rd8bYqu2vnKWS0FkfAARtkAsPiTCy+arE3PcyP3jurJABEFVBt5bCsL1gCMAFzhoa5sOORSEIBeBZQXA+AUUJEJvd6xHkBkAMpRMTg/+5xl9Q//rQZIB6p+IlFM/nyz4NfMc4l4uEfsAYRUZBWbgsD8XLgEUHd9eCIYgEwjGtfkb20Qsa5RvhSpBQTEixu1FWTYjAeQkQdQUmjD0UJ/NYjuyfQiQdfesgjUWAbAzkGWj7cCbTEAhJAvEkKWE0IeIYTcTAjZsx3jGClUCkjl61QZqFA/SA+PiasXeQBcBtqoB9BBMQB+XfLyAPqlWAEAEVthdV3i1RzvoCXyBLr0BrhRyCqWUWsIQym4V2/KAxBZ0tHDr8uU5hQQgEwlVUzDOJE8dnTKZKvQ0Y15pSB4eQ8tFaokghWWgUbPUtmLrw0Q0Y0tpID6ujxh2HUdzYDG4nB6D0AfWxxNtMsD+E9K6WGU0sMBXAfgM20ax4gQRg/lJEPhJn4z9FU8EGKSv+n3PVD10VN24bnFE5LkSaFz8wBcI30xoFBAfZH3k1R0UDHRxx5CklpoFvIE5oySCsgPknkAKi1AKRWlhbMoCyrFEsquucRBXJCNq0ha5AFo6EZ+bMP8L8obGPMARhIEjtQzcS2gUq5iqlkM1JjB5jWezHkAIwwCj4GSy2vZnjNAKd0l/dsLoHNmqwbAH27uAdy8ciO29ldx3iv2xIy+ihSQYwGj3eLGl+Wa5tVwb8UTK9EifKI8KfDtw5Dilic24lUHzwYxcLMqbntiI9ZsHYRDgHOWzMWcKV2FPqfi+a2DuOWJjbh/9VaUI1VKySPGWkB8pRNTO3EwWA4Cq1SRzgO7/alNWLV5AATA2UvmYM+p3bnjFRSQ1BPY9BDvHKzj8Rd34oT9ZgIAhmoB7l+1FactnpXcp5IIphryoXqAkCbjHKZSEPxeqGRIaeU4Rm/Fw2Mv7MSP71kt3l+0Ry9OOzA5xl3DdVz91xdQCyim95bwusP30t4rlFLcsnIjTls8K+kBSEFg1yGZ95ksbUxlAo+EAuIqIKmhCr+Opn3d/tQmHLdwBrrLrvZ9E3YPM4Pt6SigAgZgx2ANK1/cJe4dIDZSJZkCip6D3zy4DrMnd+FVB8/G3tN7GhprHtpiAACAEPJlAH8LYCeA0zK2uwTAJQAwf/78sRlcQfCHe3pvGdN6Srj20Rdx7aMvYtgP8f5T9k1MKD1lF0ORykXmT03Z4oO1AD1ltyE1Cr/RK54jJppla7fjfb98CFd+4AQctc+03H2EIcUlv3xIjH3T7ir+9ezFuZ/T4b/veBa/eXAdAOCguZPZ2KJMYEppaqIYjK5PT/RA7jerD5MqHhbM7MGWftbntRYEsaGIJv6ekhd9PjYA7//lQ8IgvrBjCJ9+7cG549UFgU0P8f89tA7/fsOTePzzr0ZXycWNj7+Ef7niUfz546cnjE0YUpRKZhmofM6ZmcAhwC9XVpEz/r17joP9ZvXhuuUv4YvXrRTvlz0HT33x7MS1v/GxDfj01Y+L/4+aPx3zZ6Qnmmc29eOSXz6EH779qPj79JxEIpgpAMzRXXbFOScbwsQeQJaBU8Fzb/i1WzizF1O6S5g3rQeDtd0A9Ndz065hvPOnD+Lrb3wFXn/kvELH4hiqBZg1qSKeTbWmEYfp3rniwXX46k1PiXuHnUc6BrDPjF54DsEP71oFANh3j97xYwAIIbcCmKN561JK6dWU0ksBXEoI+QSADwL4rG4/lNIfAvghACxdurSjPAW+4ukqubj/k2dgqBbg8C/cgmo9KY/jCTxq8Sx5GxU8vtBIQhI3LN1lV2zPJ8XhgoEkXpPln07fDz+9d404l2YwXA8wb1o3/vhPJ4lJna9w/JAmJG9AMggLAPvNmoTHPv9qAMDOIcZl13wqqYXcxPb885SypLD3nbIIv31wXSpBz4RGEsEGawGCkKIehOgqxZPajsF6wgD4IUU3bwijKQUhG23XIaIEtgoqeRJZ6p64IBvwoTP2x7tOXCiKk/3kntX41m3PoOqHYuIBgOHo+nzqNQfhS398AoN1/b75dd8xVBcr1u6ym2iB6OSQyiXH0bZElWMA3eXidfxjb5Cdz2HzpuLRz74KALB6ywAAvayWB1abEQ7UghCVkityMoIg7XkDGTk+VR9ByO5j/j1wb6UiUUAHzpmExz73anGtexr0VIqgZQaAUnpmwU0vB3A9DAagk+En3HIXFc8FITHFE0jVEctuHPysJ4JG5pT+kus0RAFxfX1PKTYAKj+bB759b8WLMlebNwB+SFH2HBEEB5KlDGR3Vx6j+joQPxi1IBS8Nk8YU11xEXspx+UAiiBW0EgUkOEhVo/Ff6uB6FDqB+BpDIAqYzQ1zJGppL6Khx2DNe24QmnRQQgRKjIAmBF1HJMnHiA2GqIaqUGlxXn/gaovjFRPyRXyWznpzQQ5GzqRNCV5AD0lt3BWd381QNl1RK9kGXEMIL0AEL2Hm2gYw+5dArdJCogfc6DqY2ZfRewTSN/73WUX3Rj9iZ+jXSqg/aV/LwDwZDvGMVLIhb44PIegLrnEAEQdd+EBJIJG+n3z+AK/yYoFgdk2XZIB4K/5BQNh3Djxvrj1gpOnDn4QT34cWTy3Lx1bBQ/y1fxQKi0ReQBcjcHPVYq9eA4pvJqUE5mcHOqNX0++b/5blw0uagFpegKrHHbJEOANKQRtk1UmWPWiZHBOWR0jv+7dkVEw1eKX6zDxcXeVXHFOctkLE+TvI5UJTOP7t2gQmBUF1E+QWUF1fq80oxCqBax1Y8mJvVkOeb1kNABSLguHLgg8FmhXDOArhJADAYQA1gJ4f5vGMSLIDzeHXPGRN/LmZXz5A1QkD8APKTzJAyjyPPD9s4cyuf/CHkCQDISq/U4bgS9p4DnUjN7E9tGxSppVJK/xUg/CVMIYCzzG3hQ/Vy8yoEU9ADmRKc/zUlf+/Ng6JRiPJ7gkLQNVud+KwQMIw1hO2ptR/TRW4qRnYpOqhH+mJ7qeptW3qMNU88UY5cWGbkGkwpM8slQmcHTYrpJbeGKWiweq4NJQ3SqfG72mDIAfouzG5UJ8TUAcMC/auIGV6SeTB9BqtEsFdFE7jjvakB9ujpITP8AyRSRrt026YRl+GMJLlCXOv1GrYlXmSJNh9Ltoj9Voe8914Lkk1e+0ETAaS+8B6CYZ4QFoVq/yao4/LPKDL3te/IH0HCfxfeSBT85OARlovPJPegIqpywvEjyNDFRQQFI9+6xaQEB2/4OsZCxTwhy/NzjHbPKYRB0mmQKS4k1+mG8AXCdu0qJOlvz77ym7haWbclFAFbLXqMJXvr9GUA8YfSlkoAlDJsUDTNfRT9OFsQEoptQbLWQaAELItciQaFJKzx/1EY0jaD0AacUp14GRH+wiQWBBATXgAdQDtjLxnHiVFdMixW50VQo5Eh287vqoRd1kyCt3FSWJOuLGQ37wZc9L7Mclxhr82vHS5LkD5lWciPMoq9mUB0CTFJDqAYggsKhmqU+UCyXV1CSpRICqpJJLQagwZazz69XlmSdMIDbaA9VA8TZjjzfXA3CI9jlgzX4Q7zOKCeTtbyDDAMheo4o4BtCkB+A5bKFAVE8m3s7sAXBvMZBeY/GyolLt0UKev3EZgK8BWA1gCMCPop9+AM+1dmidj4CmV1qe4yQ0+HwikWMASRmomQIquZIapUgxOB6ccoh4mHTudha4wWAegFOYOjLtS6VzspJz/MBsAESWbJQH4DkkoZiQV/qxEWvsHAR9IqmATJ/1FWPDf6src3lSdDWlIGoaD0BLAUkSS9FasZb2ArKycblqSq2Z5AfsvskrnyziHNVkDIDSWMaZJwOVvw9dMbgjyDM4uv5g5jhkDGRRQDnVVU3vZSEMqRA3AOwe05XFUP+WIcdSxGsRrTTWyPQAKKV3AgAh5GuU0qXSW9cSQpa1dGTjAEEYaoPAvoECqmmCX1kTjOuwFYFDkq6lCXxl4jpESB/rDVJA8ipcPpdmwGgsxQBkxQAyJi/5c5z3lVdLsudVFxRQY+cggsBSHoA5CJz0rHyxqkuWXpDvAV08Qq0BY+qXEIQUFS82AOxY6ckv2wDo20TylXZetzERAxj2EzJQIJZxOgU8AD9MewAhpaD1IXy3/C3M3NSPX+PrqAVJuaoO/VUf86bptfFZeRX8+2rUA1ATtlSlXJFnO65omwwCj3UAGCiuAuolhCzi/xBCFoJl8E5o6FY8nksSHgB/IFhyS7oZtmmVEIQhSlIGaVEKqOQ6kdokuf/iMlBZBTQyCogFspUYSWa2K4t76Nxgx+GKnlDL+8qel1rUrVEJbEIGalJpKRRbTAHleAAGCkhWAemClkwFxP5WWysmzoHLQDUTMVfLpGIAIZNv5tXO4ffvgBQE7o6S3PgKXue9yZArosoUiR9QzHn2CuxJtsGjdfyDdzUbxwsPA09ca9xff4YKKKvDmqCAGvQA+L649+kqKjM1uU27D6mpkfzaWPP/QPEg8D8DuIMQsgoAAbAPouzciYww1FFA8Q0uPxAlN75R5BWpiSdUa8gUkYFyD8CTuOZ6gzEAvn3JJfBcxxgQLAKtDNTNCAIH2ZwvXx3rpH/ySp+P2RUeQLFzkAOoIghszANIKo6MQeCcnsA1cb1lDyBN7cgKm6zqp/x7103EQgaaCgKH8Nz8bmM6CohLR8OiHoBkkGXDTOoDWLjy+/hzcDBKsw/AmzZfi8FHfgnc8Skg9IGPrwXK6TWn3BdCRba3ye+VxgwAz4UQHoDynRZpCCMH0zlqbfIAcg0AIcQBMAXA/gB4TYAnKaXVVg5sPCCgFGWF4pAf8iCMV2Kya++HVCSGZclA+U1m6iSlgt9EDpHH0BgFFK+CnREHgXUy0KymJ/I568CTpAaicrwy5IlFjgE04sWoFBT7rH6C8JXry3/rVEBOlgHwkyvKsuskSlok9kPSFJBpXDoZqOOwkiQ6GagXJSvKY1Ihl+LmhqsrooB4BnluDEASKIQhxWnOX3Gq8whOeHgIleoWfM3/B5y691E4bPMfMfXWDwM9M4HBLcDz9wP7nZHYF6WsMOAkgwHgzXO0QeAm8wDUBjRqjMk3GIPEPnQeQNCeGEDuESmlIYCPUUqrlNJHo58JP/kDEA1hZMhyzyAMtTXc/SiRhG1j8gDi+IKuhIAOsT453m/jHgCXgcaUS7PgwUUZ2ck56ZiKjFJkNHXct7zS98P4HEquU1jKqvLnWdRbILy55Gp2t8YAePL+DIlgyUxgPQXEJ/XYA9B4ChkxAP5ZnQw0QQEZTjqhAlI9gIKqHTUG8HnvZ3iTewem71iB5+e/Dg/RAxH0zsXX/YsxsPepwPvuApwSsPrO1L4GawEohdEDAKJ7JiPe1LABUPI21BhToRhAoDEAmsz4sUDRI95KCPkIIWRvQsh0/tPSkY0DyCofDtUD4A+E3MXJDykqpRwDEGaXENCBewDyRNNsKQjPIcYm5kWhlYFmBeY01zPx2ShLVhcDSMhAJTVRIx6AoIDkxK2CFJBvooCklbtDCFRbpGaAmvIAWCyB/R131krX+pelrDrosoi5fl9IdA2TYl2auLjIgAdpeSZvkTwAfq26BtZjvrMZX/bfgt+cegcePuLfxD5/EJyH1Wf/ApiyFzDvaGD1Xal9xRnhZgNg6j/RrAxUzdtQnxG10b0OuiBwzQ8TqraxQtEYwN9Ev/9Beo0CWKTZdsJAlwgmu4TyA1H2HFEGOYgoIMB8kwRSAFW3ctSBB4FdJ67QKKiKBlVAvBSEHzZfT15H6XCPwFTyWFfCgIOvjnXSv5KbLjLmRTkRhRVQUuyA/zZ91iwDNSeCuU76+04FgQ0TltwQJg4Cm2WgJi5eV0guCEORM0GIeVKUDdPOQWZ8uiUDUCQRTH4+5m77CwDgz+Eh2IfG17BbKZCGhScDd30VGNoOdE8T+1IzwnUwNc/hlF2jHoCaue0p5VJM8QAZMZUWf3/82R1rFDoipXSh5mdCT/4Af7iTr8kurvxA8JUdpaz3aUV6cHSoB0orwQKTmKCAiLwyjYJdRXlwKShZks6lGegonSwPoB5kFxPjDeVNHoCgY1QZaMFzCBUFjUOyg/Tysfgx1Ek5GQRm/Lfc4zWWFaYTBtWx8XGJDmg6FRA34Bl9eVUPoB55XoQkixaqkCfS7YM1OCT+PoUMNDcGEFMmc7c9iM10Cp6leyEMqZgwubRUXIeFJwM0BNb+ObEvtYGQDqbmOWomd1Hwz/EyE57TuAy0bqCAOjIIzEEIWQLgYACiOwil9BetGNR4AVP5pIPAQuamGACA3RR+mB8DCKQyCl5BD6AWUPSUnUTMQA0G58FXZKBFV8/6fZmLwWlXudFK1AReB1+X/alLMOLF9IrTX9G+OPWWUUk0RQEJGWiSlpGVYnxSDilEXZ90T1uizwSWAqxqa8XkOeTFAEp4YcdQ8jOS4TUZIHmsALBtoMboRqlvglz51AQRrKcUe+14ELeGhwBgr/F7PC6RHF37eUsBr5vRQItfI/ZVhAIy9RYQiWCN5gEoHchSMtAmg8D1IBSGfSxRyOQQQj4L4DvRz2kAvgrg/BaOa1xA1vlzlBQ1ihwEBtiXL2cSFpGB6koI6MADSZ4kG60rwco8yAXZSiPNBNZQOllB4HoOhVByCXYN1UUHLRnySp97OyWXMC+msAKKfV7m7POKwamewHA9TBUHEzEFJ/lZgE1AJTfOfTBnAsetFgmJOsxpesXmGwBXkwcQG15tIlp1N3Dzp+FUd4qXtg3UIrqRJ8wlFU8miHjWlmfQW9uCP4eHROcn9QNQq5J6FWD+ccCztwFBbGDjsuCNU0AiEazZILAhBhA0GQOodngQ+GIAZwDYQCl9J4BXgElDJzRYlmfyNVdKSJJVQvzLrQcho4C8ZAlj3b5l9UjRfgC8sYgqU2y0HMKoJIIFmkzgLA9AkzegfnZHxD33KXkAsrcSJ7M5gnYpgrQKyLyKU9VV8jEGohINVNHGc0pP3raulADIygSWJ1dTUxi5p4EOus/J95q2H8Hy3wJ//jYO3fEn8dKOwbq41/h1KCIDdXlMJlL1/Dk8WJxfygDI1+HwtwBbnwF+907AZ70QuLdlSgTj55OlAmo0z6WuUHZyAiI/D93fyX1wb7H9eQBFjzgUyUF9QshkAJsA7N26YY0P6FY8JYkTZEFg9rrsAbC0/jiBxrRv3hBeV0NGh3pUUMqRyg7r6q7knRMQy0BHEgOQJZAcwhAaVUDmW7LkOtgWNUJJB4H1KiDmkRWUgUaXKK7e6WQG6eXf8iQget5GL3mO4gEoMQD5wTfJFuVaQACLA6hF3QCpoqlhIu6reCmpquxtao+/4koAwH4DD4uXtg3WRNY5H19eEJ/tP/o+Vt+JnZW5eAGsP7EvG4AyXyRI1/6wNwJn/wfLCv7dOwFKRbwlizqREzBlNFsLqKp6AAYZaNbiiR+z6odSNdlQFAQcSxQ94jJCyFSwQnAPAXgYwH2tGtR4gY7zTK5E40CuXAa5HsYPvXGVEJVF4PssTgGRRMyg0bK3QkMfyUBHEgOohzRV2tnLUJr4OTGAiueI1pDpIHCsxlCrgTZKAcXUW9Yqjud0pCk2bgBUj0LXZ1jVf5c9J6qMmTxuSJMB1t6Kp1UBZVVUBdh1q0kTD/tMKBYbqTyEnS+w4KtTwoFDj2ByF9tu51BdZJ2zc2IGNC8I7DoEZVoFffZPWDXlWHiOK+7vUIkBpCbn494PnPYp4MnrgA2PFQsCGzwAfo7NykArEgWUSP6KzqHsOtocEkopakGISUogv6PzACilf08p3UEp/T6AswC8I6KCJjR0OvdELSAaU0RyGWTmAZhloGFIQWnc6aooFSMygWVNfIMeQLx6dhJ0VjPQeQBCaWKgOfIoIH651Ide9rxSBe0aDALLeQDmIH3y+spexm7FAPBJMZ4ssz0A/ro6Ntnb7Ku46B/W5AHwY2ZQQECSf5ave0o1s/IPAChwwj9icrgDR3VvAABQyrbl58YooOxEPn5+pzt/BakPYOX0s+A4sYdrlIHKWPouwPGAFVdioOrDIfH2OpQ9V8ivZTQrA1UT95jMWDKmQiXkaL17bnh4+01OA3HvfaxRNAj8S0LIewkhiymlayily1s9sPEAbR6AdEPIrrXMfcsxAJ28M27KEq8ci0zgdT/uIxwoE1NRrjOZRdt8NVDOf+soHZPUsK6JGciQV0gqBaSXgUbloItWA1X486z8C/X6+kHc5F54AEpSlq7RvFoGuGKIkch0IsDq+mgzgXNiALpCcvUgphtTeQgrrgTmvgJYytZ7JzgrxVvpILD5uByuQ3Ceex9o72ys7n0Fq7zqxJnEgEYGKqN3BrDoNGDFVdg9VEdv2cusoV92iZZuFB7ACEtBqIszfv1NAgr++ak9zADw77CjPQAAPwEwF8B3CCGrCCFXEkI+1MJxjQvoqh/KK05ZAy63QmQy0LiMbmq/CnXgucViAFWeCezqPICiFFA8aRUNPuftR0VWoDOzGFyGAdAVGXMb9gDSBsAYBFZqLPkhxZRu/lArHoCk5gKScR+1DLColeSnDYC82DD1BValrCp0dYRkD6AiZaxj22rghYeAJRcBU+fjJWcujgwewyyyA1/yfox5ZHPs1VAaS1UpBW79HPDUDanjd4f9ON15BLXFF8CnTvQdJWkvbRBYxpKLgJ3PY8aO5ZkSUMCcCRyXSmmOAuLPc0mhgPh+K56jvXf4tZ3ew0pz90sUUMd6AJTS2wF8GcCnweIASwF8oIXjGhfQBYFl3jyRB+AlKSDerUh7kyiNUYp4AJRSEUiSSxjIvQmKnhMQT57NqoDiYLLGAzD0vWUr0WwKiGNSlyoDTfeaLUVtLRstBse/0kwZqFIGOggppoqHOki8x09J10JQffDNFJBiAAxBYFXKqkKXRFaXEvZKch7Cs7ey3wedBwB4xDsMB1WX44rKF/E27zZcMHy11DqTLWxchwBPXQ/c8w3gN29hCiIJi7bciQqpo3rg64TBd0icSQxIMQDT5Lz4XMCtYMn2W3K18yZZrbxYKBJf41BloGqMie+37OnVZ/ycpvdWADADwOMCHWsACCG3AbgXrCTEUwCOppQuzv7Uyx862VtKBirpuwEe+WfUiGl1KtfjYfvMn8T8KG7A3XKV+y/cE1jtCNZkEFhuyqLCpHTJiwFkUUBy4Tpu9OJyFsnsWxPCkMIhEJRCtgcQrSClssJTuyMDEHHzpiCwvM+aUgIgrsejBIEV74jLOdXzEnGMjDwAIJmxHIQxfZWIz6y+E5gyH5i2EADwkLMEPXQAs7ADK8IFOGH4LriUy2B5ghsF/vRlYPoiYMGJwFWXAA9H+aKBjwNe/APW05kYnnOk8JB5uXPW9jI7VwQA0DUF2P8sHLHrDkwq58ccshrCAI0FglOlIKQSJED83aqegThW9PlpPbw5jx9nF7ehH0BRk7McQA3AEgCHAVhCCOlu2ajGCQKNyqXkJmWgsb6a/a4HcdVEx8Axxzx88SCwvDJxCAGlzCvQ1V7PPidJBTQCGagsJ1WRVaBL5zFwyMWyepTAn6ehvXgimDyezDErmd1ZGdhi5S95AlMiA8DzAGI+Pv4e1bHUfZqgtkoiBqA0lqGxZwIwCqge0FSZA9EQxjCXmILAslqtHoSM1F99NyvDEBmuu8lS3D/lXHys90v4nn8+poXbMHXLg2IfQUhx1MCdwKbHgVM/Cbzlt6yE8zX/CNz/PeCq92D29ofwff88BJRdO4fEVCNfUPEyzpkT80HnY2q4DQc5z5u3QX4eANCYAVA7uKmLuECKAeiCwPxY06QgsBpXGEsUyj2mlP4LABBCJgH4OwA/BTAHQKVlIxsHULXZgE4GyldWMa9ZD6LiW0S/wlR747okfyKWuUnPiZOTGm0KH3sAjJsNqT7jufB+jB6A7rzDQh5Ab9lNjceVerPKRd24gWbGJXvMjNKL/88qw63WWPJDip6KB88hgteNYxF8jDFfzlENQkwtl8T/poY5AVUSwcpxdy+5bSJX4pgCo6IpjJRFXJe6z4kV88bHgOEdzABE2BlUcNXeH8f6jf14aut0DJMuzFr7R0zDydjvrn/Ed4ZWYb/qi8CsgxlP7zjAm34N/PYdwI0fBwA8etBH8Ku/Hon3BXEHsYCmy0nL1XO1iMZ1hJ+tR+ElxFXIz0MjgeCaz+5RuceD7CWHIfNiTGVE+LG4Cmig6qeazIwlChkAQsgHAZwE4CgAa8CCwne3bljjA7rqh4kgsEQBcc6fJ4JlSRR1wchhzYQpQ/YAhurxpKfLVM1CTD85YvXuhxTlBg1AfA76GIApMJfXEQzQJ/7IRbl8+Rw0vHvWmGWDniUDTWdas0m0ryvOtFWTsvQeQJICqohYkYYCSsQA4v6+M/rkczAXggP0KqBAUavVgjAuvywZAB6wnlTxMIwKHus7EUesvR6/Kd+F6es3Yw0OwAtd++OAcz8PYUm9CvDGXwC3fR6YdRBW4VTgr48K7t1xCBDGHkRqHCZMnos1ZC8cUnvUvA3yawHx8yoKtWpnSck096PvySX6Z44fi1NAcn/ljvUAwArAfR3AQ5TSdORpAoJSxrmn8wCcxKTrSdwqwFx7nvFqqvGjKg2KJILJN5GQ5lHaeCJYEIIQtS9u43EAubGMiophdVcPs6Vw/AHRKT/k4HsgSVk5pVNECqoaoCzqTaXW+CTaW47VOSoNJhdO46gFyTrwJQP/nVYBcS7fT22XZUR1FFBdot7EhLn6LmDmAcDkufFYI2PFSy8sn3oGjl53K/YmQ1h+8o/w9/f04sx9Z+PfFxyaPKhXBl79Zfbnoy9G1yBMLKACShN1k0zBWxkP0CV43eBdQFAH3JJ2G25IKKUJr0hetTfqAcgTtatkmnNPzXTv8GP1lD2UPQf9tbi9Zkd2BAMASullAEoA3g4AhJA9osbwExaxwiNbBiqCwNFNM1yPOXaTzlznAeTJQOWbSJ64G04EC5M1iAAU7qglQw1kyygZKl7KK1Ed+OSoy/yUr7tMP8leTJExFzYASiZwPTL2fRVP0CsxH5+UgaYzgeNjymoxDkopiwEoQWBA198334viE4983nHvagehX2PZv9LqH4hlxvzYq6cci81L3ou31T6BrXscl2haYwI/Tj2igGS1WSjF1EqGMs4y7vYPQiUcYo3jDSi5LHlQ/R5VJVZRpBL3FC+eN4kyPbOyp867s3W8BxBVA10K4EAw/r8E4FcAXtm6oXU2hGQwRQGxG47XN1fLQQ9GAULPNferlYOYQCRHzFHjyDdRrDbR16rJgjwJCkPShBJIbsqiouw62DWk72dbcgmw5Rng9+8HgmTn0QsH6jiy7OMXzidSn5U5V34OhMQeQNEgcMoAGDK1+e7kY3oOWx1zeWYqn0NHAaUygWOqUBwv2ly+1XQrebYtNQaAOWQjxccg36cHBU8BtD9hALjMuOw6wgC7pQo2Hf1pPLzsnohuLNAT2I2/D0FrOfFihX/eRN1wVP0A9/gHsRls9V3A/GO128kJmPK92GwQuKYE7UVxO2m/bhTYrtfT+5Wf096Km2iv2bEeAIALwco/DwAApfRFAJNaNajxAFPGJV9x1rmLq3gAQ9Hk4DnEyDHHQUxOAZmLxnFw2aCcnemHoSSNLDaJ1wOKkhNL3Pi5NAq5ppAKY4lebnyW/QTYsByYsnfiZ6hnDg4hq3H28I2pz3oOiSWZUkmCeMWZfw6q1NJEvclGQS7m5ToEfV2lVB6AyOfQBIFVSkGuGSXGpbSqBCAaoaseQF4cBUA08SQ9AG54Sp6Dv8M1TGq56FSxDZcZl93YA0hkAvNEsIxMbiCZC8HHyvNW5KY3pnuEo3/Yxw5MwtZJB2r7BXPExQcVD0CWgY7AA/AUCojHNUy5O/Jkz0t6q5TvWKJoDKBGKaWEEAoAhJDeFo5pXMBEcciBPl0iGJcIxuWW0/uWyzGwY+SXNOayQTkGwLs0sX0Wl4G6bnLybCYGoLZXlGGU5gUhSoQCK64C9n8V8KbLE+//5a/rMemqt+GYwTuYe5OQbMael1xWWhd4NY5ZEwTWXTfZmMoeQMkl6Ku4eDFquKLWAhINYVIUkCYI7AfA//0dsOkJuJTi5nI/Zj5UAZ5k6pE5C14NgqO1pZ3zJuG+SimRByB/Zv7g4zjDeRj0hE+DdE0R28i9ix3pnpbvkYAWoIA4JRclRIrFSsBLh0hB4IyJmZdQ2LrHcZix9jfA9rXAtH1S2wmDGgRgxEV8zvG5Fb+/1fLdarIkVzbJPTkSn5dqBU2KBANqctlYIveIhEVOriOE/ADAVELIewHcCpYRPGHBjX66FlCa4wRi6z4UGYCSG9VA0eYBpFeOefMXl1WWlfosamvIPNTDWAvPPYBmksFUGktGVh7AwsHlQP8GYMnr059zXVwbHI9p/mZg3QOJ91TPK+7qFX8feVDlriYZqLzik6WnrsNWdSIGYKCAVPpBlwncs3UF8Pjvge5poDMPxDN0L2zvXQTscSDQNwuTHvwWvuz9GP3DtdQ55E3CalMYP4jjECc+/wNsoZNRW/rexGfkImicApLpRk7h5MmFXdkDUBLBEomTalVSBdzz2bjfG4BSF/Cz1wBbn0ttx0ssq8ZkJB4AV/QBPAExTjTk1QGMQeCAP//MkxqotTcGkHtEys7sDQB+B+BKsDjAZyil32nx2DoacutEGYkVkfRA8DLIQ8IDcFLNJMS+1ebkJF/HH99ERKw0/Sg9n4+nCOTVcyMSytR+pKYsKkzVQP2QYsn2W4FSD3DA2an3Sy7BreFRqJOKqFHPIa/05fLGjcYAZI/OtIpLegCxDNRzSKLhitqcRdQCisYiSgAo5aABYM/11wNOCXjTrzF04U/xD/V/xm2HfpVJKv/2GoQnfhhv8W7HCSs+AwQ+EAbAjZ/EG9Z9Cd1IVwmVcVz4MP5zw7uBbx8B+pNzMJduZmN8/A/Ye8cD+J5/PmpOT+Iz8ipVRwFxjze3JaQTLyq4TJpPlrLHXHJJtgfAg9h7LAbecS1QGwB+cArw7SPY792samnJUxYA/ZuAX7wOhwzcL2IlatJdFtTiffw+k2NCLilAAUXXsV/yADq5GNzDAHZQSj9KKf0IpfSWVg5qPMDUeSleNYcJl5YQgpLriBvXc1kNFC3HLFbPPAbgII+Gl3uVJjwAqVhZEcjSvPjhbiIGIFpLFvcASFjH4m23AweeA5TTLGPZczCAbqyZcSIrUxzEq1iVW1Y9gCKJcOoK1nEMFJD0GtezhxRCBTRQYyUa+Hebup7SapHz6uIcXQcEIea/dCPLou2ZnqKSQAicMz+Db4ZvxMGb/ghc9V4WNL//u1i68yZ81f8KUBs0nudpgzdjcrgD2OsoYNPjuKLyRRz14v8CV74bmycvwa+CM1Orb7HAcB0hQa2odKMmMVKF/H3w74nXXAooJApIX8aZg3tZvRWPVSt95w3AwRcAex4JbFwB3HVZNF6lsNzdXwNW3Y5/3vJ5nF9+KHqv+AJHLd0hlHIBX2hFEmpDDSre5KbsOugrJymgSid6ABGOBXAfIeQ5Qshy/jPSgxNCPkwIoYSQmSPd11iDzycmD4BPRDJFVHEd4QEIqZjmJqkr3oXr5K9gZY5WfigbpYB8qRl9qQH6JL2fjBgAzwNYfRfw8/OA7WtAKcX55G70+DtYFqkGfHW8bs9zgYHNwJo4F1Fc94BGtZZI6vU8qMlWpkztROJPEF9jz2GJYCEFhupBfA2URDD+us71L3kOjiTPoHd4g7gOnF5Q6cZflf8G18/9e+Dxq4DHfguc/mlcPudfsTR8lMUPdMKBMMQBQ4/gLrIUuOh/UH3L1ejBME5a9XVg3tG449gfoYpyavWdlC+WxN8yh0+puQ8Bh85D5p5WEIZxfCEnE5hTQDwYjlmLgdd9F7j4x8ARbwce+hmw43nM2rYMvy9/BuV19wI71zOBwZKL8GzpAFxGvoHjncfZ91AbZPfik3/MHH+6eF8yxsQzsR1DFz85CNzXxehCOS4w1igaBH71aB+YELI3gFcByC7m0aEQFJCmFASQzmwE2Bc8mAgC6ymgQKye40SwvBV87EYSyBUaGw0CJz2A4vSJbj+APhFM1Jy/99vMCPz0XIRL34OveD/Ci5MPx577naXdJ18pb9/rFODJSYwG2ve06DiR58V707r6STcL2jwAbSAvnpjkVoaepJDpr/pxJrCg8pIUkM71L7sOznPvg+9U4B14jhiXfC4cfRUXN05+I8494SiWDHX4m/Hn9Q9j1/ZN+MAzPwVW3SGuj8CmlegLduLe8GC8FkB91hK8sfYZfPXAZ3DkWz4P8tj2xNg4VPkiHzc/J35Ncj0AJ850DnntJUd6XkQMILsWEKfZtOWgT/4o8MivgavehyNfeBiuM4zwxr8FVixl75/5eXxhw5O4bOs/4JPe5Xiq/mbgwf9h9+L2tcB+Z7HkNQ1qfjJxz5UoLQAIaHY/bZUCGqgFqPpxXGCsUbQW0NoWHPsbAD4G4OoW7LvlMHkAcvN3lVMuuQ4G6/GXbZJ3qvEFHiTLgnxjxRmnUuvCogZAcnHjAGryQfzidSsxf3oP3nHCgsz9APEDL6PsOugLdoKuuh1k8WuB5++H+6fP497wEKx8xXfxXsPDx3so9PT0AYtfAzxxDfCarwFeBZ5D0IUqpl5+Dj63eQ0738vKOCGgeKN7AfzguNxzV7NomQw0vV0y9T+MG/g4JM7QHfZzG8IkPICgDvzkbFR2rsNb3S1YNe1UHFBhSmuRUKbca5xDxqEXx+cQUlxXeS0+ULkF+NOXmJRTnpQjyeQdtYMQhixT/Fk6D8v3fxWOLPei7O1MjI1DlhnzUtwVSRHE7z+1OKIKT1ox+yFFxSNSKYj4HCuei1Wb+3H0l2/V7od70loDMGUv1jnsge9heNpiXLDhXbh6zk/Ru/Ze4Jj3AVP3Rj/W4n+734IPD34D/c9fDTzzDVb5dMdaXP79L2PumX+P0xfPBgD86++W45iF03HRUfNSpSBijz8U198h5jIisqfOvZfPXv24eG2sUdQDGFUQQi4A8AKl9NGsbj7RtpcAuAQA5s+fPwajKwZTDCAZFEs+tGXPEXkAXP+clQgmlxDIl4HGrqXqhQDFKSBtIphy7JtXbsBBcyZnG4AsCshzcLb7IEjoA6d8DCj1oProlXjXLQfiI6We1PYcB+85GR87+0CcfMAeQOUiYPlvgOf+BBx4DlyH4O3uLShveBgPTzoLW4YdvPbAuQifvh3vda/H5uBfc89dre1kKsKXSP2PZKf8XLsiI1X1w1SyoKyZB5J0AF54CHhhGcgB5+C3T9RR3etdOCA6Brf96qXsKrli9SifQ+CUgZM+Blz7T8DTNwEHSgH11XdhR/d8vDQ8g3Wn499TNKmVNYloQFJmvO8effjEOYtxxuLZoEgaszwPQM5R4UFfQlhiVyD1wX7bcfskitzpsPf0blGBNYVT/xXonYnn5rwez/7kCTx06s9x8s5rmWEAW7Hf33cGnuv/DY597DMADYC3/Q70hk/gjHU/x+WrLhQG4OaVG1APQlx01DxtHgCQTgh0HQIvGGbBeSc+j5ofMgPhEJxz6Bys2z6IekCxx6QK9pzSlXm+rUDLDAAh5FawiqEqLgXwSTD6JxeU0h8C+CEALF26tHEuokUQjTdSHkDMm/thmHggSi4RFFDJNbuJajXQrKqUHAkPQFbEKI1L8qArBaF6DwPVIDd7Ug1kyyi7Ds5z7kMwfT+4cw4DCMHgcf8P1VtuyWwI4zoEf3/qfuyffU8DuqcxGujAc9AdDuID3jUYnH8qfux9HOu3D+G1552EjTd9G/vf92ns3P4UgD1yxyzz7Oy6p7dLBIHlGIDrxJmnPpvg9sJmLL7mfODVn4U7+djE5xPc7+q7ABDgdf+NLz/5F7y1Ei92TGVHdGoqoaQ5/C2sKcvNnwLmHc1aKQY+sOZevLTHq4Dt3EglE/Z0pSjY+cSyXkII3nfKvgCAXVHvA+EB5MQASrIKiHtcIaNOAimGcNQ+03DUPtMy95WJ7mnAyR9Bz6bdAJ7ADkwCTv6IeDsIKboqFXzdfwO+63wbOPA1wF5HoX7KJzHn8gtw8IarARwuzk307vX1HoBcFZbLQN/pXwF8/0vAe//EpKpIZn7Pm9aDL1ywpPlzHAW0zOeglJ5JKV2i/gBYBWAhgEcJIWsAzAPwMCFEZyw6FqLxhqYhDBCtcKjqAbgJGWheKQjRFL6AB5AMAkdjpHE10HpRAyD3hzXkAfRL2Yt549FNCFOCrTjOeQK1xRcKeiKrhaQWbompPp68HqgNYr/Vv8R00o8tR38kUVZ698Jz4VMHM9dcm7vLkDYuA5Wltp5DEqUHgpDiNPcR9GxZDvzmzehbw8RzggKSE4BW3QnMPQzomZ5qYhIongSHLllKTKpuCTjvW8DOdUwj378JeOkRoLYbm2ceK46vLjaEakY1AIFeqZKKAeR8f65MAUn9AETplIJff1GYSmbUwxDdJRfXh8fg3kX/DJzzFQDA8N6vxIpwAQ7dErezrAdUqPdSHgCPk/EugFEy3ORgG/4mvB6YfYiY/AFmdNvB9Zsw5iOhlD5GKZ1FKV1AKV0AYD2AIymlG8Z6LCOBKTCn8uZewgDEQWAuf9MXg0tmArsFegLLAcU4eBumatbkQbT1Q9Jdl49TC8Lc5JnYA1CeaEpx2JqfwSEU/fudn9o+qyFMCksuAuoDwFcX4cAnvoubg6MwMPMVzIvhx+3dA38OD8GstX/Uq2Ik+EFSBuo6REudqTJQeRKNSw+ECCnFYWQV/K5pwJxDMfem9+II8kyKAqrQKrD+L6L2jiqTjSmgdLypphjnRCB70SmsKcuOtcA3DgF+ei4AYOvMY9gYJQrIU5RfRhWQm6Rl+LGKewB8xRwKgytkoCHVxoxGAhGUH04agCCk6Cq5oHDwl7lvBabOF+dxTXA85g0+AWxbJXI1+OerqTyA+Hz4fl3HwWmbfwUPPnDqxxPHVau/thudM5JxBmMtoOj/aj39QJRdgqF6bAA811QOWgkeGuSIMmpRGWdeY0geA09XL9IW0Q+kujBO2gPgK6k8A6AtBUEpcMunsXjtr3C5fwaGpuwn3iq6gkxgnxOBMz8HHP1urD3wXfiC/7eMkgmSeQDXhsejZ2Ad8OLDmbtTG/w4RJ+BLXdNS1JAsQdQjSbXQ51VqM46HHj77xF2TcPHvCvgR9eOT/IzdzwCBDVg4akAOLUTHziONyXHwQqmJWMAspIGADMC77weOOYS4Jj3Aud9C7SXUWGsN0UyWC97MDJEvRov+f0IAxC9b+pFrG4vq+S8yANgstDMjzcM0QBHUzW15DoouSThzdb8ENcFx7N/VlwlzktQQIoHoAb2g5BiVrgZR2/5A67GqcCMfRPHVUtJtBttCQLLiLyAcQe12xMHvyF4MS/5gVCDR6am47py0Lky0EidQAgRDxEfQ1fJRX/Vj6tt5pxXj9LCUD42fxDUladuP0A0sdx1GXDnVwEaAmEdqxa+BZ964lzcIj14WeWjjXAc4MR/AQCsfnIT1j/6YCwDlQLZNwVH4z/KP4Vz99eBN/wccPW3PVsVShSQIZmHG+iukhutXLnxcqSeviFQG8ABZD12zroYvV1TsPuYD+H4Oz6F27fcD2C+MKIzNt0POB4wnymVVA8glQgWgU1eaQ8gpcXf8wj2wz8X1eTnSjV+nfixgSwPIJsCKpoJzFujygXyAhoXIhwtuA5BT9nV1Exi+S5qHKUehHgRM/Fc1xLsu+Iq1I/9ZwBx7aFUJrC8SLr50/jp+u/BQQBKXHwvvAhqRgsrJdE5BqBzRjLOEE/SyUvIKQA++SYoIOXGMck742YqyYk4ywuo+aGoe8JvytgAFK/p40tKDFXhAMQp+OrKU7cfACgNb2LZl3seDpzwQeD87+DpIz8NiuSDp/ZBbhRJeaEkZXUc7EIvHj/on4AnrwOufDeTXGqQCgIbYi/8ta6SA97YBGD0hryCnrxjJVxCUZ99OABg+NC/xQt0Bg598jtARC0AwNSN9wF7LQUqrLWXmgRlSgTTxgDC/HIMcsVR1VMTBswQA1Clio5Q8ehFESri7ymWSXORA6dPRhu85o4MvkgoeU7KAwCAv/SeBmx6HMGGlQCY5xuELOM7GQOIFklBACy/Auu8+bi272Jcve8XsJ7OSI2Fl9TuFLTdAxiv0JXoBWQPgE2Q8gOhppCrlQQ51NWw0PVTCgf6B0x2TV3hAbAxcP08m2SzpXUJ+kQTA+BcaJ4KiE8sfX/5DuBXgdd9T7jD5Sc3ijGL7ZvxACTEKflUW87iiUXvxKHzpgM3XwpM3hM4+99T+0j3A0BmIljFcwXlxI8lOr/5ISZvW8HObc7h7P1yF77pX4iv7Pwf4PNTcQqANV0ANgM4+WNi/2rDHJPkWFdSQz0HHWSlD5dh83uzUQ8AYPeniAEUloFGMmlC4CUSwTI/3hT6Kqzssox6RAGV3eQ15Ibsvu6T8GbyXbhPXA3gSPTXfG3ClqjYu/1ZoH8jbpz0Jtw75VwcNnMqwidWp8aiZhK3G9YANAn+0KsLlpKy+pZvaB0FJAwApUAYNRNX2inKnaRM0mi5rDBfKaoeQKGCaFIA1dPEAGI5XPa+gpBiLrai/MjPmCRR4kJF20PZAGQ0kS8Cvk+uLuFjl1/HCR8EXvwryxI98/OpbM8gTK6yufpKbScoewB1KQZQch3h3teDENN2PIYX6XRgEtOTuw7B/wWn4PWHTMExcz08s2k3rn9sA95y/ELscUxcfVOlJcwUULpcQqh4MTrIRko1lKaWlFklix2HFI7hyMoytgoHEMoewOhbALX/ARB7AGUv2XmMn8dWTAH2OgqltXcCOBKUAjuHmOeoUwH1vHAvAODR0mFM2WTIIZnwKqCXC0LBnSqcqBIDcKUvW0cBiUn5mg8CX5wJfHEmLn74bzEDO+OyzIaELBnyyiJNATGrUaSmD+9XDOgLqQkuNE8GGoZ4j3c9M2ynfCzxXlkzyWSVjigC4QFEssxULgMf72FvBIZ3AKtuT+1DTkRin2XjVC+7LwyACz8Ixb5VD2D6jsexPNw34ckFcPHY/LcDp30SKw/8IL7hX4zdx/w/oG+W2H/JNamAkuMoe06qYJqcx2GCTFOp192UB5DVtMRzSGEVEH9bdBBz4oz4vH7GzaK37In7lqMeSYVZ7+H4C+bnUfNDYOHJKG/8K3rB+jtsG2Clt8uufI+wvye99Gdgyny8RGaLOl8hRUp4oQaR243OGck4QxwDSL7uKTI61xQE5twnpSxBZ+U1wPwTgJM/iumDz+GK8hfh9m+IjhFTQCbUAyr2z21STTEARTyARAxAEwQekBJishAEFKc6j4AuOlVI7Dh0ShNVjdIouOcVcArINZzDotOArqmpctJsDGkKiL8uw1eCwMIDQA3lYAjdGIY3uBGTBp/H8nBR3BDGTcZyuIFWJ1WV2zdJjnnjdHmS0QaBFSTKlSg5J7qOZEC2B+CSmLLKm8BZVVwmr+WaeV4TS83EHi1M6vK0ndO4akuOZ3FjUAsosPBkkNDH0c6TAIAdg2kPoOQSEISYvOF+YOHJiVpAQHrxoNYSajc6ZyTjDCa3XMhAfZ7wFb+nUkAiBvDSo0B1F5Ppnf4p/HbxtzCHbAN+8+bEMbJ688qupRqHqBhWdTrITcVViRsA7I4epKxSvQBQGdqIfZ2XQBadknpPRzOo0tdGIXPLQUiF3jzuQBWdg1cGDj6fVX2sDyX2oSbuifr9iuHlHlHFcwR1cZ7zZxz/64Mx5Zv74Imud+HNd7NE90fovvH1VJLeTGWAK0pgMjQFgV3WBS3RlLxASWbZS1Gpm7KGnuP/c5mxCschghLMo5/4seTib64T99Au8vlGoQaBKY29DzXpjpe8qPkhsPexCJ0yTnBYIHgr9wAUGejB5HmUajuZAQjj5DYgXYZcLSfdbnTOSMYZ1JUTh6BfRB6AvFpQKCAeA+A9TRecBABY23c4vkHfxPjqjStj5USGByBnKKp5AI15AHEmsOgJbMgDyMor2GvHgwAAsjBtACqaQKNplVsUMl3Fu3MBUhxDPvclFwG1flYnR4KqoDFRb7IHUA9C+LVhfNS7AkNT90d45hfwb/U34+4F/4R7Fn8K94cHi3PitwKf0OXsbRnqpCQMgCYIDKSvY15BttgDi2tFcXlwLGNNnrMsM1bhOkQsCIoYcN4IiXsrbpQQWSSA3Qx6K14iEUyccxQD0FNAAVDqRv+sI3GCw4q1bY8MgPwcl1wHJzgs2M8NAC8HDSBVTLCuNJVvNzpnJOMMcYXG5OuCAhIrq/g9deXgRAkwWH0nMOsQoI8l6PgBxa3klQBxgBVXSjdTBgXkh4KbVJNzhAy0aBBYoYCCRAxAaiWYsb95O5dhO+0DZqdrncgUhLqvpmWg0mQt9zSQZYcCC04C+mYD93wdGNohXtbJQOWxydsBXAZKMfu5KzHf2YwNx34Szokfwv+E5+GBuW/Dyj1fjxBxbSa1O5mpE1Q6D4D9Vlf2uuuYSgTTIOkBJA0vr8+vdsmSZcYq3AZiAAD7TuSGSY5DGHUXtMYA9FWSFFBcAC+dB8DzW/h12THrOBxM1mIqdmP7II8BJJ/jk5zH0N+3EJg8VxgxcT9SjSG1FND4h7EUBKdf6ulEsOTKgd0kJKgBz98vygAAbBW7050KLDwFWHGlUBJlTbgJD0AZQ1dCBpqNehDGKiBNQxj5QTJmA1OKfXYuw4M4JG0hoV+5+g2sIHWQE4wSNBZJnwMcF3jtN4CNK4FfXABsW81q5QR+wmCb8i9EENhzQcIqFqz8Lh4K98fg/NPF+bFaQEiMwVG+xywPoK7zADRBYEDxABqQgbJM4FjBlDi+QjfWMyYul8QqoLz4AxBlUIdsxc8NTsCDwC2ggPoqXpTzwMYoS45LirFNBIEBbJl1HBxCcab7MGo7NoAgeR3K1e043lmJl+aeASCOIwnlntpZrcMygTtnJOMMpgqNKv8uP4wVjQdwCH0K8IcVAxApcZZcBGxfjZm7ViaOqYOcYBLLQKMYQEQBFUkES3oAafmobACMMYXtazC1tgEPEn2lQ53SZKQqIHmlLythHIe13kxdu8WvAd50ObDpCeDbhwOX7Y+v+19MUHamVZyIAZRcvBb3oGtoIy7z34hSZGj5qlItF0JIsg0on2RUo6d6AGpjGXk7AMq2+Ty8fP11va11CWZZE5cryUALU0BBHANIJoK1hgICYgVbIOJNjjYTWP69dcoS9NMuXFb6AT624jxcVvp+whOasuYGlEiA9XvFzXtcQsSiTecBWBXQywDGWkBKgNOUCcy7KR0VPMaonn1OEO+JapYHnQc4Jezz0g2JY+og5wGoSiRueIpQQDJ/Llas0gQzUMQDiGIaDzuHad9Ws6X5cYHmVUCiLG9A2fVLJOs4olhXAge8GnjPraypzJKLcCxdjul+XJNQzr+Qwcda8RycRB7BYNcc3Cdx/bEHkL5HPMcRk0I1mgxUXr3sJrXpxkQwrZw2zJ2E5YJvuvyLknJ8vq1p4pIpoKJBYLl3M4+FtUoGypv07K4yFY9o4OOSVOcx1QOoUhfvrH0Mn6q/E/d1n4KL3HswZddT8b6fuRrPhXOxpZd1b+DluLn8W713ahJV2wmwBqBJ5FJAmgeipOiHXQKcggeBuYcD3VPFe0IO1z0V2P8s7P3ijSAIMz0A+QEVQeCUDLSACkjiz4Vkz+ABqJOEwHN/wi5vBtY5e2nfrmhWrrqVaCNI9EDQBHONCqq5hwFHvwc4/VMAgMN2xPkBcWc1vQfQ5REc76zExhnHAIh5X76qFA1hpFNynHh/dZ9qefVySgWE1H74doAqp82nYdSS1UAy9qKqkACeOavfbzMxAJky4hRQq2SgKQ8gTHoAulIQPKhd80M8SBfjV8FZ+Eb5A9hFezDv0W+xjXe9hMoL9+Ha8Hjw24ufg2j/afMAXp6IH27VAzBTQGUvTuP1HIKDd92NxVjLJiB53/LDtuQidA9vxFLydLYBkCkghYYqWgsoDFmtk6QWPlmuQk6o0VJA1X7g6ZuxYtJJghJREZdMjvfLx5ZXrM6EuCcwTWQzAzHnnInpi7Cc7odDd9wmXnIdpvHG9jXAtlUiYMz3Na+2CtNJP16YdkxiDLy+TNzxSrqeUvZ3LQi0vLpKS4SGe013Hbm2Pgs8Z6LmJ9tZiuNrKKCqHybuXxkOQeE8AH4s8XxEFBCljJpplQwUiBcvcgxAPdeaRAFRShP3+PrhMn7kn4spa28CnrkFePgXIKC4Njhe9NsIKW8Ig8SxxP47rBRE54xknCEUKyfVA0jSGyq3yl8jlOLUF3+E1XQucNjfJPaR4EIPOBuB24Xz3PuyZaCJTGC9B5A3CcolDThKjpMKApcUpVMCT98I+ENYNuk042TAE2VkpcmIZaBcdx1ltya4fNcpFAC/np6APQefBLY+BwCohIP4TflL2PPnxwHfPgL4zlHA8E7hTSzqfwgAsHbykYkx8Ak80AQ15e5uJklgyXUQ0mSJYUBfCwhA4joy+jD7sXYc5tklPIAEBUQ0HoB54vIcpzEPwHGkTPl4tVwL8umrZjBJaQojl1opGTwAnl8RK7UItg3W8JPgHARd04HLLwbu+Df4s5bgOboXgmgfgtbiWeRyjkbkndo8gJcBBC+rCQITApSqO7AveQF9u58DNj8FbH4K0wZXYV/yAg5wXgSW/Rizhp7Dt4M3pMoTy9UsUenDprmn4Vz3AQS+voolkHxAhQcgVEDFYgC6icZ1SYI66q/6mNrDauho6wGtuBKYtCeeqSzJDOiqKfg649MIYs8remBVCqhA/OOP4XGgIMCynwAbVuDE+96Lo8jT2HrcJ4Cz/wMY3ALc999itTdvxzKsCudgqztLHAeIV9C6+vbyWJgkMH2NVHVPViKYfM5s22I8PK84WtfEXsxBYP1+HUfKBC5wbM8lcZ4MISJvoRaELaaAkh6ArhaQGg/g703tKWO4HmIA3dj8+t8BF/4AuPAHGLrwJ4l9+iIRjO1Dvu9MFVXbCVsMrkmITGDNDdvj+Pj6xkswqdIPXBe/fgaAMyrRP9cDm3v2wzXbj8E3lM+reuiN81+Dw9ffgF3r7wXmna8djxwEdo0qoOxVsI4O8BySaCc5UPWx97QebN5dTWnFMbSducbHvg/1TSRzNVdySSp4CYzEA2DnPhw13HEVCqhIHaSXwmlYN+kIzL/vv4D7/gtTSQnvr38IHz3iHzBj9iRg7b3Afd9F6bDTUXFCzNn+EP4vPE4cUy5Ax1fXugUCXzyYlDWyAeguu2YD4KUlrqLAWg5KIlAdr8TFft10ldFaEAoqUYXrSPWKChw7QQE5BIgORWkxGWmj6IsMwG7hAUgxAMXYyfLbehAbyOk9ZWzeXQUAkDmHAJOPYuOv+QCeFQaA0366HBJhADrIA7AGoElkNTA50nkWk2g/vuO/Dmefdjr2n83qvD/2wk784M5V6C67+M+LD8Mf1uyB4J7dqWqTahBz516nYhftxrQnfwMsWAj0zhIVJjl0eQCNJoIFGkWI5zji9SCkGKwFmNZbAqAJAj/5RyCsA0teD//W7NruZc81qICamwD4x4braSPmGhq7qPBDihsP+DwuWbgZAHDvjpm4+bp+/Av/7GmfBJ64Fq98/vtY5c5DORjAn8NDMLuenERlD0A1aI7U3Y19Z2levaxQbCKfIKUCivr3qpnABWZhHvzUleFWM5EBNhlO6tJPF0npbP6xXcdcO6gVFFDaA5BUQCoFpHgANeEBlMTrakY/INF1UY8D/rocBObGxXoALwNkeQAnOCsRwMGP/Nfg+H3PBBZMBwDsqGzGdbf/BdPdMrDkLAxtfAbAbhZ4lXbjh0kZI0pduDE4Bm9c80fg+38EKlOAjzwtmk2zYFXMJxsTwXJWwXWxGkzmK/BJgtdTmd4bUUDq/lZeDUxbAOx5JPzwwcyArqo0GWlDGK5Y4itLeSJicYxs74dPyoPdc4AlLCdj8PENAB6Kjcesg4DD3ogjl1+BI10gJC7uCw/GOeKYcQxgsOZrDUCCAjLQKqq6x5QIVhIegJoIlnmq7LOR1FNneMuekyqelpkHII2ryLE9N96/GwWAOVoTBGb3PzcA8uKtHMVbuHRYNQb1iJaa0h0bAF1DGP65MFJhZVJAHeQBdM5IxhlMiWAAcCxZgaedfbELvQkDwb/4VKliJUCpUkAuIfiS/1Y8fer3gVM/CVR3AusfFO+r3KJJBpoXCJVrpHAwGSj7HH+ApkUxgMQq0a8Ba+4F9jsLiJQuWXROmgIamQcAsOspPABFcpvnAehiOlop37mX4X8XfQX/go/gzhN/hW2YnPI6RB6ARtfuqAZApwIyxQBy8gAopVraSYeKl5Squsp9qo0BZOQBiPMrEgNwSEImrX5Xo42K56LsOuiPFGwi7iH1b+DPUCIe4IdRDSQiaCQgOYGriYZ+GDJlk0ZCbCr90U50zkjGGUzJOaj24zA8g7/gUACKa62odEwFo1jjl+RDsQt92LL3WcBxHwCIC6y+S7zPb2hVBioSwQo2hNE1ck94AFkG4MWHgfqAyGj2g+z+rqrWXUc/NYqS42BY4wEwFVDBALh83UWBOemzXZOxYtKJuNs7DrtnHg4A4phyRc2aH8tAZcgxgLqhMqRa48fUfS5tKPgxClBA0fXnSYcyBal+N0BSZqxCnvSLUECe60jFEkni860wAADzAvqjRDDVAwBiQYMqCeWeT69kAFTP1ouUcpRSUVFWV0nXVPqjneickYwzhJqVEwDg+fvhIcB99GAASlN4pcqmcBPVZBGFx41r0gDomswafEsGQJaqcciBtq6CpSB05Rg8x0FPdTNQGxQrqGmCApImidV3ASDAghOjfWUrOlSeuW66ng3AdQmq9SQdw//OC4DrPDrhASjGg3s3cd2nIDGJlry4U5g2CJyIAejzAID4e+VDN6mA4lgBv4aZp8rG6JrjFEYVkEkGKt0vzQSB1QVHK9BbiZvCJBr48P4HAfcO5IAwFd8RNwBlTUVU9p2GwgB7sgGQnu1qB8YAOmck4wymCo1YfSfq8PBgwFLDdXkAMQWkX5mnO1NFr/ObaeHJwAvLWNIV5GYdcUDRcWKKJS4Gl7cK5lRGfFtMJQP43Lp3A1f/vSipOz0KAicmidV3AXMOBXqmi2NlykBTFS/DVNJUo/AkCsjkxZig8+h0qziAeVye44jvaLieNHayB6DSNolEMAOvrtIScS2g5HZFqSIdeBlk3hs3cXxTMbgCHkCRCTyROUwUA9CCGACQrAgaS44lDyDQeQCB+I54AFwX1/KibHlZyaYrJKh66p2AzhnJOAOfLFMP2+q78LhzIHb6bJJUJwb5NVEwSi01ECRVQDGfGN2cC09m/YOfvx+A3rV0ScyzcgqoZ/cqICOZTNeU5eLqVegNdwOP/x5k42MAJAqIT+D1IWDdA8mCdkF2a0KVZ87bvghYglHkAUgPKutAlW0AdB6dbhUHRAbaJYmsb3lylGMA6jmpHoAuE7ji6id2UyJYXfUACuYBMA8g7amp2ng+liIxgCIGgAXrpclSLsHdIg+gr+KlgsBuJAMF4mud7A1ARX5Nbzkq9Ke5BszDpILK5T2BAUUGaj2Alw90Dzf6NwEvPYpHvMP0wTXuASiGIF1rRi1lwD2F6IW9jwXcsii6VjVQQHLv2rOcZXjdPRcAT11vPidBAUW3Rf9mvHb4Gvy161igawoWPcYyFrgKSEzg6x4AghorXy2dQ7YMNOkBFOllm4dEEFih0HLjH1kGQPP9sFUezz1QPQAiJYKlDUAo5QGYagHx9wGp94ShFATfTncOJpSifsJ+mK7xw4yD0g8gMxO4sRU8bwHJx5osltdKCihqZypVLlWvtWzoeAygJMUAtAYgijHx70mmgEKNAbBB4JcBtEW3Vl4NgOK+yivFS/IDIap1KhSQWjCKpZPLSoP4dQBAuQeYd4yIA+haC8pj63KBD3v/x/559DfGc0opce79Jiq0hl9Mfg9wwj9h7sY78Qb3DszZ/GdMw654Al99F+B4wD7HS+cQZspAVQ+A1e8Z2e1YckmclOUmr3ueAkpXb0en5ADiADdXSw3Xg8S5JvIANHyx3A+gUBBYMzYAUdwhTRUVMQA8E1jXhEXtksVlxqNFAZUUI6trwzna6Kt4IhEsXuiQ1LWuBqFQ/PA8gLLniNd014DHmLiQIREElvMAbBD45YMgknslsOJKYNbBWF9aIF7SewDcALDXVX66HqgxAM1EtOgU1kt490ZxY8k3p3zc3mevxWJnHbZ37wM8czMwvEt7TnJwDNXdwIM/xj3dp2MdmQcc+34MlmbgP0s/xKyr34yvl74XZ00+cwuw11FAZZK0rzwZaFJpop5zM3AdIqmARi8GkO4JTBMr12E/SHyOn5spEaxxGSj/bHI7lvsQe1JGZZoGvAyyryw2gHQmMP/b1MzcbXACV2WjjXoQzaC34sYegKwC4kFgTgH5ocgbqAdcBprtAXAPM5YSx9dBvu9EENh6AOMfQai4qzvXA8/fByx5vXbyBuIHKC0D1XgACp0DKFz0QecDoMDKq1ELQjgIMXX3M6njughQufs/8GS4N27b/9Os+cxTN2jPKaECeuoGwB/CnZNfw16v9OFnh/4cb6h/HvTId+Ak5zG4w1uBLc8CG5YDB1+Q2ldmDMDTeQAje/hLrqMNAnOONgs6CWxcYE41AMy74R7LcD1ZgK3sOVFQUC8DjXsCU+2EIqidlLonfX0qkifVSEG9OBM4TF33khs3u+fjZK/r99sohZPo1eAQRUbaKg+gJJWDjmlCfk58MVILQvRVYpGD8AC6YhWQipIb9zgGWCIlP49kEJh7AK05x2ZgDUCT4GVfBVZcxX4f8vrEDa6uDOXX4i5WaZWJzJ9rDcWsxayP8Irfoe6H+JB3FY66/jXAHf8BRFUoHYT4aulHINuexdf8N+D5vsOAKfOBFb/TnlOiKctjvwMmz8OarkMEfbKRTsPT5YNBjrkEHgmxaPNtwONXASDAIRcq+wozKR2VZuDKmpHAdWIZqJqun0sBabT24rprKLqUDFShgABgqBZoDYAvKU50lEIl5QGY1T2yZr+hILCUCJYXXK7lrFybSQSTP9uoB9EM+iouBmo+wpAm+iCr17rmh6KBDE8Eq0gUkMkD8MMwcf2zEsF4CY9OgC0F0Qyqu3HAtttxFtkOrBxmrz36v0yfP2NfuM4msanKj7pOzDuam47rKaAUjbHk9cCfvojS5uV4t3s9/PIUeHf8GzC0DafTyTihdCde6z4AnHYp/nTTEhxAKbDkQuC+7wKD24Rkk0O0OvR3As/dBhz3AbgbXDFh9VcD9iDMPgTP0b2weMvNQP8Q62Y2eU9lX9kegNp1SqdGaRSeQzCsKUvsugUooMwgcHJbPzJWMQWUloECwFA9SE2ILmGTBaXUnAdgLAWRvj4ljQdQZBIVeQCahD2ZFukquVqZsXpO4u9GKSCHJCahVrEjvRUPlAKD9SDOeHedVD2lehAKuoeXgkhQQMYYgEQBOXrathOrgXbOSMYTdr2Et6y5FJeFlwG/fTv72bQSOOxNANJqHBklN17xZHHMuvR4lSrCkosAAIfe+T50o4rV5/0OOOqdwAPfx7/Vv4rXug/ga/StwCkfi1VBh1zIJKRP35g6LX6zzlh7I9tmycXwpEJqA1Wf8aOE4GbnRCzofwTY8hQzRJp9ZVE6rBSBVMd+FCggT5oM5e+gVEAFlGUAUqU6ItpEVuGUFAoIYMFhkww01oTrJ3UgLh5mzDlBkkrLKlCo/VxEAaU8AIUWiWNM+RRQEe9DfT6cxDVvzZQkF4STFUhqPSXmAShBYNdBXzkjCBwtMOIgvKOlbfOuYzvQFgNACPkcIeQFQsgj0c+57RhH05g6H9/Y76d4m/d14P33sp+/fwA45hIAyZtYV7+FUx2eZpUApDXxJj06pi8E9joKXcOb8IfwlaxY2Wu/AXzwIby7+1t45fC38AvndeJYfkCBOa8AemYkMok5+KQ0dfW1wPR9gbmvSEj2+qu+eDj+5J3EPkRc4KALNPvKbkzCmo7E5zMaeQCuYSJxoybkWRhJEFj9XEn2AHQGgGavBo0egOZyytexoSCwG1NAquFVg9B5Gaz8eIQUDQIn6U1d9vVogydy9Vf9uCGMQ1LZ1DVJBcTLQZc8RwSG9RSQEgNw9P2kOzEPoJ0U0DcopZe18fjNo9SFFyr7YrW3FZizJP22YWIAmButBoHTmcBJSaSpNy0A4PC3wN/wOL5VvQi/cB32FM7cD2u89XgBA5jp8ngDC+zBcYAFJzEDQCnbXjruHtiB3hfvA076CEAISk5cDK6/6osHaWNpHlZ5S7Bo/j5A3x6pYQU5FJA+D2DkMlAOtcNV0UJ4jmYy0lFAJddJehlKPX2AeQD6UhBhJq8uN20HzDJQIFlWO2u79Od4LaD096TTxgNmFRCf7IpO3mqdKxkto4DKsQcgy0BVFVDNlyggyQPwXAddJUcftHeI6EQHJI2avHiwpSBeRsiqdpmliii7cQckY6kBQwxAawCWvhvXnHEbnqezk5nACs3EmqJImcS7XmB9biX4YYhz3AdAaCjoJTloOSB5AGXPwbf2/Cpw8U+016Ae0kRhNRVl100oTXRqlEaRbAOZvH65HoCGPuHjD1IUULYHwL+HwVqQOicmA5XogKxaQOrK3kQBBclEsEIUUFQGueoHKcOrauN1MmMZfFxFYzjJ69Z4ELkZiL7Aw36iC1pZOlcel+kuuSK/oipJdfsqntZgc5mxnLEt6MOE0CG6ji2iuZpBO0fyQULIckLITwgh00wbEUIuIYQsI4Qs27x581iOLxNZBiBRHEu5oedN78G8qd0A9NROGFJQWiwjFQBACAYIaziTzAPgNFOsPBKf5xm7USYxhx9QnO/eh9qMg5nKCMlKmiwGEHOhA2FF9CRQkecBqNxrXvnoIlALwMl/NxUENngAPEifqDgq9x+QPABd8lYYUlENUzehEEISiXJxLSCNAXCJFCtoIAicYaQqUbCXS2qLUkBFv7/k4sZJrPpHuggwoU9qDC9koC5JnGsQPXtlzxH5FfUg7tmwcGYv5k3vTu1bTvzj56ejD6s+kw+3SunUDFpGARFCbgUwR/PWpQC+B+CLAGj0+2sA3qXbD6X0hwB+CABLly7NforHEAGlqcQcDrUMgYzL33OsmBR0wV3elEWezB3NzSRD94Dyj/MHKlHga8a+wOS9GA20NL7s5f71WOo8jZ0HfhJlcS6x4diteADapvCI69JnUTpyP9uuksvUFiNcGamdzMTfrpNbDVQntRQZ2GoMIGAUXSJXQ/qbUyV1TTIclwzywmSmLltyY/aQppPAOMpenPtgKhut/RyPU9QCUdqDQzRQiRoA8QQquSa+ek5FjwsgRW9SjfR2tCGfkwgCE4Ke6PXBqp+Iy/D8CjlZ79fvPU47vt6yh427hhM0ok5BJnvQnYKWjYZSemaR7QghP0Kic+74QJCR6Zos5JZ8r6Tc/EBS3pm1EjWtYvnELnO0qlvOuWcAjPdfeDLL4GUtjAAAe73IlEH1xXFQ142oI0pp4gauRKUEdChCRcSTZLx6HWkMwNRYpJgHEG8bf46NR1VfcYmrKeFPR8VxOA5BSOPJtdcwISTUPZrGMmI718HuYbXIWbEYABB5AMr2fZJiBoAwVrkGoODq3VOMrAfz9Rot9IkgcAA/YIs3xyFwwHIB+mu+6AlQdh0RI+HF4AAzBcZLTcvXP1XAEew6mr7vdqEtoyGEzKWUvhT9eyGAFe0Yx0jAHkr9DeFJHH9WeWOxspcmGN3kmUkBQV9kin+Gr6q5VE1g4cksd+Huy4BuxsDtu/73eCTcF3tPXyg2K0Uy0OE6q3cuKCAvLrymIlVUTgNdIbOu0kgpoDQNw8ZRpBgcG4cuCKwaD95ERT6/kuFvdVXMPSpeWts0Icj6/pBS48pYlwdQVAUEAIM1P/U99Up0ifzbNNaGPQDFyPqI76OWGQBFBiqfc1/FQ/+wL3oClCIKaLjOi+VlL0z6Ki52D9cTKiydwq9/eAJ5ADn4KiHkcDAKaA2A97VpHE2DdXvSv8cNQ94DodMK63q0GvMAItSCwBiUlIPAiUDootMArwu4/cvipSkAfhu8G/+qkVDGq8BIDuc62DWU7BvLIVdbNEFVmoxOOWj9ipzL9CilRoPMF2qusjpl7+nzNJryAKJaQHmrajnDNwzNBkCXB9CIBzCkyVXoUwzAQJ4BiMZWlNtO9pwGKNJGd7TRXXLhEDYJcwPOwSuFCrVT5AHw885T7fRWPAzUFA9APNvxdgM16wEAACilb2/HcUcTum5PHELmmcNo6ApGiaYSOVSRDFapMT3RALI3orRFnDwX+OhzrJZ/hJ8/8Dx+fcsGXKrW0pc4azkIbGq0XmQiUpUmeeWji8CkvpJXY6Ygo5zFqe4v3Q8grQJSZacc6TwA9vk8Xr0clWtmxzNfS7lwm6lstA7x9U9XYe01UEC8Jr6KRmWgaq8LT3PNRxuEEPSW46YwqgHorwZxzSOPoOQSsW1e8bbeiocgpBisRV3OEjEAmQIKEs3lOwGdZY7GEcIMXpZPMnmctq7lIF+ll5zkJEKIOQis6ywVj4EHgTVa+Eof+4nQ7+wEsCHlSYQUgrJIBIENMYC84mH880AcwPaD7PLRReAptI/6N1u56z/LH1RdK850raYw0RFMPbYci0lnAjsIKM2lVcopCkg/bm0mcIHrWM4YY08kg+QtQAeqPrpLrpHSi8ubN0kBha2ngAAWBxio+uhSzmWS4gGUXRdlzy3sAfBA/s4h1nM4SQHF2w1UfaEA7BR0jiB1nCFTBso9gJx7WTfBmFbPcitBFaymTHJmEx6ATgZqgFwjhYP/zW/uIiogueOSCbpuVqMrA01PcFmBYF25BVMCHpe4EmmlJx9bLvaVqgUkPAA2uZpW1QkKSC08aNhOl8xmQpYBcBy2Wo49gCCTumhYBqr0EDblU4w2GFXjp8pf9EaF4uRMXUYBse8o1wMopw2ArpBg/7Av1EidAmsAmoSfwcuqHb9M0BkAXzMJA+yhzAoCqzVlxMTEZaAFyiHEmYzp/ewYqgFAoiiWyQPwJZ21CWrj8yLBtjyYZJmio1rG+cca+vg1c6JeTJt4GgNQ8uQJLXkcV8QA6ugqOcZVtRrcNdErarBYHncWSoZrxdFbcYXXx0qAmCcuVdacB1UmPRaJYAC7d3cP+1FDH4UCGo5loKxXcEwB5d2X/JnYFRkAuSGM/MwNdKAKyBqAJhFm8Mlqxy8TdBxzoimLss9MA6C4qapbzvXnWeDBMTlQyvezY5Dd3L0FPABdIFuFWu/GD0anGiiHPGHy76mecf5xEk98HQkhcIjZA5CPmSgHrUnI43AclgjGKqua+eCy6yTzADI8gPgaFs8ErmQEqoFoUpTyALImrpFQQKlYSgsLpfVFTWF8JUudN4xXPYD+ghQQ94p3DbNnhPU4YO/xZ5tSioFa56mArAFoEkGGNC+edLP3ke0BaCggQwxA11qQj020oSxYEll9APnDyt1bzneWCuQBNBoEHq0YgEOSE2aejBbQB4H5Z+XrLpLcpBpLgCJB1STkiTFG+xvIWVXL3D5TAem34wl+lNLMstG6z8VjSt+onBcHkkUAdWg4CKwIHMaiGBzAG8MH7F6Tzpk3jOf3YsVjJSKKegA8x0B4ACSmB3l8b6geIKTmoH+7YA1AkwgzOGvR+CXnZtYVjIo7U+lXjjroPIBcGagGuqYsrhIDKOQBaLKZVegooNHyAFRahT/sJtUSYC6k5hCSmaehW/2WlQkusT+HGeK8VbXcLyGgZgqoInlSIo7RgAxUPgcZchP1vAxWbreLykBVD2AsegIDXO3jp3pPcBnnsNRMiHdFA8xF8Di4IZdjAEBy0ZaX99EuWAPQJLJkoPwGyLuZdTyh4M9T6hHzCl7XWMRJTVBOAQ9A0x5QUEAsBtBTivMA+MpTha69ooqYAqLRZ7LLRxeBLiArv57lAfgaCojvS5+pnYzzeCYDoBrUyKDszjEAFSUIbMpfiIuZ0VhCXOAyymPUxSE4Xw7kZ7Carnve9kDUEMZA3Y02+qIgsFqigxu3HdEEzikgjiJ5AABEXkz8/Mf3S17eR7tgDUCTKKICynsgdAWjTFI+Jsc0ewDqaltdDbOM3pwYgKaAmwgCD9bRW3aFYVE5fBmBgcaSoXoAecXjikDQXWr8RJKBmhAXXEu+rgbf1aYeMcXmJD4TG97k/mQKaFLGZCB7WNneJnu95odSEDj/sU5SQOl988kSyI8B8OMV9gAyG8K02AOIEsHk8+fntn2ALXJYpzB9Zrdpv0DaA/Cc2IsQqi9rAF4eyMwDaNADkOfQumH1nCcDVd1UvpKSKYoijdFTwWc3jgHIN686gSf2o9HUq1AzgfPKRxeBqxg9Dr6qzzp/UzMV1fCqMl3T6pefn3oPOA4Bpfmr6pJLpFpAGYlgXtzSMKtzmIr8ILArJq08FRC/3EW/PtnLSjWEaaEB6Kt48KOELVUGCgDbI6EDrwXEkesBlJNBYJEZTdIegJWBvkzgh2ZttlcwBqArGKXT4gPZFBArWZtNAZXcfApI15SF/79zqC6CXYCs4zdTQKWMh1mXBzBa1UDNHoDZA5IrRMpgPXw1MQApuC7/5uDnp9sfkDaoKpi+nx2LUUDm7QB2Hfl9VOQyypOazlPrq5RE96zhepipWGpYBqoU7RurPIA+aaUunzMXNnAPoKJSQDkegOsQ9JTddAzASbZTBYBJGdexHbAGoEmEGZRFUVmcrmBUXayeNSvRjCCwmQKSPYA8CigdA5BloDJ/qRZzS+6niAoopi64smbUgsCqAdDEWlSEhjGr112VWpqOaaKjuJeza6ieuapO6Psz8wDY61XJAygSS9H1jpDRV2HN4HeI4L95rPI9VgQq5z+WiWAAu5cTHkC0gt82GFNA8vUpe/lj6q14QgUUGwAnDgJbD+DlhSxlRtHMSF3BqMCg5WZyRP1+dCogRxlDkZLIuhgAX+nuGKqJBwVIUzjqfthniwSBw5SypllwxZJKJYlge2YmsNkAJGW6SQMdB4OT15+vGlO1gITyC9l5AHIMIINurEjfg6gFNAoeAJ8sN+4aBpAdvGzUA+Db8R7CYycDZZPvjqFawkiqMYBUENjNn7T7Kh74bSLLwEOFArJB4JcJgsBMAQkZaOEYQDyJxiogVdefbk3IUQ/SWbRxDKB4HoBOicMn5eF6mKAsxApe41XETbfNtxene2p+GK+qR5gJzCknlUri1ybLA9I1hAGi6p0amW4cBE7+5jBSQBruWQfekIR5RzCqgOR8itBAY+lgqmQaj41915t2VRP/6yBUL4V7AievDa91xf9uFfg5DNeTni6flE0eQKmQB5Au/yHTh3kVVdsFawCaREDNFFBRD0DXctC0epYVBSqqGXkAMUWR3xVLR8PI/8vdqyoFPICs83ccVnGReQD55aOLwHTdG5OBpuMHukQ9VQaqHrOc440A2atBuVon8wD02+k9qfzHmpC4Ibruuk9SPQBD5zL5843KQBPUD2lsH81Avt7ycfi58Wz3kksSQfK8GIBp364b04cDVR+EAD2G2k/tgjUATSIIzasVvhrMTQRzOB2gkYFq1COm+buuUwEpipisUhIcumxc2RDJqxw1iCvDFMhWUY6yiRupYpkFnSSTvV6cAkoVbyN6Ckj1NtRjFvMAsoPAQLSyz6AbRR6AHxqlrCZUDNdLHtuGFlBAJcV4AmnKshVITtJO6vUdgzWUPUf0ZObIUwGp+5Yzo7n3uLvqo6/sZTaIagesAWgSWQ9lUV20bmVaD/SrONfJLgedKh2hrMpcl6CeSwFpZKAarhSQgsAaA8CNQt7DXPJ44+1RigEYVqL8+8hSAZmCwKyFoy5TOx1jkVEyBEZlA5O1qpaD7EFoTgTjZSeqQWiUshqP4aUnYg41BiDHf1Q0SgG5mgVSLJ1sPQUkjwFg3iyT+8YGVX6eihQpTOybXw9FBdRp9A9gDUDTyCpeVtQl5m8nM015Q5j0JNZIJrBugirSFjGloZe5UjkInKECMnkxKnhF0SLlo4vApL4qogIyyUDVEhqqt2JSwJQNk2tRCijlARiuZVkxFLpjGo+hmezUsW2MYgCZpSCc5LXIg7woUV9rJQWUWMBIx2HNYqIM9+i6y+XVi1BAvRoKyEsYgKDjFECANQBNI8xIzikqi1MLRgFSM5WUekTfEjIImYTSFATmDzePIehKN3Do2jLquFIgXj3qg8DFKJ2Syz2A/PLRReAZJrRCmcCR1l4XBE54AEqQXm64I8MkBNDJD3WQG+aEoZlOTOYBFA8CA3FwUysD7SoeA2jUAxAGQNqeX/eWBoEl/l0950ldTJGlBvXVTGUT5KxuR/Jm5ESwvq7OygEArAFoGlm69UYeCLXKZ1E5IgefPM0y0ORElTUJ6gqymTjr7EzgYsHIipf0AEarJ7DRA8iJAegmzpQMVKGrTDJQHpPRxRQ4Mj0AiWILshLBRsED0JaCKCc9gKzVq9tgDMDTUKRqQlgr4LkOuqNaVuo58/OLPYDk7zzoKCA5izwvm7pdsAagSQShuRx0URkokCwYBaQzTcV2hlIQfAWuuqkpDyB6P7MkssaTkP+XJ6xKZhC42Iqed7MynXOjEM1vDKUgsmohBYbMbl69k0Mdq1gxNkMBZayqExRQxmJD9QAIMUtG05/VT4ZAPCFuHahGqpiMhjCaFX0WPF0MwCEtzQHg4BO1em/KjY6A+P5uxgDwyyln7w9U/UyPr12wBqBJjIYMFEjLO2MNfZrG0PUDkJtYqNvLY+D7yyqJXNfENUweQFYmcNGgLs92HSsZqK5sBYepGJ2nBoENtYDUYxaigHIygYG4yJvpXkoEizPuSR3KShxDhuc6qHgOKM3XrjfaEMYkA221BwDEyWDqdeKLm5Iw7MnfRffrOnFDJdl7zOup0C5YA9AEeOkCYy2gBlZEDtF7ADr1iNYD8PUeQNwTOPmw5XsAykSWkMulZaBZQeC8B5pnuxYpH10EKi8vXncLnLtB1aXKQAPFWOk6ggFSHoBBBpq3qpavb0DNq/pkrMDslWZ91kTV8Qkrb+XaqIRTZzDGggICZA8gec78HNWVf5EAsLxfVdnEFw9WBfQygkj5NvUE1uicTTBxzLpicI3EAPjHVaoiaxXMYgDKfhIZk3EQKysPoF6gIQzA8wCosQtao/CkgHfidVENtBkKyCDTzegIBpgpID5B500GcgyA1QLSbxdTcbThpjpZiWBATFFNyqCqAEnCOQIPwHGSvahbBW7UUh5AV9zoCEhTQUX3K98GjqQgY0FgawBeFshLXGqkOJZcMIrtO6roqHzUJOPkK/C0wUhOQK7gwbMMQJipApIpC368qs4DKLiiL3kO068XKB9dBDp5ofx6XhBYTwE5igeQDHDnFYMzBaTz6ABegKwhCqhBA5AXq+Kr4jxjZcqFMIEQ1i9BPq7nOCOOARUBv+7qOacoIK9RCogblnh7Th9W/QD1gFoK6OWCvN6rjXCicsEoIM7GVV1+VY7IUTN5ANHHSwrPm5UMFeTJQLVB4PSYihZ345nARcpHFwF/+NT9FKGAQmoOAsunqEpWVU+Ao5ITBM41AFEBsnpAMxPBOHWSly+gP4ajHTuHoIAKGoBG6CfPTQZ9HdLaJDAOIwWkqoDc5oLA8uXnXrtoBtNhZSAAawCaQszT698XMreCMlBVZaJ7iGVFgQxTDEBd+RdJhqqHuqbw8X6LBoH9qOdqnhql7JFEDZsRxwDc5DmL1x2zseIwykBJ0kCrklUT3cevT6rHsFOMAiqpHkDGteQ1lUznYD5GNgXEJ8U8+WIjogcOz3E0MtDCH28avQYKqFfxAMrCAyh2TjrPgsftOrUQHGANQFPIy1yNuegCBsBN15vXNUZRE8Y4TCogV1kN8xVPPg2iVxNVvGSFRL7yrAVBaj+6stI68EzgUZOBSgHWxOvCA8huCKM3vE6mDNR0TBO/7hU0AHEMIEBIs+v7yBnVjUzCcS0gUwyAxXzyvJVGKSB+zGRFUqdQEbuRgscz1HPmiVzNegCxAUhSQAGlordyXiylHbAGoAnEZXf17xdtCcn2oZQbDkNta0TX0ctA+arWFARWH84sCihLBqqbBHhjeBW6jGIdRB6AQfraKEyrcb4qzvIATFr7FEWnJoI1WAqCewRZ/YDlz9d9mqvuKXtu7AE0FQQ2UUBs5Z9LATUYBGbHVHsBFy9iNxLwuIbJA6goE385Q6ml+7y8huEFHHlv5U70ADpvROMAeUW3Ypc4f19q03HT6tnUE5ivwNVglZCBKhNUZl9czbGzVqxy31p1P0UmopLiAYyUAnINnpfjkJTcVoWp765qeAOlIYxKBXEICshgUPPqwvAVaLUAt1+OvoeQNiYDLRoELuoBNEI/scQv6X8yVolgXK+vxgD0eQDlghRQ2WON5FMy0JBK3cA6b7rtvBGNA+RTQNkrKxmpcsOapizsWI3lAaiSyCIlkf2ApmgYN8MAlD1XqwKqB+kWlTqUo1IQJulro1DpLhme6wh5qg5BqC/u5yoqoLhWU/I7NvUE1nV2AwpQQEqnr2wPgF1HQvKzr3XHMPHcvQ0GgRuNAcj3+VjlAcRqH6J9vdlSEAAzLrL37roEfhiKGIBVAb1MEBsA/fuCAioSBNZ4AMaVqNYD4BSQnmpQa9Zk8+BpGSiX7OkCgWWXGPsBFHmYy1ExOLXNYrPI4qI9hwh5qg5ZQWCdDFT1NtRj8pVjqhZQQRVQstNX9r1Uch1RCqKhIHCOB9CoCqghA+CSBOUz1olg6rFSQeAGM4H5PtKJYED/cOd6AG0zAISQfySEPEkIeZwQ8tV2jaMZmJqHcMS0S/6+5IJRfN+6FZlal54j9gCSE7SrrIb56thEAYUhRUhNZQGIPgbgOcZicIU9gCBMtVlsFsLz0p2DQUXFYWrwo6Po+P6Sx0yer7EWEClmAGQPIKsjGN9WUEBNxABM35VIBMsZa6MNYQCk8gAcQsZEBsrPSRVaGD2ABgxAX8VLKZsCiQLqRA+gLSMihJwG4AIAr6CUVgkhs9oxjmaRV+pAV+3QBFXeqWvKAqTlohzGTGDloRQxAMMkmKXd9xzHQAE5Wg8gq1dC4vMuqzXDaaSRl4JIejuJ91wnOwciDLWTrI6ik49l9gA415zcHx9akfo6hMRF3nIpoOiaN+IBmHIVOBqlgBrKA3CcxPZjTQGZEsFkw+06pCEKqK/iYedQXfwfy0A7Nw+gXSbpAwC+QimtAgCldFMrD/ad257BNY++OGr748lXphvWIWB8bEED8JfV23DW1+8EALy0cxh7Te3WbrdzqC6249gxFPcxVbcH0rVqPva75dq+pCE1xzVMHkDJdXDX05tTY9qwcxh7TKpozlb5fPRwff2Wp6OxjswhzaKAXIfgmkdexAOrtmk/+8KOIew/qy/1uucSbO6vinPcOlBLHitXBaTPSchbDRJCUHId/Or+tdg17GcuJkqug2VrtsMhwPwZvZn7TYwxoxw0GyNXARXLAxiZDJQ09PlmIVRAqWqgUSKY9HrZdRqmgPhqH2DXY8OuYfzsz6vRVRqbTOdG0S4DcACAkwghXwYwDOAjlNIHdRsSQi4BcAkAzJ8/v6mD7TGpgv1npx/ukeDI+dNw3KIZ2vcIIbj03INw4v4zc/fzdycswE2PbxD/7z+7D6cekHaIzj98T2zur2obuuw5pRvTe8uJ147bdwbed/IiHDR3MgDgoLmT8cal8xI3qIqD95yCsw5OH/ujrz4QB0f7kfGuVy7EbU9uTL2+/+w+vHK//HM/86DZWPniLvhhiFmTujCrgNHIQlfJxcfPWYwzD5qdeu/9p+yLh9bqJ38+5rMOTn/uwiPmYdeQDwp23fcHsN+sSSLJ7ayDZ2PXkI8Z6vVfNB3vO3lR6rrtu0cv3n/KvjjlgD1yz+dDZ+yPx1/cCQKCC4/Yy7jdO45fgD8+xhY4px1Y3Jl+9SFzMFwPMKVb36jk2IUzcMnJi3Dk/GmZ+5nc5eEjrzoArz5kTuFjf+DUfRNG8F2vXIihejqnZLRxwOw+fODUfXHS/snrP6mrhI+dfSDOls7h4+cszj13Ge86cWHCA7jwyL3QX2X3zpK9pox88C0AyeoQNaIdE3IrAN0dcSmALwO4HcA/ATgawBUAFtGcwSxdupQuW7ZstIdqYWFh8bIGIeQhSulS9fWWeQCU0jMzBvMBAFdFE/5fCCEhgJkANrdqPBYWFhYWSbSLlPoDgNMAgBByAIAygC1tGouFhYXFhES7YgA/AfATQsgKADUA78ijfywsLCwsRhdtMQCU0hqAt7Xj2BYWFhYWDJ2nS7KwsLCwGBNYA2BhYWExQWENgIWFhcUEhTUAFhYWFhMULUsEawUIIZsBrG3y4zPR+VJTO8bRgR3jyNHp4wPsGBvBPpTSVPr5uDIAIwEhZJkuE66TYMc4OrBjHDk6fXyAHeNowFJAFhYWFhMU1gBYWFhYTFBMJAPww3YPoADsGEcHdowjR6ePD7BjHDEmTAzAwsLCwiKJieQBWFhYWFhIsAbAwsLCYoJiQhgAQsjZhJCnCCHPEkI+3gHj2ZsQcjshZCUh5HFCyIei16cTQm4hhDwT/S7ejqh1Y3UJIX8lhFwX/b+QEPJAdC2vIISU8/bR4vFNJYT8jhDyJCHkCULI8Z12HQkh/xJ9zysIIf9LCOlq93UkhPyEELIpqsjLX9NeN8Lw7WisywkhR7ZxjP8ZfdfLCSG/J4RMld77RDTGpwghr27XGKX3PkwIoYSQmdH/bbmOWXjZGwBCiAvguwDOAXAwgDcTQg5u76jgA/gwpfRgAMcB+IdoTB8HcBuldH8At0X/txsfAvCE9P9/APgGpXQ/ANsBvLsto4rxLQA3UkoXA3gF2Fg75joSQvYC63y3lFK6BIAL4E1o/3X8GYCzlddM1+0csG6Y+4O1Z/1eG8d4C4AllNLDADwN4BMAED0/bwJwSPSZ/46e/XaMEYSQvQG8CsDz0svtuo5mUEpf1j8Ajgdwk/T/JwB8ot3jUsZ4NYCzADwFYG702lwAT7V5XPPAJoLTAVwHgIBlNXq6a9uG8U0BsBqRmEF6vWOuI4C9AKwDMB2s/Pp1AF7dCdcRwAIAK/KuG4AfAHizbruxHqPy3oUALo/+TjzXAG4CcHy7xgjgd2ALkjUAZrb7Opp+XvYeAOIHkGN99FpHgBCyAMARAB4AMJtS+lL01gYA6S7lY4tvAvgYgDD6fwaAHZRS3lm+3ddyIVgb0Z9GNNX/EEJ60UHXkVL6AoDLwFaCLwHYCeAhdNZ15DBdt059ht4F4Ibo744ZIyHkAgAvUEofVd7qmDFyTAQD0LEghPQBuBLAP1NKd8nvUbZEaJtGlxDyWgCbKKUPtWsMBeABOBLA9yilRwAYgEL3dMB1nAbgAjBjtSeAXmgog05Du69bHgghl4JRqZe3eywyCCE9AD4J4DPtHksRTAQD8AKAvaX/50WvtRWEkBLY5H85pfSq6OWNhJC50ftzAWxq1/gAvBLA+YSQNQB+A0YDfQvAVEII7yTX7mu5HsB6SukD0f+/AzMInXQdzwSwmlK6mVJaB3AV2LXtpOvIYbpuHfUMEUL+DsBrAbw1MlRA54xxXzBj/2j07MwD8DAhZA46Z4wCE8EAPAhg/0h1UQYLFF3TzgERQgiAHwN4glL6demtawC8I/r7HWCxgbaAUvoJSuk8SukCsGv2J0rpWwHcDuDiaLN2j3EDgHWEkAOjl84AsBIddB3BqJ/jCCE90ffOx9gx11GC6bpdA+BvIxXLcQB2SlTRmIIQcjYYLXk+pXRQeusaAG8ihFQIIQvBAq1/GevxUUofo5TOopQuiJ6d9QCOjO7VjrmOAu0MQIzVD4BzwRQDzwG4tAPGcyKYe70cwCPRz7lgHPttAJ4BcCuA6e0eazTeUwFcF/29COzBehbA/wGotHlshwNYFl3LPwCY1mnXEcDnATwJYAWAXwKotPs6AvhfsJhEHWySerfpuoEF/78bPT+PgSma2jXGZ8F4dP7cfF/a/tJojE8BOKddY1TeX4M4CNyW65j1Y0tBWFhYWExQTAQKyMLCwsJCA2sALCwsLCYorAGwsLCwmKCwBsDCwsJigsIaAAsLC4sJCmsALCwKghDyBULImaOwn/7RGI+FxUhhZaAWFmMMQkg/pbSv3eOwsLAegMWEBiHkbYSQvxBCHiGE/ICw/gf9hJBvRDX8byOE7BFt+zNCyMXR318hrJ/DckLIZdFrCwghf4peu40QMj96fSEh5D5CyGOEkC8px/8oIeTB6DOfH+vzt5jYsAbAYsKCEHIQgL8B8EpK6eEAAgBvBSvYtoxSegiAOwF8VvncDLBSxIdQVpeeT+rfAfDz6LXLAXw7ev1bYAXrDgXLGuX7eRVYyYJjwDKajyKEnDz6Z2phoYc1ABYTGWcAOArAg4SQR6L/F4GVv74i2uZXYKU7ZOwEMAzgx4SQ1wPgNWmOB/Dr6O9fSp97JVjJAP46x6uin78CeBjAYjCDYGExJvDyN7GweNmCgK3YP5F4kZBPK9slAmWUUp8QcgyYwbgYwAfBqqVmQRdsIwD+nVL6g4ZGbWExSrAegMVExm0ALiaEzAJET9x9wJ4LXqnzLQDukT8U9XGYQim9HsC/gHV+AoA/g1VOBRiVdHf0973K6xw3AXhXtD8QQvbiY7GwGAtYD8BiwoJSupIQ8ikANxNCHLCKjv8A1ljmmOi9TWBxAhmTAFxNCOkCW8X/v+j1fwTrTvZRsE5l74xe/xCAXxNC/hVS2WdK6c1RHOI+Vika/QDehvb2L7CYQLAyUAsLBVamaTFRYCkgCwsLiwkK6wFYWFhYTFBYD8DCwsJigsIaAAsLC4sJCmsALCwsLCYorAGwsLCwmKCwBsDCwsJiguL/A52TrJyNBoECAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_all(*run_experiment(\n",
    "    model=ModelConfig(name='linear'),\n",
    "    value_function=ValueConfig(name='hybrid', gamma=[0.0, 0.0, 200]),\n",
    "    eps=[0.0, 0.0, 400],\n",
    "    num_episodes=150,\n",
    "    training=TrainConfig(train_interval=16, batch_size=64, clear_memory=False, lr=0.07)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86188ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(*run_experiment(\n",
    "    model=ModelConfig(name='linear'),\n",
    "    value_function=ValueConfig(name='hybrid', gamma=[0.0, 0.0, 200]),\n",
    "    eps=[0.0, 0.0, 400],\n",
    "    num_episodes=300,\n",
    "    training=TrainConfig(train_interval=16, batch_size=64, clear_memory=False, lr=0.07)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fcc0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
