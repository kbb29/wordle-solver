{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ebc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pathlib, random, time\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fdc686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lists.json') as f:\n",
    "    j = json.load(f)\n",
    "\n",
    "target_list = j['target']\n",
    "guess_list = j[\"guess\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9f9b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_freq(lst):\n",
    "    hist = defaultdict(int)\n",
    "    for word in lst:\n",
    "        for char in word:\n",
    "            hist[char] += 1\n",
    "    mx = max(hist.values())\n",
    "    for char in hist:\n",
    "        hist[char] /= mx\n",
    "    return hist\n",
    "\n",
    "def print_char_freq(cf):\n",
    "    for char in sorted(list(cf.keys())):\n",
    "        print(f'{char}: {cf[char]}')\n",
    "        \n",
    "def freq_score(word, cf):\n",
    "    return sum(cf[x] for x in word) / len(word) \n",
    "\n",
    "def uniq_score(word):\n",
    "    return (len(word) - len(set(word))) / (len(word) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2c056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cf = char_freq(target_list)\n",
    "#print_char_freq(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ef9d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loins\n",
      "agate\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(guess_list))\n",
    "print(random.choice(target_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f251bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = pd.DataFrame([[w, freq_score(w, cf), uniq_score(w), 1] for w in guess_list], columns=['word', 'freq_score', 'uniq_score', 'is_guess_word'])\n",
    "dft = pd.DataFrame([[w, freq_score(w, cf), uniq_score(w), 0] for w in target_list], columns=['word', 'freq_score', 'uniq_score', 'is_guess_word'])\n",
    "df = dfg.append(dft)\n",
    "df.set_index('word', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c6abba1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 2595, 5190, 7785, 10380], [2595, 5190, 7785, 10380, 12972])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a94b0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_to_state(guesses, history):\n",
    "    #print(history)\n",
    "    #so the state is going to be:\n",
    "        #  The number of green locations we know\n",
    "        #  The number of other letters we know to be in the word\n",
    "        #  The sequence number of the guess (1st guess, 2nd guess etc.)\n",
    "    \n",
    "    #the number of locations which were green at some point in the history\n",
    "    num_green_locs = np.count_nonzero(history.max(axis=0) == 2)\n",
    "    \n",
    "    green_chars = [guesses[x][y] for x,y in np.argwhere(history == 2) ]\n",
    "    orange_chars = [guesses[x][y] for x,y in np.argwhere(history == 1) ]\n",
    "    num_other_letters = len(set(orange_chars) - set(green_chars))\n",
    "    \n",
    "    sequence_number = history.shape[0]\n",
    "    \n",
    "    return np.array([num_green_locs, num_other_letters, sequence_number]) / 5\n",
    "\n",
    "def word_to_action(word, guesses, history):\n",
    "    return dfword_to_action((word, df.loc[word]), guesses, history)\n",
    "    \n",
    "def dfword_to_action(dfword, guesses, history):\n",
    "    #the action is going to be a word that we will submit next\n",
    "    #for the purposes of feeding into the model, we will represent the action word as:\n",
    "    #  how many of the entries in the hint history this word conforms to\n",
    "    #  how many untried letters it gives us\n",
    "    #  the number of uniq letters in the word\n",
    "    #  the frequency of the letters in the word\n",
    "    #  whether or not the word is in the guess list (as opposed to the target list)\n",
    "    word = dfword[0]\n",
    "    dfword = dfword[1]\n",
    "    if guesses:\n",
    "        conforms_to_history = sum([int(validate_against_hint(word,g,history[i])) for i,g in enumerate(guesses)]) / len(guesses)\n",
    "    else: # we haven't made any guess yet, so this must conform\n",
    "        conforms_to_history = 1.0\n",
    "    num_untried_letters = len(set(word) - set(''.join(guesses))) / 5 #normalise to 1\n",
    "    return np.array([conforms_to_history, num_untried_letters, dfword['freq_score'], dfword['uniq_score'], dfword['is_guess_word']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "895b599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global = None\n",
    "\n",
    "def construct_actions_global(arg): #guesses, history, start_idx, end_idx):\n",
    "    #global df_global\n",
    "    guesses, history, start_idx, end_idx = arg\n",
    "    #print(guesses, history, start_idx, end_idx)\n",
    "    return np.array([dfword_to_action(dfword, guesses, history) for dfword in df.iloc[start_idx:end_idx].iterrows()])\n",
    "    \n",
    "class ActionSpace:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "    \n",
    "    \n",
    "class Env:\n",
    "    def __init__(self, df, target_word=None):\n",
    "        self.df = df\n",
    "        if target_word:\n",
    "            self.target = target_word\n",
    "        else:\n",
    "            self.target = df[df['is_guess_word'] == 0.0].sample().iloc[0].name\n",
    "            \n",
    "        self.num_letters = len(self.target)\n",
    "        self.num_guesses = 6\n",
    "        \n",
    "        self.num_processes = mp.cpu_count() - 1\n",
    "        self.pool = mp.Pool(processes=self.num_processes)\n",
    "        self.action_space = ActionSpace(len(self.df))\n",
    "        \n",
    "    def submit_guess(self, guess):\n",
    "        wrongplace = [0] * len(self.target)\n",
    "        hints = np.zeros(len(self.target))\n",
    "        rightplace = [guess[n] == chrt for n,chrt in enumerate(self.target)]\n",
    "        \n",
    "        for n,chrt in enumerate(self.target):\n",
    "            if rightplace[n] == 1: continue #this character has already been scored, skip it\n",
    "            for m,chrg in enumerate(guess):\n",
    "                if n == m: continue # we've already checked rightplace matches above\n",
    "                if chrt != chrg: continue\n",
    "                if wrongplace[m] == 1: continue\n",
    "                if rightplace[m] == 1: continue\n",
    "                \n",
    "                wrongplace[m] = 1\n",
    "                break\n",
    "\n",
    "        for i in range(len(self.target)):\n",
    "            hints[i] = 2 if rightplace[i] == 1 else wrongplace[i]\n",
    "        \n",
    "        return hints\n",
    "    \n",
    "    def reset(self):\n",
    "        history = np.array([[]])\n",
    "        guesses = []\n",
    "        \n",
    "    def construct_actions(self, guesses, history):\n",
    "        return np.array([dfword_to_action(dfword, guesses, history) for dfword in self.df.iterrows()])\n",
    "    \n",
    "    def construct_actions_mp(self, guesses, history):\n",
    "        #global df_global\n",
    "        \n",
    "        grp_lst_args = []\n",
    "        grp_guesses = [guesses] * self.num_processes\n",
    "        grp_history = [history] * self.num_processes\n",
    "        \n",
    "        #df_global = self.df\n",
    "        chunk_size = int(len(self.df) / self.num_processes) + 1\n",
    "        start_offsets = list(range(0, len(self.df), chunk_size))\n",
    "        end_offsets = start_offsets[1:] + [len(self.df)]\n",
    "        grp_lst_args = list(zip(grp_guesses, grp_history, start_offsets, end_offsets))\n",
    "        \n",
    "        print(grp_lst_args)\n",
    "        results = self.pool.map(construct_actions_global, grp_lst_args)\n",
    "        self.pool.close()\n",
    "        self.pool.join()\n",
    "        return np.concatenate(results)\n",
    "    \n",
    "    def step_by_index(self, guess_idx):\n",
    "        return self.step(self.df.iloc[guess_idx].name)\n",
    "    \n",
    "    def step(guess): #returns state, reward, done, actions\n",
    "        #print(actions)\n",
    "        hints = e.submit_guess(guess)\n",
    "\n",
    "        print(f'======={guess}========')\n",
    "        print(list(zip(guesses,history)))\n",
    "        if history.size == 0:\n",
    "            history = np.expand_dims(hints,0)\n",
    "        else:\n",
    "            history = np.row_stack([history, hints])\n",
    "        guesses.append(guess)\n",
    "        if hints.sum() == num_letters * 2 or len(guesses) == num_guesses:\n",
    "            reward = hints.sum()\n",
    "            done = True\n",
    "        else:\n",
    "            reward = -1\n",
    "            done = False\n",
    "        return history_to_state(guesses, history), reward, done, self.construct_actions_mp(guesses, history)\n",
    "\n",
    "    \n",
    "def hint_to_hinty(hint):\n",
    "    #hint takes form [0,1,2,1,0]\n",
    "    #hinty takes form {2:[2], 1:[1,3], 0:[0,4]}\n",
    "    hinty = {}\n",
    "    for n in [0,1,2]:\n",
    "        hinty[n] = [i for i, x in enumerate(hint) if x == n]\n",
    "    #print(f'hint_to_hinty() {hint}, {hinty}')\n",
    "    return hinty\n",
    "    \n",
    "def validate_against_hint(word, guess, hint):\n",
    "    return validate_against_hinty(word, guess, hint_to_hinty(hint))\n",
    "\n",
    "def validate_against_hinty(word, guess, hinty):\n",
    "    #hinty takes form {2:[idx,..], 1:[idx,..], 0:[idx,..]}\n",
    "    for idx in hinty[2]: # check the fixed letters first\n",
    "        if word[idx] != guess[idx]:\n",
    "            return False\n",
    "    for idx in hinty[0]:\n",
    "        #get the number of times char appears in target word (minus the times it appears in the correct location)\n",
    "        indices = [i for i,x in enumerate(word) if x == guess[idx] and i not in hinty[2]]\n",
    "        #get number of times char appears in guess word in the wrong location\n",
    "        indices_g = [n for n,x in enumerate(guess) if x == guess[idx] and n in hinty[1]]\n",
    "        #we already know that there is one not-exist hint for this char, so\n",
    "        #if there are more fewer wrong location hints for this letter than there are actual occurrences of the letter\n",
    "        #then the hint does not validate against this word\n",
    "        if len(indices) > len(indices_g):\n",
    "            return False\n",
    "    for idx in hinty[1]:\n",
    "        if word[idx] == guess[idx]:\n",
    "            return False\n",
    "        #get all the indices of the character in the target word\n",
    "        indices = [i for i,x in enumerate(word) if x == guess[idx] and i not in hinty[2]]\n",
    "        #remove all the indices where there is already a fixed position hint\n",
    "        \n",
    "        #now count all the occurences of the char in guess where the location is wrong\n",
    "        indices_g = [i for i,x in enumerate(guess) if x == guess[idx] and i in hinty[1]]\n",
    "        #if there are more wrong loc hints for this char than there are actual occurrences, then it must be bogus\n",
    "        if len(indices) < len(indices_g):\n",
    "            return False\n",
    "    return True            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31bef5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([], array([], shape=(1, 0), dtype=float64), 0, 1180), ([], array([], shape=(1, 0), dtype=float64), 1180, 2360), ([], array([], shape=(1, 0), dtype=float64), 2360, 3540), ([], array([], shape=(1, 0), dtype=float64), 3540, 4720), ([], array([], shape=(1, 0), dtype=float64), 4720, 5900), ([], array([], shape=(1, 0), dtype=float64), 5900, 7080), ([], array([], shape=(1, 0), dtype=float64), 7080, 8260), ([], array([], shape=(1, 0), dtype=float64), 8260, 9440), ([], array([], shape=(1, 0), dtype=float64), 9440, 10620), ([], array([], shape=(1, 0), dtype=float64), 10620, 11800), ([], array([], shape=(1, 0), dtype=float64), 11800, 12972)]\n",
      "0.2215425968170166\n",
      "0.6290931701660156\n",
      "<class 'numpy.ndarray'>\n",
      "(12972, 5)\n",
      "<class 'numpy.ndarray'>\n",
      "(12972, 5)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "e = Env(df)\n",
    "starting_guesses = []\n",
    "starting_history = np.array([[]])\n",
    "st = time.time()\n",
    "rmp = e.construct_actions_mp(starting_guesses, starting_history)\n",
    "print(time.time() - st)\n",
    "st = time.time()\n",
    "r = e.construct_actions(starting_guesses, starting_history)\n",
    "print(time.time() - st)\n",
    "\n",
    "print(r.__class__)\n",
    "print(r.shape)\n",
    "\n",
    "print(rmp.__class__)\n",
    "print(rmp.shape)\n",
    "\n",
    "print((r == rmp).all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "14164929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcde abcde [2. 2. 2. 2. 2.] [2, 2, 2, 2, 2] [ True  True  True  True  True] True\n",
      "abcde acbde [2. 1. 1. 2. 2.] [2, 1, 1, 2, 2] [ True  True  True  True  True] True\n",
      "abcde azcde [2. 0. 2. 2. 2.] [2, 0, 2, 2, 2] [ True  True  True  True  True] True\n",
      "abcde aacde [2. 0. 2. 2. 2.] [2, 0, 2, 2, 2] [ True  True  True  True  True] True\n",
      "abcde zacde [0. 1. 2. 2. 2.] [0, 1, 2, 2, 2] [ True  True  True  True  True] True\n",
      "abcde zzdzz [0. 0. 1. 0. 0.] [0, 0, 1, 0, 0] [ True  True  True  True  True] True\n",
      "abcde zzddz [0. 0. 0. 2. 0.] [0, 0, 0, 2, 0] [ True  True  True  True  True] True\n",
      "abcde zdddz [0. 0. 0. 2. 0.] [0, 0, 0, 2, 0] [ True  True  True  True  True] True\n",
      "abcde ddddd [0. 0. 0. 2. 0.] [0, 0, 0, 2, 0] [ True  True  True  True  True] True\n",
      "abcde zzzdd [0. 0. 0. 2. 0.] [0, 0, 0, 2, 0] [ True  True  True  True  True] True\n",
      "abcde zzdez [0. 0. 1. 1. 0.] [0, 0, 1, 1, 0] [ True  True  True  True  True] True\n",
      "abcae abcde [2. 2. 2. 0. 2.] [2, 2, 2, 0, 2] [ True  True  True  True  True] True\n",
      "abcae acbde [2. 1. 1. 0. 2.] [2, 1, 1, 0, 2] [ True  True  True  True  True] True\n",
      "abcae azcde [2. 0. 2. 0. 2.] [2, 0, 2, 0, 2] [ True  True  True  True  True] True\n",
      "abcae aacde [2. 1. 2. 0. 2.] [2, 1, 2, 0, 2] [ True  True  True  True  True] True\n",
      "abcae zacde [0. 1. 2. 0. 2.] [0, 1, 2, 0, 2] [ True  True  True  True  True] True\n",
      "abcae zzdzz [0. 0. 0. 0. 0.] [0, 0, 0, 0, 0] [ True  True  True  True  True] True\n",
      "abcae zzddz [0. 0. 0. 0. 0.] [0, 0, 0, 0, 0] [ True  True  True  True  True] True\n",
      "abcae zdddz [0. 0. 0. 0. 0.] [0, 0, 0, 0, 0] [ True  True  True  True  True] True\n",
      "abcae ddddd [0. 0. 0. 0. 0.] [0, 0, 0, 0, 0] [ True  True  True  True  True] True\n",
      "abcae zzzdd [0. 0. 0. 0. 0.] [0, 0, 0, 0, 0] [ True  True  True  True  True] True\n",
      "abcae zzdez [0. 0. 0. 1. 0.] [0, 0, 0, 1, 0] [ True  True  True  True  True] True\n",
      "abcae aaaaa [2. 0. 0. 2. 0.] [2, 0, 0, 2, 0] [ True  True  True  True  True] True\n",
      "abcae aaaza [2. 1. 0. 0. 0.] [2, 1, 0, 0, 0] [ True  True  True  True  True] True\n",
      "abcae zaazz [0. 1. 1. 0. 0.] [0, 1, 1, 0, 0] [ True  True  True  True  True] True\n",
      "abcae zaaza [0. 1. 1. 0. 0.] [0, 1, 1, 0, 0] [ True  True  True  True  True] True\n"
     ]
    }
   ],
   "source": [
    "e_simple = Env(target_list, target_word='abcde')\n",
    "tests_simple = {'abcde': [2,2,2,2,2],\n",
    "         'acbde': [2,1,1,2,2],\n",
    "         'azcde': [2,0,2,2,2],\n",
    "         'aacde': [2,0,2,2,2],\n",
    "         'zacde': [0,1,2,2,2],\n",
    "         'zzdzz': [0,0,1,0,0],\n",
    "         'zzddz': [0,0,0,2,0],\n",
    "         'zdddz': [0,0,0,2,0],\n",
    "         'ddddd': [0,0,0,2,0],\n",
    "         'zzzdd': [0,0,0,2,0],\n",
    "         'zzdez': [0,0,1,1,0]}\n",
    "\n",
    "e_repeat = Env(target_list, target_word='abcae')\n",
    "tests_repeat = {'abcde': [2,2,2,0,2],\n",
    "         'acbde': [2,1,1,0,2],\n",
    "         'azcde': [2,0,2,0,2],\n",
    "         'aacde': [2,1,2,0,2],\n",
    "         'zacde': [0,1,2,0,2],\n",
    "         'zzdzz': [0,0,0,0,0],\n",
    "         'zzddz': [0,0,0,0,0],\n",
    "         'zdddz': [0,0,0,0,0],\n",
    "         'ddddd': [0,0,0,0,0],\n",
    "         'zzzdd': [0,0,0,0,0],\n",
    "         'zzdez': [0,0,0,1,0],\n",
    "         'aaaaa': [2,0,0,2,0],\n",
    "         'aaaza': [2,1,0,0,0],\n",
    "         'zaazz': [0,1,1,0,0],\n",
    "         'zaaza': [0,1,1,0,0]}\n",
    "\n",
    "for e,tests in [(e_simple, tests_simple),(e_repeat, tests_repeat)]:\n",
    "    for guess,expected in tests.items():\n",
    "        #guess = random.choice(guess_list + target_list)\n",
    "        actual = e.submit_guess(guess)\n",
    "        hinty = hint_to_hinty(expected)\n",
    "        hinty_valid = validate_against_hinty(e.target, guess, hinty)\n",
    "        print(e.target, guess, actual, expected, expected == actual, hinty_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eca16daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_guess(guess_list, target_list):\n",
    "    guess_idx = random.randint(0, len(guess_list) + len(target_list))\n",
    "    is_guess = guess_idx < len(guess_list)\n",
    "    if is_guess:\n",
    "        word = guess_list[guess_idx]\n",
    "    else:\n",
    "        word = target_list[guess_idx - len(guess_list)]\n",
    "    return word, is_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "9248df4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.4, 0.2] [0.2 0.4 0.2] [ True  True  True]\n",
      "[1.0, 0.4, 0.62287105, 0.0, 0.0] [1.         0.4        0.62287105 0.         0.        ] [ True  True False  True  True]\n"
     ]
    }
   ],
   "source": [
    "#'beast'\n",
    "#Env(target_list, target_word='beast').submit_guess('treat')\n",
    "actual = history_to_state(['treat'], np.array([[0.0, 0.0, 1.0, 1.0, 2.0]]))\n",
    "expected = [0.2, 0.4, 0.2]\n",
    "print(expected, actual, expected == actual)\n",
    "\n",
    "actual = word_to_action('feast', ['treat'], np.array([[0.0, 0.0, 1.0, 1.0, 2.0]]))\n",
    "expected = [1.0, 0.4, 0.62287105, 0.0, 0.0]\n",
    "print(expected, actual, expected == actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "f2b35e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "650e6062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocky\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'construct_actions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-941b60411caf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_guesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#guess, is_guess_list = random_guess(guess_list, target_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguesses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_to_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguesses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#here feed it into a model to choose the word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'construct_actions' is not defined"
     ]
    }
   ],
   "source": [
    "num_guesses = 6\n",
    "e = Env(df)\n",
    "\n",
    "print(e.target)\n",
    "num_letters = len(e.target)\n",
    "history = np.array([[]])\n",
    "guesses = []\n",
    "rewards = []\n",
    "for i in range(num_guesses):\n",
    "    #guess, is_guess_list = random_guess(guess_list, target_list)\n",
    "    actions = construct_actions(guesses, history)\n",
    "    state = history_to_state(guesses, history)\n",
    "    #here feed it into a model to choose the word\n",
    "    #guess, value = np.argmax(model(state)) # but do this epsilon greedy\n",
    "    \n",
    "    #print(actions)\n",
    "    hints = e.submit_guess(guess)\n",
    "    \n",
    "    print(f'======={guess}========')\n",
    "    print(list(zip(guesses,history)))\n",
    "    if history.size == 0:\n",
    "        history = np.expand_dims(hints,0)\n",
    "    else:\n",
    "        history = np.row_stack([history, hints])\n",
    "    guesses.append(guess)\n",
    "    if hints.sum() == num_letters * 2 or i == num_guesses - 1:\n",
    "        reward = hints.sum()\n",
    "        done = True\n",
    "    else:\n",
    "        reward = -1\n",
    "        done = False\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#so the state is going to be:\n",
    "#  The number of green locations we know\n",
    "#  The number of other letters we know to be in the word\n",
    "#  The sequence number of the guess (1st guess, 2nd guess etc.)\n",
    "\n",
    "#the action is going to be a word that we will submit next\n",
    "#for the purposes of feeding into the model, we will represent the action word as:\n",
    "#  whether or not it conforms to the hint history\n",
    "#  how many new letters it gives us\n",
    "#  the number of uniq letters in the word\n",
    "#  the frequency of the letters in the word\n",
    "\n",
    "#the reward is going to be:\n",
    "#  -1 on all states except the last one\n",
    "#  on the last state (which can either be after guess 6 or on guessing the correct word):\n",
    "#    the sum of the last hint (ie. 2 for a correct letter/position combo, 1 for a letter in the wrong place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9dd99de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "832e7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ae28e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb9ed4c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Env' object has no attribute 'action_space'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-cae50f10a9f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Get number of actions from gym action space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mn_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpolicy_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Env' object has no attribute 'action_space'"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state, actions):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            #now combine the state (shape 3,) and action (shape 5, n) into one input array (shape 8,n)\n",
    "            #first expand the state so that it is shape 3,1\n",
    "            #then repeat it to 3,n\n",
    "            state = np.repeat(np.expand_dims(state, 0), actions.shape[0], axis=0)\n",
    "            #then concatenate to 8,n\n",
    "            state_action = np.concatenate((state, action), axis=1)\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state_action).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14c1200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71c62073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.  0.2] [[1.         0.8        0.64444444 0.33333333 1.        ]\n",
      " [1.         0.6        0.65190592 0.66666667 1.        ]\n",
      " [1.         0.8        0.57696675 0.33333333 1.        ]\n",
      " ...\n",
      " [1.         1.         0.60032441 0.         0.        ]\n",
      " [1.         0.8        0.64282238 0.33333333 0.        ]\n",
      " [1.         1.         0.55523114 0.         0.        ]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'select_action' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-22290a38262f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Select and perform an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'select_action' is not defined"
     ]
    }
   ],
   "source": [
    "#https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "env = Env(df)\n",
    "num_episodes = 50\n",
    "starting_guesses = []\n",
    "starting_history = np.array([[]])\n",
    "starting_actions = env.construct_actions(starting_guesses, starting_history)\n",
    "starting_state = history_to_state(starting_guesses, starting_history)\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "\n",
    "    state = starting_state\n",
    "    actions = starting_actions\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        print(state, actions)\n",
    "        action = select_action(state, actions)\n",
    "        state, reward, done, actions = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
