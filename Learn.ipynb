{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ebc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pathlib, random, time\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdc686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lists.json') as f:\n",
    "    j = json.load(f)\n",
    "\n",
    "target_list = j['target']\n",
    "guess_list = j[\"guess\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_freq(lst):\n",
    "    hist = defaultdict(int)\n",
    "    for word in lst:\n",
    "        for char in word:\n",
    "            hist[char] += 1\n",
    "    mx = max(hist.values())\n",
    "    for char in hist:\n",
    "        hist[char] /= mx\n",
    "    return hist\n",
    "\n",
    "def print_char_freq(cf):\n",
    "    for char in sorted(list(cf.keys())):\n",
    "        print(f'{char}: {cf[char]}')\n",
    "        \n",
    "def freq_score(word, cf):\n",
    "    return sum(cf[x] for x in word) / len(word) \n",
    "\n",
    "def uniq_score(word):\n",
    "    return (len(word) - len(set(word))) / (len(word) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cf = char_freq(target_list)\n",
    "#print_char_freq(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ef9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random.choice(guess_list))\n",
    "print(random.choice(target_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f251bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = pd.DataFrame([[w, freq_score(w, cf), uniq_score(w), 1] for w in guess_list], columns=['word', 'freq_score', 'uniq_score', 'is_guess_word'])\n",
    "dft = pd.DataFrame([[w, freq_score(w, cf), uniq_score(w), 0] for w in target_list], columns=['word', 'freq_score', 'uniq_score', 'is_guess_word'])\n",
    "df = dfg.append(dft)\n",
    "df.set_index('word', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2801]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def word_to_action(word, guesses, history):\n",
    "    return dfword_to_action((word, df.loc[word]), guesses, history)\n",
    "    \n",
    "def dfword_to_action(dfword, guesses, history):\n",
    "    #the action is going to be a word that we will submit next\n",
    "    #for the purposes of feeding into the model, we will represent the action word as:\n",
    "    #  how many of the entries in the hint history this word conforms to\n",
    "    #  how many untried letters it gives us\n",
    "    #  the number of uniq letters in the word\n",
    "    #  the frequency of the letters in the word\n",
    "    #  whether or not the word is in the guess list (as opposed to the target list)\n",
    "    word = dfword[0]\n",
    "    dfword = dfword[1]\n",
    "    if guesses:\n",
    "        conforms_to_history = sum([int(validate_against_hint(word,g,history[i])) for i,g in enumerate(guesses)]) / len(guesses)\n",
    "    else: # we haven't made any guess yet, so this must conform\n",
    "        conforms_to_history = 1.0\n",
    "    num_untried_letters = len(set(word) - set(''.join(guesses))) / 5 #normalise to 1\n",
    "    return np.array([conforms_to_history, num_untried_letters, dfword['freq_score'], dfword['uniq_score'], dfword['is_guess_word']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global = None\n",
    "\n",
    "def construct_actions_global(arg): #guesses, history, start_idx, end_idx):\n",
    "    #global df_global\n",
    "    guesses, history, start_idx, end_idx = arg\n",
    "    #print(guesses, history, start_idx, end_idx)\n",
    "    return np.array([dfword_to_action(dfword, guesses, history) for dfword in df.iloc[start_idx:end_idx].iterrows()])\n",
    "    \n",
    "class ActionSpace:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "    \n",
    "    \n",
    "class Env:\n",
    "    def __init__(self, df, target_word=None):\n",
    "        self.df = df\n",
    "        if target_word:\n",
    "            self.target = target_word\n",
    "        else:\n",
    "            self.target = df[df['is_guess_word'] == 0.0].sample().iloc[0].name\n",
    "            \n",
    "        self.num_letters = len(self.target)\n",
    "        self.num_guesses = 6\n",
    "        \n",
    "        self.num_processes = mp.cpu_count() - 1\n",
    "        self.action_space = ActionSpace(len(self.df))\n",
    "        self.reset()\n",
    "        \n",
    "    def submit_guess(self, guess):\n",
    "        wrongplace = [0] * len(self.target)\n",
    "        hints = np.zeros(len(self.target))\n",
    "        rightplace = [guess[n] == chrt for n,chrt in enumerate(self.target)]\n",
    "        \n",
    "        for n,chrt in enumerate(self.target):\n",
    "            if rightplace[n] == 1: continue #this character has already been scored, skip it\n",
    "            for m,chrg in enumerate(guess):\n",
    "                if n == m: continue # we've already checked rightplace matches above\n",
    "                if chrt != chrg: continue\n",
    "                if wrongplace[m] == 1: continue\n",
    "                if rightplace[m] == 1: continue\n",
    "                \n",
    "                wrongplace[m] = 1\n",
    "                break\n",
    "\n",
    "        for i in range(len(self.target)):\n",
    "            hints[i] = 2 if rightplace[i] == 1 else wrongplace[i]\n",
    "        \n",
    "        return hints\n",
    "    \n",
    "    def reset(self):\n",
    "        self.history = np.array([[]])\n",
    "        self.guesses = []\n",
    "        \n",
    "    def construct_actions(self):\n",
    "        return np.array([dfword_to_action(dfword, self.guesses, self.history) for dfword in self.df.iterrows()])\n",
    "    \n",
    "    def construct_actions_mp(self):\n",
    "        #global df_global\n",
    "        \n",
    "        grp_lst_args = []\n",
    "        grp_guesses = [self.guesses] * self.num_processes\n",
    "        grp_history = [self.history] * self.num_processes\n",
    "        \n",
    "        #df_global = self.df\n",
    "        chunk_size = int(len(self.df) / self.num_processes) + 1\n",
    "        start_offsets = list(range(0, len(self.df), chunk_size))\n",
    "        end_offsets = start_offsets[1:] + [len(self.df)]\n",
    "        grp_lst_args = list(zip(grp_guesses, grp_history, start_offsets, end_offsets))\n",
    "        \n",
    "        #print(grp_lst_args)\n",
    "        self.pool = mp.Pool(processes=self.num_processes)\n",
    "        results = self.pool.map(construct_actions_global, grp_lst_args)\n",
    "        self.pool.close()\n",
    "        self.pool.join()\n",
    "        return np.concatenate(results)\n",
    "    \n",
    "    def construct_state(self):\n",
    "        #print(history)\n",
    "        #so the state is going to be:\n",
    "            #  The number of green locations we know\n",
    "            #  The number of other letters we know to be in the word\n",
    "            #  The sequence number of the guess (1st guess, 2nd guess etc.)\n",
    "\n",
    "        #the number of locations which were green at some point in the history\n",
    "        num_green_locs = np.count_nonzero(self.history.max(axis=0) == 2)\n",
    "\n",
    "        green_chars = [self.guesses[x][y] for x,y in np.argwhere(self.history == 2) ]\n",
    "        orange_chars = [self.guesses[x][y] for x,y in np.argwhere(self.history == 1) ]\n",
    "        num_other_letters = len(set(orange_chars) - set(green_chars))\n",
    "\n",
    "        sequence_number = self.history.shape[0]\n",
    "\n",
    "        return np.array([num_green_locs, num_other_letters, sequence_number]) / 5\n",
    "\n",
    "    def step_by_index(self, guess_idx):\n",
    "        return self.step(self.df.iloc[guess_idx].name)\n",
    "    \n",
    "    \n",
    "    def step(self, guess): #returns state, reward, done, actions\n",
    "        #print(actions)\n",
    "        hints = e.submit_guess(guess)\n",
    "\n",
    "        print(f'======={guess} => {hints}========')\n",
    "        print(list(zip(self.guesses,self.history)))\n",
    "        if self.history.size == 0:\n",
    "            self.history = np.expand_dims(hints,0)\n",
    "        else:\n",
    "            self.history = np.row_stack([self.history, hints])\n",
    "        self.guesses.append(guess)\n",
    "        if hints.sum() == self.num_letters * 2 or len(self.guesses) == self.num_guesses:\n",
    "            reward = hints.sum()\n",
    "            done = True\n",
    "        else:\n",
    "            reward = -1\n",
    "            done = False\n",
    "        state = self.construct_state() \n",
    "        actions = self.construct_actions_mp()\n",
    "        return state, reward, done, actions\n",
    "\n",
    "    \n",
    "def hint_to_hinty(hint):\n",
    "    #hint takes form [0,1,2,1,0]\n",
    "    #hinty takes form {2:[2], 1:[1,3], 0:[0,4]}\n",
    "    hinty = {}\n",
    "    for n in [0,1,2]:\n",
    "        hinty[n] = [i for i, x in enumerate(hint) if x == n]\n",
    "    #print(f'hint_to_hinty() {hint}, {hinty}')\n",
    "    return hinty\n",
    "    \n",
    "def validate_against_hint(word, guess, hint):\n",
    "    return validate_against_hinty(word, guess, hint_to_hinty(hint))\n",
    "\n",
    "def validate_against_hinty(word, guess, hinty):\n",
    "    #hinty takes form {2:[idx,..], 1:[idx,..], 0:[idx,..]}\n",
    "    for idx in hinty[2]: # check the fixed letters first\n",
    "        if word[idx] != guess[idx]:\n",
    "            return False\n",
    "    for idx in hinty[0]:\n",
    "        #get the number of times char appears in target word (minus the times it appears in the correct location)\n",
    "        indices = [i for i,x in enumerate(word) if x == guess[idx] and i not in hinty[2]]\n",
    "        #get number of times char appears in guess word in the wrong location\n",
    "        indices_g = [n for n,x in enumerate(guess) if x == guess[idx] and n in hinty[1]]\n",
    "        #we already know that there is one not-exist hint for this char, so\n",
    "        #if there are more fewer wrong location hints for this letter than there are actual occurrences of the letter\n",
    "        #then the hint does not validate against this word\n",
    "        if len(indices) > len(indices_g):\n",
    "            return False\n",
    "    for idx in hinty[1]:\n",
    "        if word[idx] == guess[idx]:\n",
    "            return False\n",
    "        #get all the indices of the character in the target word\n",
    "        indices = [i for i,x in enumerate(word) if x == guess[idx] and i not in hinty[2]]\n",
    "        #remove all the indices where there is already a fixed position hint\n",
    "        \n",
    "        #now count all the occurences of the char in guess where the location is wrong\n",
    "        indices_g = [i for i,x in enumerate(guess) if x == guess[idx] and i in hinty[1]]\n",
    "        #if there are more wrong loc hints for this char than there are actual occurrences, then it must be bogus\n",
    "        if len(indices) < len(indices_g):\n",
    "            return False\n",
    "    return True            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bef5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Env(df)\n",
    "e.reset()\n",
    "st = time.time()\n",
    "rmp = e.construct_actions_mp()\n",
    "print(time.time() - st)\n",
    "e.reset()\n",
    "st = time.time()\n",
    "r = e.construct_actions()\n",
    "print(time.time() - st)\n",
    "\n",
    "print(r.__class__)\n",
    "print(r.shape)\n",
    "\n",
    "print(rmp.__class__)\n",
    "print(rmp.shape)\n",
    "\n",
    "print((r == rmp).all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14164929",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_simple = Env(target_list, target_word='abcde')\n",
    "tests_simple = {'abcde': [2,2,2,2,2],\n",
    "         'acbde': [2,1,1,2,2],\n",
    "         'azcde': [2,0,2,2,2],\n",
    "         'aacde': [2,0,2,2,2],\n",
    "         'zacde': [0,1,2,2,2],\n",
    "         'zzdzz': [0,0,1,0,0],\n",
    "         'zzddz': [0,0,0,2,0],\n",
    "         'zdddz': [0,0,0,2,0],\n",
    "         'ddddd': [0,0,0,2,0],\n",
    "         'zzzdd': [0,0,0,2,0],\n",
    "         'zzdez': [0,0,1,1,0]}\n",
    "\n",
    "e_repeat = Env(target_list, target_word='abcae')\n",
    "tests_repeat = {'abcde': [2,2,2,0,2],\n",
    "         'acbde': [2,1,1,0,2],\n",
    "         'azcde': [2,0,2,0,2],\n",
    "         'aacde': [2,1,2,0,2],\n",
    "         'zacde': [0,1,2,0,2],\n",
    "         'zzdzz': [0,0,0,0,0],\n",
    "         'zzddz': [0,0,0,0,0],\n",
    "         'zdddz': [0,0,0,0,0],\n",
    "         'ddddd': [0,0,0,0,0],\n",
    "         'zzzdd': [0,0,0,0,0],\n",
    "         'zzdez': [0,0,0,1,0],\n",
    "         'aaaaa': [2,0,0,2,0],\n",
    "         'aaaza': [2,1,0,0,0],\n",
    "         'zaazz': [0,1,1,0,0],\n",
    "         'zaaza': [0,1,1,0,0]}\n",
    "\n",
    "for e,tests in [(e_simple, tests_simple),(e_repeat, tests_repeat)]:\n",
    "    for guess,expected in tests.items():\n",
    "        #guess = random.choice(guess_list + target_list)\n",
    "        actual = e.submit_guess(guess)\n",
    "        hinty = hint_to_hinty(expected)\n",
    "        hinty_valid = validate_against_hinty(e.target, guess, hinty)\n",
    "        print(e.target, guess, actual, expected, expected == actual, hinty_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca16daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_guess(guess_list, target_list):\n",
    "    guess_idx = random.randint(0, len(guess_list) + len(target_list))\n",
    "    is_guess = guess_idx < len(guess_list)\n",
    "    if is_guess:\n",
    "        word = guess_list[guess_idx]\n",
    "    else:\n",
    "        word = target_list[guess_idx - len(guess_list)]\n",
    "    return word, is_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9248df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'beast'\n",
    "e = Env(df, target_word='beast')\n",
    "e.step('treat')\n",
    "#e.guesses = ['treat']\n",
    "#e.history = np.array([[0.0, 0.0, 1.0, 1.0, 2.0]])\n",
    "#Env(target_list, target_word='beast').submit_guess('treat')\n",
    "print(e.guesses, e.history)\n",
    "actual = e.construct_state()\n",
    "expected = [0.2, 0.4, 0.2]\n",
    "print(expected, actual, expected == actual)\n",
    "\n",
    "actual = word_to_action('feast', ['treat'], np.array([[0.0, 0.0, 1.0, 1.0, 2.0]]))\n",
    "expected = [1.0, 0.4, 0.62287105, 0.0, 0.0]\n",
    "print(expected, actual, expected == actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e6062",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_guesses = 6\n",
    "e = Env(df)\n",
    "\n",
    "print(e.target)\n",
    "num_letters = len(e.target)\n",
    "history = np.array([[]])\n",
    "guesses = []\n",
    "rewards = []\n",
    "for i in range(num_guesses):\n",
    "    #guess, is_guess_list = random_guess(guess_list, target_list)\n",
    "    actions = e.construct_actions_mp()\n",
    "    state = e.construct_state()\n",
    "    #here feed it into a model to choose the word\n",
    "    #guess, value = np.argmax(model(state)) # but do this epsilon greedy\n",
    "    \n",
    "    #print(actions)\n",
    "    hints = e.submit_guess(guess)\n",
    "    \n",
    "    print(f'======={guess}========')\n",
    "    print(list(zip(guesses,history)))\n",
    "    if history.size == 0:\n",
    "        history = np.expand_dims(hints,0)\n",
    "    else:\n",
    "        history = np.row_stack([history, hints])\n",
    "    guesses.append(guess)\n",
    "    if hints.sum() == num_letters * 2 or i == num_guesses - 1:\n",
    "        reward = hints.sum()\n",
    "        done = True\n",
    "    else:\n",
    "        reward = -1\n",
    "        done = False\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#so the state is going to be:\n",
    "#  The number of green locations we know\n",
    "#  The number of other letters we know to be in the word\n",
    "#  The sequence number of the guess (1st guess, 2nd guess etc.)\n",
    "\n",
    "#the action is going to be a word that we will submit next\n",
    "#for the purposes of feeding into the model, we will represent the action word as:\n",
    "#  whether or not it conforms to the hint history\n",
    "#  how many new letters it gives us\n",
    "#  the number of uniq letters in the word\n",
    "#  the frequency of the letters in the word\n",
    "\n",
    "#the reward is going to be:\n",
    "#  -1 on all states except the last one\n",
    "#  on the last state (which can either be after guess 6 or on guessing the correct word):\n",
    "#    the sum of the last hint (ie. 2 for a correct letter/position combo, 1 for a letter in the wrong place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd99de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae28e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, inputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(inputs, 20)\n",
    "        self.fc2 = nn.Linear(20, 16)\n",
    "        self.fc3 = nn.Linear(16, 20)\n",
    "        self.head = nn.Linear(20, 1)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ed4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "#n_actions = env.action_space.n\n",
    "n_action_features = 5\n",
    "n_state_features = 3\n",
    "n_input_features = n_action_features + n_state_features\n",
    "\n",
    "policy_net = DQN(n_input_features).to(device)\n",
    "target_net = DQN(n_input_features).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state, actions):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if True or sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            #now combine the state (shape 3,) and action (shape 5, n) into one input array (shape 8,n)\n",
    "            #first expand the state so that it is shape 3,1\n",
    "            #then repeat it to 3,n\n",
    "            states = np.repeat(np.expand_dims(state, 0), actions.shape[0], axis=0)\n",
    "            print(f'states shape {states.shape} actions shape {actions.shape}')\n",
    "            #then concatenate to 8,n\n",
    "            state_actions = np.concatenate((states, actions), axis=1)\n",
    "            # policy_net(state_action) will return a single value estimate for each state/action row\n",
    "            # so, probably shape (1,n)\n",
    "            # Then return the index which has the max value\n",
    "            \n",
    "            estimate = policy_net(torch.tensor(state_actions, device=device, dtype=torch.float))\n",
    "            #print(f'ESTIMATE>>>{estimate.__class__} {estimate.shape} {estimate} {estimate.max(0).indices.item()}<<<')\n",
    "            return estimate.max(0).indices.item()\n",
    "    else:\n",
    "        randindex = random.randrange(len(actions))\n",
    "        print(f'returning random index {randindex}')\n",
    "        return randindex #torch.tensor([[randindex]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c62073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "env = Env(df)\n",
    "num_episodes = 50\n",
    "print(env.target)\n",
    "starting_actions = env.construct_actions()\n",
    "starting_state = env.construct_state()\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "\n",
    "    state = starting_state\n",
    "    actions = starting_actions\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        #print(state, actions)\n",
    "        action_idx = select_action(state, actions)\n",
    "        print(f'action {action_idx}')\n",
    "        next_state, reward, done, next_actions = env.step_by_index(action_idx)\n",
    "        print(f'reward {reward}')\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, actions[action_idx], reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "        actions = next_actions\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe362b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
